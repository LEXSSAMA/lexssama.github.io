{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"themes/fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":0,"renderable":1},{"_id":"themes/fluid/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/default.png","path":"img/default.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/loading.gif","path":"img/loading.gif","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/wallhaven-4xjllo.jpg","path":"img/wallhaven-4xjllo.jpg","modified":0,"renderable":1},{"_id":"themes/fluid/source/img/wallhaven-j5l9gw.jpg","path":"img/wallhaven-j5l9gw.jpg","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/boot.js","path":"js/boot.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/debouncer.js","path":"js/debouncer.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/events.js","path":"js/events.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/lazyload.js","path":"js/lazyload.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/local-search.js","path":"js/local-search.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/plugins.js","path":"js/plugins.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/js/utils.js","path":"js/utils.js","modified":0,"renderable":1},{"_id":"themes/fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":0,"renderable":1},{"_id":"themes/fluid/source/lib/hint/hint.min.css","path":"lib/hint/hint.min.css","modified":0,"renderable":1},{"_id":"source/Picture/Application-layer.png","path":"Picture/Application-layer.png","modified":0,"renderable":0},{"_id":"source/Picture/Bash-Shell.jpg","path":"Picture/Bash-Shell.jpg","modified":0,"renderable":0},{"_id":"source/Picture/C++log.jpg","path":"Picture/C++log.jpg","modified":0,"renderable":0},{"_id":"source/Picture/Dynamic-programming.jpeg","path":"Picture/Dynamic-programming.jpeg","modified":0,"renderable":0},{"_id":"source/Picture/EFLAGS.jpg","path":"Picture/EFLAGS.jpg","modified":0,"renderable":0},{"_id":"source/Picture/Http.png","path":"Picture/Http.png","modified":0,"renderable":0},{"_id":"source/Picture/KMP.jpg","path":"Picture/KMP.jpg","modified":0,"renderable":0},{"_id":"source/Picture/Manjaro.png","path":"Picture/Manjaro.png","modified":0,"renderable":0},{"_id":"source/Picture/N_Queens.jpg","path":"Picture/N_Queens.jpg","modified":0,"renderable":0},{"_id":"source/Picture/PA.png","path":"Picture/PA.png","modified":0,"renderable":0},{"_id":"source/Picture/Question-Mark.jpg","path":"Picture/Question-Mark.jpg","modified":0,"renderable":0},{"_id":"source/Picture/Spring-Cloud-Eureka.png","path":"Picture/Spring-Cloud-Eureka.png","modified":0,"renderable":0},{"_id":"source/Picture/TCP-UDP.png","path":"Picture/TCP-UDP.png","modified":0,"renderable":0},{"_id":"source/Picture/The-Network-Core.png","path":"Picture/The-Network-Core.png","modified":0,"renderable":0},{"_id":"source/Picture/The-Network-Edge.png","path":"Picture/The-Network-Edge.png","modified":0,"renderable":0},{"_id":"source/Picture/Vim.jpg","path":"Picture/Vim.jpg","modified":0,"renderable":0},{"_id":"source/Picture/abandon.jpg","path":"Picture/abandon.jpg","modified":0,"renderable":0},{"_id":"source/Picture/ipv4-ipv6.jpg","path":"Picture/ipv4-ipv6.jpg","modified":0,"renderable":0},{"_id":"source/Picture/line.png","path":"Picture/line.png","modified":0,"renderable":0},{"_id":"source/Picture/point.png","path":"Picture/point.png","modified":0,"renderable":0},{"_id":"source/Picture/process.png","path":"Picture/process.png","modified":0,"renderable":0},{"_id":"source/Picture/python.png","path":"Picture/python.png","modified":0,"renderable":0},{"_id":"source/Picture/spring-cloud-hystrix.png","path":"Picture/spring-cloud-hystrix.png","modified":0,"renderable":0},{"_id":"source/Picture/stack.png","path":"Picture/stack.png","modified":0,"renderable":0},{"_id":"source/Picture/wallhaven-q6q2e5.jpg","path":"Picture/wallhaven-q6q2e5.jpg","modified":0,"renderable":0}],"Cache":[{"_id":"source/Picture/Application-layer.png","hash":"f58f5e67015024b746c83855a1d3a91f674ecc12","modified":1605364836584},{"_id":"source/Picture/Dynamic-programming.jpeg","hash":"e5b666cc1bc6bf19af223c3cd6634441ff0432a0","modified":1605368324989},{"_id":"source/Picture/Bash-Shell.jpg","hash":"3cc683c7802c41d3e6b6c6b2b7f23ea2fec4ba50","modified":1605364836584},{"_id":"source/Picture/C++log.jpg","hash":"60b8cec738391869c1703fe6f48408ffd909f0db","modified":1606577569490},{"_id":"source/Picture/Manjaro.png","hash":"d9dca1f1f0cb88b8db7dc1c80eb76105bb33b7de","modified":1605364836584},{"_id":"source/Picture/Http.png","hash":"ce136e450627b96e986af679ad6cf589903d8783","modified":1605364836584},{"_id":"source/Picture/PA.png","hash":"694bd33ae9b4cdcd8e8f0c1b7ed24357791db2f5","modified":1608303076378},{"_id":"source/Picture/N_Queens.jpg","hash":"1127f10212202678419450b6865f88f28aad0ebf","modified":1605367163843},{"_id":"source/Picture/KMP.jpg","hash":"212668f98b0d6e99182b6f89d5bcc01f878c1471","modified":1605364836584},{"_id":"source/Picture/Question-Mark.jpg","hash":"4abb555d1a812e2f9eab3cb22342680b387e3e75","modified":1605364836584},{"_id":"source/Picture/The-Network-Core.png","hash":"dc0b96014728f831ef8c6ee22cf9dc09bba4039f","modified":1605364836584},{"_id":"source/Picture/The-Network-Edge.png","hash":"75dec0280e924152e5dfc4173d5e5b5f1e5fbad1","modified":1605364836584},{"_id":"source/Picture/line.png","hash":"87af42c90ae31c0a3c8aaca4f4ebabe1f4a96b75","modified":1605364836584},{"_id":"source/Picture/Vim.jpg","hash":"aa477cb7d2974e09b642028102b0835cca0f72cf","modified":1605364836584},{"_id":"source/Picture/point.png","hash":"94a1c6a220155f364c31faa57bced474771d2fd0","modified":1605364836584},{"_id":"source/Picture/process.png","hash":"154c7a334bec85f63857285fe6645db0cd273159","modified":1605366223486},{"_id":"source/Picture/stack.png","hash":"9c7c737acd5217ff48dc3d3de7c2b154c9d58071","modified":1605364836584},{"_id":"source/Picture/abandon.jpg","hash":"8181dd75ff8895fcd00cc56fe5f691b7133150e4","modified":1605364836584},{"_id":"source/about/index.md","hash":"a18e4531d95a4cfcb4409f093786ede399f8b514","modified":1605364836616},{"_id":"source/categories/index.md","hash":"3c326a71109d57615d2fd4d58106dd337469c853","modified":1605364836616},{"_id":"source/tags/index.md","hash":"643c8e4492cd30e78f35fe588fdd190d8efd2b49","modified":1605364836616},{"_id":"source/_posts/.Chapter1-Review-Questions.md.swn","hash":"b535b0daa9403bc11846a9edb8abbd7fb82b2cc7","modified":1605364836588},{"_id":"source/Picture/spring-cloud-hystrix.png","hash":"bf54e23639483dae367f299e66989277c5670611","modified":1605364836584},{"_id":"source/_posts/.Chapter1-Review-Questions.md.swo","hash":"0005532b96df1549ea5fe3168412cba09d6d3396","modified":1605364836588},{"_id":"source/_posts/.Chapter1-Review-Questions.md.swp","hash":"2c66e71ab4e92f69d9db284a4d20fc7744166a8c","modified":1605364836588},{"_id":"source/_posts/.Green-Chemistry.md.swn","hash":"e3ede1c1e7a28c7ab0bafc6341b5d164ed12124a","modified":1605364836588},{"_id":"source/_posts/.Green-Chemistry.md.swo","hash":"20be2d931fb9baba2cabe7da0fd0e281218f7c7c","modified":1605364836588},{"_id":"source/_posts/.KMP算法.md.swo","hash":"d62e1f7a843d90f848a03df3ad5f73ef8f0b0178","modified":1605364836588},{"_id":"source/_posts/.Green-Chemistry.md.swp","hash":"0d225c01efe3e65ef856f5af23953e1647e2ea84","modified":1605364836588},{"_id":"source/_posts/.chapter2-Homework-problems-and-Questions.md.swn","hash":"0f4d784eaaa7bf6c219419c7e1830661d3baae9d","modified":1605364836588},{"_id":"source/_posts/.KMP算法.md.swp","hash":"751842a7b2f1edb38203afba568276b168163f16","modified":1605364836588},{"_id":"source/_posts/.chapter2-Homework-problems-and-Questions.md.swo","hash":"c05fac82663e5265bd98241be690d72edacd93b1","modified":1605364836588},{"_id":"source/_posts/.二元组和图形描述逻辑结构.md.swo","hash":"3ac52495cbf910ee34302dd423522ba5b116a410","modified":1605364836588},{"_id":"source/_posts/.计算机网络自顶向下有意思的单词.md.swl","hash":"20f4d4ff08d1642904f93b5b3e9f75b5cb731cbd","modified":1605364836588},{"_id":"source/_posts/.二元组和图形描述逻辑结构.md.swp","hash":"1e584db0cdd077bc30788aa8fdc9d4d92c4eab56","modified":1605364836588},{"_id":"source/_posts/.计算机网络自顶向下有意思的单词.md.swm","hash":"c1c5dfb3e11501deb288f55efb4994071d6dc403","modified":1605364836588},{"_id":"source/_posts/.chapter2-Homework-problems-and-Questions.md.swp","hash":"c9cda07781c0dd5fc3ea9d7b4727fdc15f1e7859","modified":1605364836588},{"_id":"source/_posts/.计算机网络自顶向下有意思的单词.md.swp","hash":"6bd324900e5be8148b24b57f0a07ad2f52c19115","modified":1605364836588},{"_id":"source/_posts/.计算机网络自顶向下有意思的单词.md.swo","hash":"d20175af051abb88885dc99cc1951426ea30ad33","modified":1605364836588},{"_id":"source/_posts/.计算机网络自顶向下有意思的单词.md.swn","hash":"23d8fd45f0586318c5aef4d525c284e676d47c69","modified":1605364836588},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions.md","hash":"b2364994375544ef016cd755d12095d93b32fc3e","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer.md","hash":"3ffc9bd9cd2bd5fc2d95e4f6fd98b9a46a6d732d","modified":1605364836588},{"_id":"source/_posts/Chapter1-Review-Questions.md","hash":"3956140f04a5740d9ca307700779292a334419a3","modified":1605364836592},{"_id":"source/_posts/52-N-Queens-II.md","hash":"343748eb7208613a45a056ad9db3b88b491f0b06","modified":1605369747774},{"_id":"source/_posts/KMP算法.md","hash":"ec8d120abdaa92eff61cf4815ee847d1c240f0a7","modified":1605364836608},{"_id":"source/_posts/Chapter3-Transport-Layer.md","hash":"70a5e679f832b90b35307e9e81859288909c8f71","modified":1605364836596},{"_id":"source/_posts/377-Combination-Sum-IV.md","hash":"9bcba79f521d23ef66ed2bbcbbbacbd25e30d52f","modified":1605368462465},{"_id":"source/_posts/PA2实验报告.md","hash":"223b721966a5006b1b5cce84fe7304ea60a02c08","modified":1608351061481},{"_id":"source/_posts/Shell入门学习.md","hash":"ab26faf6a4e35ebfcae402ff4fbdb73ee2fd888b","modified":1605364836612},{"_id":"source/_posts/Spring-Cloud-Eureka-初入门.md","hash":"fff8a33a9d0c21c07982d0ca3649ac2331a5016c","modified":1605364836612},{"_id":"source/_posts/The-Network-Core.md","hash":"faa8aa93f756a5ef69f12ca16278e12386dfdf2c","modified":1605364836612},{"_id":"source/_posts/VIM指令学习.md","hash":"44cb70967b17f221deac4c592cebe3fee8243a64","modified":1605364836616},{"_id":"source/_posts/The Network Edge.md","hash":"8856570e87b470c540a3f36cde3aceac0a5691fe","modified":1605364836612},{"_id":"source/_posts/Manjaro-System-configuran.md","hash":"e450241207103d13ee07a0afa5723ad182808632","modified":1605364836608},{"_id":"source/_posts/chapter2-Homework-problems-and-Questions.md","hash":"2e25a27bff10fe37d6b54620f8610345293c5522","modified":1605364836616},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions.md","hash":"2fbe533334987c622ae72373f6db241f6df6040b","modified":1605364836616},{"_id":"source/_posts/二元组和图形描述逻辑结构.md","hash":"1b0705d57b20b182194610201225d9397da5e0ee","modified":1605364836616},{"_id":"source/_posts/关于汇编中EFLAGS寄存器中CF和OF标志位.md","hash":"e227eeb09715e4044a5c970898d86530a1611884","modified":1605418321456},{"_id":"source/_posts/关于进程Process的一篇写的很好的文章.md","hash":"e1d53b38820b91229cfb31f416250b32cf39d3c4","modified":1605367090537},{"_id":"source/_posts/对于指针的一些理解.md","hash":"bfb5d142dbc4b6d13179f4162c5364f49ed446b5","modified":1605364836616},{"_id":"source/_posts/process-switch-base-on-stack-switch.md","hash":"b99e02187b21692484b7026c583156d52e229540","modified":1605364836616},{"_id":"source/_posts/有符号数右移32位.md","hash":"58a6bc65be6af6406502b69ab8417f8a8160a3d3","modified":1606577592769},{"_id":"source/_posts/面试题35-复杂链表的复制.md","hash":"56aa25c8b90e4791cae471a4898223b48ae25799","modified":1605364836616},{"_id":"source/_posts/计算机网络自顶向下有意思的单词.md","hash":"418735445f899128d2c334a4662479c68fcfcf84","modified":1605364836616},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-hierarchy.png","hash":"42a12903e3d39a3a2b9e044b13c706e6fd2f92cb","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/FTP-TCP-connections.png","hash":"252cb698e648fa97962cc30bb61a0c77397aed10","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/HTTP_requires.png","hash":"f6e0958bdc612ae8c3b1a9c5b4820ae2b297f821","modified":1605364836592},{"_id":"source/_posts/Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png","hash":"deb042f942d24973f703211cc7cc2f40730a0309","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Congestion-window-size-changes-along-with-time.png","hash":"a927f2256fc9c03d6d985dcb3a92e6701568bb03","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-3-performance.png","hash":"687c84fce6ef8a851f4206b7b914d4ee62362a10","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Sender's-view-of-sequence-numbers-in-the-Go-Back-N.png","hash":"58c8a6038965c118865a17441ffb4805f52b6862","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-Segment-structure.png","hash":"b026b949cfe4cc1b85fb4d0ebcb5bf02fdd418b5","modified":1605364836600},{"_id":"source/_posts/KMP算法/BL1.png","hash":"2b717e623b919cbb201eddb40b32840d6f901aca","modified":1605364836608},{"_id":"source/_posts/KMP算法/BL2.png","hash":"83a552022e33adfc9c1218b6d2fe0bc34d710685","modified":1605364836608},{"_id":"source/_posts/KMP算法/BL3.png","hash":"61af65ffa974557fcba929dfc9edb790f112db4e","modified":1605364836608},{"_id":"source/_posts/KMP算法/BL4.png","hash":"36d27adf1022d9b9260cd30fdbbcab6382cedfa0","modified":1605364836608},{"_id":"source/_posts/KMP算法/BL5.png","hash":"5c9fed7e60504c6b3af6cfaa69a7d73412760eee","modified":1605364836608},{"_id":"source/_posts/KMP算法/BL6.png","hash":"ef78b584d26d386c06d5dc2e442f8294c1ca2c83","modified":1605364836608},{"_id":"source/_posts/KMP算法/KMP举例1.png","hash":"5c9fed7e60504c6b3af6cfaa69a7d73412760eee","modified":1605364836608},{"_id":"source/_posts/KMP算法/KMP举例2.png","hash":"25629e5d00bf0c3c6cccba409e12b293e9f4fd5f","modified":1605364836608},{"_id":"source/_posts/KMP算法/next1.png","hash":"8d971b1dfdfa57c25a8dff2132764736f0ffb4b9","modified":1605364836608},{"_id":"source/_posts/KMP算法/next2.png","hash":"aaebd238b3687ea1bb2e601735a9577ba3273cde","modified":1605364836608},{"_id":"source/_posts/KMP算法/next3.png","hash":"82c055640e2a6a172e0b411fcba0995d61688f4f","modified":1605364836608},{"_id":"source/_posts/KMP算法/next4.png","hash":"ca0c56c1475d908450db220a2544c7b8e7616193","modified":1605364836608},{"_id":"source/_posts/KMP算法/next5.png","hash":"7f238da8d349be91bdf73dc4e7be0ecc4761a929","modified":1605364836608},{"_id":"source/_posts/KMP算法/next6.png","hash":"ba318af8eb51e8ce79efe32f0b330015d42784ae","modified":1605364836608},{"_id":"source/_posts/KMP算法/证明1.png","hash":"2c6b062b9be55192d2dd27c5163c671c690c74db","modified":1605364836608},{"_id":"source/_posts/KMP算法/证明2.png","hash":"d985c91f822ecd15385304a93ce1071d1cbfb6dc","modified":1605364836608},{"_id":"source/_posts/KMP算法/证明3.png","hash":"524b5a24822aca584eeaef32bf489b8ea3168abd","modified":1605364836608},{"_id":"source/_posts/KMP算法/证明１.png","hash":"2c6b062b9be55192d2dd27c5163c671c690c74db","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/ASs-connection-graph-RIP.png","hash":"caa97664c133afc969bad44f2cf473f0a4f52837","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/Advertisement-From-RouterA.png","hash":"18c52a90d11075a66b979780dc23b44f8e5af74e","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/General-en.svg.png","hash":"4ebd7813a10efe70a1dc0dddc1233a6853b2264a","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/IPv6-Datagram-Format.png","hash":"ddf9643de2927b4e6ca819779f76c244857bfcbe","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Input-Port-Processing.png","hash":"5991122162188bc2ddea80bc9e9d244d9980ec8d","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Output-Port-Processing.png","hash":"4846b4ea1c107e7d09cb5f8284f30b4487f8ca43","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Result-Of-LS-Algorithm.png","hash":"e04b5201ba9705dcef71c5f49e9b8e753f717aa0","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png","hash":"0e38e05a3abcf662556543745150b1e222d1f0da","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png","hash":"da9cf48e46437359f6020ce2d58b988260491e86","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Simple-VC-Path.png","hash":"312efab0e1835d5900d518f44ef0147eec4de4aa","modified":1605364836608},{"_id":"source/_posts/Manjaro-System-configuran/albert.png","hash":"f0be5751f68228c8de53332d6ef4014a5933def0","modified":1605364836608},{"_id":"source/_posts/Manjaro-System-configuran/albert2.png","hash":"e0e21f9b5d55cfb1c190575bcbac954d879dd1c2","modified":1605364836608},{"_id":"source/_posts/Spring-Cloud-Eureka-初入门/eureka-architecture.png","hash":"905633dc622d108f97efeb6ae5472192543933a0","modified":1605364836612},{"_id":"source/_posts/The Network Edge/2020-02-27 21-43-25 的屏幕截图.png","hash":"9d38f1fb610151e1694998f44a2a7a1cb5471052","modified":1605364836612},{"_id":"source/_posts/The Network Edge/2020-02-27 23-49-06 的屏幕截图.png","hash":"5925781f6c8256f1973baa633e5c40d4dcf5f9e4","modified":1605364836612},{"_id":"source/_posts/The Network Edge/2020-02-28 00-21-20 的屏幕截图.png","hash":"7184f370210cd64c915cecb348ee9fb75d7a00d0","modified":1605364836612},{"_id":"source/_posts/The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png","hash":"be331f4399fabfab5e075c0b868a289c3946c5b0","modified":1605364836612},{"_id":"source/_posts/process-switch-base-on-stack-switch/wm.png","hash":"638878e7a7e042fd3db6a42fdb4ce52c6ceb5b08","modified":1605364836616},{"_id":"source/_posts/process-switch-base-on-stack-switch/wm1.png","hash":"98e8f274066bee2e2916f09aac57d2652aff34d9","modified":1605364836616},{"_id":"source/_posts/process-switch-base-on-stack-switch/wm2.png","hash":"64fa8056049496709460781c80064e582b8bf197","modified":1605364836616},{"_id":"source/_posts/二元组和图形描述逻辑结构/870358-20160102224630526-1483051229.jpg","hash":"3ae5895250c4d823e1f534add6121f43cab45dd4","modified":1605364836616},{"_id":"source/_posts/面试题35-复杂链表的复制/优化迭代法-图解.png","hash":"9f7f80d3726ee0c7d3545ff6e024bfc60b696768","modified":1605364836616},{"_id":"source/Picture/EFLAGS.jpg","hash":"ebb02e2490c960bb4694151d0eae766ce619b1eb","modified":1605418283881},{"_id":"source/Picture/Spring-Cloud-Eureka.png","hash":"34fcddce95b02811a595861ad1f6d8cbb2917000","modified":1605364836584},{"_id":"source/Picture/TCP-UDP.png","hash":"d947faddccb8d479e3835c92889cabb93d9cdca7","modified":1605364836584},{"_id":"source/Picture/ipv4-ipv6.jpg","hash":"1ea75d97153561f416a62deda6ee3b901ce84269","modified":1605364836584},{"_id":"source/Picture/python.png","hash":"c8a756475599e6e3c904b24077b4b0a31983752c","modified":1605364836584},{"_id":"source/_posts/Chapter4-The-Network-Layer.md","hash":"cc433a3548f21162f7018b99e129c50b24314752","modified":1605364836600},{"_id":"source/_posts/377-Combination-Sum-IV/377-Combination-Sum-IV-1.png","hash":"247881e5b2415a27ec812d15cc83a617721ac2f4","modified":1605368371577},{"_id":"source/_posts/Chapter-2-Application-Layer/Circle-DHT.png","hash":"c6e117b73e6bd8d33f4a2cfdb8a8ee42594b20f9","modified":1605364836588},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-server-iterative-queries.png","hash":"ff508b4fddadf4b9944d85909dd02f257011894f","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-Messages.png","hash":"33ef94dd425980207afb851affd54ff9c44accad","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-server-recursive-queries.png","hash":"5945685e357357956026553710a0dfbcc2d687d3","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/FTP-transfer-file.png","hash":"9fb625f989e5645c08d5f070b0c6a2da9e0deaa8","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/SMTP-access-mail.png","hash":"a5c16aba386cd4b905fded39be4025366efa358e","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/SMTP-transfer.png","hash":"6c30ed78de2fe0ba6b3847dca2b707af6c35a75d","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/HTTP_respont.png","hash":"73a8f21fad2d35d0ef066953bedbfae81d9ef675","modified":1605364836592},{"_id":"source/_posts/Chapter-2-Application-Layer/Web-cache.png","hash":"e3945cf4e5f53a0f964e4230d2bd519ad12bb799","modified":1605364836592},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-10_15:03_select.png","hash":"7d35955d8e2468af65b41f9a4b379f00768f9fbc","modified":1605364836592},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-09_21:03_select.png","hash":"029a01fc4db75f25cb54b846855045b2bca9d8b1","modified":1605364836592},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-11_09:03_select.png","hash":"8eb71e4ec804ce499501a7444fc65300ba18a47a","modified":1605364836592},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-11_14:03:1583906551_select.png","hash":"61a9ff664fccb4046058480994c83cac3916e6a6","modified":1605364836592},{"_id":"source/_posts/Chapter3-Transport-Layer/Code-snippet-of-fast-retransmit.png","hash":"9d8e65b75b62edeaa1393ad0fbf7bdfee7d013b4","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/GBN's-FSM-receiver.png","hash":"d2a5aab41b25fe9a5c6ccd3764fe434533849ba0","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/GBN-in-operation.png","hash":"d3907f90800f035c155a9938bd41060acb34307e","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/RTT-sample-and-RTT-estimates.png","hash":"fac4bf5ef8ad97ba9912fac81f3f79e6f18c5539","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Reliable-data-tranfer.png","hash":"811aae7247800c205766d425192febef766233f8","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-2-performance.png","hash":"a5c5970c787319fea747da568b85a4f59c2ffa05","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png","hash":"5ecace31ff5737a59de7178c94ed24e0f7906913","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Slow-Start.png","hash":"6c8a2897f798a585fbad4abb1cdf8a3efee28f97","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/Stop-and-wait-versus-pipelined-protocol.png","hash":"5cd506798700b1bb8a81f4907f1419db20e1446d","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-RcvBuffer.png","hash":"0e2a807be30bb5fd3551bd06d971dfa109dce630","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-1.png","hash":"920ada7a47319c59b41d03ae8b89ddcc1c684896","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-2.png","hash":"64f50ff8887336b4dd7c607aa926e11d5fc821ce","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection.png","hash":"e2147af3bb4c149ebb9705a8482aef45e568391e","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-3.png","hash":"dc6e6eb91cffd598dd1c93183bb75a7a82e9de9b","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-4.png","hash":"f830b262c5c0f7785926f9efd5dc67a8061cf87e","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-sender-and-receiver-buffer.png","hash":"340fe4b10c3dba341cc63c056148b616b5725819","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/Two-feedback-way.png","hash":"425045cc7d36463c3a193eaa76548a6fbcdd19ba","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt1.0-finite-state-machine.png","hash":"493a6bda7571f6e64135cad420440af9add47b52","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.0-A-protocol.png","hash":"7159fe1f6d4e76ec4351af0daa4c8f8a64661d7f","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/A-Dual-Stack-Approachs.png","hash":"bd521972165b2f433685531687452dfd1b433d46","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/A-Look-Inside-The-Internet-Network-Layer.png","hash":"7d5bb647a78adecbf6308e993404e2ef2eb27dcb","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/BGP-sessions.png","hash":"977712a0b46316c7c073e895b673ce693d413108","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/Changes-in-link-cost.png","hash":"0504e6c3e30159083f128f3e1372574c0f46e6e8","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/DHCP-Client-Server-Interaction.png","hash":"0b4138b08e07e05b65a1a025f918e44dc8386b56","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/SR-receiver-dilemma-a.png","hash":"529e40b8845f99a4107f0c4da3c054b4cb9ae79d","modified":1605364836596},{"_id":"source/_posts/Chapter4-The-Network-Layer/DV-Simple-Example.png","hash":"330b1c13edc4e566c8922cfffb2e157150172dce","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Datagram-Forwarding-Table.png","hash":"a134ce54b8516e464272e2fdb0d10a1c285ab096","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Graph-Of-Link-State-Algorithm.png","hash":"61046bcc5d7044959b6ea08e4ccae6dff1ff31b2","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/HOL-Block-At-An-Input-Queued-Switch.png","hash":"86d80079c34f65f2fb67813f644534df37c378a6","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/ICMP-Message-Types.png","hash":"5bc1c246d08e18ea0a916cfe460f3205bf147c3c","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Internet-ATM.png","hash":"ced4074d0d27ba0530930cd78260280513aa36f7","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Ip-fragments.png","hash":"9ac0677e296e5bb664d6776567f54c6539799f4f","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Ipv4-Datagram-Format.png","hash":"dc6b9f08ef7b6a05040c985440c32f64255639ec","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Organization-Address.png","hash":"2cc0e0d31f512ec75760c8eca15934f835f95917","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Output-Port-Queueing.png","hash":"274bb70e8eab99fbb5355a0364713ee56d35c717","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/RIP-UDP-Application.png","hash":"61b211057b3cc3ef937313819f6caecaea75ed1e","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/RPF.png","hash":"a91450b1babaaad2703bfc1ad7ccc98fecf7066d","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Router-Architecture.png","hash":"633ed6c6dadf1b6dfdc1ea4d5aeb340ca3660ecd","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Simple-Virtual-Circult-Network.png","hash":"b262d40185fd5c21719bba1705335e0048fe1c40","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Source-duplication-In-network-duplication.png","hash":"aa1ca07b68333484ca4dd9377cb1135983bc9870","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Three-Switching-Techniques.png","hash":"2342f3110eaebdc6710d3941b7a519a5b4effb1d","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/hot-potato-algorithm.png","hash":"bbed2c516d9b04e7b1d1366e15c9a77ed754deae","modified":1605364836608},{"_id":"source/_posts/Manjaro-System-configuran/albert1.png","hash":"0e537ac67bbdad04ef4991be82f8ca1eafca905a","modified":1605364836608},{"_id":"source/_posts/The Network Edge/2020-02-27 20-56-20 的屏幕截图.png","hash":"fe83d13f0afd360ab73b2b11393f4a157849b7d0","modified":1605364836612},{"_id":"source/_posts/chapter2-Homework-problems-and-Questions/Messagesheader.png","hash":"0f63cb9e3940a193b76abb0ccc6aaf2d2151b227","modified":1605364836616},{"_id":"source/_posts/chapter2-Homework-problems-and-Questions/TCP-handshake.png","hash":"d1523e522887c310224a3fcee9509bbfb11f3c57","modified":1605364836616},{"_id":"source/_posts/377-Combination-Sum-IV/377-Combination-Sum-IV-2.png","hash":"1b5aa8eb2c66af27bdd0e05cc3297bd0aa4d92e6","modified":1605368384537},{"_id":"source/_posts/Chapter-2-Application-Layer/Cookie-process.png","hash":"59c97f34e53e93cec60a6d5db7c5023e6be7b22f","modified":1605364836592},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-11_20:03:1583929611_select.png","hash":"98b54dc874094e9fa526b6b5906600e9e6b8640c","modified":1605364836592},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/6.png","hash":"e92ddb67987a09d7c12ac0dc0d1d4fda7b0b5659","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/GBN's-FSM-description-senderi.png","hash":"e0d7c41a29c3e120602a30771b3ddf33b2576834","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-2-two-hosts.png","hash":"4c495d65b394107490b0343b3cb62c3e10afe60b","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/SR-receiver-dilemma-b.png","hash":"80276eea87b99956da8928206abf60f83889b830","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/SR-operation.png","hash":"deb2554c76df1f7108f6fcc4b6576e12126720b0","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.1-receiver.png","hash":"9c67df8011e3f13113d122a52fcaf9acee39a8e3","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.1-sender.png","hash":"5db722914954360ee458cd6b018031a504a4c123","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.2-receiver.png","hash":"cb7dd27888081787c15560d81eef70a191c11727","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.2-sender.png","hash":"05506207516b417738b48b3fadab44971161a952","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt3.0-sender.png","hash":"cdd91be6facb428ffe5c572b3b6b63f3a2b176a6","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/IGMP-component.png","hash":"39ecb1ede9e2a85f1f4c7abeffbd80e891e895db","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/IP-fragmentation-and-reassembly.png","hash":"214c714520d2fa934494a83a2e997412ca1af546","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Oscillations-With-Congestion-Sensitive-Routing.png","hash":"af1a33890288a240fb47245fda19214d9a45cc0b","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/RPF-Multicast.png","hash":"c8bae968a1946431b2efe683a05ab4fdf0772378","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Routing-algorithm-determine-value-in-forwarding-tables.png","hash":"d1234ca0170ed09dbda5fe8d11a7065e2186ce27","modified":1605364836608},{"_id":"source/_posts/Chapter4-The-Network-Layer/Tunneling.png","hash":"0482eb7887d029685a360665a8f94f6a406e97dd","modified":1605364836608},{"_id":"source/_posts/The Network Edge/2020-02-27 14-34-38 的屏幕截图.png","hash":"727e5ec3f704610ebecf1fbba26dbb970b80d858","modified":1605364836612},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/6.png","hash":"4f0a62cc7b6b5b761b925061644e63fdb0acabfe","modified":1605364836616},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-Messagas-dig.png","hash":"680110053977f7d7e2d3a4129b6f97b2262d04c9","modified":1605364836592},{"_id":"source/_posts/Chapter3-Transport-Layer/Fast-retransmit.png","hash":"fb1426f1293b76caeae29020cecde109aded2447","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-3-Four-senders.png","hash":"7c1cb5a62fb66a2a88da4eb0a235453a286a0335","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/operation-of-rdt3.0-1.png","hash":"db72cdc5dffb1626b0681ad10ef8374c76435d6e","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/operation-of-rdt3.0-2.png","hash":"27e2f24eb171fe54cd6d3cb2825cf2faa3e1ed3f","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/Interface-Address-And-Subnets.png","hash":"dbb15c5abdabedd901ee65df575e5a80afa33a14","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Virtual-Circuit-Setup.png","hash":"db0649af8113844acc340ca2eb74fc0acf5a0ce3","modified":1605364836608},{"_id":"source/_posts/The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png","hash":"8a66dd9f6d28721e9b605bb2e40d139519881b94","modified":1605364836612},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/1.png","hash":"2109130b39b2bc7c7e4e0fc07952544df4230852","modified":1605364836616},{"_id":"source/_posts/Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png","hash":"cc97ce395c3c5fb92776a7695a93ca01ea5633a0","modified":1605364836596},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-ACK-Generation-Recommendation.png","hash":"fce1d92cbd9c3cdef438e9d8ccb3860896ff804d","modified":1605364836600},{"_id":"source/_posts/Chapter3-Transport-Layer/The-three-state-of-congestion-algorithm.png","hash":"3ed7c69518641c629437436cd9e020dc428f2f34","modified":1605364836600},{"_id":"source/_posts/Chapter4-The-Network-Layer/Datagram-Network.png","hash":"67753379961e5b0feb08f1caafa079035f0e5af1","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/Network-Address-Translation.png","hash":"f163622b9993e35e48a24b4fe1f7ca6272fe0703","modified":1605364836604},{"_id":"source/_posts/Chapter4-The-Network-Layer/autonomous-system-graph.png","hash":"0dcc92334ebaa8e62e83dc89bfb8a4d78f857b8e","modified":1605364836608},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/5.png","hash":"d346298da4989f6bf22737f960073e000bab6622","modified":1605364836616},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/7.png","hash":"13fb9b419f1cea2a167b96ec7f3d3aa2c7308544","modified":1605364836616},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/4.png","hash":"6fc55d79e7bff4fe6a744e8713db9583c3a6f4e1","modified":1605364836596},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/5.png","hash":"ef31c92358dcce48e12b19bb794c2f785b056604","modified":1605364836596},{"_id":"source/_posts/Chapter4-The-Network-Layer/DHCP-Client-Server-Scenario.png","hash":"a56dca8425a31935494f44a808098acd074ca0de","modified":1605364836604},{"_id":"source/_posts/对于指针的一些理解/指针.png","hash":"c0e8245567ad5fb4365f972cabc9975fd822ac67","modified":1605364836616},{"_id":"themes/fluid/source/css/_pages/_category/category.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1606897462000},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/4.png","hash":"8624d2c4740f3d91e435cb1292a098d51536fb15","modified":1605364836616},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/1.png","hash":"08cb14657cb4ee3a025d8e41ec5674cae282dbb2","modified":1605364836592},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/2.png","hash":"e2e1dc062feb8928303f07fae38c209245cf22d8","modified":1605364836592},{"_id":"themes/fluid/.editorconfig","hash":"33218fbd623feb43edf5f99f15965392cecc44a6","modified":1606897462000},{"_id":"themes/fluid/.eslintrc","hash":"4bc2b19ce2b8c4d242f97d4ccf2d741e68ab0097","modified":1606897462000},{"_id":"themes/fluid/.gitattributes","hash":"a54f902957d49356376b59287b894b1a3d7a003f","modified":1606897462000},{"_id":"themes/fluid/.gitignore","hash":"bd095eee271360a38772ee1a42d4f000fb722e5f","modified":1606897462000},{"_id":"themes/fluid/LICENSE","hash":"5b919c12e4f5f5cdebb7c17ded4f10f1ebe64811","modified":1606897462000},{"_id":"themes/fluid/README.md","hash":"ea55d234aeae3eb9e232f729f8411810d65c6f49","modified":1606897462000},{"_id":"themes/fluid/README_en.md","hash":"ca8fd19a4948de1f253616a62c0e8a7d81f692f5","modified":1606897462000},{"_id":"themes/fluid/gulpfile.js","hash":"dc82b6be72c786721a2f5e2acc10a2a94995c540","modified":1606897462000},{"_id":"themes/fluid/package.json","hash":"965e5c125090572b5a2ef04923f1c24ee34f68eb","modified":1606897462000},{"_id":"themes/fluid/languages/de.yml","hash":"13a6a799415fc2f6f69ebd1a399fb44426a5d641","modified":1606897462000},{"_id":"themes/fluid/languages/en.yml","hash":"a85dcc5cc21f9cab50df31e5001b8818ee62d1e2","modified":1606897462000},{"_id":"themes/fluid/languages/ja.yml","hash":"91020031a847c0361a6fd7ab990c7be4bf17529b","modified":1606897462000},{"_id":"themes/fluid/languages/zh-CN.yml","hash":"21307b4137c3d9b04bb58243747e75af0abc5a71","modified":1606897462000},{"_id":"themes/fluid/layout/404.ejs","hash":"689d9f4efd2a7f5edfd9b24561a7ade69d46617c","modified":1606897462000},{"_id":"themes/fluid/layout/about.ejs","hash":"e3e2de8b0dc63ece51c324bb7942f240cdbfc7bf","modified":1606897462000},{"_id":"themes/fluid/layout/archive.ejs","hash":"472d0813ca5b88000a7bc6039f33b7e27b5a3216","modified":1606897462000},{"_id":"themes/fluid/layout/categories.ejs","hash":"6c4ab9fcdf5f7b58238bf06276b027075872c424","modified":1606897462000},{"_id":"themes/fluid/layout/category.ejs","hash":"58291dfec65c36889dfce0ddc603540b67e4c598","modified":1606897462000},{"_id":"themes/fluid/layout/index.ejs","hash":"58e994d28fd72d585d2e4c63d0c0fd3e61dd14b8","modified":1606897462000},{"_id":"themes/fluid/layout/layout.ejs","hash":"d772721214358a658cfacaecb194d9c6db971488","modified":1606897462000},{"_id":"themes/fluid/layout/links.ejs","hash":"6abd180ff4dd1d5d22e4c70328e3c7f83d174d9c","modified":1606897462000},{"_id":"themes/fluid/layout/page.ejs","hash":"8cab50ead4cdb992d35710147a9a5308fb5df290","modified":1606897462000},{"_id":"themes/fluid/layout/tag.ejs","hash":"0ad89eb7c92a822980fa9a85285e6d94ad845d1d","modified":1606897462000},{"_id":"themes/fluid/layout/post.ejs","hash":"f334657509a9b8b4e05d425d3e5f47a1c21b7dd7","modified":1606897462000},{"_id":"themes/fluid/layout/tags.ejs","hash":"1d06af34b6cf1d8a20d2eb565e309326ceba309f","modified":1606897462000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"16d33eb89ecf90f4046720fde5395d972c7ba1fd","modified":1606897462000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"af977ed0792508bb0766ea8afe82d34ef1e8fb3c","modified":1606897462000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"c134dd57ffd269b93402ccfffe7dbe0f0b583bec","modified":1606897462000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"ed08574b196447376dd74411cca664ac9227a5d4","modified":1606897462000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question.md","hash":"ab5eab9e3ff889c4ba7fd82846e7f5b7ae15bebc","modified":1606897462000},{"_id":"themes/fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"e24b470f7aa8044499a4f5e39634e5dc43899011","modified":1606897462000},{"_id":"themes/fluid/.github/workflows/limit.yaml","hash":"f8bd2edeb4424ee7a055b31583445d5d5dff91a4","modified":1606897462000},{"_id":"themes/fluid/.github/workflows/lint.yaml","hash":"bccd7961fa146dd5f0d70f77e7ab94e9f58d5bd3","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/archive-list.ejs","hash":"8723aa57f61134a2c1dc84cc7ea88ea366f4fda3","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/beian.ejs","hash":"6ec30a9dd56341590af07f4227324f619025c109","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/css.ejs","hash":"dd71c9065bcf305188a03ae023cacaad67ec124e","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/footer.ejs","hash":"382bd3ee27bc6d90776fc9171a487ff208bc4caa","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/head.ejs","hash":"ab70ddfcf7b14c7000130d1a2b54c75dde106d66","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/nav.ejs","hash":"70490c67b7313ae305d39331238232fe62f094f1","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/paginator.ejs","hash":"783eee847562ce14db8f723b4ae742fb69aaf620","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/post-meta.ejs","hash":"3e0fa1731b6e54dbcf52ccf8e200e83dc4549bfa","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/scripts.ejs","hash":"2818548389e73197326e754e656657c4dee0e424","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/search.ejs","hash":"cdd7919fa01f6ef7ccc09938d662ff3d77f5d999","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/statistics.ejs","hash":"920bc618d357d48d2b96f8758f6ae8f9488fc4d8","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/toc.ejs","hash":"3d2fb5552f373e5a0c56bc356702d807bcbcb411","modified":1606897462000},{"_id":"themes/fluid/scripts/events/index.js","hash":"a6ab2c6d9f9ba58cd1fabb85c2817874246fd525","modified":1606897462000},{"_id":"themes/fluid/scripts/filters/locals.js","hash":"58d0fec976f6b1d35e7ea03edc45414088acf05c","modified":1606897462000},{"_id":"themes/fluid/scripts/filters/post-filter.js","hash":"fd567dccd9ea8c158a5dae6847dd99e272c3f43c","modified":1606897462000},{"_id":"themes/fluid/scripts/generators/local-search.js","hash":"fc2c50405b771b06b7f6cfc4e9de97b992691555","modified":1606897462000},{"_id":"themes/fluid/scripts/generators/pages.js","hash":"d9971f15fbb6b775e3d31a1b9b45011959395010","modified":1606897462000},{"_id":"themes/fluid/scripts/helpers/export-config.js","hash":"2ec0e2c79de89886c67391d5e94b0f18b2a6021e","modified":1606897462000},{"_id":"themes/fluid/scripts/helpers/page.js","hash":"4607607445233b3029ef20ed5e91de0da0a7f9c5","modified":1606897462000},{"_id":"themes/fluid/scripts/helpers/url.js","hash":"99ab4551dc9c035abcc3bf4da5def2f63449d7ec","modified":1606897462000},{"_id":"themes/fluid/scripts/helpers/utils.js","hash":"9045f47c7a71aab39f16cffb3e3847b752c2e0f1","modified":1606897462000},{"_id":"themes/fluid/scripts/helpers/wordcount.js","hash":"e58d422eddb44c1be893f65f79f4c7feecfe6d5f","modified":1606897462000},{"_id":"themes/fluid/scripts/tags/button.js","hash":"3eb43a8cdea0a64576ad6b31b4df6c2bf5698d4c","modified":1606897462000},{"_id":"themes/fluid/scripts/tags/checkbox.js","hash":"63468f7875c09d9557fe8315afc97175745d9087","modified":1606897462000},{"_id":"themes/fluid/scripts/tags/group-image.js","hash":"4aeebb797026f1df25646a5d69f7fde79b1bcd26","modified":1606897462000},{"_id":"themes/fluid/scripts/tags/label.js","hash":"f05a6d32cca79535b22907dc03edb9d3fa2d8176","modified":1606897462000},{"_id":"themes/fluid/scripts/tags/mermaid.js","hash":"75160561e1ef3603b6d2ad2938464ab1cb77fd38","modified":1606897462000},{"_id":"themes/fluid/scripts/tags/note.js","hash":"0886cfe3f8589671a1d289495e359c20a9908080","modified":1606897462000},{"_id":"themes/fluid/scripts/utils/join-path.js","hash":"629e7deb3955f750c1cfa6fc773f412e020fcef4","modified":1606897462000},{"_id":"themes/fluid/scripts/utils/object.js","hash":"61e9555f99edcb23d55361c7154e23af33153ecb","modified":1606897462000},{"_id":"themes/fluid/source/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1606897462000},{"_id":"themes/fluid/source/css/main.styl","hash":"d5a8a59c8d1fd17d699a951e59c4ce9ae44c419d","modified":1606897462000},{"_id":"themes/fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1606897462000},{"_id":"themes/fluid/source/img/favicon.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1606897462000},{"_id":"themes/fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1606897462000},{"_id":"themes/fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1606897462000},{"_id":"themes/fluid/source/img/wallhaven-4xjllo.jpg","hash":"877d3247e4d0628e28dc6bfa85da6e3ffd58ae49","modified":1608358003500},{"_id":"themes/fluid/source/js/boot.js","hash":"1aea6f229e2298c7c134e9f1cc94576cd3f30611","modified":1606897462000},{"_id":"themes/fluid/source/js/debouncer.js","hash":"045f324777bdfb99d4c17b1806169f029f897a65","modified":1606897462000},{"_id":"themes/fluid/source/js/events.js","hash":"9b3a3dfdbc64e6b367ae2ebf7700ed611ecd0d47","modified":1606897462000},{"_id":"themes/fluid/source/js/lazyload.js","hash":"0df461660bbd73a79f3125ba4e9bdbc856232e6b","modified":1606897462000},{"_id":"themes/fluid/source/js/leancloud.js","hash":"4701f49b3dc62939adff5cc11f6d21963df7f135","modified":1606897462000},{"_id":"themes/fluid/source/js/local-search.js","hash":"13d5ef2fe68c49bd6096781034dbb26c190b5176","modified":1606897462000},{"_id":"themes/fluid/source/js/plugins.js","hash":"e1fd90d773b3e8dfb075086f58787de21288d650","modified":1606897462000},{"_id":"themes/fluid/source/js/utils.js","hash":"3086cede8d6d96ac5f4b5236b06271599a1ebbcb","modified":1606897462000},{"_id":"themes/fluid/source/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/changyan.ejs","hash":"1b42e725454f3ae8d3bff086afcc294ca2fdeb72","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/disqus.ejs","hash":"335b52bfa1cdd671cec1c4d745216d8404b2df45","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/gitalk.ejs","hash":"3cd99f13535e444fff65c97a1f60e838aeaadba6","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/livere.ejs","hash":"593649f7e3f86779649e078b69f6fdc584648d72","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/remark42.ejs","hash":"eefda20a23a199ed0e268da7d2f81f35483aa8bf","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/twikoo.ejs","hash":"d7d689156a8d2a6b00b306bd30628fa961449135","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/utterances.ejs","hash":"71239ad210d24ad10a01c339590a797062153e8a","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/valine.ejs","hash":"899664e8eea0e77ffcff436a24198ee2da750d11","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/comments/waline.ejs","hash":"1c7d62572ef1722797c367d6cc62f8d0c5f29111","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/plugins/analytics.ejs","hash":"557077a8825fffc0a2c7fe2b29f319287950244f","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/plugins/local-search.ejs","hash":"1e9ed2dde3050b5a650d0e45b9f712a6279f8f0c","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/plugins/math.ejs","hash":"76c4e0608ae362a265ac5e9c0fc49f75c1bc568e","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/plugins/mermaid.ejs","hash":"10ed1f9a611449d37736e17c4e251127b38b3772","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/plugins/nprogress.ejs","hash":"19245797dda67bc97d534a5c3f283ff6dfa8a321","modified":1606897462000},{"_id":"themes/fluid/layout/_partial/plugins/typed.ejs","hash":"ab71df2e56b60e8e193ff827e81704e5b358a977","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/footnote.js","hash":"3b2abc5f5e3b681874637e98e047dc4969eb1983","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/hello.js","hash":"38f6953e430d452d6608dacc4895ca623b4844a5","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/highlight.js","hash":"723e3dc9421483dfdfccd618a83e53fb4c25d0ba","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/lazyload.js","hash":"309db8e7640142c1c50c7886a1fde302a655d3f2","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/merge-configs.js","hash":"2264bec80ba051a19ba80396618f3d0c22948f0b","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/preset-configs.js","hash":"fe76f86d3c187bba08a2ecfa8e97dae28b6b6dac","modified":1606897462000},{"_id":"themes/fluid/scripts/events/lib/version.js","hash":"0250fb16c7c798afd1f7fc816163ea0728765568","modified":1606897462000},{"_id":"themes/fluid/source/css/_functions/base.styl","hash":"2e46f3f4e2c9fe34c1ff1c598738fc7349ae8188","modified":1606897462000},{"_id":"themes/fluid/source/css/_mixins/base.styl","hash":"542e306ee9494e8a78e44d6d7d409605d94caeb3","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/pages.styl","hash":"b8e887bc7fb3b765a1f8ec9448eff8603a41984f","modified":1606897462000},{"_id":"themes/fluid/source/css/_variables/base.styl","hash":"11deab27c5e384b8fb565c249e597edebd0788bb","modified":1606897462000},{"_id":"themes/fluid/source/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_about/about.styl","hash":"15d2786d00418e61022475194ad76445d68e27ea","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_archive/archive.styl","hash":"6e6f22b664199772370b59ce1678b0c148b5849f","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/base.styl","hash":"aa2528e71c290dc43b69dfbdcf4d8d6c258015a4","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/color-schema.styl","hash":"f7004d597163e0af7b9107b0be1df12f4c0a7bc0","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/keyframes.styl","hash":"94065ea50f5bef7566d184f2422f6ac20866ba22","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/inline.styl","hash":"fab8441a0b8d8f9db6c8370013659c035345ae79","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_category/categories.styl","hash":"1ab7db37c2f7dc7ccdb994dcb41c16a4c8920397","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/rewrite.styl","hash":"28f26f5e05bc5bc1db798f0aac5c3cf93796f0b3","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_index/index.styl","hash":"4304bab8ad087911cbf5025a41014fbb67f20b5a","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_links/links.styl","hash":"cd4ebb1426abed9fda93b797b02c6d5dd71dc2a1","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_post/tag_plugin.styl","hash":"cbb49a17fcc030029f0c2fbe1e056613109d1ecc","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_post/post.styl","hash":"8c589796e3a8a0d5213a62c347aece80b0718935","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_tag/tags.styl","hash":"65bfc01c76abc927fa1a23bf2422892b0d566c3f","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/banner.styl","hash":"e3d4acfdf0647e89a7a88f53e754ea543641ae30","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/board.styl","hash":"32d90bcc8bf2fd5d8d78e86a567973d4b69bcfa1","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/copy-btn.styl","hash":"2c9e05a354d4be820646a1c99f814740f299ed37","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footer.styl","hash":"35539a1ce8476e75515015a06d01ec66e4af6834","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"ae9289cc89649af2042907f8a003303b987f3404","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/header.styl","hash":"7c8170d0e2de47570fe8ed523f10ee1c33138a9f","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"461d609a802a4f9aa9f492411ed8074813a956b7","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"ad41fe6e38a61856018021a8a9865f9fa1122bfc","modified":1606897462000},{"_id":"themes/fluid/source/css/_pages/_base/_widget/search.styl","hash":"10f7e91a91e681fb9fe46f9df7707b9ef78707c8","modified":1606897462000},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/3.png","hash":"e82d0f89e4558867af342098f64068d385eef5a3","modified":1605364836596},{"_id":"themes/fluid/_config.yml","hash":"18a2464dafc149c73814eff7d8705b6fcd33fa3b","modified":1608359402060},{"_id":"themes/fluid/source/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1606897462000},{"_id":"themes/fluid/source/js/color-schema.js","hash":"7d7444387e549e06a4a378706df92558de62e4e7","modified":1606897462000},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/3.png","hash":"7da3c2a7f27a5c24c44b0b0c3e6d76af3464128e","modified":1605364836616},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/2.png","hash":"1b211ba4d0828a58e1f62cc7ea1609111e174ca9","modified":1605364836616},{"_id":"source/Picture/wallhaven-q6q2e5.jpg","hash":"f452f76c5b178ad458392c3220bd4060109cd411","modified":1605364836588},{"_id":"themes/fluid/source/img/wallhaven-j5l9gw.jpg","hash":"145e4effe71ff8c6661c2f9a6445e7cd888e71a1","modified":1608357688414},{"_id":"source/_posts/Manjaro-System-configuran/manjaro_System_finish.png","hash":"72c0d0f7ead2b837166d2ca7fcdf6fd8003a2520","modified":1605364836612},{"_id":"public/local-search.xml","hash":"3c868ff121162ba4cc0d5924f0bb0314e3285ef4","modified":1608359136604},{"_id":"public/about/index.html","hash":"f0d70d3c0aa0ab8720a2c95607ed93f122ad0409","modified":1608359136604},{"_id":"public/tags/index.html","hash":"eef45233ba017fefd51b3091dc300a7b047240e4","modified":1608359136604},{"_id":"public/2020/11/28/有符号数右移32位/index.html","hash":"2256a3ae051094e3e3b88d1ec7724416873a3d0a","modified":1608359136604},{"_id":"public/2020/11/15/关于汇编中EFLAGS寄存器中CF和OF标志位/index.html","hash":"0b62f5abde1d6232ecccd19331fc06de4909a022","modified":1608359136604},{"_id":"public/2020/11/14/377-Combination-Sum-IV/index.html","hash":"d845321b46a559dd2ddc9b6025dd9d6569f89ade","modified":1608359136604},{"_id":"public/2020/11/14/关于进程Process的一篇写的很好的文章/index.html","hash":"c776392ca29656c1ed24a5e425d909dfa786a0e9","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/index.html","hash":"05d615e5516cca417125af237507c81689824436","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/index.html","hash":"cb830a2db8f488d0450d39f2de170042b656dd39","modified":1608359136604},{"_id":"public/2020/03/20/二元组和图形描述逻辑结构/index.html","hash":"51994af66be1c19ddc6d45219d8b43edbce7bb1d","modified":1608359136604},{"_id":"public/archives/index.html","hash":"06d0d7b870ac630267bbeea44e9502b21e9968b6","modified":1608359136604},{"_id":"public/archives/page/2/index.html","hash":"939113d4c0253e4506b1963dee039c1e396e59d6","modified":1608359136604},{"_id":"public/archives/page/3/index.html","hash":"0f00545030630bb872b2087762a6f87619bda1e3","modified":1608359136604},{"_id":"public/archives/2020/index.html","hash":"158126dffb3a990afabad2068064b2cf43b9718b","modified":1608359136604},{"_id":"public/archives/2020/page/2/index.html","hash":"ac4f640ef2f1aaa19f80302a80e2745c4b5fb9e7","modified":1608359136604},{"_id":"public/archives/2020/page/3/index.html","hash":"88a1de77199c27066792216b476b829409ab95e0","modified":1608359136604},{"_id":"public/archives/2020/02/index.html","hash":"a38162f9fbd19f09fff5105680f69829a339ff84","modified":1608359136604},{"_id":"public/archives/2020/03/index.html","hash":"b57befa44e3d87e6ddda7300a8195f3f1b01ae25","modified":1608359136604},{"_id":"public/archives/2020/04/index.html","hash":"9dbb95f04c08570b42eeb3db46cd858922be36e1","modified":1608359136604},{"_id":"public/archives/2020/05/index.html","hash":"ce61f48e1043478f54b140086374575859e3b850","modified":1608359136604},{"_id":"public/archives/2020/06/index.html","hash":"7bd99c68962cee514e09f5ba0cd24e0ad81cda5c","modified":1608359136604},{"_id":"public/archives/2020/11/index.html","hash":"cdfc619833cb570ce42b264efed787beec833d91","modified":1608359136604},{"_id":"public/archives/2020/12/index.html","hash":"91f2554a2e127d0158f50d97e3c2fc22106b745a","modified":1608359136604},{"_id":"public/categories/力扣/index.html","hash":"682b2c482654d5216eaf286d4c2ffc676bb628dd","modified":1608359136604},{"_id":"public/categories/Computer-Network-A-Top-Down-Approach/index.html","hash":"921fcf361a23bf9cc8d56362172459cf7e73d248","modified":1608359136604},{"_id":"public/categories/数据结构/index.html","hash":"46c55e45fcae1cc150eb4544e4116bfc331478ed","modified":1608359136604},{"_id":"public/categories/操作系统/index.html","hash":"7699cc48afcc76d3af32ebd6d1124973d27643e1","modified":1608359136604},{"_id":"public/categories/PA/index.html","hash":"eda03d4e1b2ce4067e5f67e4dca6a026a3b549d5","modified":1608359136604},{"_id":"public/categories/微服务学习/index.html","hash":"000cd1d0a95d351cbb4a8e96e1aba6c984502d39","modified":1608359136604},{"_id":"public/categories/vim/index.html","hash":"8b1c4933055ebb0f8879167261cc68a4d3631b80","modified":1608359136604},{"_id":"public/categories/计算机组成原理/index.html","hash":"6653b6504bd9f99fec0da1ae22ce71f6b72f7d9c","modified":1608359136604},{"_id":"public/categories/C-C/index.html","hash":"0071005d30eb314eb5185018fc925e6c69eb838e","modified":1608359136604},{"_id":"public/categories/操作系统/Shell/index.html","hash":"b29c8c4af6f4b9b3e3a903ac3d7a902e87d4149e","modified":1608359136604},{"_id":"public/tags/力扣/index.html","hash":"eac6552ffdbd5b49ad1f3d6745d7b2d40e3b3ffa","modified":1608359136604},{"_id":"public/tags/动态规划/index.html","hash":"c8c7cc10962c048ac312e1bcb05efd933416e503","modified":1608359136604},{"_id":"public/tags/Computer-Network-A-Top-Down-Approach/index.html","hash":"92a0e08228b9551b5463b25b06d0b138218af532","modified":1608359136604},{"_id":"public/tags/数据结构/index.html","hash":"90969933976116375c7128bdbe8d9bde37fc0a28","modified":1608359136604},{"_id":"public/tags/操作系统/index.html","hash":"e40175822068da8e3d0b00678d1099751e33d01f","modified":1608359136604},{"_id":"public/tags/PA/index.html","hash":"df756e812144376e6b49c704507bccdb8b08f13f","modified":1608359136604},{"_id":"public/tags/Shell/index.html","hash":"3b1003638a31297d03233337aa45a49ed35974fa","modified":1608359136604},{"_id":"public/tags/微服务学习/index.html","hash":"4b2c9334422b5762e11e2d02406d82e5f85967d7","modified":1608359136604},{"_id":"public/tags/vim/index.html","hash":"65458ccca8a20d35694246798ba12435f69b1af9","modified":1608359136604},{"_id":"public/tags/计算机组成原理/index.html","hash":"d0a83ac07dad61ea5d5cb7abd6e75c2a3f23de80","modified":1608359136604},{"_id":"public/tags/C-C/index.html","hash":"5397a506e392dbc700725710722b1f6342bd1d94","modified":1608359136604},{"_id":"public/tags/英语学习/index.html","hash":"f30834c5ace4fc735e9de05879de2d404ec88c19","modified":1608359136604},{"_id":"public/404.html","hash":"af6168dbbab44ae1a27d6fcac601b0013808a5fa","modified":1608359136604},{"_id":"public/links/index.html","hash":"f4ba7a9e281caaa4b5fa8da2a82e16eb4cfc4efd","modified":1608359136604},{"_id":"public/categories/index.html","hash":"72c4375d738d2db3aee5d96759ba94eae4ef39a9","modified":1608359136604},{"_id":"public/2020/12/18/PA2实验报告/index.html","hash":"d25755aac589fa049aa7650e4ac2369659b3fc6e","modified":1608359136604},{"_id":"public/2020/11/14/52-N-Queens-II/index.html","hash":"6b23f55efa75a00ea9eb4cb050692c534c0a446c","modified":1608359136604},{"_id":"public/2020/06/17/Spring-Cloud-Eureka-初入门/index.html","hash":"c2430b458d1ea8c34ec4f26ff3b8c0b2c1538abf","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/index.html","hash":"1dbc6f5dfd39deb5c8e5dab958cfc07af49304e2","modified":1608359136604},{"_id":"public/2020/04/27/面试题35-复杂链表的复制/index.html","hash":"1b7ce6b9765115d3bc5151aaad34a2e1415dab27","modified":1608359136604},{"_id":"public/2020/04/20/对于指针的一些理解/index.html","hash":"c0e842ac02b841c9245d043396f2f3ec77c85467","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/index.html","hash":"d68d06c8af7d57438fdfcc646851e91137ea6150","modified":1608359136604},{"_id":"public/2020/04/09/Shell入门学习/index.html","hash":"dfce95af3768af274aebf7525cce304b8307c3f4","modified":1608359136604},{"_id":"public/2020/04/03/Manjaro-System-configuran/index.html","hash":"4f192338d1d81b6e5162cc09d38aaad8434d644c","modified":1608359136604},{"_id":"public/2020/03/31/chapter2-Homework-problems-and-Questions/index.html","hash":"e703a49a2e6b7da0fa0fe7fd1bb9f28c56b01766","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/index.html","hash":"6e9484a15f0c2e269665dbb2ace2d3c1ffee1ea8","modified":1608359136604},{"_id":"public/2020/03/22/VIM指令学习/index.html","hash":"d915163183d337960c1888dc601d20334d41e0dc","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/index.html","hash":"ddc73eda5509fbbba4aaf0147bfe338e0535a690","modified":1608359136604},{"_id":"public/2020/03/09/Chapter1-Review-Questions/index.html","hash":"724816609adaa875c56f80b43782d395644dccf2","modified":1608359136604},{"_id":"public/2020/03/03/计算机网络自顶向下有意思的单词/index.html","hash":"a07759519e0bc06b9402ff75bbb27116f8eabaff","modified":1608359136604},{"_id":"public/2020/02/28/The-Network-Core/index.html","hash":"5351d61f8c4a76cad1688aeb4a7882f791162452","modified":1608359136604},{"_id":"public/2020/02/27/The Network Edge/index.html","hash":"41151bf1508ddfe9071de46b7a40759b93ace58c","modified":1608359136604},{"_id":"public/2020/02/16/process-switch-base-on-stack-switch/index.html","hash":"eb1d4a6b0db2fc54b5f7051931fbdb0b50902f0a","modified":1608359136604},{"_id":"public/index.html","hash":"b1926bf1010f4ff49a95ec69454519ae990e0450","modified":1608359136604},{"_id":"public/page/2/index.html","hash":"9d55bd540a40edf2c7519acab483175819cc527e","modified":1608359136604},{"_id":"public/page/3/index.html","hash":"c19413c77f811a1d154d85b5d65145f158f7834d","modified":1608359136604},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1608359136604},{"_id":"public/img/default.png","hash":"7bb2b8ee07db305bcadee2985b81b942027ae940","modified":1608359136604},{"_id":"public/img/favicon.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1608359136604},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1608359136604},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1608359136604},{"_id":"public/img/wallhaven-4xjllo.jpg","hash":"877d3247e4d0628e28dc6bfa85da6e3ffd58ae49","modified":1608359136604},{"_id":"public/xml/local-search.xml","hash":"8c96ba6a064705602ce28d096fd7dd9069630a55","modified":1608359136604},{"_id":"public/Picture/Application-layer.png","hash":"f58f5e67015024b746c83855a1d3a91f674ecc12","modified":1608359136604},{"_id":"public/Picture/C++log.jpg","hash":"60b8cec738391869c1703fe6f48408ffd909f0db","modified":1608359136604},{"_id":"public/Picture/Manjaro.png","hash":"d9dca1f1f0cb88b8db7dc1c80eb76105bb33b7de","modified":1608359136604},{"_id":"public/Picture/PA.png","hash":"694bd33ae9b4cdcd8e8f0c1b7ed24357791db2f5","modified":1608359136604},{"_id":"public/Picture/N_Queens.jpg","hash":"1127f10212202678419450b6865f88f28aad0ebf","modified":1608359136604},{"_id":"public/Picture/KMP.jpg","hash":"212668f98b0d6e99182b6f89d5bcc01f878c1471","modified":1608359136604},{"_id":"public/Picture/Question-Mark.jpg","hash":"4abb555d1a812e2f9eab3cb22342680b387e3e75","modified":1608359136604},{"_id":"public/Picture/The-Network-Core.png","hash":"dc0b96014728f831ef8c6ee22cf9dc09bba4039f","modified":1608359136604},{"_id":"public/Picture/line.png","hash":"87af42c90ae31c0a3c8aaca4f4ebabe1f4a96b75","modified":1608359136604},{"_id":"public/Picture/point.png","hash":"94a1c6a220155f364c31faa57bced474771d2fd0","modified":1608359136604},{"_id":"public/Picture/stack.png","hash":"9c7c737acd5217ff48dc3d3de7c2b154c9d58071","modified":1608359136604},{"_id":"public/Picture/process.png","hash":"154c7a334bec85f63857285fe6645db0cd273159","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/BL1.png","hash":"2b717e623b919cbb201eddb40b32840d6f901aca","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/BL2.png","hash":"83a552022e33adfc9c1218b6d2fe0bc34d710685","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/BL3.png","hash":"61af65ffa974557fcba929dfc9edb790f112db4e","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/BL5.png","hash":"5c9fed7e60504c6b3af6cfaa69a7d73412760eee","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/BL6.png","hash":"ef78b584d26d386c06d5dc2e442f8294c1ca2c83","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/BL4.png","hash":"36d27adf1022d9b9260cd30fdbbcab6382cedfa0","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/KMP举例2.png","hash":"25629e5d00bf0c3c6cccba409e12b293e9f4fd5f","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/KMP举例1.png","hash":"5c9fed7e60504c6b3af6cfaa69a7d73412760eee","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/next1.png","hash":"8d971b1dfdfa57c25a8dff2132764736f0ffb4b9","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/next3.png","hash":"82c055640e2a6a172e0b411fcba0995d61688f4f","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/next2.png","hash":"aaebd238b3687ea1bb2e601735a9577ba3273cde","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/next4.png","hash":"ca0c56c1475d908450db220a2544c7b8e7616193","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/next5.png","hash":"7f238da8d349be91bdf73dc4e7be0ecc4761a929","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/next6.png","hash":"ba318af8eb51e8ce79efe32f0b330015d42784ae","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/证明1.png","hash":"2c6b062b9be55192d2dd27c5163c671c690c74db","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/证明2.png","hash":"d985c91f822ecd15385304a93ce1071d1cbfb6dc","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/证明１.png","hash":"2c6b062b9be55192d2dd27c5163c671c690c74db","modified":1608359136604},{"_id":"public/2020/03/22/KMP算法/证明3.png","hash":"524b5a24822aca584eeaef32bf489b8ea3168abd","modified":1608359136604},{"_id":"public/2020/04/03/Manjaro-System-configuran/albert.png","hash":"f0be5751f68228c8de53332d6ef4014a5933def0","modified":1608359136604},{"_id":"public/2020/03/20/二元组和图形描述逻辑结构/870358-20160102224630526-1483051229.jpg","hash":"3ae5895250c4d823e1f534add6121f43cab45dd4","modified":1608359136604},{"_id":"public/2020/04/27/面试题35-复杂链表的复制/优化迭代法-图解.png","hash":"9f7f80d3726ee0c7d3545ff6e024bfc60b696768","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/DNS-hierarchy.png","hash":"42a12903e3d39a3a2b9e044b13c706e6fd2f92cb","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/FTP-TCP-connections.png","hash":"252cb698e648fa97962cc30bb61a0c77397aed10","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/HTTP_requires.png","hash":"f6e0958bdc612ae8c3b1a9c5b4820ae2b297f821","modified":1608359136604},{"_id":"public/2020/02/16/process-switch-base-on-stack-switch/wm.png","hash":"638878e7a7e042fd3db6a42fdb4ce52c6ceb5b08","modified":1608359136604},{"_id":"public/2020/02/16/process-switch-base-on-stack-switch/wm1.png","hash":"98e8f274066bee2e2916f09aac57d2652aff34d9","modified":1608359136604},{"_id":"public/2020/02/16/process-switch-base-on-stack-switch/wm2.png","hash":"64fa8056049496709460781c80064e582b8bf197","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png","hash":"deb042f942d24973f703211cc7cc2f40730a0309","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Congestion-window-size-changes-along-with-time.png","hash":"a927f2256fc9c03d6d985dcb3a92e6701568bb03","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Scenario-3-performance.png","hash":"687c84fce6ef8a851f4206b7b914d4ee62362a10","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Sender's-view-of-sequence-numbers-in-the-Go-Back-N.png","hash":"58c8a6038965c118865a17441ffb4805f52b6862","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-Segment-structure.png","hash":"b026b949cfe4cc1b85fb4d0ebcb5bf02fdd418b5","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Advertisement-From-RouterA.png","hash":"18c52a90d11075a66b979780dc23b44f8e5af74e","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/ASs-connection-graph-RIP.png","hash":"caa97664c133afc969bad44f2cf473f0a4f52837","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/General-en.svg.png","hash":"4ebd7813a10efe70a1dc0dddc1233a6853b2264a","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/IPv6-Datagram-Format.png","hash":"ddf9643de2927b4e6ca819779f76c244857bfcbe","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Input-Port-Processing.png","hash":"5991122162188bc2ddea80bc9e9d244d9980ec8d","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Output-Port-Processing.png","hash":"4846b4ea1c107e7d09cb5f8284f30b4487f8ca43","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Result-Of-LS-Algorithm.png","hash":"e04b5201ba9705dcef71c5f49e9b8e753f717aa0","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png","hash":"0e38e05a3abcf662556543745150b1e222d1f0da","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png","hash":"da9cf48e46437359f6020ce2d58b988260491e86","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Simple-VC-Path.png","hash":"312efab0e1835d5900d518f44ef0147eec4de4aa","modified":1608359136604},{"_id":"public/Picture/Bash-Shell.jpg","hash":"3cc683c7802c41d3e6b6c6b2b7f23ea2fec4ba50","modified":1608359136604},{"_id":"public/Picture/Dynamic-programming.jpeg","hash":"e5b666cc1bc6bf19af223c3cd6634441ff0432a0","modified":1608359136604},{"_id":"public/Picture/Http.png","hash":"ce136e450627b96e986af679ad6cf589903d8783","modified":1608359136604},{"_id":"public/Picture/EFLAGS.jpg","hash":"ebb02e2490c960bb4694151d0eae766ce619b1eb","modified":1608359136604},{"_id":"public/Picture/Spring-Cloud-Eureka.png","hash":"34fcddce95b02811a595861ad1f6d8cbb2917000","modified":1608359136604},{"_id":"public/Picture/TCP-UDP.png","hash":"d947faddccb8d479e3835c92889cabb93d9cdca7","modified":1608359136604},{"_id":"public/Picture/The-Network-Edge.png","hash":"75dec0280e924152e5dfc4173d5e5b5f1e5fbad1","modified":1608359136604},{"_id":"public/Picture/Vim.jpg","hash":"aa477cb7d2974e09b642028102b0835cca0f72cf","modified":1608359136604},{"_id":"public/Picture/abandon.jpg","hash":"8181dd75ff8895fcd00cc56fe5f691b7133150e4","modified":1608359136604},{"_id":"public/Picture/ipv4-ipv6.jpg","hash":"1ea75d97153561f416a62deda6ee3b901ce84269","modified":1608359136604},{"_id":"public/Picture/python.png","hash":"c8a756475599e6e3c904b24077b4b0a31983752c","modified":1608359136604},{"_id":"public/Picture/spring-cloud-hystrix.png","hash":"bf54e23639483dae367f299e66989277c5670611","modified":1608359136604},{"_id":"public/2020/11/14/377-Combination-Sum-IV/377-Combination-Sum-IV-1.png","hash":"247881e5b2415a27ec812d15cc83a617721ac2f4","modified":1608359136604},{"_id":"public/2020/03/09/Chapter1-Review-Questions/2020-03-10_15:03_select.png","hash":"7d35955d8e2468af65b41f9a4b379f00768f9fbc","modified":1608359136604},{"_id":"public/2020/03/09/Chapter1-Review-Questions/2020-03-11_14:03:1583906551_select.png","hash":"61a9ff664fccb4046058480994c83cac3916e6a6","modified":1608359136604},{"_id":"public/2020/03/09/Chapter1-Review-Questions/2020-03-11_09:03_select.png","hash":"8eb71e4ec804ce499501a7444fc65300ba18a47a","modified":1608359136604},{"_id":"public/2020/04/03/Manjaro-System-configuran/albert2.png","hash":"e0e21f9b5d55cfb1c190575bcbac954d879dd1c2","modified":1608359136604},{"_id":"public/2020/06/17/Spring-Cloud-Eureka-初入门/eureka-architecture.png","hash":"905633dc622d108f97efeb6ae5472192543933a0","modified":1608359136604},{"_id":"public/2020/04/03/Manjaro-System-configuran/albert1.png","hash":"0e537ac67bbdad04ef4991be82f8ca1eafca905a","modified":1608359136604},{"_id":"public/2020/02/27/The Network Edge/2020-02-27 23-49-06 的屏幕截图.png","hash":"5925781f6c8256f1973baa633e5c40d4dcf5f9e4","modified":1608359136604},{"_id":"public/2020/02/27/The Network Edge/2020-02-27 20-56-20 的屏幕截图.png","hash":"fe83d13f0afd360ab73b2b11393f4a157849b7d0","modified":1608359136604},{"_id":"public/2020/02/27/The Network Edge/2020-02-28 00-21-20 的屏幕截图.png","hash":"7184f370210cd64c915cecb348ee9fb75d7a00d0","modified":1608359136604},{"_id":"public/2020/02/27/The Network Edge/2020-02-27 21-43-25 的屏幕截图.png","hash":"9d38f1fb610151e1694998f44a2a7a1cb5471052","modified":1608359136604},{"_id":"public/2020/02/28/The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png","hash":"be331f4399fabfab5e075c0b868a289c3946c5b0","modified":1608359136604},{"_id":"public/2020/03/31/chapter2-Homework-problems-and-Questions/Messagesheader.png","hash":"0f63cb9e3940a193b76abb0ccc6aaf2d2151b227","modified":1608359136604},{"_id":"public/2020/03/31/chapter2-Homework-problems-and-Questions/TCP-handshake.png","hash":"d1523e522887c310224a3fcee9509bbfb11f3c57","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/Circle-DHT.png","hash":"c6e117b73e6bd8d33f4a2cfdb8a8ee42594b20f9","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/DNS-Messages.png","hash":"33ef94dd425980207afb851affd54ff9c44accad","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/DNS-server-iterative-queries.png","hash":"ff508b4fddadf4b9944d85909dd02f257011894f","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/DNS-server-recursive-queries.png","hash":"5945685e357357956026553710a0dfbcc2d687d3","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/FTP-transfer-file.png","hash":"9fb625f989e5645c08d5f070b0c6a2da9e0deaa8","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/HTTP_respont.png","hash":"73a8f21fad2d35d0ef066953bedbfae81d9ef675","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/SMTP-access-mail.png","hash":"a5c16aba386cd4b905fded39be4025366efa358e","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/SMTP-transfer.png","hash":"6c30ed78de2fe0ba6b3847dca2b707af6c35a75d","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/Web-cache.png","hash":"e3945cf4e5f53a0f964e4230d2bd519ad12bb799","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Code-snippet-of-fast-retransmit.png","hash":"9d8e65b75b62edeaa1393ad0fbf7bdfee7d013b4","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/GBN's-FSM-receiver.png","hash":"d2a5aab41b25fe9a5c6ccd3764fe434533849ba0","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/GBN-in-operation.png","hash":"d3907f90800f035c155a9938bd41060acb34307e","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/RTT-sample-and-RTT-estimates.png","hash":"fac4bf5ef8ad97ba9912fac81f3f79e6f18c5539","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Reliable-data-tranfer.png","hash":"811aae7247800c205766d425192febef766233f8","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/SR-receiver-dilemma-a.png","hash":"529e40b8845f99a4107f0c4da3c054b4cb9ae79d","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Scenario-2-performance.png","hash":"a5c5970c787319fea747da568b85a4f59c2ffa05","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png","hash":"5ecace31ff5737a59de7178c94ed24e0f7906913","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Slow-Start.png","hash":"6c8a2897f798a585fbad4abb1cdf8a3efee28f97","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Stop-and-wait-versus-pipelined-protocol.png","hash":"5cd506798700b1bb8a81f4907f1419db20e1446d","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-RcvBuffer.png","hash":"0e2a807be30bb5fd3551bd06d971dfa109dce630","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-connection-manage-1.png","hash":"920ada7a47319c59b41d03ae8b89ddcc1c684896","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-connection-manage-2.png","hash":"64f50ff8887336b4dd7c607aa926e11d5fc821ce","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-connection-manage-3.png","hash":"dc6e6eb91cffd598dd1c93183bb75a7a82e9de9b","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-connection-manage-4.png","hash":"f830b262c5c0f7785926f9efd5dc67a8061cf87e","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-connection.png","hash":"e2147af3bb4c149ebb9705a8482aef45e568391e","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-sender-and-receiver-buffer.png","hash":"340fe4b10c3dba341cc63c056148b616b5725819","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Two-feedback-way.png","hash":"425045cc7d36463c3a193eaa76548a6fbcdd19ba","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt1.0-finite-state-machine.png","hash":"493a6bda7571f6e64135cad420440af9add47b52","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt2.0-A-protocol.png","hash":"7159fe1f6d4e76ec4351af0daa4c8f8a64661d7f","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/A-Dual-Stack-Approachs.png","hash":"bd521972165b2f433685531687452dfd1b433d46","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/A-Look-Inside-The-Internet-Network-Layer.png","hash":"7d5bb647a78adecbf6308e993404e2ef2eb27dcb","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/BGP-sessions.png","hash":"977712a0b46316c7c073e895b673ce693d413108","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Changes-in-link-cost.png","hash":"0504e6c3e30159083f128f3e1372574c0f46e6e8","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/DHCP-Client-Server-Interaction.png","hash":"0b4138b08e07e05b65a1a025f918e44dc8386b56","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/DV-Simple-Example.png","hash":"330b1c13edc4e566c8922cfffb2e157150172dce","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Datagram-Forwarding-Table.png","hash":"a134ce54b8516e464272e2fdb0d10a1c285ab096","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Graph-Of-Link-State-Algorithm.png","hash":"61046bcc5d7044959b6ea08e4ccae6dff1ff31b2","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/HOL-Block-At-An-Input-Queued-Switch.png","hash":"86d80079c34f65f2fb67813f644534df37c378a6","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/ICMP-Message-Types.png","hash":"5bc1c246d08e18ea0a916cfe460f3205bf147c3c","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Internet-ATM.png","hash":"ced4074d0d27ba0530930cd78260280513aa36f7","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Ip-fragments.png","hash":"9ac0677e296e5bb664d6776567f54c6539799f4f","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Ipv4-Datagram-Format.png","hash":"dc6b9f08ef7b6a05040c985440c32f64255639ec","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Organization-Address.png","hash":"2cc0e0d31f512ec75760c8eca15934f835f95917","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Output-Port-Queueing.png","hash":"274bb70e8eab99fbb5355a0364713ee56d35c717","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/RIP-UDP-Application.png","hash":"61b211057b3cc3ef937313819f6caecaea75ed1e","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/RPF.png","hash":"a91450b1babaaad2703bfc1ad7ccc98fecf7066d","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Router-Architecture.png","hash":"633ed6c6dadf1b6dfdc1ea4d5aeb340ca3660ecd","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Simple-Virtual-Circult-Network.png","hash":"b262d40185fd5c21719bba1705335e0048fe1c40","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Source-duplication-In-network-duplication.png","hash":"aa1ca07b68333484ca4dd9377cb1135983bc9870","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Three-Switching-Techniques.png","hash":"2342f3110eaebdc6710d3941b7a519a5b4effb1d","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/hot-potato-algorithm.png","hash":"bbed2c516d9b04e7b1d1366e15c9a77ed754deae","modified":1608359136604},{"_id":"public/2020/11/14/377-Combination-Sum-IV/377-Combination-Sum-IV-2.png","hash":"1b5aa8eb2c66af27bdd0e05cc3297bd0aa4d92e6","modified":1608359136604},{"_id":"public/2020/03/09/Chapter1-Review-Questions/2020-03-09_21:03_select.png","hash":"029a01fc4db75f25cb54b846855045b2bca9d8b1","modified":1608359136604},{"_id":"public/2020/03/09/Chapter1-Review-Questions/2020-03-11_20:03:1583929611_select.png","hash":"98b54dc874094e9fa526b6b5906600e9e6b8640c","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/6.png","hash":"e92ddb67987a09d7c12ac0dc0d1d4fda7b0b5659","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/6.png","hash":"4f0a62cc7b6b5b761b925061644e63fdb0acabfe","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/Cookie-process.png","hash":"59c97f34e53e93cec60a6d5db7c5023e6be7b22f","modified":1608359136604},{"_id":"public/2020/03/28/Chapter-2-Application-Layer/DNS-Messagas-dig.png","hash":"680110053977f7d7e2d3a4129b6f97b2262d04c9","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/GBN's-FSM-description-senderi.png","hash":"e0d7c41a29c3e120602a30771b3ddf33b2576834","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/SR-operation.png","hash":"deb2554c76df1f7108f6fcc4b6576e12126720b0","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/SR-receiver-dilemma-b.png","hash":"80276eea87b99956da8928206abf60f83889b830","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt2.1-receiver.png","hash":"9c67df8011e3f13113d122a52fcaf9acee39a8e3","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt2.1-sender.png","hash":"5db722914954360ee458cd6b018031a504a4c123","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt2.2-receiver.png","hash":"cb7dd27888081787c15560d81eef70a191c11727","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt2.2-sender.png","hash":"05506207516b417738b48b3fadab44971161a952","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/rdt3.0-sender.png","hash":"cdd91be6facb428ffe5c572b3b6b63f3a2b176a6","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/IP-fragmentation-and-reassembly.png","hash":"214c714520d2fa934494a83a2e997412ca1af546","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Oscillations-With-Congestion-Sensitive-Routing.png","hash":"af1a33890288a240fb47245fda19214d9a45cc0b","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/RPF-Multicast.png","hash":"c8bae968a1946431b2efe683a05ab4fdf0772378","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Routing-algorithm-determine-value-in-forwarding-tables.png","hash":"d1234ca0170ed09dbda5fe8d11a7065e2186ce27","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Tunneling.png","hash":"0482eb7887d029685a360665a8f94f6a406e97dd","modified":1608359136604},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1608359136604},{"_id":"public/js/boot.js","hash":"1aea6f229e2298c7c134e9f1cc94576cd3f30611","modified":1608359136604},{"_id":"public/js/color-schema.js","hash":"7d7444387e549e06a4a378706df92558de62e4e7","modified":1608359136604},{"_id":"public/js/debouncer.js","hash":"045f324777bdfb99d4c17b1806169f029f897a65","modified":1608359136604},{"_id":"public/js/events.js","hash":"9b3a3dfdbc64e6b367ae2ebf7700ed611ecd0d47","modified":1608359136604},{"_id":"public/js/lazyload.js","hash":"0df461660bbd73a79f3125ba4e9bdbc856232e6b","modified":1608359136604},{"_id":"public/js/leancloud.js","hash":"4701f49b3dc62939adff5cc11f6d21963df7f135","modified":1608359136604},{"_id":"public/js/local-search.js","hash":"13d5ef2fe68c49bd6096781034dbb26c190b5176","modified":1608359136604},{"_id":"public/js/plugins.js","hash":"e1fd90d773b3e8dfb075086f58787de21288d650","modified":1608359136604},{"_id":"public/js/utils.js","hash":"3086cede8d6d96ac5f4b5236b06271599a1ebbcb","modified":1608359136604},{"_id":"public/lib/hint/hint.min.css","hash":"b38df228460ebfb4c0b6085336ee2878fe85aafe","modified":1608359136604},{"_id":"public/css/main.css","hash":"6a0b0f3381fcc0b0bcaf1366422d2bd51b4dcae1","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/1.png","hash":"2109130b39b2bc7c7e4e0fc07952544df4230852","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/7.png","hash":"13fb9b419f1cea2a167b96ec7f3d3aa2c7308544","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Fast-retransmit.png","hash":"fb1426f1293b76caeae29020cecde109aded2447","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Scenario-2-two-hosts.png","hash":"4c495d65b394107490b0343b3cb62c3e10afe60b","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Scenario-3-Four-senders.png","hash":"7c1cb5a62fb66a2a88da4eb0a235453a286a0335","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Datagram-Network.png","hash":"67753379961e5b0feb08f1caafa079035f0e5af1","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/IGMP-component.png","hash":"39ecb1ede9e2a85f1f4c7abeffbd80e891e895db","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Interface-Address-And-Subnets.png","hash":"dbb15c5abdabedd901ee65df575e5a80afa33a14","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Virtual-Circuit-Setup.png","hash":"db0649af8113844acc340ca2eb74fc0acf5a0ce3","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/4.png","hash":"6fc55d79e7bff4fe6a744e8713db9583c3a6f4e1","modified":1608359136604},{"_id":"public/2020/02/27/The Network Edge/2020-02-27 14-34-38 的屏幕截图.png","hash":"727e5ec3f704610ebecf1fbba26dbb970b80d858","modified":1608359136604},{"_id":"public/2020/02/28/The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png","hash":"8a66dd9f6d28721e9b605bb2e40d139519881b94","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/5.png","hash":"d346298da4989f6bf22737f960073e000bab6622","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png","hash":"cc97ce395c3c5fb92776a7695a93ca01ea5633a0","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/TCP-ACK-Generation-Recommendation.png","hash":"fce1d92cbd9c3cdef438e9d8ccb3860896ff804d","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/operation-of-rdt3.0-1.png","hash":"db72cdc5dffb1626b0681ad10ef8374c76435d6e","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/operation-of-rdt3.0-2.png","hash":"27e2f24eb171fe54cd6d3cb2825cf2faa3e1ed3f","modified":1608359136604},{"_id":"public/2020/04/17/Chapter3-Transport-Layer/The-three-state-of-congestion-algorithm.png","hash":"3ed7c69518641c629437436cd9e020dc428f2f34","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/Network-Address-Translation.png","hash":"f163622b9993e35e48a24b4fe1f7ca6272fe0703","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/autonomous-system-graph.png","hash":"0dcc92334ebaa8e62e83dc89bfb8a4d78f857b8e","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/4.png","hash":"8624d2c4740f3d91e435cb1292a098d51536fb15","modified":1608359136604},{"_id":"public/2020/05/18/Chapter4-The-Network-Layer/DHCP-Client-Server-Scenario.png","hash":"a56dca8425a31935494f44a808098acd074ca0de","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/5.png","hash":"ef31c92358dcce48e12b19bb794c2f785b056604","modified":1608359136604},{"_id":"public/2020/04/20/对于指针的一些理解/指针.png","hash":"c0e8245567ad5fb4365f972cabc9975fd822ac67","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/1.png","hash":"08cb14657cb4ee3a025d8e41ec5674cae282dbb2","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/2.png","hash":"e2e1dc062feb8928303f07fae38c209245cf22d8","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/3.png","hash":"7da3c2a7f27a5c24c44b0b0c3e6d76af3464128e","modified":1608359136604},{"_id":"public/2020/05/28/chapter4-Homework-problems-and-Questions/2.png","hash":"1b211ba4d0828a58e1f62cc7ea1609111e174ca9","modified":1608359136604},{"_id":"public/2020/05/01/Chapter3-Homework-Problems-and-Questions/3.png","hash":"e82d0f89e4558867af342098f64068d385eef5a3","modified":1608359136604},{"_id":"public/img/wallhaven-j5l9gw.jpg","hash":"145e4effe71ff8c6661c2f9a6445e7cd888e71a1","modified":1608359136604},{"_id":"public/Picture/wallhaven-q6q2e5.jpg","hash":"f452f76c5b178ad458392c3220bd4060109cd411","modified":1608359136604},{"_id":"public/2020/04/03/Manjaro-System-configuran/manjaro_System_finish.png","hash":"72c0d0f7ead2b837166d2ca7fcdf6fd8003a2520","modified":1608359136604},{"_id":"themes/fluid/._config.yml.swp","hash":"ffabe918f7d0477f11a73e7a681897917d785954","modified":1608359410123}],"Category":[{"name":"力扣","_id":"ckivbi4rq0004r8s87vc684jm"},{"name":"Computer Network A Top-Down Approach","_id":"ckivbi4s0000er8s8b73w3bm6"},{"name":"数据结构","_id":"ckivbi4s7000rr8s8d4ui1vm9"},{"name":"操作系统","_id":"ckivbi4s9000yr8s808uua0wa"},{"name":"PA","_id":"ckivbi4sc0015r8s8g0c4hwzw"},{"name":"微服务学习","_id":"ckivbi4si001mr8s84xt1ec51"},{"name":"vim","_id":"ckivbi4sk001sr8s8fucj070k"},{"name":"计算机组成原理","_id":"ckivbi4sl001yr8s85dkz52yw"},{"name":"C/C++","_id":"ckivbi4sl0022r8s8hot4fvdx"},{"name":"Shell","parent":"ckivbi4s9000yr8s808uua0wa","_id":"ckivbi4sm0026r8s8hlv18l25"}],"Data":[],"Page":[{"title":"about","date":"2020-04-29T11:52:22.000Z","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2020-04-29 19:52:22\nlayout: about\n---\n","updated":"2020-11-14T14:40:36.616Z","path":"about/index.html","comments":1,"_id":"ckivbi4rj0000r8s8bvl93m7h","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories/","date":"2020-04-02T11:28:53.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories/\ndate: 2020-04-02 19:28:53\ntype: \"categories\"\n---\n","updated":"2020-11-14T14:40:36.616Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ckivbi4ro0002r8s88lqh673k","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2020-03-20T05:52:24.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2020-03-20 13:52:24\ntype: \"tags\"\n---\n","updated":"2020-11-14T14:40:36.616Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ckivbi4rs0006r8s86tjybjks","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"377. Combination Sum IV","index_img":"/Picture/Dynamic-programming.jpeg","date":"2020-11-14T15:38:27.000Z","banner_img":null,"_content":"![377-Combination-Sum-IV-1.png](377-Combination-Sum-IV-1.png)<br>\n![377-Combination-Sum-IV-2.png](377-Combination-Sum-IV-2.png)<br>\n\n```java\nclass Solution {\n    public int combinationSum4(int[] nums, int target) {\n        int[] fina = new int[target+1];\n        //到达target=0时到达target==0的方式有1种,就是什么都不选\n        fina[0]=1;\n        //fina[i]表示target=i时有几种方式(路)可以到达target=0.\n        for(int i=1;i<=target;++i)\n        {\n            for(int j=0;j<nums.length;++j)\n            {\n                if(nums[j]<=i)\n                fina[i]+=fina[i-nums[j]];\n            }\n        }\n        return fina[target];\n    }\n}\n```\n","source":"_posts/377-Combination-Sum-IV.md","raw":"---\ntitle: 377. Combination Sum IV\nindex_img: /Picture/Dynamic-programming.jpeg\ndate: 2020-11-14 23:38:27\ntags:\n- 力扣\n- 动态规划\ncategories:\n- 力扣\nbanner_img:\n---\n![377-Combination-Sum-IV-1.png](377-Combination-Sum-IV-1.png)<br>\n![377-Combination-Sum-IV-2.png](377-Combination-Sum-IV-2.png)<br>\n\n```java\nclass Solution {\n    public int combinationSum4(int[] nums, int target) {\n        int[] fina = new int[target+1];\n        //到达target=0时到达target==0的方式有1种,就是什么都不选\n        fina[0]=1;\n        //fina[i]表示target=i时有几种方式(路)可以到达target=0.\n        for(int i=1;i<=target;++i)\n        {\n            for(int j=0;j<nums.length;++j)\n            {\n                if(nums[j]<=i)\n                fina[i]+=fina[i-nums[j]];\n            }\n        }\n        return fina[target];\n    }\n}\n```\n","slug":"377-Combination-Sum-IV","published":1,"updated":"2020-11-14T15:41:02.465Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4rm0001r8s8cq184jgu","content":"<p><img src=\"377-Combination-Sum-IV-1.png\" alt=\"377-Combination-Sum-IV-1.png\"><br><br><img src=\"377-Combination-Sum-IV-2.png\" alt=\"377-Combination-Sum-IV-2.png\"><br></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> </span>&#123;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">combinationSum4</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span>[] nums, <span class=\"hljs-keyword\">int</span> target)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">int</span>[] fina = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-keyword\">int</span>[target+<span class=\"hljs-number\">1</span>];<br>        <span class=\"hljs-comment\">//到达target=0时到达target==0的方式有1种,就是什么都不选</span><br>        fina[<span class=\"hljs-number\">0</span>]=<span class=\"hljs-number\">1</span>;<br>        <span class=\"hljs-comment\">//fina[i]表示target=i时有几种方式(路)可以到达target=0.</span><br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">1</span>;i&lt;=target;++i)<br>        &#123;<br>            <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j=<span class=\"hljs-number\">0</span>;j&lt;nums.length;++j)<br>            &#123;<br>                <span class=\"hljs-keyword\">if</span>(nums[j]&lt;=i)<br>                fina[i]+=fina[i-nums[j]];<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> fina[target];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><img src=\"377-Combination-Sum-IV-1.png\" alt=\"377-Combination-Sum-IV-1.png\"><br><br><img src=\"377-Combination-Sum-IV-2.png\" alt=\"377-Combination-Sum-IV-2.png\"><br></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> </span>&#123;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">combinationSum4</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span>[] nums, <span class=\"hljs-keyword\">int</span> target)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">int</span>[] fina = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-keyword\">int</span>[target+<span class=\"hljs-number\">1</span>];<br>        <span class=\"hljs-comment\">//到达target=0时到达target==0的方式有1种,就是什么都不选</span><br>        fina[<span class=\"hljs-number\">0</span>]=<span class=\"hljs-number\">1</span>;<br>        <span class=\"hljs-comment\">//fina[i]表示target=i时有几种方式(路)可以到达target=0.</span><br>        <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> i=<span class=\"hljs-number\">1</span>;i&lt;=target;++i)<br>        &#123;<br>            <span class=\"hljs-keyword\">for</span>(<span class=\"hljs-keyword\">int</span> j=<span class=\"hljs-number\">0</span>;j&lt;nums.length;++j)<br>            &#123;<br>                <span class=\"hljs-keyword\">if</span>(nums[j]&lt;=i)<br>                fina[i]+=fina[i-nums[j]];<br>            &#125;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> fina[target];<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>"},{"title":"52. N-Queens II","index_img":"/Picture/N_Queens.jpg","date":"2020-11-14T15:18:32.000Z","banner_img":null,"_content":"# N皇后\nN皇后是经典题目了，这篇文章不写解题思路,看解题思路可以看这一篇力扣的官方文章[52. N-Queens](https://leetcode-cn.com/problems/n-queens-ii/solution/nhuang-hou-ii-by-leetcode-solution/)\n**这篇文章主要记录一下用二进制数解N皇后的疑问和解答**<br>\n\n先贴代码:\n```java\nclass Solution {\n    public int totalNQueens(int n) {\n        return solve(n, 0, 0, 0, 0);\n    }\n    public int solve(int n, int row, int columns, int diagonals1, int diagonals2) {\n        if(n==row)\n            return 1;\n        int count =0;\n        int availablePosition = ~(columns|diagonals1|diagonals2)&((1<<n)-1);\n        while(availablePosition>0)\n        {\n            int position = availablePosition&(-availablePosition);\n            count += solve(n,row+1,columns|position,(diagonals1|position)<<1,(diagonals2|position)>>1);\n            availablePosition &=(availablePosition-1);\n        }\n        return count ;\n    }\n}\n```\n## 疑问\n**疑问一: int position = availablePosition&(-availablePosition);这段代码的作用是什么?**<br>\n二进制位运算:正数x与其相反数-x的与操作x&(-x)得到的数是二进制x第一个出现的1代表的值(这里说的不太清楚看下面例子)<br>\n\n| 注意：负数在计算机中用补码表示 |  二进制  | 十进制 |\n|:------------------------------:|:--------:|:------:|\n|                x               | 01100100 |   100  |\n|               -x               | 10011100 |  -100  |\n|             x&(-x)             | 00000100 |    4   |\n\n\n由上表可以看出我们可以通过x&(-x)提取出x的二进制表示时第一个不为0的数.\n\n**疑问二: availablePosition &=(availablePosition-1);这段代码的作用是?**<br>\n\n我们把availablePosition 看成x，这样好表示一点.<br>\nx&=(x-1)是为了将x二进制中第一个不为0的数置为0,看下面例子<br>\n\n| -        | 二进制   | 十进制       |\n|----------|----------|--------------|\n| x        | 01100100 | 100          |\n| x-1      | 01100010 | 99           |\n| x&=(x-1) | 01100000 | 这个数不重要 |\n\n通过上表可以看到x&(x-1)成功把x中第一个不为0的数置为0.\n","source":"_posts/52-N-Queens-II.md","raw":"---\ntitle: 52. N-Queens II\nindex_img: /Picture/N_Queens.jpg\ndate: 2020-11-14 23:18:32\ntags:\n- 力扣\ncategories:\n- 力扣\nbanner_img:\n---\n# N皇后\nN皇后是经典题目了，这篇文章不写解题思路,看解题思路可以看这一篇力扣的官方文章[52. N-Queens](https://leetcode-cn.com/problems/n-queens-ii/solution/nhuang-hou-ii-by-leetcode-solution/)\n**这篇文章主要记录一下用二进制数解N皇后的疑问和解答**<br>\n\n先贴代码:\n```java\nclass Solution {\n    public int totalNQueens(int n) {\n        return solve(n, 0, 0, 0, 0);\n    }\n    public int solve(int n, int row, int columns, int diagonals1, int diagonals2) {\n        if(n==row)\n            return 1;\n        int count =0;\n        int availablePosition = ~(columns|diagonals1|diagonals2)&((1<<n)-1);\n        while(availablePosition>0)\n        {\n            int position = availablePosition&(-availablePosition);\n            count += solve(n,row+1,columns|position,(diagonals1|position)<<1,(diagonals2|position)>>1);\n            availablePosition &=(availablePosition-1);\n        }\n        return count ;\n    }\n}\n```\n## 疑问\n**疑问一: int position = availablePosition&(-availablePosition);这段代码的作用是什么?**<br>\n二进制位运算:正数x与其相反数-x的与操作x&(-x)得到的数是二进制x第一个出现的1代表的值(这里说的不太清楚看下面例子)<br>\n\n| 注意：负数在计算机中用补码表示 |  二进制  | 十进制 |\n|:------------------------------:|:--------:|:------:|\n|                x               | 01100100 |   100  |\n|               -x               | 10011100 |  -100  |\n|             x&(-x)             | 00000100 |    4   |\n\n\n由上表可以看出我们可以通过x&(-x)提取出x的二进制表示时第一个不为0的数.\n\n**疑问二: availablePosition &=(availablePosition-1);这段代码的作用是?**<br>\n\n我们把availablePosition 看成x，这样好表示一点.<br>\nx&=(x-1)是为了将x二进制中第一个不为0的数置为0,看下面例子<br>\n\n| -        | 二进制   | 十进制       |\n|----------|----------|--------------|\n| x        | 01100100 | 100          |\n| x-1      | 01100010 | 99           |\n| x&=(x-1) | 01100000 | 这个数不重要 |\n\n通过上表可以看到x&(x-1)成功把x中第一个不为0的数置为0.\n","slug":"52-N-Queens-II","published":1,"updated":"2020-11-14T16:02:27.774Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4rp0003r8s8d2lr715a","content":"<h1 id=\"N皇后\"><a href=\"#N皇后\" class=\"headerlink\" title=\"N皇后\"></a>N皇后</h1><p>N皇后是经典题目了，这篇文章不写解题思路,看解题思路可以看这一篇力扣的官方文章<a href=\"https://leetcode-cn.com/problems/n-queens-ii/solution/nhuang-hou-ii-by-leetcode-solution/\">52. N-Queens</a><br><strong>这篇文章主要记录一下用二进制数解N皇后的疑问和解答</strong><br></p>\n<p>先贴代码:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> </span>&#123;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">totalNQueens</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> solve(n, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>);<br>    &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">solve</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n, <span class=\"hljs-keyword\">int</span> row, <span class=\"hljs-keyword\">int</span> columns, <span class=\"hljs-keyword\">int</span> diagonals1, <span class=\"hljs-keyword\">int</span> diagonals2)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span>(n==row)<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span>;<br>        <span class=\"hljs-keyword\">int</span> count =<span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-keyword\">int</span> availablePosition = ~(columns|diagonals1|diagonals2)&amp;((<span class=\"hljs-number\">1</span>&lt;&lt;n)-<span class=\"hljs-number\">1</span>);<br>        <span class=\"hljs-keyword\">while</span>(availablePosition&gt;<span class=\"hljs-number\">0</span>)<br>        &#123;<br>            <span class=\"hljs-keyword\">int</span> position = availablePosition&amp;(-availablePosition);<br>            count += solve(n,row+<span class=\"hljs-number\">1</span>,columns|position,(diagonals1|position)&lt;&lt;<span class=\"hljs-number\">1</span>,(diagonals2|position)&gt;&gt;<span class=\"hljs-number\">1</span>);<br>            availablePosition &amp;=(availablePosition-<span class=\"hljs-number\">1</span>);<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> count ;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p>\n<h2 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h2><p><strong>疑问一: int position = availablePosition&amp;(-availablePosition);这段代码的作用是什么?</strong><br><br>二进制位运算:正数x与其相反数-x的与操作x&amp;(-x)得到的数是二进制x第一个出现的1代表的值(这里说的不太清楚看下面例子)<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">注意：负数在计算机中用补码表示</th>\n<th style=\"text-align:center\">二进制</th>\n<th style=\"text-align:center\">十进制</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">01100100</td>\n<td style=\"text-align:center\">100</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-x</td>\n<td style=\"text-align:center\">10011100</td>\n<td style=\"text-align:center\">-100</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">x&amp;(-x)</td>\n<td style=\"text-align:center\">00000100</td>\n<td style=\"text-align:center\">4</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>由上表可以看出我们可以通过x&amp;(-x)提取出x的二进制表示时第一个不为0的数.</p>\n<p><strong>疑问二: availablePosition &amp;=(availablePosition-1);这段代码的作用是?</strong><br></p>\n<p>我们把availablePosition 看成x，这样好表示一点.<br><br>x&amp;=(x-1)是为了将x二进制中第一个不为0的数置为0,看下面例子<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>-</th>\n<th>二进制</th>\n<th>十进制</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>x</td>\n<td>01100100</td>\n<td>100</td>\n</tr>\n<tr>\n<td>x-1</td>\n<td>01100010</td>\n<td>99</td>\n</tr>\n<tr>\n<td>x&amp;=(x-1)</td>\n<td>01100000</td>\n<td>这个数不重要</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>通过上表可以看到x&amp;(x-1)成功把x中第一个不为0的数置为0.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"N皇后\"><a href=\"#N皇后\" class=\"headerlink\" title=\"N皇后\"></a>N皇后</h1><p>N皇后是经典题目了，这篇文章不写解题思路,看解题思路可以看这一篇力扣的官方文章<a href=\"https://leetcode-cn.com/problems/n-queens-ii/solution/nhuang-hou-ii-by-leetcode-solution/\">52. N-Queens</a><br><strong>这篇文章主要记录一下用二进制数解N皇后的疑问和解答</strong><br></p>\n<p>先贴代码:<br><figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs java\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> </span>&#123;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">totalNQueens</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">return</span> solve(n, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>);<br>    &#125;<br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">public</span> <span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">solve</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> n, <span class=\"hljs-keyword\">int</span> row, <span class=\"hljs-keyword\">int</span> columns, <span class=\"hljs-keyword\">int</span> diagonals1, <span class=\"hljs-keyword\">int</span> diagonals2)</span> </span>&#123;<br>        <span class=\"hljs-keyword\">if</span>(n==row)<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1</span>;<br>        <span class=\"hljs-keyword\">int</span> count =<span class=\"hljs-number\">0</span>;<br>        <span class=\"hljs-keyword\">int</span> availablePosition = ~(columns|diagonals1|diagonals2)&amp;((<span class=\"hljs-number\">1</span>&lt;&lt;n)-<span class=\"hljs-number\">1</span>);<br>        <span class=\"hljs-keyword\">while</span>(availablePosition&gt;<span class=\"hljs-number\">0</span>)<br>        &#123;<br>            <span class=\"hljs-keyword\">int</span> position = availablePosition&amp;(-availablePosition);<br>            count += solve(n,row+<span class=\"hljs-number\">1</span>,columns|position,(diagonals1|position)&lt;&lt;<span class=\"hljs-number\">1</span>,(diagonals2|position)&gt;&gt;<span class=\"hljs-number\">1</span>);<br>            availablePosition &amp;=(availablePosition-<span class=\"hljs-number\">1</span>);<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> count ;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure></p>\n<h2 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h2><p><strong>疑问一: int position = availablePosition&amp;(-availablePosition);这段代码的作用是什么?</strong><br><br>二进制位运算:正数x与其相反数-x的与操作x&amp;(-x)得到的数是二进制x第一个出现的1代表的值(这里说的不太清楚看下面例子)<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">注意：负数在计算机中用补码表示</th>\n<th style=\"text-align:center\">二进制</th>\n<th style=\"text-align:center\">十进制</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">x</td>\n<td style=\"text-align:center\">01100100</td>\n<td style=\"text-align:center\">100</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-x</td>\n<td style=\"text-align:center\">10011100</td>\n<td style=\"text-align:center\">-100</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">x&amp;(-x)</td>\n<td style=\"text-align:center\">00000100</td>\n<td style=\"text-align:center\">4</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>由上表可以看出我们可以通过x&amp;(-x)提取出x的二进制表示时第一个不为0的数.</p>\n<p><strong>疑问二: availablePosition &amp;=(availablePosition-1);这段代码的作用是?</strong><br></p>\n<p>我们把availablePosition 看成x，这样好表示一点.<br><br>x&amp;=(x-1)是为了将x二进制中第一个不为0的数置为0,看下面例子<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>-</th>\n<th>二进制</th>\n<th>十进制</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>x</td>\n<td>01100100</td>\n<td>100</td>\n</tr>\n<tr>\n<td>x-1</td>\n<td>01100010</td>\n<td>99</td>\n</tr>\n<tr>\n<td>x&amp;=(x-1)</td>\n<td>01100000</td>\n<td>这个数不重要</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>通过上表可以看到x&amp;(x-1)成功把x中第一个不为0的数置为0.</p>\n"},{"title":"Chapter1 Review Questions","date":"2020-03-09T08:46:14.000Z","index_img":"/Picture/Question-Mark.jpg","_content":" 关于计算机网络自顶向下的第一章的问题回答\n-------\n**R1:主机和终端系统有什么不同？<br>**\n终端系统（end system）和主机(host)系统其实没有很大的区别都就具有连接网络和交换信息的能力，本质上没有很大的区别．但是在现实生活中主机常常指提供服务的一方，而终端指手机，手提电脑，台式电脑之类的．<br>\n**R2:protocol在维基百科上的定义<br>**\nprotocol（协议）在维基百科上的定义是：给数据/信息在电子通信和网络上的传输制定的规则<br>\n**R3:为什么协议（protocol）如此重要？<br>**\nprotocol由Internet engineering task force(IETF)制定，为了提供更好的更加有质量，更加安全的协议来给消费者使用，标准协议为了每个用户之间能够更有效的互相交流．例如：书上说的人打招呼的例子，如果没有协议就会乱套．<br>\n**R4:列出６个访问技术，以及将其分类家庭访问，企业访问和广域无线访问<br>**\n*家庭访问：<br>*\n1.DSL(digtal subscriber line):数字订阅通路<br>\n2.cable internet access: 有线上网，也可以叫做HFC(hybird fiber coax)：混合光纤同轴电缆<br>\n3.fiber to the home: 光纤到家（光纤）<br>\n4.Dial_up :数字拨号（用电话线<br>\n5.satellite:卫星<br>\n*企业访问（家庭其实也可以）:<br>*\n6.WIFI<br>\n7.Enternet<br>\n广域无线访问：\n8.third/(fouth)-generation(3G)<br>\n9.LTE(long-term-Evolution)<br>\n**R5:HFC的传输速度是用户独享还是分享？是否可能在HFC的下游发生数据碰撞？<br>**\nHFC(hybird fiber coax)混合光纤同轴电缆也就是cable internet access有线连接，用的是电视公司提供的有线电视的电视线连接，因为这个互联网访问方式中用到了两种电缆线分别是光纤和同轴电缆，所以就叫HFC．![cable internet access](2020-03-09_21:03_select.png)\n如图所示HFC是用户分享类型的，如图HFC的下载源只有一个所以downstream不冲突，但是上传（upstream）就有可能冲突，需要用协议来解决．<br>\n**R6:列出你所在城市的住宅访问技术（access technologies）,以及它们各种的下载，上传速度和价钱.**\n目前中国电信能够提供基于ADSL、LAN以及FTTH光纤接入三种技术的宽带实现方式。速率从1Mbps到20Mbps不等，价格也从119到559不等。(抄的．．)<br>\n**R7:以太局域网（Enthernet LANs）的传输速度是多少？**<br>\n对于用户：通常有100Mbps,对于服务器：通常有１Gbps~10Gbps .<br>\n\n**R8:Enthernet（以太网）运行的物理介质是什么，有那些？**<br>\n有同轴电缆（coaxial cable）光纤（fiber optic）,双绞铜线（twisted-pair-copper Wire).<br>\n**R9:提供Dial-up modems,DSL,HFC,FTTH的速度范围和判断其是用户独占还是用户共享**<br>\n- DSL:上传速度：2.5Mbps，下载速度：24Mbps.[2003]\n- HFC:上传速度：30.7Mbps,下载速度：42.8Mbps.[DOCSIS.2.0]\n- FTTH:理论上可以达到１Gbps实际平均下载速度可以达到20Mbps[2011]\n- Dial-up modems: 56kbps [巨慢]<br>\n\n**R10:描述现在最流行的无线连接技术，并且比较它们的差异**<br>\n最流行的无线连接技术:现在是WIFI和4G<br>\n差异：<br>\nWIFI是用户无线或有线连接到自己附近的路由器，通过路由器这个接入点连接网络如图：\n![WIFI](2020-03-10_15:03_select.png)<br>\n一般WIFI的范围是10米之内．WIFI提供的理论接入速度可以达到600Mbps(来自知乎，书上是54Mbps).<br>\n4G:4G用的是蜂窝技术（cellular telephony),4G提供的理论接入速度是100 Mbps,而且蜂窝技术的范围可以达到10千米内（范围更大）.<br>\n**R11:假设有只有一个分组交换机(parket switch)在发送端和接收端之间，传输速度发送端到分组交换机为R1,分组交换机到接收端之间为R2,假设使用的是存储转发交换机制(store-and-forward packet switch),计算端到端的总延迟[忽略处理延迟(processing delay),队列延迟(queuing delay),传播延迟（propagation delay）]**<br>\n那总延迟就等于这段路上的传输延迟（transmission delay）=R1+R2.<br>\n\n**R12:电路交换网络(circuit-switched network)相比分组交换网络(packet-switch network)有什么优势，在电路交换网络中，TDM对比FDM有什么优势**<br>\n我觉得电路交换网络系统的缺点也可以算是它的优点，因为其在传输信息时需要建立连接状态（circuit）这个时候用户可以用这条链路上的所有的速度，但是此时其他的用户无法使用，此时如果建立链路没有在传输信息而是待工，这个时候链路资源就没办法有效利用，这就是circut-switch network的缺点，但是如果其的应用场景使用链路的密度很大，这个时候就很OK,因为其传输速度是满的．<br>\nTDM(Time-Division Multiplexing)时分复用对比FDM(Frequency-Division Multiplexing)频分复用的优势：<br>\n```\n TDM is relatively a newer technique used for digital signals.\n TDM advantage over FDM is that it offers bandwidth saving with\n ATDM (allocate time slots on demand dynamically) and \n there is low interference between the signals that are being\n multiplexed(from google)\n``` \n**R13:假设用户分享2Mbps的带宽，同时假设每个用户在传输数据是持续以1Mbps的带宽，链接网络时传输的占的时间与总时间的比值为20%**　<br>\n**a.如果使用电路交换网络(circuit-switched network),可以支持多少用户使用.** <br>\n**b.假设使用分组分配，两个或者更少用户同时传输数据的时候为什么实际上没有队列（排队）延迟，三个用户同时使用为什么会有队列延迟**<br>\n**c.计算用户正在传输的概率**<br>\n**d.假定现在有三个用户计算这个三个用户同时使用链路的概率，找到队列增长的概率**(c.d应该是承接b)<br>\n\n1.两个用户可以同时使用<br>\n2.因为两个或者更少用户用的时候没有超过链路的最大带宽，而三个以上用户就会超过，所以用分组分配就会有队列延迟．<br>\n3.用户真正传输的概率是20%<br>\n4.三个用户同时使用的概率是$1\\over5$ $\\times$ $1\\over5$ $\\times$ $1\\over5$ $=$ $1\\over125$,队列增长的概率也是 $1\\over125$<br>\n**R14:为什么处于同一个层级的ISPs互相对等，IXP是怎么赚钱的？**<br>\n一个城市与临近的另一个城市需要的用户需要数据传输如果这两个城市的ISPs没有进行对等(peer),则还需要通过更上一层的ISPs来达到互相连接，而更高一层的ISPs就会向低级的ISPs收费（收费的多少体现在流量上），对等（peer）了之后就不用通过更上一层ISPs,以达到节省开支的目的，而IXP(Internet Exchange Point)，IXP通常由电信公司以外的第三方公司来建立，主要作为ISPs的对接点，提供ISPs的对等服务．IXP赚钱通过想ISPs们收取少量的端口费盈利．<br>\n![网络提供者的层级结构](2020-03-11_09:03_select.png)\n**R15:一些内容的提供者也建立了它们自己的网络，描述一下Google,是什么促进它们建立自己的网络？**<br>\ngoogle通过自己提供的TCP/IP网络把它分布在全球的大的小的数据中心连接起来（大的数据中心可能连接上百万个用户，小的可能几百个用户），\n这些数据中心大多都是连接比较底层的用户或者ISPs提供，可以让谷歌绕过更高层级的ISPs．<br>\n促进他们建立自己网络的理由是：内容提供商（例如谷歌）建立自己的网络服务可以减少向上层ISPs支付费用，（因为谷歌可以直接和用户相连，或者连接更下层的ISPs和IXP,所以减少了中间ISPs的数量），同时也可以达到对用户更好的控制．<br>\n**R16:考虑在固定线路上从源主机发送一个包（packet）到目标主机，列出端到端的延迟，以及表示出那个延迟是常数，那个延迟是变量．**<br>\n分别有传输延迟（transmission delay），传播延迟(propagation delay)，队列延迟(queueing delay)，处理延迟(processing delay).<br>\n队列延迟是可变的，其他延迟是常数．<br>\n**R17:去这个小程序网站：Transmission Versus Propagation Delay，通过调整rates,propagation delay和packet sizes的大小，找到两个组合，使packet在源主机传输完成之前，第一个被发送的bit到达目标主机，和pakect在源主机完成传输之后，第一个被发送的bit才到达目标主机．**<br>第一个组合是：1000KM,1Mbps,100bytes.\n第二个组合是：100KM,1Mbps,100bytes.<br>\n**R18:发送长度为1000bytes的packet,距离为2500Km,传播速度是$2.5$x$10^8$m/s,传输速度是2Mbps需要多长时间,更加抽象一点，发送长度为L的packet,距离为d,传播速度是s,传输速度是Rbps需要多长时间,在传递信息中的延迟是由打包的数据长度决定？还是传输的速度决定？**\n假设忽略了处理延迟和队列延迟，那么需要的时间为<br>\n$1000\\div(2000000\\div8)+2500\\times 1000 \\div(2.5\\times10^8)=0.01+0.004=0.014s=14msec$<br>\n抽象一点：\n$time=L\\times8/R+d/s$ <br>\n打包的数据长度和传输速度都不能呢个决定延迟大小．<br>\n**R19:假设源主机Ａ想传递一个很大的文件给目标主机Ｂ，在两者直接有三条链路，速度分别为R1=500kbps,R2=2Mbps,R3=1Mbps.**<br>\n- 假设没有其他的流量在网络中，这个文件传输的吞吐量是多少？\n- 假设文件大小为4Mbytes,大致需要多长时间传输这个文件．\n- 重算1,2题现在R2降低到100kbps.<br>\n1.这个文件的吞吐量由最小的通路决定，文件吞吐量为500Kbps.<br>\n2.$T=4000000\\div(500\\times1000\\div 8)=64s$<br>\n3.如果R2降为100kbps,文件传输的吞吐量为100kbps,则4Mbytes的文件传输大致时间为$4000000\\div(100\\times1000\\div8)=320s$<br>\n\n\n**R20:假设一个很大的文件从主机A传输到主机B,从一个比较高的角度描述一下主机A如何把一个文件变成一个个的packet，当一个packet到达交换机（switch）,哪些信息被用来指引（确定）packet前进路线，以及为什么互联网中分组交换需要模拟汽车从一个城市到另外一个城市并沿着路线不断问路的过程．**<br>\n![packet的运行路线](2020-03-11_14:03:1583906551_select.png)<br>\n主机Ａ的文件本来是一个整体在层级结构中被称作消息(message),传递给下面的传输层（Transport layer),传输层中的TCP协议可以把message分割成一块一块加上一些信息放在每一块上组成段(segment),同时TCP协议拥有流控制（flow control）功能[匹配发生者和接受者的速度]，和拥堵控制机制（congestion-control mechanism),然后传递给网络层（Network layer),然后把段传到网络层(Network layer),网络层执行的是IP协议，以及一些路由协议（routing protocol）,同样是在每个段的头部加上一些信息组成数据报(Datagram),然后在传递给链路层（Link layer）,链路层用的协议不同链路上用的协议就不同，有：WIFI,Ethernet and cable network的DORSIS protocol,操作也是在数据报头部加入一些信息形成的桢（Frame）最后就是送到物理层（physical layer),物理层就把每一个桢中的数据一个bit一个bit的传播出去，物理层同样有协议，根据使用的物理介质的不同而不同．<br>\n一个packet到达交换机后根据每个packet中的IP地址找到前进路线．<br>\n第三问着实不懂．<br>\n\n**R21:去执行Queuing and Loss这个小程序,然后找到最大发送速率和最小的传输速率是多少？对于这些速率，流量强度是多少？用这些速率运行该小程序并确定出现丢包要花费多长时间？然后第多次重复该实验，再次确定出现丢包花费多长时间。这些值有什么不同？为什么会有这种现象？**<br>\n最大的发射速度是500packet/s,最小的传输速度是350packet/s,对于这些流量强度是$500\\div350=1.428$用这些速度去运行，出现丢包的时间大约在31~34秒左右，并不能确定具体哪个时间会发生丢包，为什么？因为用户发生数据包有随机性，我们并不能控制每一个用户．\n\n\n**R22:列出一层都可以执行5个任务,并且是否有可能这些任务中有可以执行在两个或者多个层？**<br>\n任务: 封装本层的报文段, 设置各种参数, 对接受到的报文段进行差错检查, 还可能进行流量设置, 分组重组等等.多个层是可能执行相同的一个(或两个)任务的, 比如差错检验<br>\n**R23:互联网协议栈的五层是什么，每一层的的主要职责是什么？**\n互联网协议栈的五层从上到下分别是，应用层，传输层，网络层，链路层，物理层．关于他们的主要职责：在R20有讲到.\n\n**R24:什么是应用层报文（message）,传输层报文（segment),网络层数据报（Datagram）,链路层帧(Frame).**\n```mermaid\ngraph TD\nA[message]-->B[message+Headt=segment]-->C[segment+Headn=Datagram]-->D[Datagram+Headl=Frame];\n```\n<br>\n\n**R25:在互联网协议栈中路由器处理哪几层，链路交换机处理哪几层，主机处理哪几层？**<br>\n路由器处理１到３层(现代路由器里还有防火墙和缓存组件，也可以处理传输层)，链路交换机处理１－２两层，主机处理全５层．<br>\n\n**R26:病毒（virus）和虫（worms）有什么不同?**<br>\n病毒需要用户与其互动，有交互，需要人进行操作，例如ＱＱ发个网站点进网站被盗号等，虫就是不需要与用户进行互动，例如用户运行一个很脆弱的软件，恶意软件进来不需要用户统一直接运行，并且会自我复制自动寻找下一个脆弱的软件进行攻击．<Br>\n\n**R27:描述一下僵尸网络(botnet)是怎么形成的,以及怎么利用僵尸网络来进行DDoS攻击？**\n僵尸网络就是这个bad guy通过找到别人的应用或者是系统的漏洞，利用虫（worms)来侵入别人的主机，而这个虫又可以通过漏洞来复制和接着进行传播，僵尸网络的属性就是attacker可以远程通过命令来操控僵尸网络中的主机运作．而DDos（distributed denail-of-service attack）攻击就是通过成败上千台僵尸主机同时想目标主机发送信息，导致目标主机的带宽被占满从而使正确的信息无法传到目标主机．<br>\n![botnet](2020-03-11_20:03:1583929611_select.png)<br>\n**R28:假设Alice和Bob真正互相发送信息，同时假设Trudy定位自己在网络中，Trudy可以捕获所有Alice发生的消息，也可以发送任何消息给Bob,同理相对与Bob也一样，列举出Trudy处在这个位置上可以做的恶意的事情**<br>\n借钱打这个账户1008668001.\n","source":"_posts/Chapter1-Review-Questions.md","raw":"---\ntitle: Chapter1 Review Questions\ndate: 2020-03-09 16:46:14\nindex_img: /Picture/Question-Mark.jpg\ncategories:\n- Computer Network A Top-Down Approach\ntags:\n- Computer Network A Top-Down Approach\n---\n 关于计算机网络自顶向下的第一章的问题回答\n-------\n**R1:主机和终端系统有什么不同？<br>**\n终端系统（end system）和主机(host)系统其实没有很大的区别都就具有连接网络和交换信息的能力，本质上没有很大的区别．但是在现实生活中主机常常指提供服务的一方，而终端指手机，手提电脑，台式电脑之类的．<br>\n**R2:protocol在维基百科上的定义<br>**\nprotocol（协议）在维基百科上的定义是：给数据/信息在电子通信和网络上的传输制定的规则<br>\n**R3:为什么协议（protocol）如此重要？<br>**\nprotocol由Internet engineering task force(IETF)制定，为了提供更好的更加有质量，更加安全的协议来给消费者使用，标准协议为了每个用户之间能够更有效的互相交流．例如：书上说的人打招呼的例子，如果没有协议就会乱套．<br>\n**R4:列出６个访问技术，以及将其分类家庭访问，企业访问和广域无线访问<br>**\n*家庭访问：<br>*\n1.DSL(digtal subscriber line):数字订阅通路<br>\n2.cable internet access: 有线上网，也可以叫做HFC(hybird fiber coax)：混合光纤同轴电缆<br>\n3.fiber to the home: 光纤到家（光纤）<br>\n4.Dial_up :数字拨号（用电话线<br>\n5.satellite:卫星<br>\n*企业访问（家庭其实也可以）:<br>*\n6.WIFI<br>\n7.Enternet<br>\n广域无线访问：\n8.third/(fouth)-generation(3G)<br>\n9.LTE(long-term-Evolution)<br>\n**R5:HFC的传输速度是用户独享还是分享？是否可能在HFC的下游发生数据碰撞？<br>**\nHFC(hybird fiber coax)混合光纤同轴电缆也就是cable internet access有线连接，用的是电视公司提供的有线电视的电视线连接，因为这个互联网访问方式中用到了两种电缆线分别是光纤和同轴电缆，所以就叫HFC．![cable internet access](2020-03-09_21:03_select.png)\n如图所示HFC是用户分享类型的，如图HFC的下载源只有一个所以downstream不冲突，但是上传（upstream）就有可能冲突，需要用协议来解决．<br>\n**R6:列出你所在城市的住宅访问技术（access technologies）,以及它们各种的下载，上传速度和价钱.**\n目前中国电信能够提供基于ADSL、LAN以及FTTH光纤接入三种技术的宽带实现方式。速率从1Mbps到20Mbps不等，价格也从119到559不等。(抄的．．)<br>\n**R7:以太局域网（Enthernet LANs）的传输速度是多少？**<br>\n对于用户：通常有100Mbps,对于服务器：通常有１Gbps~10Gbps .<br>\n\n**R8:Enthernet（以太网）运行的物理介质是什么，有那些？**<br>\n有同轴电缆（coaxial cable）光纤（fiber optic）,双绞铜线（twisted-pair-copper Wire).<br>\n**R9:提供Dial-up modems,DSL,HFC,FTTH的速度范围和判断其是用户独占还是用户共享**<br>\n- DSL:上传速度：2.5Mbps，下载速度：24Mbps.[2003]\n- HFC:上传速度：30.7Mbps,下载速度：42.8Mbps.[DOCSIS.2.0]\n- FTTH:理论上可以达到１Gbps实际平均下载速度可以达到20Mbps[2011]\n- Dial-up modems: 56kbps [巨慢]<br>\n\n**R10:描述现在最流行的无线连接技术，并且比较它们的差异**<br>\n最流行的无线连接技术:现在是WIFI和4G<br>\n差异：<br>\nWIFI是用户无线或有线连接到自己附近的路由器，通过路由器这个接入点连接网络如图：\n![WIFI](2020-03-10_15:03_select.png)<br>\n一般WIFI的范围是10米之内．WIFI提供的理论接入速度可以达到600Mbps(来自知乎，书上是54Mbps).<br>\n4G:4G用的是蜂窝技术（cellular telephony),4G提供的理论接入速度是100 Mbps,而且蜂窝技术的范围可以达到10千米内（范围更大）.<br>\n**R11:假设有只有一个分组交换机(parket switch)在发送端和接收端之间，传输速度发送端到分组交换机为R1,分组交换机到接收端之间为R2,假设使用的是存储转发交换机制(store-and-forward packet switch),计算端到端的总延迟[忽略处理延迟(processing delay),队列延迟(queuing delay),传播延迟（propagation delay）]**<br>\n那总延迟就等于这段路上的传输延迟（transmission delay）=R1+R2.<br>\n\n**R12:电路交换网络(circuit-switched network)相比分组交换网络(packet-switch network)有什么优势，在电路交换网络中，TDM对比FDM有什么优势**<br>\n我觉得电路交换网络系统的缺点也可以算是它的优点，因为其在传输信息时需要建立连接状态（circuit）这个时候用户可以用这条链路上的所有的速度，但是此时其他的用户无法使用，此时如果建立链路没有在传输信息而是待工，这个时候链路资源就没办法有效利用，这就是circut-switch network的缺点，但是如果其的应用场景使用链路的密度很大，这个时候就很OK,因为其传输速度是满的．<br>\nTDM(Time-Division Multiplexing)时分复用对比FDM(Frequency-Division Multiplexing)频分复用的优势：<br>\n```\n TDM is relatively a newer technique used for digital signals.\n TDM advantage over FDM is that it offers bandwidth saving with\n ATDM (allocate time slots on demand dynamically) and \n there is low interference between the signals that are being\n multiplexed(from google)\n``` \n**R13:假设用户分享2Mbps的带宽，同时假设每个用户在传输数据是持续以1Mbps的带宽，链接网络时传输的占的时间与总时间的比值为20%**　<br>\n**a.如果使用电路交换网络(circuit-switched network),可以支持多少用户使用.** <br>\n**b.假设使用分组分配，两个或者更少用户同时传输数据的时候为什么实际上没有队列（排队）延迟，三个用户同时使用为什么会有队列延迟**<br>\n**c.计算用户正在传输的概率**<br>\n**d.假定现在有三个用户计算这个三个用户同时使用链路的概率，找到队列增长的概率**(c.d应该是承接b)<br>\n\n1.两个用户可以同时使用<br>\n2.因为两个或者更少用户用的时候没有超过链路的最大带宽，而三个以上用户就会超过，所以用分组分配就会有队列延迟．<br>\n3.用户真正传输的概率是20%<br>\n4.三个用户同时使用的概率是$1\\over5$ $\\times$ $1\\over5$ $\\times$ $1\\over5$ $=$ $1\\over125$,队列增长的概率也是 $1\\over125$<br>\n**R14:为什么处于同一个层级的ISPs互相对等，IXP是怎么赚钱的？**<br>\n一个城市与临近的另一个城市需要的用户需要数据传输如果这两个城市的ISPs没有进行对等(peer),则还需要通过更上一层的ISPs来达到互相连接，而更高一层的ISPs就会向低级的ISPs收费（收费的多少体现在流量上），对等（peer）了之后就不用通过更上一层ISPs,以达到节省开支的目的，而IXP(Internet Exchange Point)，IXP通常由电信公司以外的第三方公司来建立，主要作为ISPs的对接点，提供ISPs的对等服务．IXP赚钱通过想ISPs们收取少量的端口费盈利．<br>\n![网络提供者的层级结构](2020-03-11_09:03_select.png)\n**R15:一些内容的提供者也建立了它们自己的网络，描述一下Google,是什么促进它们建立自己的网络？**<br>\ngoogle通过自己提供的TCP/IP网络把它分布在全球的大的小的数据中心连接起来（大的数据中心可能连接上百万个用户，小的可能几百个用户），\n这些数据中心大多都是连接比较底层的用户或者ISPs提供，可以让谷歌绕过更高层级的ISPs．<br>\n促进他们建立自己网络的理由是：内容提供商（例如谷歌）建立自己的网络服务可以减少向上层ISPs支付费用，（因为谷歌可以直接和用户相连，或者连接更下层的ISPs和IXP,所以减少了中间ISPs的数量），同时也可以达到对用户更好的控制．<br>\n**R16:考虑在固定线路上从源主机发送一个包（packet）到目标主机，列出端到端的延迟，以及表示出那个延迟是常数，那个延迟是变量．**<br>\n分别有传输延迟（transmission delay），传播延迟(propagation delay)，队列延迟(queueing delay)，处理延迟(processing delay).<br>\n队列延迟是可变的，其他延迟是常数．<br>\n**R17:去这个小程序网站：Transmission Versus Propagation Delay，通过调整rates,propagation delay和packet sizes的大小，找到两个组合，使packet在源主机传输完成之前，第一个被发送的bit到达目标主机，和pakect在源主机完成传输之后，第一个被发送的bit才到达目标主机．**<br>第一个组合是：1000KM,1Mbps,100bytes.\n第二个组合是：100KM,1Mbps,100bytes.<br>\n**R18:发送长度为1000bytes的packet,距离为2500Km,传播速度是$2.5$x$10^8$m/s,传输速度是2Mbps需要多长时间,更加抽象一点，发送长度为L的packet,距离为d,传播速度是s,传输速度是Rbps需要多长时间,在传递信息中的延迟是由打包的数据长度决定？还是传输的速度决定？**\n假设忽略了处理延迟和队列延迟，那么需要的时间为<br>\n$1000\\div(2000000\\div8)+2500\\times 1000 \\div(2.5\\times10^8)=0.01+0.004=0.014s=14msec$<br>\n抽象一点：\n$time=L\\times8/R+d/s$ <br>\n打包的数据长度和传输速度都不能呢个决定延迟大小．<br>\n**R19:假设源主机Ａ想传递一个很大的文件给目标主机Ｂ，在两者直接有三条链路，速度分别为R1=500kbps,R2=2Mbps,R3=1Mbps.**<br>\n- 假设没有其他的流量在网络中，这个文件传输的吞吐量是多少？\n- 假设文件大小为4Mbytes,大致需要多长时间传输这个文件．\n- 重算1,2题现在R2降低到100kbps.<br>\n1.这个文件的吞吐量由最小的通路决定，文件吞吐量为500Kbps.<br>\n2.$T=4000000\\div(500\\times1000\\div 8)=64s$<br>\n3.如果R2降为100kbps,文件传输的吞吐量为100kbps,则4Mbytes的文件传输大致时间为$4000000\\div(100\\times1000\\div8)=320s$<br>\n\n\n**R20:假设一个很大的文件从主机A传输到主机B,从一个比较高的角度描述一下主机A如何把一个文件变成一个个的packet，当一个packet到达交换机（switch）,哪些信息被用来指引（确定）packet前进路线，以及为什么互联网中分组交换需要模拟汽车从一个城市到另外一个城市并沿着路线不断问路的过程．**<br>\n![packet的运行路线](2020-03-11_14:03:1583906551_select.png)<br>\n主机Ａ的文件本来是一个整体在层级结构中被称作消息(message),传递给下面的传输层（Transport layer),传输层中的TCP协议可以把message分割成一块一块加上一些信息放在每一块上组成段(segment),同时TCP协议拥有流控制（flow control）功能[匹配发生者和接受者的速度]，和拥堵控制机制（congestion-control mechanism),然后传递给网络层（Network layer),然后把段传到网络层(Network layer),网络层执行的是IP协议，以及一些路由协议（routing protocol）,同样是在每个段的头部加上一些信息组成数据报(Datagram),然后在传递给链路层（Link layer）,链路层用的协议不同链路上用的协议就不同，有：WIFI,Ethernet and cable network的DORSIS protocol,操作也是在数据报头部加入一些信息形成的桢（Frame）最后就是送到物理层（physical layer),物理层就把每一个桢中的数据一个bit一个bit的传播出去，物理层同样有协议，根据使用的物理介质的不同而不同．<br>\n一个packet到达交换机后根据每个packet中的IP地址找到前进路线．<br>\n第三问着实不懂．<br>\n\n**R21:去执行Queuing and Loss这个小程序,然后找到最大发送速率和最小的传输速率是多少？对于这些速率，流量强度是多少？用这些速率运行该小程序并确定出现丢包要花费多长时间？然后第多次重复该实验，再次确定出现丢包花费多长时间。这些值有什么不同？为什么会有这种现象？**<br>\n最大的发射速度是500packet/s,最小的传输速度是350packet/s,对于这些流量强度是$500\\div350=1.428$用这些速度去运行，出现丢包的时间大约在31~34秒左右，并不能确定具体哪个时间会发生丢包，为什么？因为用户发生数据包有随机性，我们并不能控制每一个用户．\n\n\n**R22:列出一层都可以执行5个任务,并且是否有可能这些任务中有可以执行在两个或者多个层？**<br>\n任务: 封装本层的报文段, 设置各种参数, 对接受到的报文段进行差错检查, 还可能进行流量设置, 分组重组等等.多个层是可能执行相同的一个(或两个)任务的, 比如差错检验<br>\n**R23:互联网协议栈的五层是什么，每一层的的主要职责是什么？**\n互联网协议栈的五层从上到下分别是，应用层，传输层，网络层，链路层，物理层．关于他们的主要职责：在R20有讲到.\n\n**R24:什么是应用层报文（message）,传输层报文（segment),网络层数据报（Datagram）,链路层帧(Frame).**\n```mermaid\ngraph TD\nA[message]-->B[message+Headt=segment]-->C[segment+Headn=Datagram]-->D[Datagram+Headl=Frame];\n```\n<br>\n\n**R25:在互联网协议栈中路由器处理哪几层，链路交换机处理哪几层，主机处理哪几层？**<br>\n路由器处理１到３层(现代路由器里还有防火墙和缓存组件，也可以处理传输层)，链路交换机处理１－２两层，主机处理全５层．<br>\n\n**R26:病毒（virus）和虫（worms）有什么不同?**<br>\n病毒需要用户与其互动，有交互，需要人进行操作，例如ＱＱ发个网站点进网站被盗号等，虫就是不需要与用户进行互动，例如用户运行一个很脆弱的软件，恶意软件进来不需要用户统一直接运行，并且会自我复制自动寻找下一个脆弱的软件进行攻击．<Br>\n\n**R27:描述一下僵尸网络(botnet)是怎么形成的,以及怎么利用僵尸网络来进行DDoS攻击？**\n僵尸网络就是这个bad guy通过找到别人的应用或者是系统的漏洞，利用虫（worms)来侵入别人的主机，而这个虫又可以通过漏洞来复制和接着进行传播，僵尸网络的属性就是attacker可以远程通过命令来操控僵尸网络中的主机运作．而DDos（distributed denail-of-service attack）攻击就是通过成败上千台僵尸主机同时想目标主机发送信息，导致目标主机的带宽被占满从而使正确的信息无法传到目标主机．<br>\n![botnet](2020-03-11_20:03:1583929611_select.png)<br>\n**R28:假设Alice和Bob真正互相发送信息，同时假设Trudy定位自己在网络中，Trudy可以捕获所有Alice发生的消息，也可以发送任何消息给Bob,同理相对与Bob也一样，列举出Trudy处在这个位置上可以做的恶意的事情**<br>\n借钱打这个账户1008668001.\n","slug":"Chapter1-Review-Questions","published":1,"updated":"2020-11-14T14:40:36.592Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4rt0007r8s86hiv2h01","content":"<h2 id=\"关于计算机网络自顶向下的第一章的问题回答\"><a href=\"#关于计算机网络自顶向下的第一章的问题回答\" class=\"headerlink\" title=\" 关于计算机网络自顶向下的第一章的问题回答\"></a> 关于计算机网络自顶向下的第一章的问题回答</h2><p><strong>R1:主机和终端系统有什么不同？<br></strong><br>终端系统（end system）和主机(host)系统其实没有很大的区别都就具有连接网络和交换信息的能力，本质上没有很大的区别．但是在现实生活中主机常常指提供服务的一方，而终端指手机，手提电脑，台式电脑之类的．<br><br><strong>R2:protocol在维基百科上的定义<br></strong><br>protocol（协议）在维基百科上的定义是：给数据/信息在电子通信和网络上的传输制定的规则<br><br><strong>R3:为什么协议（protocol）如此重要？<br></strong><br>protocol由Internet engineering task force(IETF)制定，为了提供更好的更加有质量，更加安全的协议来给消费者使用，标准协议为了每个用户之间能够更有效的互相交流．例如：书上说的人打招呼的例子，如果没有协议就会乱套．<br><br><strong>R4:列出６个访问技术，以及将其分类家庭访问，企业访问和广域无线访问<br></strong><br><em>家庭访问：<br></em><br>1.DSL(digtal subscriber line):数字订阅通路<br><br>2.cable internet access: 有线上网，也可以叫做HFC(hybird fiber coax)：混合光纤同轴电缆<br><br>3.fiber to the home: 光纤到家（光纤）<br><br>4.Dial_up :数字拨号（用电话线<br><br>5.satellite:卫星<br><br><em>企业访问（家庭其实也可以）:<br></em><br>6.WIFI<br><br>7.Enternet<br><br>广域无线访问：<br>8.third/(fouth)-generation(3G)<br><br>9.LTE(long-term-Evolution)<br><br><strong>R5:HFC的传输速度是用户独享还是分享？是否可能在HFC的下游发生数据碰撞？<br></strong><br>HFC(hybird fiber coax)混合光纤同轴电缆也就是cable internet access有线连接，用的是电视公司提供的有线电视的电视线连接，因为这个互联网访问方式中用到了两种电缆线分别是光纤和同轴电缆，所以就叫HFC．<img src=\"2020-03-09_21:03_select.png\" alt=\"cable internet access\"><br>如图所示HFC是用户分享类型的，如图HFC的下载源只有一个所以downstream不冲突，但是上传（upstream）就有可能冲突，需要用协议来解决．<br><br><strong>R6:列出你所在城市的住宅访问技术（access technologies）,以及它们各种的下载，上传速度和价钱.</strong><br>目前中国电信能够提供基于ADSL、LAN以及FTTH光纤接入三种技术的宽带实现方式。速率从1Mbps到20Mbps不等，价格也从119到559不等。(抄的．．)<br><br><strong>R7:以太局域网（Enthernet LANs）的传输速度是多少？</strong><br><br>对于用户：通常有100Mbps,对于服务器：通常有１Gbps~10Gbps .<br></p>\n<p><strong>R8:Enthernet（以太网）运行的物理介质是什么，有那些？</strong><br><br>有同轴电缆（coaxial cable）光纤（fiber optic）,双绞铜线（twisted-pair-copper Wire).<br><br><strong>R9:提供Dial-up modems,DSL,HFC,FTTH的速度范围和判断其是用户独占还是用户共享</strong><br></p>\n<ul>\n<li>DSL:上传速度：2.5Mbps，下载速度：24Mbps.[2003]</li>\n<li>HFC:上传速度：30.7Mbps,下载速度：42.8Mbps.[DOCSIS.2.0]</li>\n<li>FTTH:理论上可以达到１Gbps实际平均下载速度可以达到20Mbps[2011]</li>\n<li>Dial-up modems: 56kbps [巨慢]<br></li>\n</ul>\n<p><strong>R10:描述现在最流行的无线连接技术，并且比较它们的差异</strong><br><br>最流行的无线连接技术:现在是WIFI和4G<br><br>差异：<br><br>WIFI是用户无线或有线连接到自己附近的路由器，通过路由器这个接入点连接网络如图：<br><img src=\"2020-03-10_15:03_select.png\" alt=\"WIFI\"><br><br>一般WIFI的范围是10米之内．WIFI提供的理论接入速度可以达到600Mbps(来自知乎，书上是54Mbps).<br><br>4G:4G用的是蜂窝技术（cellular telephony),4G提供的理论接入速度是100 Mbps,而且蜂窝技术的范围可以达到10千米内（范围更大）.<br><br><strong>R11:假设有只有一个分组交换机(parket switch)在发送端和接收端之间，传输速度发送端到分组交换机为R1,分组交换机到接收端之间为R2,假设使用的是存储转发交换机制(store-and-forward packet switch),计算端到端的总延迟[忽略处理延迟(processing delay),队列延迟(queuing delay),传播延迟（propagation delay）]</strong><br><br>那总延迟就等于这段路上的传输延迟（transmission delay）=R1+R2.<br></p>\n<p><strong>R12:电路交换网络(circuit-switched network)相比分组交换网络(packet-switch network)有什么优势，在电路交换网络中，TDM对比FDM有什么优势</strong><br><br>我觉得电路交换网络系统的缺点也可以算是它的优点，因为其在传输信息时需要建立连接状态（circuit）这个时候用户可以用这条链路上的所有的速度，但是此时其他的用户无法使用，此时如果建立链路没有在传输信息而是待工，这个时候链路资源就没办法有效利用，这就是circut-switch network的缺点，但是如果其的应用场景使用链路的密度很大，这个时候就很OK,因为其传输速度是满的．<br><br>TDM(Time-Division Multiplexing)时分复用对比FDM(Frequency-Division Multiplexing)频分复用的优势：<br><br><figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">TDM <span class=\"hljs-keyword\">is</span> relatively a newer technique used <span class=\"hljs-keyword\">for</span> digital signals.<br>TDM advantage <span class=\"hljs-keyword\">over</span> FDM <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">that</span> <span class=\"hljs-keyword\">it</span> offers bandwidth saving <span class=\"hljs-keyword\">with</span><br>ATDM (allocate <span class=\"hljs-built_in\">time</span> slots <span class=\"hljs-keyword\">on</span> demand dynamically) <span class=\"hljs-keyword\">and</span> <br>there <span class=\"hljs-keyword\">is</span> low interference <span class=\"hljs-keyword\">between</span> <span class=\"hljs-keyword\">the</span> signals <span class=\"hljs-keyword\">that</span> are being<br>multiplexed(<span class=\"hljs-keyword\">from</span> google)<br></code></pre></td></tr></table></figure><br><strong>R13:假设用户分享2Mbps的带宽，同时假设每个用户在传输数据是持续以1Mbps的带宽，链接网络时传输的占的时间与总时间的比值为20%</strong>　<br><br><strong>a.如果使用电路交换网络(circuit-switched network),可以支持多少用户使用.</strong> <br><br><strong>b.假设使用分组分配，两个或者更少用户同时传输数据的时候为什么实际上没有队列（排队）延迟，三个用户同时使用为什么会有队列延迟</strong><br><br><strong>c.计算用户正在传输的概率</strong><br><br><strong>d.假定现在有三个用户计算这个三个用户同时使用链路的概率，找到队列增长的概率</strong>(c.d应该是承接b)<br></p>\n<p>1.两个用户可以同时使用<br><br>2.因为两个或者更少用户用的时候没有超过链路的最大带宽，而三个以上用户就会超过，所以用分组分配就会有队列延迟．<br><br>3.用户真正传输的概率是20%<br><br>4.三个用户同时使用的概率是$1\\over5$ $\\times$ $1\\over5$ $\\times$ $1\\over5$ $=$ $1\\over125$,队列增长的概率也是 $1\\over125$<br><br><strong>R14:为什么处于同一个层级的ISPs互相对等，IXP是怎么赚钱的？</strong><br><br>一个城市与临近的另一个城市需要的用户需要数据传输如果这两个城市的ISPs没有进行对等(peer),则还需要通过更上一层的ISPs来达到互相连接，而更高一层的ISPs就会向低级的ISPs收费（收费的多少体现在流量上），对等（peer）了之后就不用通过更上一层ISPs,以达到节省开支的目的，而IXP(Internet Exchange Point)，IXP通常由电信公司以外的第三方公司来建立，主要作为ISPs的对接点，提供ISPs的对等服务．IXP赚钱通过想ISPs们收取少量的端口费盈利．<br><br><img src=\"2020-03-11_09:03_select.png\" alt=\"网络提供者的层级结构\"><br><strong>R15:一些内容的提供者也建立了它们自己的网络，描述一下Google,是什么促进它们建立自己的网络？</strong><br><br>google通过自己提供的TCP/IP网络把它分布在全球的大的小的数据中心连接起来（大的数据中心可能连接上百万个用户，小的可能几百个用户），<br>这些数据中心大多都是连接比较底层的用户或者ISPs提供，可以让谷歌绕过更高层级的ISPs．<br><br>促进他们建立自己网络的理由是：内容提供商（例如谷歌）建立自己的网络服务可以减少向上层ISPs支付费用，（因为谷歌可以直接和用户相连，或者连接更下层的ISPs和IXP,所以减少了中间ISPs的数量），同时也可以达到对用户更好的控制．<br><br><strong>R16:考虑在固定线路上从源主机发送一个包（packet）到目标主机，列出端到端的延迟，以及表示出那个延迟是常数，那个延迟是变量．</strong><br><br>分别有传输延迟（transmission delay），传播延迟(propagation delay)，队列延迟(queueing delay)，处理延迟(processing delay).<br><br>队列延迟是可变的，其他延迟是常数．<br><br><strong>R17:去这个小程序网站：Transmission Versus Propagation Delay，通过调整rates,propagation delay和packet sizes的大小，找到两个组合，使packet在源主机传输完成之前，第一个被发送的bit到达目标主机，和pakect在源主机完成传输之后，第一个被发送的bit才到达目标主机．</strong><br>第一个组合是：1000KM,1Mbps,100bytes.<br>第二个组合是：100KM,1Mbps,100bytes.<br><br><strong>R18:发送长度为1000bytes的packet,距离为2500Km,传播速度是$2.5$x$10^8$m/s,传输速度是2Mbps需要多长时间,更加抽象一点，发送长度为L的packet,距离为d,传播速度是s,传输速度是Rbps需要多长时间,在传递信息中的延迟是由打包的数据长度决定？还是传输的速度决定？</strong><br>假设忽略了处理延迟和队列延迟，那么需要的时间为<br><br>$1000\\div(2000000\\div8)+2500\\times 1000 \\div(2.5\\times10^8)=0.01+0.004=0.014s=14msec$<br><br>抽象一点：<br>$time=L\\times8/R+d/s$ <br><br>打包的数据长度和传输速度都不能呢个决定延迟大小．<br><br><strong>R19:假设源主机Ａ想传递一个很大的文件给目标主机Ｂ，在两者直接有三条链路，速度分别为R1=500kbps,R2=2Mbps,R3=1Mbps.</strong><br></p>\n<ul>\n<li>假设没有其他的流量在网络中，这个文件传输的吞吐量是多少？</li>\n<li>假设文件大小为4Mbytes,大致需要多长时间传输这个文件．</li>\n<li>重算1,2题现在R2降低到100kbps.<br><br>1.这个文件的吞吐量由最小的通路决定，文件吞吐量为500Kbps.<br><br>2.$T=4000000\\div(500\\times1000\\div 8)=64s$<br><br>3.如果R2降为100kbps,文件传输的吞吐量为100kbps,则4Mbytes的文件传输大致时间为$4000000\\div(100\\times1000\\div8)=320s$<br></li>\n</ul>\n<p><strong>R20:假设一个很大的文件从主机A传输到主机B,从一个比较高的角度描述一下主机A如何把一个文件变成一个个的packet，当一个packet到达交换机（switch）,哪些信息被用来指引（确定）packet前进路线，以及为什么互联网中分组交换需要模拟汽车从一个城市到另外一个城市并沿着路线不断问路的过程．</strong><br><br><img src=\"2020-03-11_14:03:1583906551_select.png\" alt=\"packet的运行路线\"><br><br>主机Ａ的文件本来是一个整体在层级结构中被称作消息(message),传递给下面的传输层（Transport layer),传输层中的TCP协议可以把message分割成一块一块加上一些信息放在每一块上组成段(segment),同时TCP协议拥有流控制（flow control）功能[匹配发生者和接受者的速度]，和拥堵控制机制（congestion-control mechanism),然后传递给网络层（Network layer),然后把段传到网络层(Network layer),网络层执行的是IP协议，以及一些路由协议（routing protocol）,同样是在每个段的头部加上一些信息组成数据报(Datagram),然后在传递给链路层（Link layer）,链路层用的协议不同链路上用的协议就不同，有：WIFI,Ethernet and cable network的DORSIS protocol,操作也是在数据报头部加入一些信息形成的桢（Frame）最后就是送到物理层（physical layer),物理层就把每一个桢中的数据一个bit一个bit的传播出去，物理层同样有协议，根据使用的物理介质的不同而不同．<br><br>一个packet到达交换机后根据每个packet中的IP地址找到前进路线．<br><br>第三问着实不懂．<br></p>\n<p><strong>R21:去执行Queuing and Loss这个小程序,然后找到最大发送速率和最小的传输速率是多少？对于这些速率，流量强度是多少？用这些速率运行该小程序并确定出现丢包要花费多长时间？然后第多次重复该实验，再次确定出现丢包花费多长时间。这些值有什么不同？为什么会有这种现象？</strong><br><br>最大的发射速度是500packet/s,最小的传输速度是350packet/s,对于这些流量强度是$500\\div350=1.428$用这些速度去运行，出现丢包的时间大约在31~34秒左右，并不能确定具体哪个时间会发生丢包，为什么？因为用户发生数据包有随机性，我们并不能控制每一个用户．</p>\n<p><strong>R22:列出一层都可以执行5个任务,并且是否有可能这些任务中有可以执行在两个或者多个层？</strong><br><br>任务: 封装本层的报文段, 设置各种参数, 对接受到的报文段进行差错检查, 还可能进行流量设置, 分组重组等等.多个层是可能执行相同的一个(或两个)任务的, 比如差错检验<br><br><strong>R23:互联网协议栈的五层是什么，每一层的的主要职责是什么？</strong><br>互联网协议栈的五层从上到下分别是，应用层，传输层，网络层，链路层，物理层．关于他们的主要职责：在R20有讲到.</p>\n<p><strong>R24:什么是应用层报文（message）,传输层报文（segment),网络层数据报（Datagram）,链路层帧(Frame).</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>A[message]--&gt;B[message+Headt&#x3D;segment]--&gt;C[segment+Headn&#x3D;Datagram]--&gt;D[Datagram+Headl&#x3D;Frame];<br></code></pre></td></tr></table></figure><br><br></p>\n<p><strong>R25:在互联网协议栈中路由器处理哪几层，链路交换机处理哪几层，主机处理哪几层？</strong><br><br>路由器处理１到３层(现代路由器里还有防火墙和缓存组件，也可以处理传输层)，链路交换机处理１－２两层，主机处理全５层．<br></p>\n<p><strong>R26:病毒（virus）和虫（worms）有什么不同?</strong><br><br>病毒需要用户与其互动，有交互，需要人进行操作，例如ＱＱ发个网站点进网站被盗号等，虫就是不需要与用户进行互动，例如用户运行一个很脆弱的软件，恶意软件进来不需要用户统一直接运行，并且会自我复制自动寻找下一个脆弱的软件进行攻击．<Br></p>\n<p><strong>R27:描述一下僵尸网络(botnet)是怎么形成的,以及怎么利用僵尸网络来进行DDoS攻击？</strong><br>僵尸网络就是这个bad guy通过找到别人的应用或者是系统的漏洞，利用虫（worms)来侵入别人的主机，而这个虫又可以通过漏洞来复制和接着进行传播，僵尸网络的属性就是attacker可以远程通过命令来操控僵尸网络中的主机运作．而DDos（distributed denail-of-service attack）攻击就是通过成败上千台僵尸主机同时想目标主机发送信息，导致目标主机的带宽被占满从而使正确的信息无法传到目标主机．<br><br><img src=\"2020-03-11_20:03:1583929611_select.png\" alt=\"botnet\"><br><br><strong>R28:假设Alice和Bob真正互相发送信息，同时假设Trudy定位自己在网络中，Trudy可以捕获所有Alice发生的消息，也可以发送任何消息给Bob,同理相对与Bob也一样，列举出Trudy处在这个位置上可以做的恶意的事情</strong><br><br>借钱打这个账户1008668001.</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"关于计算机网络自顶向下的第一章的问题回答\"><a href=\"#关于计算机网络自顶向下的第一章的问题回答\" class=\"headerlink\" title=\" 关于计算机网络自顶向下的第一章的问题回答\"></a> 关于计算机网络自顶向下的第一章的问题回答</h2><p><strong>R1:主机和终端系统有什么不同？<br></strong><br>终端系统（end system）和主机(host)系统其实没有很大的区别都就具有连接网络和交换信息的能力，本质上没有很大的区别．但是在现实生活中主机常常指提供服务的一方，而终端指手机，手提电脑，台式电脑之类的．<br><br><strong>R2:protocol在维基百科上的定义<br></strong><br>protocol（协议）在维基百科上的定义是：给数据/信息在电子通信和网络上的传输制定的规则<br><br><strong>R3:为什么协议（protocol）如此重要？<br></strong><br>protocol由Internet engineering task force(IETF)制定，为了提供更好的更加有质量，更加安全的协议来给消费者使用，标准协议为了每个用户之间能够更有效的互相交流．例如：书上说的人打招呼的例子，如果没有协议就会乱套．<br><br><strong>R4:列出６个访问技术，以及将其分类家庭访问，企业访问和广域无线访问<br></strong><br><em>家庭访问：<br></em><br>1.DSL(digtal subscriber line):数字订阅通路<br><br>2.cable internet access: 有线上网，也可以叫做HFC(hybird fiber coax)：混合光纤同轴电缆<br><br>3.fiber to the home: 光纤到家（光纤）<br><br>4.Dial_up :数字拨号（用电话线<br><br>5.satellite:卫星<br><br><em>企业访问（家庭其实也可以）:<br></em><br>6.WIFI<br><br>7.Enternet<br><br>广域无线访问：<br>8.third/(fouth)-generation(3G)<br><br>9.LTE(long-term-Evolution)<br><br><strong>R5:HFC的传输速度是用户独享还是分享？是否可能在HFC的下游发生数据碰撞？<br></strong><br>HFC(hybird fiber coax)混合光纤同轴电缆也就是cable internet access有线连接，用的是电视公司提供的有线电视的电视线连接，因为这个互联网访问方式中用到了两种电缆线分别是光纤和同轴电缆，所以就叫HFC．<img src=\"2020-03-09_21:03_select.png\" alt=\"cable internet access\"><br>如图所示HFC是用户分享类型的，如图HFC的下载源只有一个所以downstream不冲突，但是上传（upstream）就有可能冲突，需要用协议来解决．<br><br><strong>R6:列出你所在城市的住宅访问技术（access technologies）,以及它们各种的下载，上传速度和价钱.</strong><br>目前中国电信能够提供基于ADSL、LAN以及FTTH光纤接入三种技术的宽带实现方式。速率从1Mbps到20Mbps不等，价格也从119到559不等。(抄的．．)<br><br><strong>R7:以太局域网（Enthernet LANs）的传输速度是多少？</strong><br><br>对于用户：通常有100Mbps,对于服务器：通常有１Gbps~10Gbps .<br></p>\n<p><strong>R8:Enthernet（以太网）运行的物理介质是什么，有那些？</strong><br><br>有同轴电缆（coaxial cable）光纤（fiber optic）,双绞铜线（twisted-pair-copper Wire).<br><br><strong>R9:提供Dial-up modems,DSL,HFC,FTTH的速度范围和判断其是用户独占还是用户共享</strong><br></p>\n<ul>\n<li>DSL:上传速度：2.5Mbps，下载速度：24Mbps.[2003]</li>\n<li>HFC:上传速度：30.7Mbps,下载速度：42.8Mbps.[DOCSIS.2.0]</li>\n<li>FTTH:理论上可以达到１Gbps实际平均下载速度可以达到20Mbps[2011]</li>\n<li>Dial-up modems: 56kbps [巨慢]<br></li>\n</ul>\n<p><strong>R10:描述现在最流行的无线连接技术，并且比较它们的差异</strong><br><br>最流行的无线连接技术:现在是WIFI和4G<br><br>差异：<br><br>WIFI是用户无线或有线连接到自己附近的路由器，通过路由器这个接入点连接网络如图：<br><img src=\"2020-03-10_15:03_select.png\" alt=\"WIFI\"><br><br>一般WIFI的范围是10米之内．WIFI提供的理论接入速度可以达到600Mbps(来自知乎，书上是54Mbps).<br><br>4G:4G用的是蜂窝技术（cellular telephony),4G提供的理论接入速度是100 Mbps,而且蜂窝技术的范围可以达到10千米内（范围更大）.<br><br><strong>R11:假设有只有一个分组交换机(parket switch)在发送端和接收端之间，传输速度发送端到分组交换机为R1,分组交换机到接收端之间为R2,假设使用的是存储转发交换机制(store-and-forward packet switch),计算端到端的总延迟[忽略处理延迟(processing delay),队列延迟(queuing delay),传播延迟（propagation delay）]</strong><br><br>那总延迟就等于这段路上的传输延迟（transmission delay）=R1+R2.<br></p>\n<p><strong>R12:电路交换网络(circuit-switched network)相比分组交换网络(packet-switch network)有什么优势，在电路交换网络中，TDM对比FDM有什么优势</strong><br><br>我觉得电路交换网络系统的缺点也可以算是它的优点，因为其在传输信息时需要建立连接状态（circuit）这个时候用户可以用这条链路上的所有的速度，但是此时其他的用户无法使用，此时如果建立链路没有在传输信息而是待工，这个时候链路资源就没办法有效利用，这就是circut-switch network的缺点，但是如果其的应用场景使用链路的密度很大，这个时候就很OK,因为其传输速度是满的．<br><br>TDM(Time-Division Multiplexing)时分复用对比FDM(Frequency-Division Multiplexing)频分复用的优势：<br><br><figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\">TDM <span class=\"hljs-keyword\">is</span> relatively a newer technique used <span class=\"hljs-keyword\">for</span> digital signals.<br>TDM advantage <span class=\"hljs-keyword\">over</span> FDM <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">that</span> <span class=\"hljs-keyword\">it</span> offers bandwidth saving <span class=\"hljs-keyword\">with</span><br>ATDM (allocate <span class=\"hljs-built_in\">time</span> slots <span class=\"hljs-keyword\">on</span> demand dynamically) <span class=\"hljs-keyword\">and</span> <br>there <span class=\"hljs-keyword\">is</span> low interference <span class=\"hljs-keyword\">between</span> <span class=\"hljs-keyword\">the</span> signals <span class=\"hljs-keyword\">that</span> are being<br>multiplexed(<span class=\"hljs-keyword\">from</span> google)<br></code></pre></td></tr></table></figure><br><strong>R13:假设用户分享2Mbps的带宽，同时假设每个用户在传输数据是持续以1Mbps的带宽，链接网络时传输的占的时间与总时间的比值为20%</strong>　<br><br><strong>a.如果使用电路交换网络(circuit-switched network),可以支持多少用户使用.</strong> <br><br><strong>b.假设使用分组分配，两个或者更少用户同时传输数据的时候为什么实际上没有队列（排队）延迟，三个用户同时使用为什么会有队列延迟</strong><br><br><strong>c.计算用户正在传输的概率</strong><br><br><strong>d.假定现在有三个用户计算这个三个用户同时使用链路的概率，找到队列增长的概率</strong>(c.d应该是承接b)<br></p>\n<p>1.两个用户可以同时使用<br><br>2.因为两个或者更少用户用的时候没有超过链路的最大带宽，而三个以上用户就会超过，所以用分组分配就会有队列延迟．<br><br>3.用户真正传输的概率是20%<br><br>4.三个用户同时使用的概率是$1\\over5$ $\\times$ $1\\over5$ $\\times$ $1\\over5$ $=$ $1\\over125$,队列增长的概率也是 $1\\over125$<br><br><strong>R14:为什么处于同一个层级的ISPs互相对等，IXP是怎么赚钱的？</strong><br><br>一个城市与临近的另一个城市需要的用户需要数据传输如果这两个城市的ISPs没有进行对等(peer),则还需要通过更上一层的ISPs来达到互相连接，而更高一层的ISPs就会向低级的ISPs收费（收费的多少体现在流量上），对等（peer）了之后就不用通过更上一层ISPs,以达到节省开支的目的，而IXP(Internet Exchange Point)，IXP通常由电信公司以外的第三方公司来建立，主要作为ISPs的对接点，提供ISPs的对等服务．IXP赚钱通过想ISPs们收取少量的端口费盈利．<br><br><img src=\"2020-03-11_09:03_select.png\" alt=\"网络提供者的层级结构\"><br><strong>R15:一些内容的提供者也建立了它们自己的网络，描述一下Google,是什么促进它们建立自己的网络？</strong><br><br>google通过自己提供的TCP/IP网络把它分布在全球的大的小的数据中心连接起来（大的数据中心可能连接上百万个用户，小的可能几百个用户），<br>这些数据中心大多都是连接比较底层的用户或者ISPs提供，可以让谷歌绕过更高层级的ISPs．<br><br>促进他们建立自己网络的理由是：内容提供商（例如谷歌）建立自己的网络服务可以减少向上层ISPs支付费用，（因为谷歌可以直接和用户相连，或者连接更下层的ISPs和IXP,所以减少了中间ISPs的数量），同时也可以达到对用户更好的控制．<br><br><strong>R16:考虑在固定线路上从源主机发送一个包（packet）到目标主机，列出端到端的延迟，以及表示出那个延迟是常数，那个延迟是变量．</strong><br><br>分别有传输延迟（transmission delay），传播延迟(propagation delay)，队列延迟(queueing delay)，处理延迟(processing delay).<br><br>队列延迟是可变的，其他延迟是常数．<br><br><strong>R17:去这个小程序网站：Transmission Versus Propagation Delay，通过调整rates,propagation delay和packet sizes的大小，找到两个组合，使packet在源主机传输完成之前，第一个被发送的bit到达目标主机，和pakect在源主机完成传输之后，第一个被发送的bit才到达目标主机．</strong><br>第一个组合是：1000KM,1Mbps,100bytes.<br>第二个组合是：100KM,1Mbps,100bytes.<br><br><strong>R18:发送长度为1000bytes的packet,距离为2500Km,传播速度是$2.5$x$10^8$m/s,传输速度是2Mbps需要多长时间,更加抽象一点，发送长度为L的packet,距离为d,传播速度是s,传输速度是Rbps需要多长时间,在传递信息中的延迟是由打包的数据长度决定？还是传输的速度决定？</strong><br>假设忽略了处理延迟和队列延迟，那么需要的时间为<br><br>$1000\\div(2000000\\div8)+2500\\times 1000 \\div(2.5\\times10^8)=0.01+0.004=0.014s=14msec$<br><br>抽象一点：<br>$time=L\\times8/R+d/s$ <br><br>打包的数据长度和传输速度都不能呢个决定延迟大小．<br><br><strong>R19:假设源主机Ａ想传递一个很大的文件给目标主机Ｂ，在两者直接有三条链路，速度分别为R1=500kbps,R2=2Mbps,R3=1Mbps.</strong><br></p>\n<ul>\n<li>假设没有其他的流量在网络中，这个文件传输的吞吐量是多少？</li>\n<li>假设文件大小为4Mbytes,大致需要多长时间传输这个文件．</li>\n<li>重算1,2题现在R2降低到100kbps.<br><br>1.这个文件的吞吐量由最小的通路决定，文件吞吐量为500Kbps.<br><br>2.$T=4000000\\div(500\\times1000\\div 8)=64s$<br><br>3.如果R2降为100kbps,文件传输的吞吐量为100kbps,则4Mbytes的文件传输大致时间为$4000000\\div(100\\times1000\\div8)=320s$<br></li>\n</ul>\n<p><strong>R20:假设一个很大的文件从主机A传输到主机B,从一个比较高的角度描述一下主机A如何把一个文件变成一个个的packet，当一个packet到达交换机（switch）,哪些信息被用来指引（确定）packet前进路线，以及为什么互联网中分组交换需要模拟汽车从一个城市到另外一个城市并沿着路线不断问路的过程．</strong><br><br><img src=\"2020-03-11_14:03:1583906551_select.png\" alt=\"packet的运行路线\"><br><br>主机Ａ的文件本来是一个整体在层级结构中被称作消息(message),传递给下面的传输层（Transport layer),传输层中的TCP协议可以把message分割成一块一块加上一些信息放在每一块上组成段(segment),同时TCP协议拥有流控制（flow control）功能[匹配发生者和接受者的速度]，和拥堵控制机制（congestion-control mechanism),然后传递给网络层（Network layer),然后把段传到网络层(Network layer),网络层执行的是IP协议，以及一些路由协议（routing protocol）,同样是在每个段的头部加上一些信息组成数据报(Datagram),然后在传递给链路层（Link layer）,链路层用的协议不同链路上用的协议就不同，有：WIFI,Ethernet and cable network的DORSIS protocol,操作也是在数据报头部加入一些信息形成的桢（Frame）最后就是送到物理层（physical layer),物理层就把每一个桢中的数据一个bit一个bit的传播出去，物理层同样有协议，根据使用的物理介质的不同而不同．<br><br>一个packet到达交换机后根据每个packet中的IP地址找到前进路线．<br><br>第三问着实不懂．<br></p>\n<p><strong>R21:去执行Queuing and Loss这个小程序,然后找到最大发送速率和最小的传输速率是多少？对于这些速率，流量强度是多少？用这些速率运行该小程序并确定出现丢包要花费多长时间？然后第多次重复该实验，再次确定出现丢包花费多长时间。这些值有什么不同？为什么会有这种现象？</strong><br><br>最大的发射速度是500packet/s,最小的传输速度是350packet/s,对于这些流量强度是$500\\div350=1.428$用这些速度去运行，出现丢包的时间大约在31~34秒左右，并不能确定具体哪个时间会发生丢包，为什么？因为用户发生数据包有随机性，我们并不能控制每一个用户．</p>\n<p><strong>R22:列出一层都可以执行5个任务,并且是否有可能这些任务中有可以执行在两个或者多个层？</strong><br><br>任务: 封装本层的报文段, 设置各种参数, 对接受到的报文段进行差错检查, 还可能进行流量设置, 分组重组等等.多个层是可能执行相同的一个(或两个)任务的, 比如差错检验<br><br><strong>R23:互联网协议栈的五层是什么，每一层的的主要职责是什么？</strong><br>互联网协议栈的五层从上到下分别是，应用层，传输层，网络层，链路层，物理层．关于他们的主要职责：在R20有讲到.</p>\n<p><strong>R24:什么是应用层报文（message）,传输层报文（segment),网络层数据报（Datagram）,链路层帧(Frame).</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>A[message]--&gt;B[message+Headt&#x3D;segment]--&gt;C[segment+Headn&#x3D;Datagram]--&gt;D[Datagram+Headl&#x3D;Frame];<br></code></pre></td></tr></table></figure><br><br></p>\n<p><strong>R25:在互联网协议栈中路由器处理哪几层，链路交换机处理哪几层，主机处理哪几层？</strong><br><br>路由器处理１到３层(现代路由器里还有防火墙和缓存组件，也可以处理传输层)，链路交换机处理１－２两层，主机处理全５层．<br></p>\n<p><strong>R26:病毒（virus）和虫（worms）有什么不同?</strong><br><br>病毒需要用户与其互动，有交互，需要人进行操作，例如ＱＱ发个网站点进网站被盗号等，虫就是不需要与用户进行互动，例如用户运行一个很脆弱的软件，恶意软件进来不需要用户统一直接运行，并且会自我复制自动寻找下一个脆弱的软件进行攻击．<Br></p>\n<p><strong>R27:描述一下僵尸网络(botnet)是怎么形成的,以及怎么利用僵尸网络来进行DDoS攻击？</strong><br>僵尸网络就是这个bad guy通过找到别人的应用或者是系统的漏洞，利用虫（worms)来侵入别人的主机，而这个虫又可以通过漏洞来复制和接着进行传播，僵尸网络的属性就是attacker可以远程通过命令来操控僵尸网络中的主机运作．而DDos（distributed denail-of-service attack）攻击就是通过成败上千台僵尸主机同时想目标主机发送信息，导致目标主机的带宽被占满从而使正确的信息无法传到目标主机．<br><br><img src=\"2020-03-11_20:03:1583929611_select.png\" alt=\"botnet\"><br><br><strong>R28:假设Alice和Bob真正互相发送信息，同时假设Trudy定位自己在网络中，Trudy可以捕获所有Alice发生的消息，也可以发送任何消息给Bob,同理相对与Bob也一样，列举出Trudy处在这个位置上可以做的恶意的事情</strong><br><br>借钱打这个账户1008668001.</p>\n"},{"title":"Chapter3-Homework-Problems-and-Questions","index_img":"/Picture/Question-Mark.jpg","date":"2020-05-01T12:29:29.000Z","banner_img":null,"_content":"# Chapter3-Homework-Problems-and-Questions\n![1.png](1.png)<br>\n![2.png](2.png)<br>\n![3.png](3.png)<br>\n![4.png](4.png)<br>\n![5.png](5.png)<br>\n![6.png](6.png)<br>\n","source":"_posts/Chapter3-Homework-Problems-and-Questions.md","raw":"---\ntitle: Chapter3-Homework-Problems-and-Questions\nindex_img: /Picture/Question-Mark.jpg\ndate: 2020-05-01 20:29:29\ntags:\n- Computer Network A Top-Down Approach\ncategories:\n- Computer Network A Top-Down Approach \nbanner_img:\n---\n# Chapter3-Homework-Problems-and-Questions\n![1.png](1.png)<br>\n![2.png](2.png)<br>\n![3.png](3.png)<br>\n![4.png](4.png)<br>\n![5.png](5.png)<br>\n![6.png](6.png)<br>\n","slug":"Chapter3-Homework-Problems-and-Questions","published":1,"updated":"2020-11-14T14:40:36.592Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4ru0008r8s8aeem85px","content":"<h1 id=\"Chapter3-Homework-Problems-and-Questions\"><a href=\"#Chapter3-Homework-Problems-and-Questions\" class=\"headerlink\" title=\"Chapter3-Homework-Problems-and-Questions\"></a>Chapter3-Homework-Problems-and-Questions</h1><p><img src=\"1.png\" alt=\"1.png\"><br><br><img src=\"2.png\" alt=\"2.png\"><br><br><img src=\"3.png\" alt=\"3.png\"><br><br><img src=\"4.png\" alt=\"4.png\"><br><br><img src=\"5.png\" alt=\"5.png\"><br><br><img src=\"6.png\" alt=\"6.png\"><br></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Chapter3-Homework-Problems-and-Questions\"><a href=\"#Chapter3-Homework-Problems-and-Questions\" class=\"headerlink\" title=\"Chapter3-Homework-Problems-and-Questions\"></a>Chapter3-Homework-Problems-and-Questions</h1><p><img src=\"1.png\" alt=\"1.png\"><br><br><img src=\"2.png\" alt=\"2.png\"><br><br><img src=\"3.png\" alt=\"3.png\"><br><br><img src=\"4.png\" alt=\"4.png\"><br><br><img src=\"5.png\" alt=\"5.png\"><br><br><img src=\"6.png\" alt=\"6.png\"><br></p>\n"},{"title":"KMP算法","date":"2020-03-22T06:35:33.000Z","index_img":"/Picture/KMP.jpg","_content":"**感谢:<br>**\n[KMP算法 Next数组详解(【洛谷3375】KMP字符串匹配 )](https://blog.csdn.net/qq_30974369/article/details/74276186)<br>\n[从头到尾彻底理解 KMP](https://wiki.jikexueyuan.com/project/kmp-algorithm/define.html)<br>\n[字符串匹配的KMP算法](http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html)<br>\n\n\n\nKMP算法即是用来解决在一个字符串S(例如ABCDEFG)中快速查找字符串P(ABCD)的一个算法.<br>\n在介绍KMP算法之前我们先介绍暴力查找字符的算法<br>\n\n# 字符串的暴力查找法\n如下图用暴力查找法在字符串S(BB....DE)中寻找匹配项字符P(ABCDABD）．<br>\n\n\n*暴力查找法核心就是发现S[i]和P[j]不相等，S和P就开始回退，S回退到i=i-(j-1)处 ,j回退为０．具体看下图：<br>*\n\n\n**比较S[0]!=P[0]不相等则回退,i=i-(j-1)=0-0+1=1,j=0,相当于S向前进一步，而P回到j=0再开始比较**\n![BL1](KMP算法/BL1.png)\n**还是不相等，与上面情况相同**\n![BL2](KMP算法/BL2.png)\n**S[i]=p[i],i++,j++继续向下比较**\n![BL3](KMP算法/BL3.png)\n![BL4](KMP算法/BL4.png)\n**发现S[i]!=P[j]不相等开始回退**\n![BL5](KMP算法/BL5.png)\n**置i=i-(j-1)=9-(6-1)=4,j=0,继续比较,即开始比较S[4]=B和P[0]=A,**\n![BL6](KMP算法/BL6.png)\n\n可以发现暴力查找的缺点就在发现不相等，S和P都要回退，再重新比较，倘若S和P都特别长，假设S有10000个字符，P有1000个字符，S与P从第０个字符开始相等，而在第998个字符不等，这时，S就要从１号开始再和P从０开始重新比较，太费时．<br>\n\n有没有一种方法让i不改变而只改变j的方法来解决这个字符串的查找问题？没错就是KMP算法.<br>\n\n# KMP算法\n在介绍KMP算法之前，需要先介绍**部分匹配值表**<br>\n\n首先，要了解两个概念：\"前缀\"和\"后缀\"。 \"前缀\"指除了最后一个字符以外，一个字符串的全部头部组合；\"后缀\"指除了第一个字符以外，一个字符串的全部尾部组合。\n\n**部分匹配值**就是许多字符串＂前缀＂和＂后缀＂最长的共有元素长度，部分匹配值表就是各个子字符串的所以部分匹配值组成的表．<br>\n\n\n以字符串ABCDABD为例：<br>\n```\n-\"A\",的＂前缀＂和＂后缀＂都是空集　共有元素长度是0． \n-\"AB\",的＂前缀＂是｛A｝和＂后缀＂是｛B｝　共有元素长度是0 \n-\"ABC\",的＂前缀＂是｛A,AB｝和＂后缀＂是{C,BC}　共有元素长度是0. \n-\"ABCD\",的＂前缀＂是{A,AB,ABC}和＂后缀＂{D,CD,BCD}　共有元素长度是0 \n-\"ABCDA\",的＂前缀＂是｛A,AB,ABC,ABCD｝和＂后缀＂是{A,DA,CDA,BCDA}　共有元素是A长度是1 \n-\"ABCDAB\",的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA｝和＂后缀＂是｛B,AB,DAB,CDAB,BCDAB｝　共有元素是AB长度是2. \n-\"ABCDABD\",的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝和＂后缀＂是｛D,BD,ABD,DABD,CDABD,BCDABD,｝　共有元素长度0 \n```\n|字符串中各个子串|前缀|后缀|最大共有元素长度|\n|:-----:|:-----:|:-----:|:-----:|\n|A|空集|空集|0|\n|AB|｛A｝|｛B｝|0|\n|ABC|｛A,AB｝|{C,BC}|0|\n|ABCD|{A,AB,ABC}|{D,CD,BCD}　|0|\n|ABCDA|｛A,AB,ABC,ABCD｝|{A,DA,CDA,BCDA}|1|\n|ABCDAB|｛A,AB,ABC,ABCD,ABCDA｝|｛B,AB,DAB,CDAB,BCDAB｝|2|\n|ABCDABD|｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝|｛D,BD,ABD,DABD,CDABD,BCDABD,｝|0|\n\n<br>\n\n如下图KMP算法在遇到S[i]!=P[j]时，i不改变而只改变j，j会向右前进，移动的位数符合以下公式：<br>\n```\n移动位数（Z）　＝　已匹配位数(X)　－　匹配子字符串的部分匹配值(Y)　\n```\n\n\n![KMP1](KMP算法/KMP举例1.png)<br>\n\nP要向前移动的位数是6-2=4位，再进行比较．\n![KMP2](KMP算法/KMP举例2.png)\n\n\n**为什么移动的位数要等于4呢，如果小于4会怎样？<br>**\n答：因为移动的位数等于4，再次比较时P字符前Y个字符不会发生不匹配的现象，而如果移动位数小于4，则再次\n字符P,S再次比较时一定会发生不匹配的现象．<br>\n**为什么如果右移动小于Z就会发生不匹配的现象呢？**<br>\n答：如果向又移动３位则且要求再次比较不会发生不匹配的现象，就要求字符串P的前三位P0P1P2,与P3P4P5相等才不会发生不匹配的现象，但现在现实时P0P1和P4P5相等（部分匹配值为２），P0P1P2和P3P4P5不等，所以向右移动３一定会不匹配，同理向右移动２或者１都一样．<br>\n\n## KMP的代码实现\n\nnext[i]里面存放就是计算出来的部分匹配值表的变形<br>\n部分匹配值表：<br>\n|部分匹配值表|||||||\n|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|0|1|2|3|4|5|6|\n|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|\n|0|0|0|0|1|2|0|\n\n|next[i]表|相当于|部分匹配值|右移１位|再把next[0]|赋值为-1||\n|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|0|1|2|3|4|5|6|\n|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|\n|-1|0|0|0|0|1|2|\n\n**为什么要这么做呢？而且为什么要把next[0]赋值为-1呢？**<br>\n因为这样方便写代码．把next[0]赋成-1,我认为是用来做一个标记，如果next[0]=0当两字符串从第0个就不匹配时，向又移动的位数就是0-0=0,相当于不移动，所以把next[0]设置成-1,当j=-1时代表第０个不匹配，就不用公式计算移动位数，直接i++,j++<br>\n假设现在文本串 S 匹配到 i 位置，模块串 P 匹配到 j 位置<br>\n- 1.if (j == -1 || s[i] == p[j]) 则j++,i++<br>\n- 2.否则若s[i] != p[j]&& j!=-1,j=next[j]　(这里就相当于P向右边移动了j-next[j]位)<br>1\n\n\n\n\n``` c\n\nint KmpSearch(char* s, char* p)  \n{  \n    int i = 0;  \n    int j = 0;  \n    int sLen = strlen(s);  \n    int pLen = strlen(p);  \n    while (i < sLen && j < pLen)  \n    {  \n        //如果j = -1(第0个就不想等直接下一位)，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++      \n        if (j == -1 || s[i] == p[j])  \n        {  \n            i++;  \n            j++;  \n        }  \n        else  \n        {  \n            //如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j] (这条指令的效果相当于向右移动Z=j-next[j]位)     \n            //next[j]即为j所对应的next值        \n            j = next[j];  \n        }  \n    }  \n    if (j == pLen)  \n        return i - j;  \n    else  \n        return -1;  \n}  \n```\n执行上述代码需要的条件是已经计算出需要匹配字符P的next[i]数组．\n\n## next数组的计算\n\n**给出一个字符串P到底怎么计算出next[i]数组呢？**\n答：<br>\n\n**这就是给出的字符串，黑黑一坨**<br>\n![next1](KMP算法/next1.png)<br> \n**假设:字符串P的红色部分已经匹配，现在准备比较蓝色的位置**<br>\n![next2](KMP算法/next2.png)<br>\n**蓝色位置和绿色位置比较,(后缀的下一位和前缀的下一位比较)**\n![next3](KMP算法/next3.png)<br>\n**蓝色与绿色匹配不上,此时寻找红色前缀的最大公共前后缀，即两个灰色部分相等**<br>\n![next4](KMP算法/next4.png)<br>\n**由于两个红色部分是相同的所以红色后缀，也有两个灰色相同，（这四个灰色都是相同的）**<br>\n![next5](KMP算法/next5.png)<br>\n**最后用第１个灰色的下一位，也就是紫色，与第４个灰色的下一位，也就是蓝色相比较**<br>\n![next6](KMP算法/next6.png)<br>\n\n有点递归的感觉,具体代码如下：<br>\n```c\nvoid GetNext(char* p,int next[])\n{\n\tint pLen = strlen(p);\n\tnext[0] = -1;\n\tint k = -1;\n\tint j = 0;\n\twhile (j < pLen - 1)\n\t{\n\t\t//p[k]表示前缀，p[j]表示后缀\n//next[0]=-1,next[1]=0是固定的\n\t\tif (k == -1 || p[j] == p[k]) \n\t\t{\n\t\t\t++k;\n\t\t\t++j;\n\t\t\tnext[j] = k;\n\t\t}\n\t\telse \n\t\t{\n\t\t\tk = next[k];\n\t\t}\n\t}\n}\n```\n尽管next数组已经可以很到的提高匹配的效率，但是如果遇到极端情况例如：<br>\n|0|1|2|3|4|5|6|7|8|9|10|11|12||\n|:-----:|:-----:|:-----:|:-----:|:-----:|-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|A|A|A|A|A|A|A|A|B|B|B|B|B|.....|\n|A|A|A|A|A|A|A|A|A|\n|-1|0|1|2|3|4|5|6|7|这里是|next数组||\n这样子匹配时，在８这里发生不匹配发生移动，移动的位数是８－７＝１位，也就是下次比较时是P[7]和S[8]比较，但是这两者也不匹配，则又会移动，同样是同样是移动１位，根据上图可以看出，如果遇到这种情况，KMP算法就相当于遍历又变成了暴力搜索了．<br>\n\n**那是否有办法解决这个问题？**<br>\n答案是：改进next数组，得到的新数组就是nextval数组．<br>\n\n\n## nextval数组\nnextval数组值的求解方法：<br>\n**如果下标a的字符P[a]＝P[next[a]],则nextval[a]=nextval[next[a]]<br>如果不等则nextval[a]=next[a]**<br>\n所以得到的nextval数组：<br>\n|0|1|2|3|4|5|6|7|8|9|10|11|12||\n|:-----:|:-----:|:-----:|:-----:|:-----:|-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|A|A|A|A|A|A|A|A|B|B|B|B|B|.....|\n|A|A|A|A|A|A|A|A|A|\n|-1|0|1|2|3|4|5|6|7|next数组|||\n|-1|-1|-1|-1|-1|-1|-1|-1|-1|nextval数组||\n可以看到如果用nextval数组代替next数组，当在８号位不匹配时，直接遇到标志值，直接向右边移动了８位，再次比较时就是P[0]和S[8]比较了<br>\n \n\n**nextval数组是怎么解决这个问题的呢?**<br>\n答:下标为a的位置不匹配，next[a]表示的是(0~a-1),a个字符的部分匹配值**X**(**注意：部分匹配值是从１开始算的**)，所以0~X-1的字符是其匹配的前缀，P[next[a]]是匹配前缀的下一个数，所以如果P[a]=P[next[a]]再次跳到P[next[a]]这里比较还会不匹配，所以nextval[a]=nextval[next[a]]（相当于一个递归向前寻找），如果不相等，再次跳到这里比较就有意义，所以nextval[a]=next[a]\n","source":"_posts/KMP算法.md","raw":"---\ntitle: KMP算法\ndate: 2020-03-22 14:35:33\nindex_img: /Picture/KMP.jpg\ncategories:\n- 数据结构\ntags:\n- 数据结构\n---\n**感谢:<br>**\n[KMP算法 Next数组详解(【洛谷3375】KMP字符串匹配 )](https://blog.csdn.net/qq_30974369/article/details/74276186)<br>\n[从头到尾彻底理解 KMP](https://wiki.jikexueyuan.com/project/kmp-algorithm/define.html)<br>\n[字符串匹配的KMP算法](http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html)<br>\n\n\n\nKMP算法即是用来解决在一个字符串S(例如ABCDEFG)中快速查找字符串P(ABCD)的一个算法.<br>\n在介绍KMP算法之前我们先介绍暴力查找字符的算法<br>\n\n# 字符串的暴力查找法\n如下图用暴力查找法在字符串S(BB....DE)中寻找匹配项字符P(ABCDABD）．<br>\n\n\n*暴力查找法核心就是发现S[i]和P[j]不相等，S和P就开始回退，S回退到i=i-(j-1)处 ,j回退为０．具体看下图：<br>*\n\n\n**比较S[0]!=P[0]不相等则回退,i=i-(j-1)=0-0+1=1,j=0,相当于S向前进一步，而P回到j=0再开始比较**\n![BL1](KMP算法/BL1.png)\n**还是不相等，与上面情况相同**\n![BL2](KMP算法/BL2.png)\n**S[i]=p[i],i++,j++继续向下比较**\n![BL3](KMP算法/BL3.png)\n![BL4](KMP算法/BL4.png)\n**发现S[i]!=P[j]不相等开始回退**\n![BL5](KMP算法/BL5.png)\n**置i=i-(j-1)=9-(6-1)=4,j=0,继续比较,即开始比较S[4]=B和P[0]=A,**\n![BL6](KMP算法/BL6.png)\n\n可以发现暴力查找的缺点就在发现不相等，S和P都要回退，再重新比较，倘若S和P都特别长，假设S有10000个字符，P有1000个字符，S与P从第０个字符开始相等，而在第998个字符不等，这时，S就要从１号开始再和P从０开始重新比较，太费时．<br>\n\n有没有一种方法让i不改变而只改变j的方法来解决这个字符串的查找问题？没错就是KMP算法.<br>\n\n# KMP算法\n在介绍KMP算法之前，需要先介绍**部分匹配值表**<br>\n\n首先，要了解两个概念：\"前缀\"和\"后缀\"。 \"前缀\"指除了最后一个字符以外，一个字符串的全部头部组合；\"后缀\"指除了第一个字符以外，一个字符串的全部尾部组合。\n\n**部分匹配值**就是许多字符串＂前缀＂和＂后缀＂最长的共有元素长度，部分匹配值表就是各个子字符串的所以部分匹配值组成的表．<br>\n\n\n以字符串ABCDABD为例：<br>\n```\n-\"A\",的＂前缀＂和＂后缀＂都是空集　共有元素长度是0． \n-\"AB\",的＂前缀＂是｛A｝和＂后缀＂是｛B｝　共有元素长度是0 \n-\"ABC\",的＂前缀＂是｛A,AB｝和＂后缀＂是{C,BC}　共有元素长度是0. \n-\"ABCD\",的＂前缀＂是{A,AB,ABC}和＂后缀＂{D,CD,BCD}　共有元素长度是0 \n-\"ABCDA\",的＂前缀＂是｛A,AB,ABC,ABCD｝和＂后缀＂是{A,DA,CDA,BCDA}　共有元素是A长度是1 \n-\"ABCDAB\",的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA｝和＂后缀＂是｛B,AB,DAB,CDAB,BCDAB｝　共有元素是AB长度是2. \n-\"ABCDABD\",的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝和＂后缀＂是｛D,BD,ABD,DABD,CDABD,BCDABD,｝　共有元素长度0 \n```\n|字符串中各个子串|前缀|后缀|最大共有元素长度|\n|:-----:|:-----:|:-----:|:-----:|\n|A|空集|空集|0|\n|AB|｛A｝|｛B｝|0|\n|ABC|｛A,AB｝|{C,BC}|0|\n|ABCD|{A,AB,ABC}|{D,CD,BCD}　|0|\n|ABCDA|｛A,AB,ABC,ABCD｝|{A,DA,CDA,BCDA}|1|\n|ABCDAB|｛A,AB,ABC,ABCD,ABCDA｝|｛B,AB,DAB,CDAB,BCDAB｝|2|\n|ABCDABD|｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝|｛D,BD,ABD,DABD,CDABD,BCDABD,｝|0|\n\n<br>\n\n如下图KMP算法在遇到S[i]!=P[j]时，i不改变而只改变j，j会向右前进，移动的位数符合以下公式：<br>\n```\n移动位数（Z）　＝　已匹配位数(X)　－　匹配子字符串的部分匹配值(Y)　\n```\n\n\n![KMP1](KMP算法/KMP举例1.png)<br>\n\nP要向前移动的位数是6-2=4位，再进行比较．\n![KMP2](KMP算法/KMP举例2.png)\n\n\n**为什么移动的位数要等于4呢，如果小于4会怎样？<br>**\n答：因为移动的位数等于4，再次比较时P字符前Y个字符不会发生不匹配的现象，而如果移动位数小于4，则再次\n字符P,S再次比较时一定会发生不匹配的现象．<br>\n**为什么如果右移动小于Z就会发生不匹配的现象呢？**<br>\n答：如果向又移动３位则且要求再次比较不会发生不匹配的现象，就要求字符串P的前三位P0P1P2,与P3P4P5相等才不会发生不匹配的现象，但现在现实时P0P1和P4P5相等（部分匹配值为２），P0P1P2和P3P4P5不等，所以向右移动３一定会不匹配，同理向右移动２或者１都一样．<br>\n\n## KMP的代码实现\n\nnext[i]里面存放就是计算出来的部分匹配值表的变形<br>\n部分匹配值表：<br>\n|部分匹配值表|||||||\n|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|0|1|2|3|4|5|6|\n|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|\n|0|0|0|0|1|2|0|\n\n|next[i]表|相当于|部分匹配值|右移１位|再把next[0]|赋值为-1||\n|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|0|1|2|3|4|5|6|\n|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|\n|-1|0|0|0|0|1|2|\n\n**为什么要这么做呢？而且为什么要把next[0]赋值为-1呢？**<br>\n因为这样方便写代码．把next[0]赋成-1,我认为是用来做一个标记，如果next[0]=0当两字符串从第0个就不匹配时，向又移动的位数就是0-0=0,相当于不移动，所以把next[0]设置成-1,当j=-1时代表第０个不匹配，就不用公式计算移动位数，直接i++,j++<br>\n假设现在文本串 S 匹配到 i 位置，模块串 P 匹配到 j 位置<br>\n- 1.if (j == -1 || s[i] == p[j]) 则j++,i++<br>\n- 2.否则若s[i] != p[j]&& j!=-1,j=next[j]　(这里就相当于P向右边移动了j-next[j]位)<br>1\n\n\n\n\n``` c\n\nint KmpSearch(char* s, char* p)  \n{  \n    int i = 0;  \n    int j = 0;  \n    int sLen = strlen(s);  \n    int pLen = strlen(p);  \n    while (i < sLen && j < pLen)  \n    {  \n        //如果j = -1(第0个就不想等直接下一位)，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++      \n        if (j == -1 || s[i] == p[j])  \n        {  \n            i++;  \n            j++;  \n        }  \n        else  \n        {  \n            //如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j] (这条指令的效果相当于向右移动Z=j-next[j]位)     \n            //next[j]即为j所对应的next值        \n            j = next[j];  \n        }  \n    }  \n    if (j == pLen)  \n        return i - j;  \n    else  \n        return -1;  \n}  \n```\n执行上述代码需要的条件是已经计算出需要匹配字符P的next[i]数组．\n\n## next数组的计算\n\n**给出一个字符串P到底怎么计算出next[i]数组呢？**\n答：<br>\n\n**这就是给出的字符串，黑黑一坨**<br>\n![next1](KMP算法/next1.png)<br> \n**假设:字符串P的红色部分已经匹配，现在准备比较蓝色的位置**<br>\n![next2](KMP算法/next2.png)<br>\n**蓝色位置和绿色位置比较,(后缀的下一位和前缀的下一位比较)**\n![next3](KMP算法/next3.png)<br>\n**蓝色与绿色匹配不上,此时寻找红色前缀的最大公共前后缀，即两个灰色部分相等**<br>\n![next4](KMP算法/next4.png)<br>\n**由于两个红色部分是相同的所以红色后缀，也有两个灰色相同，（这四个灰色都是相同的）**<br>\n![next5](KMP算法/next5.png)<br>\n**最后用第１个灰色的下一位，也就是紫色，与第４个灰色的下一位，也就是蓝色相比较**<br>\n![next6](KMP算法/next6.png)<br>\n\n有点递归的感觉,具体代码如下：<br>\n```c\nvoid GetNext(char* p,int next[])\n{\n\tint pLen = strlen(p);\n\tnext[0] = -1;\n\tint k = -1;\n\tint j = 0;\n\twhile (j < pLen - 1)\n\t{\n\t\t//p[k]表示前缀，p[j]表示后缀\n//next[0]=-1,next[1]=0是固定的\n\t\tif (k == -1 || p[j] == p[k]) \n\t\t{\n\t\t\t++k;\n\t\t\t++j;\n\t\t\tnext[j] = k;\n\t\t}\n\t\telse \n\t\t{\n\t\t\tk = next[k];\n\t\t}\n\t}\n}\n```\n尽管next数组已经可以很到的提高匹配的效率，但是如果遇到极端情况例如：<br>\n|0|1|2|3|4|5|6|7|8|9|10|11|12||\n|:-----:|:-----:|:-----:|:-----:|:-----:|-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|A|A|A|A|A|A|A|A|B|B|B|B|B|.....|\n|A|A|A|A|A|A|A|A|A|\n|-1|0|1|2|3|4|5|6|7|这里是|next数组||\n这样子匹配时，在８这里发生不匹配发生移动，移动的位数是８－７＝１位，也就是下次比较时是P[7]和S[8]比较，但是这两者也不匹配，则又会移动，同样是同样是移动１位，根据上图可以看出，如果遇到这种情况，KMP算法就相当于遍历又变成了暴力搜索了．<br>\n\n**那是否有办法解决这个问题？**<br>\n答案是：改进next数组，得到的新数组就是nextval数组．<br>\n\n\n## nextval数组\nnextval数组值的求解方法：<br>\n**如果下标a的字符P[a]＝P[next[a]],则nextval[a]=nextval[next[a]]<br>如果不等则nextval[a]=next[a]**<br>\n所以得到的nextval数组：<br>\n|0|1|2|3|4|5|6|7|8|9|10|11|12||\n|:-----:|:-----:|:-----:|:-----:|:-----:|-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|\n|A|A|A|A|A|A|A|A|B|B|B|B|B|.....|\n|A|A|A|A|A|A|A|A|A|\n|-1|0|1|2|3|4|5|6|7|next数组|||\n|-1|-1|-1|-1|-1|-1|-1|-1|-1|nextval数组||\n可以看到如果用nextval数组代替next数组，当在８号位不匹配时，直接遇到标志值，直接向右边移动了８位，再次比较时就是P[0]和S[8]比较了<br>\n \n\n**nextval数组是怎么解决这个问题的呢?**<br>\n答:下标为a的位置不匹配，next[a]表示的是(0~a-1),a个字符的部分匹配值**X**(**注意：部分匹配值是从１开始算的**)，所以0~X-1的字符是其匹配的前缀，P[next[a]]是匹配前缀的下一个数，所以如果P[a]=P[next[a]]再次跳到P[next[a]]这里比较还会不匹配，所以nextval[a]=nextval[next[a]]（相当于一个递归向前寻找），如果不相等，再次跳到这里比较就有意义，所以nextval[a]=next[a]\n","slug":"KMP算法","published":1,"updated":"2020-11-14T14:40:36.608Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4rv0009r8s8cwdne9fr","content":"<p><strong>感谢:<br></strong><br><a href=\"https://blog.csdn.net/qq_30974369/article/details/74276186\">KMP算法 Next数组详解(【洛谷3375】KMP字符串匹配 )</a><br><br><a href=\"https://wiki.jikexueyuan.com/project/kmp-algorithm/define.html\">从头到尾彻底理解 KMP</a><br><br><a href=\"http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\">字符串匹配的KMP算法</a><br></p>\n<p>KMP算法即是用来解决在一个字符串S(例如ABCDEFG)中快速查找字符串P(ABCD)的一个算法.<br><br>在介绍KMP算法之前我们先介绍暴力查找字符的算法<br></p>\n<h1 id=\"字符串的暴力查找法\"><a href=\"#字符串的暴力查找法\" class=\"headerlink\" title=\"字符串的暴力查找法\"></a>字符串的暴力查找法</h1><p>如下图用暴力查找法在字符串S(BB….DE)中寻找匹配项字符P(ABCDABD）．<br></p>\n<p><em>暴力查找法核心就是发现S[i]和P[j]不相等，S和P就开始回退，S回退到i=i-(j-1)处 ,j回退为０．具体看下图：<br></em></p>\n<p><strong>比较S[0]!=P[0]不相等则回退,i=i-(j-1)=0-0+1=1,j=0,相当于S向前进一步，而P回到j=0再开始比较</strong><br><img src=\"KMP算法/BL1.png\" alt=\"BL1\"><br><strong>还是不相等，与上面情况相同</strong><br><img src=\"KMP算法/BL2.png\" alt=\"BL2\"><br><strong>S[i]=p[i],i++,j++继续向下比较</strong><br><img src=\"KMP算法/BL3.png\" alt=\"BL3\"><br><img src=\"KMP算法/BL4.png\" alt=\"BL4\"><br><strong>发现S[i]!=P[j]不相等开始回退</strong><br><img src=\"KMP算法/BL5.png\" alt=\"BL5\"><br><strong>置i=i-(j-1)=9-(6-1)=4,j=0,继续比较,即开始比较S[4]=B和P[0]=A,</strong><br><img src=\"KMP算法/BL6.png\" alt=\"BL6\"></p>\n<p>可以发现暴力查找的缺点就在发现不相等，S和P都要回退，再重新比较，倘若S和P都特别长，假设S有10000个字符，P有1000个字符，S与P从第０个字符开始相等，而在第998个字符不等，这时，S就要从１号开始再和P从０开始重新比较，太费时．<br></p>\n<p>有没有一种方法让i不改变而只改变j的方法来解决这个字符串的查找问题？没错就是KMP算法.<br></p>\n<h1 id=\"KMP算法\"><a href=\"#KMP算法\" class=\"headerlink\" title=\"KMP算法\"></a>KMP算法</h1><p>在介绍KMP算法之前，需要先介绍<strong>部分匹配值表</strong><br></p>\n<p>首先，要了解两个概念：”前缀”和”后缀”。 “前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。</p>\n<p><strong>部分匹配值</strong>就是许多字符串＂前缀＂和＂后缀＂最长的共有元素长度，部分匹配值表就是各个子字符串的所以部分匹配值组成的表．<br></p>\n<p>以字符串ABCDABD为例：<br><br><figure class=\"highlight haml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs haml\">-<span class=\"ruby\"><span class=\"hljs-string\">&quot;A&quot;</span>,的＂前缀＂和＂后缀＂都是空集　共有元素长度是<span class=\"hljs-number\">0</span>． </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;AB&quot;</span>,的＂前缀＂是｛A｝和＂后缀＂是｛B｝　共有元素长度是<span class=\"hljs-number\">0</span> </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABC&quot;</span>,的＂前缀＂是｛A,AB｝和＂后缀＂是&#123;C,BC&#125;　共有元素长度是<span class=\"hljs-number\">0</span>. </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCD&quot;</span>,的＂前缀＂是&#123;A,AB,ABC&#125;和＂后缀＂&#123;D,CD,BCD&#125;　共有元素长度是<span class=\"hljs-number\">0</span> </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCDA&quot;</span>,的＂前缀＂是｛A,AB,ABC,ABCD｝和＂后缀＂是&#123;A,DA,CDA,BCDA&#125;　共有元素是A长度是<span class=\"hljs-number\">1</span> </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCDAB&quot;</span>,的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA｝和＂后缀＂是｛B,AB,DAB,CDAB,BCDAB｝　共有元素是AB长度是<span class=\"hljs-number\">2</span>. </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCDABD&quot;</span>,的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝和＂后缀＂是｛D,BD,ABD,DABD,CDABD,BCDABD,｝　共有元素长度<span class=\"hljs-number\">0</span> </span><br></code></pre></td></tr></table></figure><br>|字符串中各个子串|前缀|后缀|最大共有元素长度|<br>|:——-:|:——-:|:——-:|:——-:|<br>|A|空集|空集|0|<br>|AB|｛A｝|｛B｝|0|<br>|ABC|｛A,AB｝|{C,BC}|0|<br>|ABCD|{A,AB,ABC}|{D,CD,BCD}　|0|<br>|ABCDA|｛A,AB,ABC,ABCD｝|{A,DA,CDA,BCDA}|1|<br>|ABCDAB|｛A,AB,ABC,ABCD,ABCDA｝|｛B,AB,DAB,CDAB,BCDAB｝|2|<br>|ABCDABD|｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝|｛D,BD,ABD,DABD,CDABD,BCDABD,｝|0|</p>\n<p><br></p>\n<p>如下图KMP算法在遇到S[i]!=P[j]时，i不改变而只改变j，j会向右前进，移动的位数符合以下公式：<br><br><figure class=\"highlight tp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tp\">移动位数（<span class=\"hljs-keyword\">Z</span>）　＝　已匹配位数(<span class=\"hljs-keyword\">X</span>)　－　匹配子字符串的部分匹配值(<span class=\"hljs-keyword\">Y</span>)　<br></code></pre></td></tr></table></figure></p>\n<p><img src=\"KMP算法/KMP举例1.png\" alt=\"KMP1\"><br></p>\n<p>P要向前移动的位数是6-2=4位，再进行比较．<br><img src=\"KMP算法/KMP举例2.png\" alt=\"KMP2\"></p>\n<p><strong>为什么移动的位数要等于4呢，如果小于4会怎样？<br></strong><br>答：因为移动的位数等于4，再次比较时P字符前Y个字符不会发生不匹配的现象，而如果移动位数小于4，则再次<br>字符P,S再次比较时一定会发生不匹配的现象．<br><br><strong>为什么如果右移动小于Z就会发生不匹配的现象呢？</strong><br><br>答：如果向又移动３位则且要求再次比较不会发生不匹配的现象，就要求字符串P的前三位P0P1P2,与P3P4P5相等才不会发生不匹配的现象，但现在现实时P0P1和P4P5相等（部分匹配值为２），P0P1P2和P3P4P5不等，所以向右移动３一定会不匹配，同理向右移动２或者１都一样．<br></p>\n<h2 id=\"KMP的代码实现\"><a href=\"#KMP的代码实现\" class=\"headerlink\" title=\"KMP的代码实现\"></a>KMP的代码实现</h2><p>next[i]里面存放就是计算出来的部分匹配值表的变形<br><br>部分匹配值表：<br><br>|部分匹配值表|||||||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|0|1|2|3|4|5|6|<br>|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|<br>|0|0|0|0|1|2|0|</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">next[i]表</th>\n<th style=\"text-align:center\">相当于</th>\n<th style=\"text-align:center\">部分匹配值</th>\n<th style=\"text-align:center\">右移１位</th>\n<th style=\"text-align:center\">再把next[0]</th>\n<th style=\"text-align:center\">赋值为-1</th>\n<th style=\"text-align:center\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">5</td>\n<td style=\"text-align:center\">6</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">AB</td>\n<td style=\"text-align:center\">ABC</td>\n<td style=\"text-align:center\">ABCD</td>\n<td style=\"text-align:center\">ABCDA</td>\n<td style=\"text-align:center\">ABCDAB</td>\n<td style=\"text-align:center\">ABCDABD</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-1</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>为什么要这么做呢？而且为什么要把next[0]赋值为-1呢？</strong><br><br>因为这样方便写代码．把next[0]赋成-1,我认为是用来做一个标记，如果next[0]=0当两字符串从第0个就不匹配时，向又移动的位数就是0-0=0,相当于不移动，所以把next[0]设置成-1,当j=-1时代表第０个不匹配，就不用公式计算移动位数，直接i++,j++<br><br>假设现在文本串 S 匹配到 i 位置，模块串 P 匹配到 j 位置<br></p>\n<ul>\n<li>1.if (j == -1 || s[i] == p[j]) 则j++,i++<br></li>\n<li>2.否则若s[i] != p[j]&amp;&amp; j!=-1,j=next[j]　(这里就相当于P向右边移动了j-next[j]位)<br>1</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">KmpSearch</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span>* s, <span class=\"hljs-keyword\">char</span>* p)</span>  </span><br><span class=\"hljs-function\"></span>&#123;  <br>    <span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>;  <br>    <span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>;  <br>    <span class=\"hljs-keyword\">int</span> sLen = <span class=\"hljs-built_in\">strlen</span>(s);  <br>    <span class=\"hljs-keyword\">int</span> pLen = <span class=\"hljs-built_in\">strlen</span>(p);  <br>    <span class=\"hljs-keyword\">while</span> (i &lt; sLen &amp;&amp; j &lt; pLen)  <br>    &#123;  <br>        <span class=\"hljs-comment\">//如果j = -1(第0个就不想等直接下一位)，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++      </span><br>        <span class=\"hljs-keyword\">if</span> (j == <span class=\"hljs-number\">-1</span> || s[i] == p[j])  <br>        &#123;  <br>            i++;  <br>            j++;  <br>        &#125;  <br>        <span class=\"hljs-keyword\">else</span>  <br>        &#123;  <br>            <span class=\"hljs-comment\">//如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j] (这条指令的效果相当于向右移动Z=j-next[j]位)     </span><br>            <span class=\"hljs-comment\">//next[j]即为j所对应的next值        </span><br>            j = next[j];  <br>        &#125;  <br>    &#125;  <br>    <span class=\"hljs-keyword\">if</span> (j == pLen)  <br>        <span class=\"hljs-keyword\">return</span> i - j;  <br>    <span class=\"hljs-keyword\">else</span>  <br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>;  <br>&#125;  <br></code></pre></td></tr></table></figure>\n<p>执行上述代码需要的条件是已经计算出需要匹配字符P的next[i]数组．</p>\n<h2 id=\"next数组的计算\"><a href=\"#next数组的计算\" class=\"headerlink\" title=\"next数组的计算\"></a>next数组的计算</h2><p><strong>给出一个字符串P到底怎么计算出next[i]数组呢？</strong><br>答：<br></p>\n<p><strong>这就是给出的字符串，黑黑一坨</strong><br><br><img src=\"KMP算法/next1.png\" alt=\"next1\"><br><br><strong>假设:字符串P的红色部分已经匹配，现在准备比较蓝色的位置</strong><br><br><img src=\"KMP算法/next2.png\" alt=\"next2\"><br><br><strong>蓝色位置和绿色位置比较,(后缀的下一位和前缀的下一位比较)</strong><br><img src=\"KMP算法/next3.png\" alt=\"next3\"><br><br><strong>蓝色与绿色匹配不上,此时寻找红色前缀的最大公共前后缀，即两个灰色部分相等</strong><br><br><img src=\"KMP算法/next4.png\" alt=\"next4\"><br><br><strong>由于两个红色部分是相同的所以红色后缀，也有两个灰色相同，（这四个灰色都是相同的）</strong><br><br><img src=\"KMP算法/next5.png\" alt=\"next5\"><br><br><strong>最后用第１个灰色的下一位，也就是紫色，与第４个灰色的下一位，也就是蓝色相比较</strong><br><br><img src=\"KMP算法/next6.png\" alt=\"next6\"><br></p>\n<p>有点递归的感觉,具体代码如下：<br><br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">GetNext</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span>* p,<span class=\"hljs-keyword\">int</span> next[])</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> pLen = <span class=\"hljs-built_in\">strlen</span>(p);<br>\tnext[<span class=\"hljs-number\">0</span>] = <span class=\"hljs-number\">-1</span>;<br>\t<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">-1</span>;<br>\t<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">while</span> (j &lt; pLen - <span class=\"hljs-number\">1</span>)<br>\t&#123;<br>\t\t<span class=\"hljs-comment\">//p[k]表示前缀，p[j]表示后缀</span><br><span class=\"hljs-comment\">//next[0]=-1,next[1]=0是固定的</span><br>\t\t<span class=\"hljs-keyword\">if</span> (k == <span class=\"hljs-number\">-1</span> || p[j] == p[k]) <br>\t\t&#123;<br>\t\t\t++k;<br>\t\t\t++j;<br>\t\t\tnext[j] = k;<br>\t\t&#125;<br>\t\t<span class=\"hljs-keyword\">else</span> <br>\t\t&#123;<br>\t\t\tk = next[k];<br>\t\t&#125;<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure><br>尽管next数组已经可以很到的提高匹配的效率，但是如果遇到极端情况例如：<br><br>|0|1|2|3|4|5|6|7|8|9|10|11|12||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|A|A|A|A|A|A|A|A|B|B|B|B|B|…..|<br>|A|A|A|A|A|A|A|A|A|<br>|-1|0|1|2|3|4|5|6|7|这里是|next数组||<br>这样子匹配时，在８这里发生不匹配发生移动，移动的位数是８－７＝１位，也就是下次比较时是P[7]和S[8]比较，但是这两者也不匹配，则又会移动，同样是同样是移动１位，根据上图可以看出，如果遇到这种情况，KMP算法就相当于遍历又变成了暴力搜索了．<br></p>\n<p><strong>那是否有办法解决这个问题？</strong><br><br>答案是：改进next数组，得到的新数组就是nextval数组．<br></p>\n<h2 id=\"nextval数组\"><a href=\"#nextval数组\" class=\"headerlink\" title=\"nextval数组\"></a>nextval数组</h2><p>nextval数组值的求解方法：<br><br><strong>如果下标a的字符P[a]＝P[next[a]],则nextval[a]=nextval[next[a]]<br>如果不等则nextval[a]=next[a]</strong><br><br>所以得到的nextval数组：<br><br>|0|1|2|3|4|5|6|7|8|9|10|11|12||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|A|A|A|A|A|A|A|A|B|B|B|B|B|…..|<br>|A|A|A|A|A|A|A|A|A|<br>|-1|0|1|2|3|4|5|6|7|next数组|||<br>|-1|-1|-1|-1|-1|-1|-1|-1|-1|nextval数组||<br>可以看到如果用nextval数组代替next数组，当在８号位不匹配时，直接遇到标志值，直接向右边移动了８位，再次比较时就是P[0]和S[8]比较了<br></p>\n<p><strong>nextval数组是怎么解决这个问题的呢?</strong><br><br>答:下标为a的位置不匹配，next[a]表示的是(0~a-1),a个字符的部分匹配值<strong>X</strong>(<strong>注意：部分匹配值是从１开始算的</strong>)，所以0~X-1的字符是其匹配的前缀，P[next[a]]是匹配前缀的下一个数，所以如果P[a]=P[next[a]]再次跳到P[next[a]]这里比较还会不匹配，所以nextval[a]=nextval[next[a]]（相当于一个递归向前寻找），如果不相等，再次跳到这里比较就有意义，所以nextval[a]=next[a]</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>感谢:<br></strong><br><a href=\"https://blog.csdn.net/qq_30974369/article/details/74276186\">KMP算法 Next数组详解(【洛谷3375】KMP字符串匹配 )</a><br><br><a href=\"https://wiki.jikexueyuan.com/project/kmp-algorithm/define.html\">从头到尾彻底理解 KMP</a><br><br><a href=\"http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html\">字符串匹配的KMP算法</a><br></p>\n<p>KMP算法即是用来解决在一个字符串S(例如ABCDEFG)中快速查找字符串P(ABCD)的一个算法.<br><br>在介绍KMP算法之前我们先介绍暴力查找字符的算法<br></p>\n<h1 id=\"字符串的暴力查找法\"><a href=\"#字符串的暴力查找法\" class=\"headerlink\" title=\"字符串的暴力查找法\"></a>字符串的暴力查找法</h1><p>如下图用暴力查找法在字符串S(BB….DE)中寻找匹配项字符P(ABCDABD）．<br></p>\n<p><em>暴力查找法核心就是发现S[i]和P[j]不相等，S和P就开始回退，S回退到i=i-(j-1)处 ,j回退为０．具体看下图：<br></em></p>\n<p><strong>比较S[0]!=P[0]不相等则回退,i=i-(j-1)=0-0+1=1,j=0,相当于S向前进一步，而P回到j=0再开始比较</strong><br><img src=\"KMP算法/BL1.png\" alt=\"BL1\"><br><strong>还是不相等，与上面情况相同</strong><br><img src=\"KMP算法/BL2.png\" alt=\"BL2\"><br><strong>S[i]=p[i],i++,j++继续向下比较</strong><br><img src=\"KMP算法/BL3.png\" alt=\"BL3\"><br><img src=\"KMP算法/BL4.png\" alt=\"BL4\"><br><strong>发现S[i]!=P[j]不相等开始回退</strong><br><img src=\"KMP算法/BL5.png\" alt=\"BL5\"><br><strong>置i=i-(j-1)=9-(6-1)=4,j=0,继续比较,即开始比较S[4]=B和P[0]=A,</strong><br><img src=\"KMP算法/BL6.png\" alt=\"BL6\"></p>\n<p>可以发现暴力查找的缺点就在发现不相等，S和P都要回退，再重新比较，倘若S和P都特别长，假设S有10000个字符，P有1000个字符，S与P从第０个字符开始相等，而在第998个字符不等，这时，S就要从１号开始再和P从０开始重新比较，太费时．<br></p>\n<p>有没有一种方法让i不改变而只改变j的方法来解决这个字符串的查找问题？没错就是KMP算法.<br></p>\n<h1 id=\"KMP算法\"><a href=\"#KMP算法\" class=\"headerlink\" title=\"KMP算法\"></a>KMP算法</h1><p>在介绍KMP算法之前，需要先介绍<strong>部分匹配值表</strong><br></p>\n<p>首先，要了解两个概念：”前缀”和”后缀”。 “前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。</p>\n<p><strong>部分匹配值</strong>就是许多字符串＂前缀＂和＂后缀＂最长的共有元素长度，部分匹配值表就是各个子字符串的所以部分匹配值组成的表．<br></p>\n<p>以字符串ABCDABD为例：<br><br><figure class=\"highlight haml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs haml\">-<span class=\"ruby\"><span class=\"hljs-string\">&quot;A&quot;</span>,的＂前缀＂和＂后缀＂都是空集　共有元素长度是<span class=\"hljs-number\">0</span>． </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;AB&quot;</span>,的＂前缀＂是｛A｝和＂后缀＂是｛B｝　共有元素长度是<span class=\"hljs-number\">0</span> </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABC&quot;</span>,的＂前缀＂是｛A,AB｝和＂后缀＂是&#123;C,BC&#125;　共有元素长度是<span class=\"hljs-number\">0</span>. </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCD&quot;</span>,的＂前缀＂是&#123;A,AB,ABC&#125;和＂后缀＂&#123;D,CD,BCD&#125;　共有元素长度是<span class=\"hljs-number\">0</span> </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCDA&quot;</span>,的＂前缀＂是｛A,AB,ABC,ABCD｝和＂后缀＂是&#123;A,DA,CDA,BCDA&#125;　共有元素是A长度是<span class=\"hljs-number\">1</span> </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCDAB&quot;</span>,的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA｝和＂后缀＂是｛B,AB,DAB,CDAB,BCDAB｝　共有元素是AB长度是<span class=\"hljs-number\">2</span>. </span><br><span class=\"ruby\">-<span class=\"hljs-string\">&quot;ABCDABD&quot;</span>,的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝和＂后缀＂是｛D,BD,ABD,DABD,CDABD,BCDABD,｝　共有元素长度<span class=\"hljs-number\">0</span> </span><br></code></pre></td></tr></table></figure><br>|字符串中各个子串|前缀|后缀|最大共有元素长度|<br>|:——-:|:——-:|:——-:|:——-:|<br>|A|空集|空集|0|<br>|AB|｛A｝|｛B｝|0|<br>|ABC|｛A,AB｝|{C,BC}|0|<br>|ABCD|{A,AB,ABC}|{D,CD,BCD}　|0|<br>|ABCDA|｛A,AB,ABC,ABCD｝|{A,DA,CDA,BCDA}|1|<br>|ABCDAB|｛A,AB,ABC,ABCD,ABCDA｝|｛B,AB,DAB,CDAB,BCDAB｝|2|<br>|ABCDABD|｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝|｛D,BD,ABD,DABD,CDABD,BCDABD,｝|0|</p>\n<p><br></p>\n<p>如下图KMP算法在遇到S[i]!=P[j]时，i不改变而只改变j，j会向右前进，移动的位数符合以下公式：<br><br><figure class=\"highlight tp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs tp\">移动位数（<span class=\"hljs-keyword\">Z</span>）　＝　已匹配位数(<span class=\"hljs-keyword\">X</span>)　－　匹配子字符串的部分匹配值(<span class=\"hljs-keyword\">Y</span>)　<br></code></pre></td></tr></table></figure></p>\n<p><img src=\"KMP算法/KMP举例1.png\" alt=\"KMP1\"><br></p>\n<p>P要向前移动的位数是6-2=4位，再进行比较．<br><img src=\"KMP算法/KMP举例2.png\" alt=\"KMP2\"></p>\n<p><strong>为什么移动的位数要等于4呢，如果小于4会怎样？<br></strong><br>答：因为移动的位数等于4，再次比较时P字符前Y个字符不会发生不匹配的现象，而如果移动位数小于4，则再次<br>字符P,S再次比较时一定会发生不匹配的现象．<br><br><strong>为什么如果右移动小于Z就会发生不匹配的现象呢？</strong><br><br>答：如果向又移动３位则且要求再次比较不会发生不匹配的现象，就要求字符串P的前三位P0P1P2,与P3P4P5相等才不会发生不匹配的现象，但现在现实时P0P1和P4P5相等（部分匹配值为２），P0P1P2和P3P4P5不等，所以向右移动３一定会不匹配，同理向右移动２或者１都一样．<br></p>\n<h2 id=\"KMP的代码实现\"><a href=\"#KMP的代码实现\" class=\"headerlink\" title=\"KMP的代码实现\"></a>KMP的代码实现</h2><p>next[i]里面存放就是计算出来的部分匹配值表的变形<br><br>部分匹配值表：<br><br>|部分匹配值表|||||||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|0|1|2|3|4|5|6|<br>|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|<br>|0|0|0|0|1|2|0|</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">next[i]表</th>\n<th style=\"text-align:center\">相当于</th>\n<th style=\"text-align:center\">部分匹配值</th>\n<th style=\"text-align:center\">右移１位</th>\n<th style=\"text-align:center\">再把next[0]</th>\n<th style=\"text-align:center\">赋值为-1</th>\n<th style=\"text-align:center\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">2</td>\n<td style=\"text-align:center\">3</td>\n<td style=\"text-align:center\">4</td>\n<td style=\"text-align:center\">5</td>\n<td style=\"text-align:center\">6</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">AB</td>\n<td style=\"text-align:center\">ABC</td>\n<td style=\"text-align:center\">ABCD</td>\n<td style=\"text-align:center\">ABCDA</td>\n<td style=\"text-align:center\">ABCDAB</td>\n<td style=\"text-align:center\">ABCDABD</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">-1</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">0</td>\n<td style=\"text-align:center\">1</td>\n<td style=\"text-align:center\">2</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>为什么要这么做呢？而且为什么要把next[0]赋值为-1呢？</strong><br><br>因为这样方便写代码．把next[0]赋成-1,我认为是用来做一个标记，如果next[0]=0当两字符串从第0个就不匹配时，向又移动的位数就是0-0=0,相当于不移动，所以把next[0]设置成-1,当j=-1时代表第０个不匹配，就不用公式计算移动位数，直接i++,j++<br><br>假设现在文本串 S 匹配到 i 位置，模块串 P 匹配到 j 位置<br></p>\n<ul>\n<li>1.if (j == -1 || s[i] == p[j]) 则j++,i++<br></li>\n<li>2.否则若s[i] != p[j]&amp;&amp; j!=-1,j=next[j]　(这里就相当于P向右边移动了j-next[j]位)<br>1</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">KmpSearch</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span>* s, <span class=\"hljs-keyword\">char</span>* p)</span>  </span><br><span class=\"hljs-function\"></span>&#123;  <br>    <span class=\"hljs-keyword\">int</span> i = <span class=\"hljs-number\">0</span>;  <br>    <span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>;  <br>    <span class=\"hljs-keyword\">int</span> sLen = <span class=\"hljs-built_in\">strlen</span>(s);  <br>    <span class=\"hljs-keyword\">int</span> pLen = <span class=\"hljs-built_in\">strlen</span>(p);  <br>    <span class=\"hljs-keyword\">while</span> (i &lt; sLen &amp;&amp; j &lt; pLen)  <br>    &#123;  <br>        <span class=\"hljs-comment\">//如果j = -1(第0个就不想等直接下一位)，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++      </span><br>        <span class=\"hljs-keyword\">if</span> (j == <span class=\"hljs-number\">-1</span> || s[i] == p[j])  <br>        &#123;  <br>            i++;  <br>            j++;  <br>        &#125;  <br>        <span class=\"hljs-keyword\">else</span>  <br>        &#123;  <br>            <span class=\"hljs-comment\">//如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j] (这条指令的效果相当于向右移动Z=j-next[j]位)     </span><br>            <span class=\"hljs-comment\">//next[j]即为j所对应的next值        </span><br>            j = next[j];  <br>        &#125;  <br>    &#125;  <br>    <span class=\"hljs-keyword\">if</span> (j == pLen)  <br>        <span class=\"hljs-keyword\">return</span> i - j;  <br>    <span class=\"hljs-keyword\">else</span>  <br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">-1</span>;  <br>&#125;  <br></code></pre></td></tr></table></figure>\n<p>执行上述代码需要的条件是已经计算出需要匹配字符P的next[i]数组．</p>\n<h2 id=\"next数组的计算\"><a href=\"#next数组的计算\" class=\"headerlink\" title=\"next数组的计算\"></a>next数组的计算</h2><p><strong>给出一个字符串P到底怎么计算出next[i]数组呢？</strong><br>答：<br></p>\n<p><strong>这就是给出的字符串，黑黑一坨</strong><br><br><img src=\"KMP算法/next1.png\" alt=\"next1\"><br><br><strong>假设:字符串P的红色部分已经匹配，现在准备比较蓝色的位置</strong><br><br><img src=\"KMP算法/next2.png\" alt=\"next2\"><br><br><strong>蓝色位置和绿色位置比较,(后缀的下一位和前缀的下一位比较)</strong><br><img src=\"KMP算法/next3.png\" alt=\"next3\"><br><br><strong>蓝色与绿色匹配不上,此时寻找红色前缀的最大公共前后缀，即两个灰色部分相等</strong><br><br><img src=\"KMP算法/next4.png\" alt=\"next4\"><br><br><strong>由于两个红色部分是相同的所以红色后缀，也有两个灰色相同，（这四个灰色都是相同的）</strong><br><br><img src=\"KMP算法/next5.png\" alt=\"next5\"><br><br><strong>最后用第１个灰色的下一位，也就是紫色，与第４个灰色的下一位，也就是蓝色相比较</strong><br><br><img src=\"KMP算法/next6.png\" alt=\"next6\"><br></p>\n<p>有点递归的感觉,具体代码如下：<br><br><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">GetNext</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">char</span>* p,<span class=\"hljs-keyword\">int</span> next[])</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> pLen = <span class=\"hljs-built_in\">strlen</span>(p);<br>\tnext[<span class=\"hljs-number\">0</span>] = <span class=\"hljs-number\">-1</span>;<br>\t<span class=\"hljs-keyword\">int</span> k = <span class=\"hljs-number\">-1</span>;<br>\t<span class=\"hljs-keyword\">int</span> j = <span class=\"hljs-number\">0</span>;<br>\t<span class=\"hljs-keyword\">while</span> (j &lt; pLen - <span class=\"hljs-number\">1</span>)<br>\t&#123;<br>\t\t<span class=\"hljs-comment\">//p[k]表示前缀，p[j]表示后缀</span><br><span class=\"hljs-comment\">//next[0]=-1,next[1]=0是固定的</span><br>\t\t<span class=\"hljs-keyword\">if</span> (k == <span class=\"hljs-number\">-1</span> || p[j] == p[k]) <br>\t\t&#123;<br>\t\t\t++k;<br>\t\t\t++j;<br>\t\t\tnext[j] = k;<br>\t\t&#125;<br>\t\t<span class=\"hljs-keyword\">else</span> <br>\t\t&#123;<br>\t\t\tk = next[k];<br>\t\t&#125;<br>\t&#125;<br>&#125;<br></code></pre></td></tr></table></figure><br>尽管next数组已经可以很到的提高匹配的效率，但是如果遇到极端情况例如：<br><br>|0|1|2|3|4|5|6|7|8|9|10|11|12||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|A|A|A|A|A|A|A|A|B|B|B|B|B|…..|<br>|A|A|A|A|A|A|A|A|A|<br>|-1|0|1|2|3|4|5|6|7|这里是|next数组||<br>这样子匹配时，在８这里发生不匹配发生移动，移动的位数是８－７＝１位，也就是下次比较时是P[7]和S[8]比较，但是这两者也不匹配，则又会移动，同样是同样是移动１位，根据上图可以看出，如果遇到这种情况，KMP算法就相当于遍历又变成了暴力搜索了．<br></p>\n<p><strong>那是否有办法解决这个问题？</strong><br><br>答案是：改进next数组，得到的新数组就是nextval数组．<br></p>\n<h2 id=\"nextval数组\"><a href=\"#nextval数组\" class=\"headerlink\" title=\"nextval数组\"></a>nextval数组</h2><p>nextval数组值的求解方法：<br><br><strong>如果下标a的字符P[a]＝P[next[a]],则nextval[a]=nextval[next[a]]<br>如果不等则nextval[a]=next[a]</strong><br><br>所以得到的nextval数组：<br><br>|0|1|2|3|4|5|6|7|8|9|10|11|12||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|A|A|A|A|A|A|A|A|B|B|B|B|B|…..|<br>|A|A|A|A|A|A|A|A|A|<br>|-1|0|1|2|3|4|5|6|7|next数组|||<br>|-1|-1|-1|-1|-1|-1|-1|-1|-1|nextval数组||<br>可以看到如果用nextval数组代替next数组，当在８号位不匹配时，直接遇到标志值，直接向右边移动了８位，再次比较时就是P[0]和S[8]比较了<br></p>\n<p><strong>nextval数组是怎么解决这个问题的呢?</strong><br><br>答:下标为a的位置不匹配，next[a]表示的是(0~a-1),a个字符的部分匹配值<strong>X</strong>(<strong>注意：部分匹配值是从１开始算的</strong>)，所以0~X-1的字符是其匹配的前缀，P[next[a]]是匹配前缀的下一个数，所以如果P[a]=P[next[a]]再次跳到P[next[a]]这里比较还会不匹配，所以nextval[a]=nextval[next[a]]（相当于一个递归向前寻找），如果不相等，再次跳到这里比较就有意义，所以nextval[a]=next[a]</p>\n"},{"title":"Manjaro-System-configuran","date":"2020-04-03T04:43:11.000Z","index_img":"/Picture/Manjaro.png","_content":"# Manjaro System finish picture\n\n![Manjaro](manjaro_System_finish.png)\n\n一下配置文件都在 https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System\n\n\n# 步骤\n## 1.首先下载镜像安装\n\n## ２．换源\n```\nsudo pacman-mirrors -i -c China -m rank\n```\n选择一个好用的就可以，我选择的是\nhttps://mirrors.sjtug.sjtu.edu.cn/manjaro/\n\n## ３．更新系统\n```\nsudo pacman -Syy \t#更新缓存\nsudo Pacman -Syyu\t#更新系统\n```\n## ４．配置VIM\n```\nsudo pacman -S vim\n```\n然后编辑$HOME下的.vim/vimrc文件即可<br>\n我的也是刚刚开始使用vim所以配置的内容并不丰富\n```\nsyntax on\nset number\nset relativenumber\nset hlsearch\nset smartcase\nset cursorline\nset cursorcolumn \nhi CursorColumn term=reverse ctermbg=white guibg=grey40\nhi CursorColumn ctermbg=238 guibg=grey40\nhi CursorLine term=underline cterm=underline guibg=grey40\nset ignorecase\nset cursorline\nset wrap\nset incsearch\nset showcmd\nset wildmenu\nmap s <nop>\nmap S :w<CR>\nmap Q :q<CR>\nmap R :source $MYVIMRC<CR>\nnoremap U 5k\nnoremap D 5j\ncall plug#begin('~/.vim/plugged')\nPlug 'vim-airline/vim-airline'\nPlug 'rakr/vim-one'\nPlug 'preservim/nerdtree'\nPlug 'ybian/smartim'\nPlug 'arcticicestudio/nord-vim' Plug 'connorholyday/vim-snazzy'\nPlug 'Valloric/YouCompleteMe'\nPlug 'iamcco/markdown-preview.nvim', { 'do': 'cd app & yarn install'  }\nPlug 'dhruvasagar/vim-table-mode', { 'on': 'TableModeToggle' }\nPlug 'vimwiki/vimwiki'\n\ncall plug#end()\t\n\nlet g:lightline = {\n\\ 'colorscheme': 'snazzy',\n\\ }\n\n```\n## 5.安装i3wm\n\n```\nsudo pacman -S i3\n```\n配置i3只需要配置~/.config/i3/config文件即可<br>\n安装完i3可能会有分辨率的问题可以修改$HOME下的.Xresources文件\n添加一下语句：<br>\n```\nXft.dpi = 200 \t#数字可以随便改\n```\n\n## 6.安装fcitx中文输入法\n```\n$ sudo pacman -S fcitx-sogoupinyin\n$ sudo pacman -S fcitx-im     # 全部安装\n$ sudo pacman -S fcitx-configtool     # 图形化配置工具\n```\n将fcitx添加到环境变量中去\n```\nsudo vim ~/.xprofile \n```\n然后在里面添加：\n```\nexport GTK_IM_MODULE=fcitx\nexport QT_IM_MODULE=fcitx\nexport XMODIFIERS=”@im=fcitx”\n```\n最后在~/.config/i3/config文件中添加\n```\nexec_always fcitx\n```\n这样开机就会直接启动fcitx了\n## 7.安装alacritty\n```\nsudo pacman -S alacritty\n```\n在i3中修改alacritty的快捷键为mod+回车键\n```\nbindsym $mod+return exec alacritty\n```\n配置alacritty只需要修改~/.config/alacritty/alacritty.yml文件即可<br>\n\n**如果~/.config/文件中没有alacritty/alacritty.yml文件就自己创建一个，或者上github上面复制一个就可以了**<br>\n如果要alacritty的透明的话要安装picom，这个软件就是以前的compton\n```\nsudo pacman -S picom\n```\n执行picom,然后修改~/.config/alacritty/alacritty.yml<br>\n```\nbackground_opacity: 0.75 \n```\n也可以修改成其他的值，我比较喜欢0.75的透明度<br>\n最后把picom加入i3的开机启动中\n\n\n\n## 8.安装SSR\n**无图像界面的SSR client**\n```\nwget http://www.texfox.com/ssr\nsudo mv ssr /usr/local/bin\nsudo chmod +x /usr/local/bin/ssr\nssr install\n```\n安装完成后配置SSR\n```\nssr config\n```\n把机场的SSR信息填入\n```\nssr start \n```\n就连接上了，有不明白的命令可以执行\n```\nssr help\n```\n**有图像界面的SSR client可以用electron-ssr**<br>\n链接：\nhttps://github.com/qingshuisiyuan/electron-ssr-backup\n## 9.安装google-chrome_(谷歌浏览器)\n```\nsudo pacman -S google-chrome\n```\n因为很经常用到google所以我把它设置成i3的快捷键，即在~/.config/i3/config中添加下面语句\n```\nbindsym $mod+c exec google-chrome-stable \n```\n## 10.安装Albert\n因为i3默认的$mod+d的菜单快捷键太丑了，所以安装Albert \n![albert](albert.png)<br>\n```\nsudo pacman -S albert\n```\n在i3中设置albert开机启动<br>\n```\nexec_always albert\n```\n然后修改albert的热键在终端第一次执行albert时会提醒修改热键，下图是我的配置．<br>\n\n![albert1](albert1.png)<br>\n![albert2](albert2.png)<br>\n因为我设置的热键ALT+d与i3的热键冲突（我的$mod键是ALT键）,所以我干脆取消了i3中的热键\n\n## 11. 安装ranger\n```\nsudo pacman -S ranger\n```\n配置ranger依旧是修改~/.config/ranger/rc.conf文件<br>\n**如果没有这些文件可以自己创建，详细看官方**\n## 12. 安装网易云音乐\n```\nsudo pacman -S netease-cloud-music\n```\n\n## 13.安装QQ/TIM\n```\nsudo pacman -S deepin.qq.com.office\nsudo pacman -S deepin.qq.com.im\n```\n由于在i3的环境下，一打开QQ就会闪退，解决方法是<br>\n```\nyaourt -S gnome-setting-daemon\n```\n然后运行/usr/lib/gsd-xsettings(最好在i3配置中设置开机启动)，然后就可以运行ＱＱ了\n\n\n## 14. 安装light \n因为i3装上之后亮度调节是个问题所以装一个light\n```\nsudo pacman -S light\n```\n要设置亮度的时候只要在命令行输入\n```\nsudo light -S 20 \t#数值可改，我一般用２０\n```\n\n","source":"_posts/Manjaro-System-configuran.md","raw":"---\ntitle: Manjaro-System-configuran\ndate: 2020-04-03 12:43:11\nindex_img: /Picture/Manjaro.png\ncategories:\n- 操作系统\ntags:\n- 操作系统\n---\n# Manjaro System finish picture\n\n![Manjaro](manjaro_System_finish.png)\n\n一下配置文件都在 https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System\n\n\n# 步骤\n## 1.首先下载镜像安装\n\n## ２．换源\n```\nsudo pacman-mirrors -i -c China -m rank\n```\n选择一个好用的就可以，我选择的是\nhttps://mirrors.sjtug.sjtu.edu.cn/manjaro/\n\n## ３．更新系统\n```\nsudo pacman -Syy \t#更新缓存\nsudo Pacman -Syyu\t#更新系统\n```\n## ４．配置VIM\n```\nsudo pacman -S vim\n```\n然后编辑$HOME下的.vim/vimrc文件即可<br>\n我的也是刚刚开始使用vim所以配置的内容并不丰富\n```\nsyntax on\nset number\nset relativenumber\nset hlsearch\nset smartcase\nset cursorline\nset cursorcolumn \nhi CursorColumn term=reverse ctermbg=white guibg=grey40\nhi CursorColumn ctermbg=238 guibg=grey40\nhi CursorLine term=underline cterm=underline guibg=grey40\nset ignorecase\nset cursorline\nset wrap\nset incsearch\nset showcmd\nset wildmenu\nmap s <nop>\nmap S :w<CR>\nmap Q :q<CR>\nmap R :source $MYVIMRC<CR>\nnoremap U 5k\nnoremap D 5j\ncall plug#begin('~/.vim/plugged')\nPlug 'vim-airline/vim-airline'\nPlug 'rakr/vim-one'\nPlug 'preservim/nerdtree'\nPlug 'ybian/smartim'\nPlug 'arcticicestudio/nord-vim' Plug 'connorholyday/vim-snazzy'\nPlug 'Valloric/YouCompleteMe'\nPlug 'iamcco/markdown-preview.nvim', { 'do': 'cd app & yarn install'  }\nPlug 'dhruvasagar/vim-table-mode', { 'on': 'TableModeToggle' }\nPlug 'vimwiki/vimwiki'\n\ncall plug#end()\t\n\nlet g:lightline = {\n\\ 'colorscheme': 'snazzy',\n\\ }\n\n```\n## 5.安装i3wm\n\n```\nsudo pacman -S i3\n```\n配置i3只需要配置~/.config/i3/config文件即可<br>\n安装完i3可能会有分辨率的问题可以修改$HOME下的.Xresources文件\n添加一下语句：<br>\n```\nXft.dpi = 200 \t#数字可以随便改\n```\n\n## 6.安装fcitx中文输入法\n```\n$ sudo pacman -S fcitx-sogoupinyin\n$ sudo pacman -S fcitx-im     # 全部安装\n$ sudo pacman -S fcitx-configtool     # 图形化配置工具\n```\n将fcitx添加到环境变量中去\n```\nsudo vim ~/.xprofile \n```\n然后在里面添加：\n```\nexport GTK_IM_MODULE=fcitx\nexport QT_IM_MODULE=fcitx\nexport XMODIFIERS=”@im=fcitx”\n```\n最后在~/.config/i3/config文件中添加\n```\nexec_always fcitx\n```\n这样开机就会直接启动fcitx了\n## 7.安装alacritty\n```\nsudo pacman -S alacritty\n```\n在i3中修改alacritty的快捷键为mod+回车键\n```\nbindsym $mod+return exec alacritty\n```\n配置alacritty只需要修改~/.config/alacritty/alacritty.yml文件即可<br>\n\n**如果~/.config/文件中没有alacritty/alacritty.yml文件就自己创建一个，或者上github上面复制一个就可以了**<br>\n如果要alacritty的透明的话要安装picom，这个软件就是以前的compton\n```\nsudo pacman -S picom\n```\n执行picom,然后修改~/.config/alacritty/alacritty.yml<br>\n```\nbackground_opacity: 0.75 \n```\n也可以修改成其他的值，我比较喜欢0.75的透明度<br>\n最后把picom加入i3的开机启动中\n\n\n\n## 8.安装SSR\n**无图像界面的SSR client**\n```\nwget http://www.texfox.com/ssr\nsudo mv ssr /usr/local/bin\nsudo chmod +x /usr/local/bin/ssr\nssr install\n```\n安装完成后配置SSR\n```\nssr config\n```\n把机场的SSR信息填入\n```\nssr start \n```\n就连接上了，有不明白的命令可以执行\n```\nssr help\n```\n**有图像界面的SSR client可以用electron-ssr**<br>\n链接：\nhttps://github.com/qingshuisiyuan/electron-ssr-backup\n## 9.安装google-chrome_(谷歌浏览器)\n```\nsudo pacman -S google-chrome\n```\n因为很经常用到google所以我把它设置成i3的快捷键，即在~/.config/i3/config中添加下面语句\n```\nbindsym $mod+c exec google-chrome-stable \n```\n## 10.安装Albert\n因为i3默认的$mod+d的菜单快捷键太丑了，所以安装Albert \n![albert](albert.png)<br>\n```\nsudo pacman -S albert\n```\n在i3中设置albert开机启动<br>\n```\nexec_always albert\n```\n然后修改albert的热键在终端第一次执行albert时会提醒修改热键，下图是我的配置．<br>\n\n![albert1](albert1.png)<br>\n![albert2](albert2.png)<br>\n因为我设置的热键ALT+d与i3的热键冲突（我的$mod键是ALT键）,所以我干脆取消了i3中的热键\n\n## 11. 安装ranger\n```\nsudo pacman -S ranger\n```\n配置ranger依旧是修改~/.config/ranger/rc.conf文件<br>\n**如果没有这些文件可以自己创建，详细看官方**\n## 12. 安装网易云音乐\n```\nsudo pacman -S netease-cloud-music\n```\n\n## 13.安装QQ/TIM\n```\nsudo pacman -S deepin.qq.com.office\nsudo pacman -S deepin.qq.com.im\n```\n由于在i3的环境下，一打开QQ就会闪退，解决方法是<br>\n```\nyaourt -S gnome-setting-daemon\n```\n然后运行/usr/lib/gsd-xsettings(最好在i3配置中设置开机启动)，然后就可以运行ＱＱ了\n\n\n## 14. 安装light \n因为i3装上之后亮度调节是个问题所以装一个light\n```\nsudo pacman -S light\n```\n要设置亮度的时候只要在命令行输入\n```\nsudo light -S 20 \t#数值可改，我一般用２０\n```\n\n","slug":"Manjaro-System-configuran","published":1,"updated":"2020-11-14T14:40:36.608Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4ry000cr8s87kusf251","content":"<h1 id=\"Manjaro-System-finish-picture\"><a href=\"#Manjaro-System-finish-picture\" class=\"headerlink\" title=\"Manjaro System finish picture\"></a>Manjaro System finish picture</h1><p><img src=\"manjaro_System_finish.png\" alt=\"Manjaro\"></p>\n<p>一下配置文件都在 <a href=\"https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System\">https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System</a></p>\n<h1 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h1><h2 id=\"1-首先下载镜像安装\"><a href=\"#1-首先下载镜像安装\" class=\"headerlink\" title=\"1.首先下载镜像安装\"></a>1.首先下载镜像安装</h2><h2 id=\"２．换源\"><a href=\"#２．换源\" class=\"headerlink\" title=\"２．换源\"></a>２．换源</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman-mirrors -i -c China -m rank</span><br></code></pre></td></tr></table></figure>\n<p>选择一个好用的就可以，我选择的是<br><a href=\"https://mirrors.sjtug.sjtu.edu.cn/manjaro/\">https://mirrors.sjtug.sjtu.edu.cn/manjaro/</a></p>\n<h2 id=\"３．更新系统\"><a href=\"#３．更新系统\" class=\"headerlink\" title=\"３．更新系统\"></a>３．更新系统</h2><figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">sudo</span> pacman -Syy \t<span class=\"hljs-comment\">#更新缓存</span><br>sudo Pacman -Syyu\t<span class=\"hljs-comment\">#更新系统</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"４．配置VIM\"><a href=\"#４．配置VIM\" class=\"headerlink\" title=\"４．配置VIM\"></a>４．配置VIM</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S vim</span><br></code></pre></td></tr></table></figure>\n<p>然后编辑$HOME下的.vim/vimrc文件即可<br><br>我的也是刚刚开始使用vim所以配置的内容并不丰富<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gams\">syntax on<br><span class=\"hljs-keyword\">set</span> number<br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">relativenumber</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">hlsearch</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">smartcase</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">cursorline</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">cursorcolumn</span> <br>hi <span class=\"hljs-comment\">CursorColumn term=reverse ctermbg=white guibg=grey40</span><br>hi <span class=\"hljs-comment\">CursorColumn ctermbg=238 guibg=grey40</span><br>hi <span class=\"hljs-comment\">CursorLine term=underline cterm=underline guibg=grey40</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">ignorecase</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">cursorline</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">wrap</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">incsearch</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">showcmd</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">wildmenu</span><br>map <span class=\"hljs-comment\">s &lt;nop&gt;</span><br>map <span class=\"hljs-comment\">S :w&lt;CR&gt;</span><br>map <span class=\"hljs-comment\">Q :q&lt;CR&gt;</span><br>map <span class=\"hljs-comment\">R :source $MYVIMRC&lt;CR&gt;</span><br>noremap <span class=\"hljs-comment\">U 5k</span><br>noremap <span class=\"hljs-comment\">D 5j</span><br>call <span class=\"hljs-comment\">plug#begin(</span><span class=\"hljs-comment\">&#x27;~/.vim/plugged&#x27;</span><span class=\"hljs-comment\">)</span><br>Plug <span class=\"hljs-comment\">&#x27;vim-airline/vim-airline&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;rakr/vim-one&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;preservim/nerdtree&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;ybian/smartim&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;arcticicestudio/nord-vim&#x27;</span> <span class=\"hljs-comment\">Plug</span> <span class=\"hljs-comment\">&#x27;connorholyday/vim-snazzy&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;Valloric/YouCompleteMe&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;iamcco/markdown-preview.nvim&#x27;</span><span class=\"hljs-comment\">, &#123;</span> <span class=\"hljs-comment\">&#x27;do&#x27;</span><span class=\"hljs-comment\">:</span> <span class=\"hljs-comment\">&#x27;cd app &amp; yarn install&#x27;</span>  <span class=\"hljs-comment\">&#125;</span><br>Plug <span class=\"hljs-comment\">&#x27;dhruvasagar/vim-table-mode&#x27;</span><span class=\"hljs-comment\">, &#123;</span> <span class=\"hljs-comment\">&#x27;on&#x27;</span><span class=\"hljs-comment\">:</span> <span class=\"hljs-comment\">&#x27;TableModeToggle&#x27;</span> <span class=\"hljs-comment\">&#125;</span><br>Plug <span class=\"hljs-comment\">&#x27;vimwiki/vimwiki&#x27;</span><br><br>call <span class=\"hljs-comment\">plug#end()</span>\t<br><br>let <span class=\"hljs-comment\">g:lightline = &#123;</span><br>\\ <span class=\"hljs-string\">&#x27;colorscheme&#x27;</span>: <span class=\"hljs-string\">&#x27;snazzy&#x27;</span>,<br>\\ &#125;<br><br></code></pre></td></tr></table></figure></p>\n<h2 id=\"5-安装i3wm\"><a href=\"#5-安装i3wm\" class=\"headerlink\" title=\"5.安装i3wm\"></a>5.安装i3wm</h2><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">sudo</span> pacman -S i<span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n<p>配置i3只需要配置~/.config/i3/config文件即可<br><br>安装完i3可能会有分辨率的问题可以修改$HOME下的.Xresources文件<br>添加一下语句：<br><br><figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ini\"><span class=\"hljs-attr\">Xft.dpi</span> = <span class=\"hljs-number\">200</span> \t<span class=\"hljs-comment\">#数字可以随便改</span><br></code></pre></td></tr></table></figure></p>\n<h2 id=\"6-安装fcitx中文输入法\"><a href=\"#6-安装fcitx中文输入法\" class=\"headerlink\" title=\"6.安装fcitx中文输入法\"></a>6.安装fcitx中文输入法</h2><figure class=\"highlight elixir\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs elixir\"><span class=\"hljs-variable\">$ </span>sudo pacman -S fcitx-sogoupinyin<br><span class=\"hljs-variable\">$ </span>sudo pacman -S fcitx-im     <span class=\"hljs-comment\"># 全部安装</span><br><span class=\"hljs-variable\">$ </span>sudo pacman -S fcitx-configtool     <span class=\"hljs-comment\"># 图形化配置工具</span><br></code></pre></td></tr></table></figure>\n<p>将fcitx添加到环境变量中去<br><figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">sudo</span> <span class=\"hljs-selector-tag\">vim</span> ~/<span class=\"hljs-selector-class\">.xprofile</span> <br></code></pre></td></tr></table></figure><br>然后在里面添加：<br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\"><span class=\"hljs-builtin-name\">export</span> <span class=\"hljs-attribute\">GTK_IM_MODULE</span>=fcitx<br><span class=\"hljs-builtin-name\">export</span> <span class=\"hljs-attribute\">QT_IM_MODULE</span>=fcitx<br><span class=\"hljs-builtin-name\">export</span> <span class=\"hljs-attribute\">XMODIFIERS</span>=”@im=fcitx”<br></code></pre></td></tr></table></figure><br>最后在~/.config/i3/config文件中添加<br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">exec_always fcitx</span><br></code></pre></td></tr></table></figure><br>这样开机就会直接启动fcitx了</p>\n<h2 id=\"7-安装alacritty\"><a href=\"#7-安装alacritty\" class=\"headerlink\" title=\"7.安装alacritty\"></a>7.安装alacritty</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S alacritty</span><br></code></pre></td></tr></table></figure>\n<p>在i3中修改alacritty的快捷键为mod+回车键<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">bindsym <span class=\"hljs-variable\">$mod</span>+<span class=\"hljs-built_in\">return</span> <span class=\"hljs-built_in\">exec</span> alacritty<br></code></pre></td></tr></table></figure><br>配置alacritty只需要修改~/.config/alacritty/alacritty.yml文件即可<br></p>\n<p><strong>如果~/.config/文件中没有alacritty/alacritty.yml文件就自己创建一个，或者上github上面复制一个就可以了</strong><br><br>如果要alacritty的透明的话要安装picom，这个软件就是以前的compton<br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S picom</span><br></code></pre></td></tr></table></figure><br>执行picom,然后修改~/.config/alacritty/alacritty.yml<br><br><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">background_opacity</span>: <span class=\"hljs-number\">0</span>.<span class=\"hljs-number\">75</span> <br></code></pre></td></tr></table></figure><br>也可以修改成其他的值，我比较喜欢0.75的透明度<br><br>最后把picom加入i3的开机启动中</p>\n<h2 id=\"8-安装SSR\"><a href=\"#8-安装SSR\" class=\"headerlink\" title=\"8.安装SSR\"></a>8.安装SSR</h2><p><strong>无图像界面的SSR client</strong><br><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">wget http:<span class=\"hljs-regexp\">//</span>www.texfox.com/ssr<br>sudo mv ssr <span class=\"hljs-regexp\">/usr/</span>local/bin<br>sudo chmod +x <span class=\"hljs-regexp\">/usr/</span>local<span class=\"hljs-regexp\">/bin/</span>ssr<br>ssr install<br></code></pre></td></tr></table></figure><br>安装完成后配置SSR<br><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\">ssr <span class=\"hljs-built_in\">config</span><br></code></pre></td></tr></table></figure><br>把机场的SSR信息填入<br><figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">ssr <span class=\"hljs-literal\">start</span> <br></code></pre></td></tr></table></figure><br>就连接上了，有不明白的命令可以执行<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">ssr <span class=\"hljs-built_in\">help</span><br></code></pre></td></tr></table></figure><br><strong>有图像界面的SSR client可以用electron-ssr</strong><br><br>链接：<br><a href=\"https://github.com/qingshuisiyuan/electron-ssr-backup\">https://github.com/qingshuisiyuan/electron-ssr-backup</a></p>\n<h2 id=\"9-安装google-chrome-谷歌浏览器\"><a href=\"#9-安装google-chrome-谷歌浏览器\" class=\"headerlink\" title=\"9.安装google-chrome_(谷歌浏览器)\"></a>9.安装google-chrome_(谷歌浏览器)</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S google-chrome</span><br></code></pre></td></tr></table></figure>\n<p>因为很经常用到google所以我把它设置成i3的快捷键，即在~/.config/i3/config中添加下面语句<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">bindsym <span class=\"hljs-variable\">$mod</span>+c <span class=\"hljs-built_in\">exec</span> google-chrome-stable <br></code></pre></td></tr></table></figure></p>\n<h2 id=\"10-安装Albert\"><a href=\"#10-安装Albert\" class=\"headerlink\" title=\"10.安装Albert\"></a>10.安装Albert</h2><p>因为i3默认的$mod+d的菜单快捷键太丑了，所以安装Albert<br><img src=\"albert.png\" alt=\"albert\"><br><br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S albert</span><br></code></pre></td></tr></table></figure><br>在i3中设置albert开机启动<br><br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">exec_always albert</span><br></code></pre></td></tr></table></figure><br>然后修改albert的热键在终端第一次执行albert时会提醒修改热键，下图是我的配置．<br></p>\n<p><img src=\"albert1.png\" alt=\"albert1\"><br><br><img src=\"albert2.png\" alt=\"albert2\"><br><br>因为我设置的热键ALT+d与i3的热键冲突（我的$mod键是ALT键）,所以我干脆取消了i3中的热键</p>\n<h2 id=\"11-安装ranger\"><a href=\"#11-安装ranger\" class=\"headerlink\" title=\"11. 安装ranger\"></a>11. 安装ranger</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S ranger</span><br></code></pre></td></tr></table></figure>\n<p>配置ranger依旧是修改~/.config/ranger/rc.conf文件<br><br><strong>如果没有这些文件可以自己创建，详细看官方</strong></p>\n<h2 id=\"12-安装网易云音乐\"><a href=\"#12-安装网易云音乐\" class=\"headerlink\" title=\"12. 安装网易云音乐\"></a>12. 安装网易云音乐</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S netease-cloud-music</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"13-安装QQ-TIM\"><a href=\"#13-安装QQ-TIM\" class=\"headerlink\" title=\"13.安装QQ/TIM\"></a>13.安装QQ/TIM</h2><figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">sudo</span> <span class=\"hljs-selector-tag\">pacman</span> <span class=\"hljs-selector-tag\">-S</span> <span class=\"hljs-selector-tag\">deepin</span><span class=\"hljs-selector-class\">.qq</span><span class=\"hljs-selector-class\">.com</span><span class=\"hljs-selector-class\">.office</span><br><span class=\"hljs-selector-tag\">sudo</span> <span class=\"hljs-selector-tag\">pacman</span> <span class=\"hljs-selector-tag\">-S</span> <span class=\"hljs-selector-tag\">deepin</span><span class=\"hljs-selector-class\">.qq</span><span class=\"hljs-selector-class\">.com</span><span class=\"hljs-selector-class\">.im</span><br></code></pre></td></tr></table></figure>\n<p>由于在i3的环境下，一打开QQ就会闪退，解决方法是<br><br><figure class=\"highlight axapta\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs axapta\">yaourt -S gnome-<span class=\"hljs-keyword\">setting</span>-daemon<br></code></pre></td></tr></table></figure><br>然后运行/usr/lib/gsd-xsettings(最好在i3配置中设置开机启动)，然后就可以运行ＱＱ了</p>\n<h2 id=\"14-安装light\"><a href=\"#14-安装light\" class=\"headerlink\" title=\"14. 安装light\"></a>14. 安装light</h2><p>因为i3装上之后亮度调节是个问题所以装一个light<br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S light</span><br></code></pre></td></tr></table></figure><br>要设置亮度的时候只要在命令行输入<br><figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">sudo</span> light -S <span class=\"hljs-number\">20</span> \t<span class=\"hljs-comment\">#数值可改，我一般用２０</span><br></code></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Manjaro-System-finish-picture\"><a href=\"#Manjaro-System-finish-picture\" class=\"headerlink\" title=\"Manjaro System finish picture\"></a>Manjaro System finish picture</h1><p><img src=\"manjaro_System_finish.png\" alt=\"Manjaro\"></p>\n<p>一下配置文件都在 <a href=\"https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System\">https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System</a></p>\n<h1 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h1><h2 id=\"1-首先下载镜像安装\"><a href=\"#1-首先下载镜像安装\" class=\"headerlink\" title=\"1.首先下载镜像安装\"></a>1.首先下载镜像安装</h2><h2 id=\"２．换源\"><a href=\"#２．换源\" class=\"headerlink\" title=\"２．换源\"></a>２．换源</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman-mirrors -i -c China -m rank</span><br></code></pre></td></tr></table></figure>\n<p>选择一个好用的就可以，我选择的是<br><a href=\"https://mirrors.sjtug.sjtu.edu.cn/manjaro/\">https://mirrors.sjtug.sjtu.edu.cn/manjaro/</a></p>\n<h2 id=\"３．更新系统\"><a href=\"#３．更新系统\" class=\"headerlink\" title=\"３．更新系统\"></a>３．更新系统</h2><figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">sudo</span> pacman -Syy \t<span class=\"hljs-comment\">#更新缓存</span><br>sudo Pacman -Syyu\t<span class=\"hljs-comment\">#更新系统</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"４．配置VIM\"><a href=\"#４．配置VIM\" class=\"headerlink\" title=\"４．配置VIM\"></a>４．配置VIM</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S vim</span><br></code></pre></td></tr></table></figure>\n<p>然后编辑$HOME下的.vim/vimrc文件即可<br><br>我的也是刚刚开始使用vim所以配置的内容并不丰富<br><figure class=\"highlight gams\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gams\">syntax on<br><span class=\"hljs-keyword\">set</span> number<br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">relativenumber</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">hlsearch</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">smartcase</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">cursorline</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">cursorcolumn</span> <br>hi <span class=\"hljs-comment\">CursorColumn term=reverse ctermbg=white guibg=grey40</span><br>hi <span class=\"hljs-comment\">CursorColumn ctermbg=238 guibg=grey40</span><br>hi <span class=\"hljs-comment\">CursorLine term=underline cterm=underline guibg=grey40</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">ignorecase</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">cursorline</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">wrap</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">incsearch</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">showcmd</span><br><span class=\"hljs-keyword\">set</span> <span class=\"hljs-comment\">wildmenu</span><br>map <span class=\"hljs-comment\">s &lt;nop&gt;</span><br>map <span class=\"hljs-comment\">S :w&lt;CR&gt;</span><br>map <span class=\"hljs-comment\">Q :q&lt;CR&gt;</span><br>map <span class=\"hljs-comment\">R :source $MYVIMRC&lt;CR&gt;</span><br>noremap <span class=\"hljs-comment\">U 5k</span><br>noremap <span class=\"hljs-comment\">D 5j</span><br>call <span class=\"hljs-comment\">plug#begin(</span><span class=\"hljs-comment\">&#x27;~/.vim/plugged&#x27;</span><span class=\"hljs-comment\">)</span><br>Plug <span class=\"hljs-comment\">&#x27;vim-airline/vim-airline&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;rakr/vim-one&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;preservim/nerdtree&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;ybian/smartim&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;arcticicestudio/nord-vim&#x27;</span> <span class=\"hljs-comment\">Plug</span> <span class=\"hljs-comment\">&#x27;connorholyday/vim-snazzy&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;Valloric/YouCompleteMe&#x27;</span><br>Plug <span class=\"hljs-comment\">&#x27;iamcco/markdown-preview.nvim&#x27;</span><span class=\"hljs-comment\">, &#123;</span> <span class=\"hljs-comment\">&#x27;do&#x27;</span><span class=\"hljs-comment\">:</span> <span class=\"hljs-comment\">&#x27;cd app &amp; yarn install&#x27;</span>  <span class=\"hljs-comment\">&#125;</span><br>Plug <span class=\"hljs-comment\">&#x27;dhruvasagar/vim-table-mode&#x27;</span><span class=\"hljs-comment\">, &#123;</span> <span class=\"hljs-comment\">&#x27;on&#x27;</span><span class=\"hljs-comment\">:</span> <span class=\"hljs-comment\">&#x27;TableModeToggle&#x27;</span> <span class=\"hljs-comment\">&#125;</span><br>Plug <span class=\"hljs-comment\">&#x27;vimwiki/vimwiki&#x27;</span><br><br>call <span class=\"hljs-comment\">plug#end()</span>\t<br><br>let <span class=\"hljs-comment\">g:lightline = &#123;</span><br>\\ <span class=\"hljs-string\">&#x27;colorscheme&#x27;</span>: <span class=\"hljs-string\">&#x27;snazzy&#x27;</span>,<br>\\ &#125;<br><br></code></pre></td></tr></table></figure></p>\n<h2 id=\"5-安装i3wm\"><a href=\"#5-安装i3wm\" class=\"headerlink\" title=\"5.安装i3wm\"></a>5.安装i3wm</h2><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">sudo</span> pacman -S i<span class=\"hljs-number\">3</span><br></code></pre></td></tr></table></figure>\n<p>配置i3只需要配置~/.config/i3/config文件即可<br><br>安装完i3可能会有分辨率的问题可以修改$HOME下的.Xresources文件<br>添加一下语句：<br><br><figure class=\"highlight ini\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ini\"><span class=\"hljs-attr\">Xft.dpi</span> = <span class=\"hljs-number\">200</span> \t<span class=\"hljs-comment\">#数字可以随便改</span><br></code></pre></td></tr></table></figure></p>\n<h2 id=\"6-安装fcitx中文输入法\"><a href=\"#6-安装fcitx中文输入法\" class=\"headerlink\" title=\"6.安装fcitx中文输入法\"></a>6.安装fcitx中文输入法</h2><figure class=\"highlight elixir\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs elixir\"><span class=\"hljs-variable\">$ </span>sudo pacman -S fcitx-sogoupinyin<br><span class=\"hljs-variable\">$ </span>sudo pacman -S fcitx-im     <span class=\"hljs-comment\"># 全部安装</span><br><span class=\"hljs-variable\">$ </span>sudo pacman -S fcitx-configtool     <span class=\"hljs-comment\"># 图形化配置工具</span><br></code></pre></td></tr></table></figure>\n<p>将fcitx添加到环境变量中去<br><figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">sudo</span> <span class=\"hljs-selector-tag\">vim</span> ~/<span class=\"hljs-selector-class\">.xprofile</span> <br></code></pre></td></tr></table></figure><br>然后在里面添加：<br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\"><span class=\"hljs-builtin-name\">export</span> <span class=\"hljs-attribute\">GTK_IM_MODULE</span>=fcitx<br><span class=\"hljs-builtin-name\">export</span> <span class=\"hljs-attribute\">QT_IM_MODULE</span>=fcitx<br><span class=\"hljs-builtin-name\">export</span> <span class=\"hljs-attribute\">XMODIFIERS</span>=”@im=fcitx”<br></code></pre></td></tr></table></figure><br>最后在~/.config/i3/config文件中添加<br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">exec_always fcitx</span><br></code></pre></td></tr></table></figure><br>这样开机就会直接启动fcitx了</p>\n<h2 id=\"7-安装alacritty\"><a href=\"#7-安装alacritty\" class=\"headerlink\" title=\"7.安装alacritty\"></a>7.安装alacritty</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S alacritty</span><br></code></pre></td></tr></table></figure>\n<p>在i3中修改alacritty的快捷键为mod+回车键<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">bindsym <span class=\"hljs-variable\">$mod</span>+<span class=\"hljs-built_in\">return</span> <span class=\"hljs-built_in\">exec</span> alacritty<br></code></pre></td></tr></table></figure><br>配置alacritty只需要修改~/.config/alacritty/alacritty.yml文件即可<br></p>\n<p><strong>如果~/.config/文件中没有alacritty/alacritty.yml文件就自己创建一个，或者上github上面复制一个就可以了</strong><br><br>如果要alacritty的透明的话要安装picom，这个软件就是以前的compton<br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S picom</span><br></code></pre></td></tr></table></figure><br>执行picom,然后修改~/.config/alacritty/alacritty.yml<br><br><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">background_opacity</span>: <span class=\"hljs-number\">0</span>.<span class=\"hljs-number\">75</span> <br></code></pre></td></tr></table></figure><br>也可以修改成其他的值，我比较喜欢0.75的透明度<br><br>最后把picom加入i3的开机启动中</p>\n<h2 id=\"8-安装SSR\"><a href=\"#8-安装SSR\" class=\"headerlink\" title=\"8.安装SSR\"></a>8.安装SSR</h2><p><strong>无图像界面的SSR client</strong><br><figure class=\"highlight awk\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs awk\">wget http:<span class=\"hljs-regexp\">//</span>www.texfox.com/ssr<br>sudo mv ssr <span class=\"hljs-regexp\">/usr/</span>local/bin<br>sudo chmod +x <span class=\"hljs-regexp\">/usr/</span>local<span class=\"hljs-regexp\">/bin/</span>ssr<br>ssr install<br></code></pre></td></tr></table></figure><br>安装完成后配置SSR<br><figure class=\"highlight arduino\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs arduino\">ssr <span class=\"hljs-built_in\">config</span><br></code></pre></td></tr></table></figure><br>把机场的SSR信息填入<br><figure class=\"highlight crmsh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs crmsh\">ssr <span class=\"hljs-literal\">start</span> <br></code></pre></td></tr></table></figure><br>就连接上了，有不明白的命令可以执行<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">ssr <span class=\"hljs-built_in\">help</span><br></code></pre></td></tr></table></figure><br><strong>有图像界面的SSR client可以用electron-ssr</strong><br><br>链接：<br><a href=\"https://github.com/qingshuisiyuan/electron-ssr-backup\">https://github.com/qingshuisiyuan/electron-ssr-backup</a></p>\n<h2 id=\"9-安装google-chrome-谷歌浏览器\"><a href=\"#9-安装google-chrome-谷歌浏览器\" class=\"headerlink\" title=\"9.安装google-chrome_(谷歌浏览器)\"></a>9.安装google-chrome_(谷歌浏览器)</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S google-chrome</span><br></code></pre></td></tr></table></figure>\n<p>因为很经常用到google所以我把它设置成i3的快捷键，即在~/.config/i3/config中添加下面语句<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">bindsym <span class=\"hljs-variable\">$mod</span>+c <span class=\"hljs-built_in\">exec</span> google-chrome-stable <br></code></pre></td></tr></table></figure></p>\n<h2 id=\"10-安装Albert\"><a href=\"#10-安装Albert\" class=\"headerlink\" title=\"10.安装Albert\"></a>10.安装Albert</h2><p>因为i3默认的$mod+d的菜单快捷键太丑了，所以安装Albert<br><img src=\"albert.png\" alt=\"albert\"><br><br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S albert</span><br></code></pre></td></tr></table></figure><br>在i3中设置albert开机启动<br><br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">exec_always albert</span><br></code></pre></td></tr></table></figure><br>然后修改albert的热键在终端第一次执行albert时会提醒修改热键，下图是我的配置．<br></p>\n<p><img src=\"albert1.png\" alt=\"albert1\"><br><br><img src=\"albert2.png\" alt=\"albert2\"><br><br>因为我设置的热键ALT+d与i3的热键冲突（我的$mod键是ALT键）,所以我干脆取消了i3中的热键</p>\n<h2 id=\"11-安装ranger\"><a href=\"#11-安装ranger\" class=\"headerlink\" title=\"11. 安装ranger\"></a>11. 安装ranger</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S ranger</span><br></code></pre></td></tr></table></figure>\n<p>配置ranger依旧是修改~/.config/ranger/rc.conf文件<br><br><strong>如果没有这些文件可以自己创建，详细看官方</strong></p>\n<h2 id=\"12-安装网易云音乐\"><a href=\"#12-安装网易云音乐\" class=\"headerlink\" title=\"12. 安装网易云音乐\"></a>12. 安装网易云音乐</h2><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S netease-cloud-music</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"13-安装QQ-TIM\"><a href=\"#13-安装QQ-TIM\" class=\"headerlink\" title=\"13.安装QQ/TIM\"></a>13.安装QQ/TIM</h2><figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-tag\">sudo</span> <span class=\"hljs-selector-tag\">pacman</span> <span class=\"hljs-selector-tag\">-S</span> <span class=\"hljs-selector-tag\">deepin</span><span class=\"hljs-selector-class\">.qq</span><span class=\"hljs-selector-class\">.com</span><span class=\"hljs-selector-class\">.office</span><br><span class=\"hljs-selector-tag\">sudo</span> <span class=\"hljs-selector-tag\">pacman</span> <span class=\"hljs-selector-tag\">-S</span> <span class=\"hljs-selector-tag\">deepin</span><span class=\"hljs-selector-class\">.qq</span><span class=\"hljs-selector-class\">.com</span><span class=\"hljs-selector-class\">.im</span><br></code></pre></td></tr></table></figure>\n<p>由于在i3的环境下，一打开QQ就会闪退，解决方法是<br><br><figure class=\"highlight axapta\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs axapta\">yaourt -S gnome-<span class=\"hljs-keyword\">setting</span>-daemon<br></code></pre></td></tr></table></figure><br>然后运行/usr/lib/gsd-xsettings(最好在i3配置中设置开机启动)，然后就可以运行ＱＱ了</p>\n<h2 id=\"14-安装light\"><a href=\"#14-安装light\" class=\"headerlink\" title=\"14. 安装light\"></a>14. 安装light</h2><p>因为i3装上之后亮度调节是个问题所以装一个light<br><figure class=\"highlight ebnf\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ebnf\"><span class=\"hljs-attribute\">sudo pacman -S light</span><br></code></pre></td></tr></table></figure><br>要设置亮度的时候只要在命令行输入<br><figure class=\"highlight nginx\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs nginx\"><span class=\"hljs-attribute\">sudo</span> light -S <span class=\"hljs-number\">20</span> \t<span class=\"hljs-comment\">#数值可改，我一般用２０</span><br></code></pre></td></tr></table></figure></p>\n"},{"title":"PA2实验报告","index_img":"/Picture/PA.png","date":"2020-12-18T07:42:37.000Z","banner_img":null,"_content":"**1.RTFSC 请整理一条指令在NEMU中的执行过程. (我们其实已经在PA2.1阶段提到过这道题了)**<br>\n\t程序在nexus-am中被交叉编译成二进制指令被装入NEMU的内存中，NEMU通过一系列函数来取指令，解码指令，执行指令<br>\n函数调用历程如图:<br>\n\n```mermaid\ngraph LR;\n\tA[cpu_exec];\n\tB[exec_once];\n\tC[isa_exec];\n\tD[update_pc];\n\tE[instr_fetch];\n\tF[set_width];\n\tG[idex];\n\tA-->B;\n\tB-->C;\n\tB-->D;\n\tC-->E;\n\tC-->F;\n\tC-->G;\n```\n\n以指令0x00为例cpu执行模拟函数cpu_exec一路执行到instr_fetch在内存中取出指令0x00然后查询*NEMU模拟器中存储的符合x指令集规范的表opcode_table(需要我们手动实现)*得到对应的0x00这一条指令的执行宽度,opcode_table[0x00].width,调用宽度设置函数set_width设置宽度,然后进入idex函数运行对应的内置解码程序opcode_table[0x00].decode,和指令对于的内置执行程序opcode_table[0x00].execute,最后调用update_pc函数，更新pc寄存器.<br>\n\t\n**2.编译与链接 在nemu/include/rtl/rtl.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?**<br>\n\n**static:**<解释来自stackoverflow><br>\n-\t1. Static defined **local** variables do not lose their value between function calls. In other words they are global variables, but scoped to the local function they are defined in.<函数内定义的变量用static关键字修饰就会被编译器放入静态存储区，应该是被放在.data表内，其实就相当于一个另类的全局变量了.>\n-\t2. A static **global** variable or a function is \"seen\" only in the file it's declared in.<字面意思>\n\n**inline:**<br>\n每次函数调用都要执行押入参数，保存返回地址，保存寄存器等工作会让函数调用变慢,inline的作用有点像define,可以将代码直接展开到调用处直接执行就可以让函数调用变快，但是缺点是这个操作可能让可执行文件变得更大或者更小无法预测<br>\n\n有了这些基础现在开始回答问题:<br>\n-\t1. 去掉inline:<br>\n\nstatic 和 static inline 其实没有很大的不同,只是函数的调用方式改变了,但是我试图编译时出现了这个错误:\n\n```c\n./include/rtl/rtl.h:138:14: error: ‘rtl_sext’ defined but not used [-Werror=unused-function]\n static  void rtl_sext(rtlreg_t* dest, const rtlreg_t* src1, int width) {\n              ^~~~~~~~\n```\n\n原因是我们在gcc中加入了-Werror把所有的警告都当成error来处理,把-Werror去掉就可以了<br>\n-\t2. 去掉static:<br>\n因为有inline关键字的存在所以，程序就像define一样会在调用处展开所以定义在头文件中的无static有inline的函数不会出现多次定义,只要把makefile文件中的-Werror去掉就可以编译链接成功<br>\n\n-\t3.去掉static inline:<br>\n因为头文件会被许多文件引用所以如果去掉static inline,这个函数就会被多次定义，在链接的时候会报一下错误:<br>\n\n```c\n+ LD build/x86-nemu\nbuild/obj-x86/isa/x86/decode/decode.o: In function `rtl_setrelopi':\n/home/oeoe/Documents/ICS-PA-2019/nemu/./include/rtl/rtl.h:145: multiple definition of `rtl_setrelopi'\n```\n\n**3.编译与链接**\n- 1. 在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?**\n- 2. 添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.**\n- 3. 修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.)**\n\n\n**Volatile tells the compiler not to optimize anything that has to do with the volatile variable. <来自stackoverflow><br>**\n\n1. 答案是74个，在build/obj中利用`grep  -r -c  'dummy' ./* | grep '\\.o:[1-9]'| wc -l`命令得出.\n2. 答案仍然是74个.\n3. 两个初始化后会出现多次定义的错误:<br>\n \n```c\n./include/common.h:2:21: note: previous definition of ‘dummy’ was here\n volatile static int dummy=0;\n                     ^~~~~\nIn file included from ./include/device/map.h:4:0,\n                 from src/memory/memory.c:2:\n./include/common.h:2:21: error: redefinition of ‘dummy’\n```\n\n原因是强弱定义的问题，当两个dummy都没有初始化的时候dummy是一个弱符号,编译器不会报错,编译器会选择占用内存最大的那个弱符号，当把两个dummy都初始化后，两个dummy就变成强符号了，链接器不允许强符号被多次定义，如果一个是强符号一个是弱符号，那么弱符号会被强符号覆盖(当然这个弱符号的占用内存大小不能大于强符号，否则会报错).<br>\n\n**4. 了解Makefile 请描述你在nemu/目录下敲入make 后, make程序如何组织.c和.h文件, 最终生成可执行文件nemu/build/$ISA-nemu. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:**<br>\n- 1. Makefile中使用了变量, 包含文件等特性\n- 2. Makefile运用并重写了一些implicit rules\n- 3. 在man make中搜索-n选项, 也许会对你有帮助\n\n```makefile\nNAME = nemu\n#如果$(MAKECMDGOALS)和clean）不相等则执行ifneq ...endif内的语句\n#$MAKECMDGOALS是一个特殊参数:这个参数存放你在命令行指定的目标列表,如果什么都没指定则为空\nifneq ($(MAKECMDGOALS),clean) # ignore check for make clean\n# ?=用来设置变量，当没有设置ISA值或者没有ISA这个变量的时候\nISA ?= x86\n#相当于执行一条shell命令\nISAS = $(shell ls src/isa/)\n#打印信息到标准输出\n$(info Building $(ISA)-$(NAME))\n#$(filter pattern…,text):\n#Returns all whitespace-separated words in text that\n#do match any of the pattern words, removing any words that do not match. \nifeq ($(filter $(ISAS), $(ISA)), ) # ISA must be valid\n#产生致命错误，并提示Invalid ISA. Supported: $(ISAS)给用户\n$(error Invalid ISA. Supported: $(ISAS))\nendif\nendif\n\nINC_DIR += ./include ./src/isa/$(ISA)/include\nBUILD_DIR ?= ./build\n\n#如果SHARE的值不为空就为true\nifdef SHARE\nSO = -so\n# -D_SHARE:-Dmacro=defn  相当于 C 语言中的 #define macro=defn\n# -fPIC:生成位置无关代码\nSO_CFLAGS = -fPIC -D_SHARE=1\nSO_LDLAGS = -shared -fPIC\nendif\n\nOBJ_DIR ?= $(BUILD_DIR)/obj-$(ISA)$(SO)\nBINARY ?= $(BUILD_DIR)/$(ISA)-$(NAME)$(SO)\n\n#类似C中的#include\ninclude Makefile.git\n#设置默认目标，如果没有在命令行指定目标则使用默认目标\n.DEFAULT_GOAL = app\n\n# Compilation flags\nCC = gcc\nLD = gcc\n#$(addprefix,prefix,names...):The value of prefix is prepended to the front of \n# each individual name and the resulting larger names are concatenated with single\n# spaces between them \nINCLUDES  = $(addprefix -I, $(INC_DIR))\n# -O2:允许编译器对代码进行优化,级别为2\n# -MMD:生成文件关联信息但是忽略由#include<file>造成的依赖关系并且写入filename.d文件中，可以去看看-M\n# -Wall:开启所有警告信息\n# -Werror: every warning is treated as an error\n# -ggdb3:(搞不懂是什么意思)produces extra debugging information, for example: including macro definitions.\n# -D__ISA__:-Dmacro=defn  相当于 C 语言中的 #define macro=defn\n# -fomit-frame-pointer :(这个参数有关于栈指针)看这篇文章:https://stackoverflow.com/questions/14666665/trying-to-understand-gcc-option-fomit-frame-pointer\nCFLAGS   += -O2 -MMD -Wall -Werror -ggdb3 $(INCLUDES) -D__ISA__=$(ISA) -fomit-frame-pointer\n\nQEMU_DIFF_PATH = $(NEMU_HOME)/tools/qemu-diff\nQEMU_SO = $(QEMU_DIFF_PATH)/build/$(ISA)-qemu-so\n\n#执行make指令$(MAkE)是特殊变量 -C用来指定目录\n$(QEMU_SO):\n\t$(MAKE) -C $(QEMU_DIFF_PATH)\n\n# Files to be compiled\n# -v 表示不匹配“isa\"\nSRCS = $(shell find src/ -name \"*.c\" | grep -v \"isa\")\nSRCS += $(shell find src/isa/$(ISA) -name \"*.c\")\n#$(var:a=b)，是将 var 变量中每一个单词后面的 a 替换为 b\nOBJS = $(SRCS:src/%.c=$(OBJ_DIR)/%.o)\n\n# Compilation patterns\n#@表示不显示执行的指令\n#$<代表第一个依赖项\n#$(dir NAMES...):取出每个文件名的目录部分\n$(OBJ_DIR)/%.o: src/%.c\n\t@echo + CC $<\n\t@mkdir -p $(dir $@)\n\t@$(CC) $(CFLAGS) $(SO_CFLAGS) -c -o $@ $<\n\n\n#看这篇文章https://blog.csdn.net/xiaozhi_su/article/details/4202779\n# Depencies\n#将OBJS中的文件后缀为.o的文件然后把后缀改为.d\n-include $(OBJS:.o=.d)\n\n# Some convenient rules\n\n.PHONY: app run gdb clean run-env $(QEMU_SO)\napp: $(BINARY)\n\noverride ARGS ?= -l $(BUILD_DIR)/nemu-log.txt\noverride ARGS += -d $(QEMU_SO)\n\n# Command to execute NEMU\nIMG :=\nNEMU_EXEC := $(BINARY) $(ARGS) $(IMG)\n\n$(BINARY): $(OBJS)\n\t$(call git_commit, \"compile\")\n\t@echo + LD $@\n\t@$(LD) -O2 -rdynamic $(SO_LDLAGS) -o $@ $^ -lSDL2 -lreadline -ldl\n\nrun-env: $(BINARY) $(QEMU_SO)\n\nrun: run-env\n\t$(call git_commit, \"run\")\n\t$(NEMU_EXEC)\n\ngdb: run-env\n\t$(call git_commit, \"gdb\")\n\tgdb -s $(BINARY) --args $(NEMU_EXEC)\n\nclean:\n\t-rm -rf $(BUILD_DIR)\n\t$(MAKE) -C tools/gen-expr clean\n\t$(MAKE) -C tools/qemu-diff clean\ncount:\n\t@echo  \"\\e[1;32m\"\n\t@echo \"The .c and .h file total number of row equal to :\"\n\t@find ./ -name \"*.[ch]\" | xargs wc -l | awk 'END{printf \"%s\\n\",$$1}'\n\t@echo \"The .c and .h file (without blank line) total number of row equal to :\"\n\t@find ./ -name \"*.[ch]\" | xargs cat | grep -v '^\\s*$$'| wc -l\n\t@echo \"\\e[0m\"\n\n\n\n```\n","source":"_posts/PA2实验报告.md","raw":"---\ntitle: PA2实验报告\nindex_img: /Picture/PA.png\ndate: 2020-12-18 15:42:37\ntags:\n- PA\ncategories:\n- PA\nbanner_img:\n---\n**1.RTFSC 请整理一条指令在NEMU中的执行过程. (我们其实已经在PA2.1阶段提到过这道题了)**<br>\n\t程序在nexus-am中被交叉编译成二进制指令被装入NEMU的内存中，NEMU通过一系列函数来取指令，解码指令，执行指令<br>\n函数调用历程如图:<br>\n\n```mermaid\ngraph LR;\n\tA[cpu_exec];\n\tB[exec_once];\n\tC[isa_exec];\n\tD[update_pc];\n\tE[instr_fetch];\n\tF[set_width];\n\tG[idex];\n\tA-->B;\n\tB-->C;\n\tB-->D;\n\tC-->E;\n\tC-->F;\n\tC-->G;\n```\n\n以指令0x00为例cpu执行模拟函数cpu_exec一路执行到instr_fetch在内存中取出指令0x00然后查询*NEMU模拟器中存储的符合x指令集规范的表opcode_table(需要我们手动实现)*得到对应的0x00这一条指令的执行宽度,opcode_table[0x00].width,调用宽度设置函数set_width设置宽度,然后进入idex函数运行对应的内置解码程序opcode_table[0x00].decode,和指令对于的内置执行程序opcode_table[0x00].execute,最后调用update_pc函数，更新pc寄存器.<br>\n\t\n**2.编译与链接 在nemu/include/rtl/rtl.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?**<br>\n\n**static:**<解释来自stackoverflow><br>\n-\t1. Static defined **local** variables do not lose their value between function calls. In other words they are global variables, but scoped to the local function they are defined in.<函数内定义的变量用static关键字修饰就会被编译器放入静态存储区，应该是被放在.data表内，其实就相当于一个另类的全局变量了.>\n-\t2. A static **global** variable or a function is \"seen\" only in the file it's declared in.<字面意思>\n\n**inline:**<br>\n每次函数调用都要执行押入参数，保存返回地址，保存寄存器等工作会让函数调用变慢,inline的作用有点像define,可以将代码直接展开到调用处直接执行就可以让函数调用变快，但是缺点是这个操作可能让可执行文件变得更大或者更小无法预测<br>\n\n有了这些基础现在开始回答问题:<br>\n-\t1. 去掉inline:<br>\n\nstatic 和 static inline 其实没有很大的不同,只是函数的调用方式改变了,但是我试图编译时出现了这个错误:\n\n```c\n./include/rtl/rtl.h:138:14: error: ‘rtl_sext’ defined but not used [-Werror=unused-function]\n static  void rtl_sext(rtlreg_t* dest, const rtlreg_t* src1, int width) {\n              ^~~~~~~~\n```\n\n原因是我们在gcc中加入了-Werror把所有的警告都当成error来处理,把-Werror去掉就可以了<br>\n-\t2. 去掉static:<br>\n因为有inline关键字的存在所以，程序就像define一样会在调用处展开所以定义在头文件中的无static有inline的函数不会出现多次定义,只要把makefile文件中的-Werror去掉就可以编译链接成功<br>\n\n-\t3.去掉static inline:<br>\n因为头文件会被许多文件引用所以如果去掉static inline,这个函数就会被多次定义，在链接的时候会报一下错误:<br>\n\n```c\n+ LD build/x86-nemu\nbuild/obj-x86/isa/x86/decode/decode.o: In function `rtl_setrelopi':\n/home/oeoe/Documents/ICS-PA-2019/nemu/./include/rtl/rtl.h:145: multiple definition of `rtl_setrelopi'\n```\n\n**3.编译与链接**\n- 1. 在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?**\n- 2. 添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.**\n- 3. 修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.)**\n\n\n**Volatile tells the compiler not to optimize anything that has to do with the volatile variable. <来自stackoverflow><br>**\n\n1. 答案是74个，在build/obj中利用`grep  -r -c  'dummy' ./* | grep '\\.o:[1-9]'| wc -l`命令得出.\n2. 答案仍然是74个.\n3. 两个初始化后会出现多次定义的错误:<br>\n \n```c\n./include/common.h:2:21: note: previous definition of ‘dummy’ was here\n volatile static int dummy=0;\n                     ^~~~~\nIn file included from ./include/device/map.h:4:0,\n                 from src/memory/memory.c:2:\n./include/common.h:2:21: error: redefinition of ‘dummy’\n```\n\n原因是强弱定义的问题，当两个dummy都没有初始化的时候dummy是一个弱符号,编译器不会报错,编译器会选择占用内存最大的那个弱符号，当把两个dummy都初始化后，两个dummy就变成强符号了，链接器不允许强符号被多次定义，如果一个是强符号一个是弱符号，那么弱符号会被强符号覆盖(当然这个弱符号的占用内存大小不能大于强符号，否则会报错).<br>\n\n**4. 了解Makefile 请描述你在nemu/目录下敲入make 后, make程序如何组织.c和.h文件, 最终生成可执行文件nemu/build/$ISA-nemu. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:**<br>\n- 1. Makefile中使用了变量, 包含文件等特性\n- 2. Makefile运用并重写了一些implicit rules\n- 3. 在man make中搜索-n选项, 也许会对你有帮助\n\n```makefile\nNAME = nemu\n#如果$(MAKECMDGOALS)和clean）不相等则执行ifneq ...endif内的语句\n#$MAKECMDGOALS是一个特殊参数:这个参数存放你在命令行指定的目标列表,如果什么都没指定则为空\nifneq ($(MAKECMDGOALS),clean) # ignore check for make clean\n# ?=用来设置变量，当没有设置ISA值或者没有ISA这个变量的时候\nISA ?= x86\n#相当于执行一条shell命令\nISAS = $(shell ls src/isa/)\n#打印信息到标准输出\n$(info Building $(ISA)-$(NAME))\n#$(filter pattern…,text):\n#Returns all whitespace-separated words in text that\n#do match any of the pattern words, removing any words that do not match. \nifeq ($(filter $(ISAS), $(ISA)), ) # ISA must be valid\n#产生致命错误，并提示Invalid ISA. Supported: $(ISAS)给用户\n$(error Invalid ISA. Supported: $(ISAS))\nendif\nendif\n\nINC_DIR += ./include ./src/isa/$(ISA)/include\nBUILD_DIR ?= ./build\n\n#如果SHARE的值不为空就为true\nifdef SHARE\nSO = -so\n# -D_SHARE:-Dmacro=defn  相当于 C 语言中的 #define macro=defn\n# -fPIC:生成位置无关代码\nSO_CFLAGS = -fPIC -D_SHARE=1\nSO_LDLAGS = -shared -fPIC\nendif\n\nOBJ_DIR ?= $(BUILD_DIR)/obj-$(ISA)$(SO)\nBINARY ?= $(BUILD_DIR)/$(ISA)-$(NAME)$(SO)\n\n#类似C中的#include\ninclude Makefile.git\n#设置默认目标，如果没有在命令行指定目标则使用默认目标\n.DEFAULT_GOAL = app\n\n# Compilation flags\nCC = gcc\nLD = gcc\n#$(addprefix,prefix,names...):The value of prefix is prepended to the front of \n# each individual name and the resulting larger names are concatenated with single\n# spaces between them \nINCLUDES  = $(addprefix -I, $(INC_DIR))\n# -O2:允许编译器对代码进行优化,级别为2\n# -MMD:生成文件关联信息但是忽略由#include<file>造成的依赖关系并且写入filename.d文件中，可以去看看-M\n# -Wall:开启所有警告信息\n# -Werror: every warning is treated as an error\n# -ggdb3:(搞不懂是什么意思)produces extra debugging information, for example: including macro definitions.\n# -D__ISA__:-Dmacro=defn  相当于 C 语言中的 #define macro=defn\n# -fomit-frame-pointer :(这个参数有关于栈指针)看这篇文章:https://stackoverflow.com/questions/14666665/trying-to-understand-gcc-option-fomit-frame-pointer\nCFLAGS   += -O2 -MMD -Wall -Werror -ggdb3 $(INCLUDES) -D__ISA__=$(ISA) -fomit-frame-pointer\n\nQEMU_DIFF_PATH = $(NEMU_HOME)/tools/qemu-diff\nQEMU_SO = $(QEMU_DIFF_PATH)/build/$(ISA)-qemu-so\n\n#执行make指令$(MAkE)是特殊变量 -C用来指定目录\n$(QEMU_SO):\n\t$(MAKE) -C $(QEMU_DIFF_PATH)\n\n# Files to be compiled\n# -v 表示不匹配“isa\"\nSRCS = $(shell find src/ -name \"*.c\" | grep -v \"isa\")\nSRCS += $(shell find src/isa/$(ISA) -name \"*.c\")\n#$(var:a=b)，是将 var 变量中每一个单词后面的 a 替换为 b\nOBJS = $(SRCS:src/%.c=$(OBJ_DIR)/%.o)\n\n# Compilation patterns\n#@表示不显示执行的指令\n#$<代表第一个依赖项\n#$(dir NAMES...):取出每个文件名的目录部分\n$(OBJ_DIR)/%.o: src/%.c\n\t@echo + CC $<\n\t@mkdir -p $(dir $@)\n\t@$(CC) $(CFLAGS) $(SO_CFLAGS) -c -o $@ $<\n\n\n#看这篇文章https://blog.csdn.net/xiaozhi_su/article/details/4202779\n# Depencies\n#将OBJS中的文件后缀为.o的文件然后把后缀改为.d\n-include $(OBJS:.o=.d)\n\n# Some convenient rules\n\n.PHONY: app run gdb clean run-env $(QEMU_SO)\napp: $(BINARY)\n\noverride ARGS ?= -l $(BUILD_DIR)/nemu-log.txt\noverride ARGS += -d $(QEMU_SO)\n\n# Command to execute NEMU\nIMG :=\nNEMU_EXEC := $(BINARY) $(ARGS) $(IMG)\n\n$(BINARY): $(OBJS)\n\t$(call git_commit, \"compile\")\n\t@echo + LD $@\n\t@$(LD) -O2 -rdynamic $(SO_LDLAGS) -o $@ $^ -lSDL2 -lreadline -ldl\n\nrun-env: $(BINARY) $(QEMU_SO)\n\nrun: run-env\n\t$(call git_commit, \"run\")\n\t$(NEMU_EXEC)\n\ngdb: run-env\n\t$(call git_commit, \"gdb\")\n\tgdb -s $(BINARY) --args $(NEMU_EXEC)\n\nclean:\n\t-rm -rf $(BUILD_DIR)\n\t$(MAKE) -C tools/gen-expr clean\n\t$(MAKE) -C tools/qemu-diff clean\ncount:\n\t@echo  \"\\e[1;32m\"\n\t@echo \"The .c and .h file total number of row equal to :\"\n\t@find ./ -name \"*.[ch]\" | xargs wc -l | awk 'END{printf \"%s\\n\",$$1}'\n\t@echo \"The .c and .h file (without blank line) total number of row equal to :\"\n\t@find ./ -name \"*.[ch]\" | xargs cat | grep -v '^\\s*$$'| wc -l\n\t@echo \"\\e[0m\"\n\n\n\n```\n","slug":"PA2实验报告","published":1,"updated":"2020-12-19T04:11:01.481Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4rz000dr8s80hxr7czb","content":"<p><strong>1.RTFSC 请整理一条指令在NEMU中的执行过程. (我们其实已经在PA2.1阶段提到过这道题了)</strong><br><br>    程序在nexus-am中被交叉编译成二进制指令被装入NEMU的内存中，NEMU通过一系列函数来取指令，解码指令，执行指令<br><br>函数调用历程如图:<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph LR;<br>\tA[cpu_exec];<br>\tB[exec_once];<br>\tC[isa_exec];<br>\tD[update_pc];<br>\tE[instr_fetch];<br>\tF[set_width];<br>\tG[idex];<br>\tA--&gt;B;<br>\tB--&gt;C;<br>\tB--&gt;D;<br>\tC--&gt;E;<br>\tC--&gt;F;<br>\tC--&gt;G;<br></code></pre></td></tr></table></figure>\n<p>以指令0x00为例cpu执行模拟函数cpu_exec一路执行到instr_fetch在内存中取出指令0x00然后查询<em>NEMU模拟器中存储的符合x指令集规范的表opcode_table(需要我们手动实现)</em>得到对应的0x00这一条指令的执行宽度,opcode_table[0x00].width,调用宽度设置函数set_width设置宽度,然后进入idex函数运行对应的内置解码程序opcode_table[0x00].decode,和指令对于的内置执行程序opcode_table[0x00].execute,最后调用update_pc函数，更新pc寄存器.<br></p>\n<p><strong>2.编译与链接 在nemu/include/rtl/rtl.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?</strong><br></p>\n<p><strong>static:</strong>&lt;解释来自stackoverflow&gt;<br></p>\n<ul>\n<li><ol>\n<li>Static defined <strong>local</strong> variables do not lose their value between function calls. In other words they are global variables, but scoped to the local function they are defined in.&lt;函数内定义的变量用static关键字修饰就会被编译器放入静态存储区，应该是被放在.data表内，其实就相当于一个另类的全局变量了.&gt;</li>\n</ol>\n</li>\n<li><ol>\n<li>A static <strong>global</strong> variable or a function is “seen” only in the file it’s declared in.&lt;字面意思&gt;</li>\n</ol>\n</li>\n</ul>\n<p><strong>inline:</strong><br><br>每次函数调用都要执行押入参数，保存返回地址，保存寄存器等工作会让函数调用变慢,inline的作用有点像define,可以将代码直接展开到调用处直接执行就可以让函数调用变快，但是缺点是这个操作可能让可执行文件变得更大或者更小无法预测<br></p>\n<p>有了这些基础现在开始回答问题:<br></p>\n<ul>\n<li><ol>\n<li>去掉inline:<br></li>\n</ol>\n</li>\n</ul>\n<p>static 和 static inline 其实没有很大的不同,只是函数的调用方式改变了,但是我试图编译时出现了这个错误:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">./include/rtl/rtl.h:<span class=\"hljs-number\">138</span>:<span class=\"hljs-number\">14</span>: error: ‘rtl_sext’ defined but <span class=\"hljs-keyword\">not</span> used [-Werror=unused-function]<br> <span class=\"hljs-keyword\">static</span>  <span class=\"hljs-keyword\">void</span> rtl_sext(<span class=\"hljs-keyword\">rtlreg_t</span>* dest, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">rtlreg_t</span>* src1, <span class=\"hljs-keyword\">int</span> width) &#123;<br>              ^~~~~~~~<br></code></pre></td></tr></table></figure>\n<p>原因是我们在gcc中加入了-Werror把所有的警告都当成error来处理,把-Werror去掉就可以了<br></p>\n<ul>\n<li><ol>\n<li>去掉static:<br><br>因为有inline关键字的存在所以，程序就像define一样会在调用处展开所以定义在头文件中的无static有inline的函数不会出现多次定义,只要把makefile文件中的-Werror去掉就可以编译链接成功<br></li>\n</ol>\n</li>\n<li><p>3.去掉static inline:<br><br>因为头文件会被许多文件引用所以如果去掉static inline,这个函数就会被多次定义，在链接的时候会报一下错误:<br></p>\n</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">+ LD build/x86-nemu<br>build/obj-x86/isa/x86/decode/decode.o: In function `rtl_setrelopi<span class=\"hljs-number\">&#x27;</span>:<br>/home/oeoe/Documents/ICS-PA<span class=\"hljs-number\">-2019</span>/nemu/./include/rtl/rtl.h:<span class=\"hljs-number\">145</span>: multiple definition of `rtl_setrelopi<span class=\"hljs-number\">&#x27;</span><br></code></pre></td></tr></table></figure>\n<p><strong>3.编译与链接</strong></p>\n<ul>\n<li><ol>\n<li>在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?**</li>\n</ol>\n</li>\n<li><ol>\n<li>添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.**</li>\n</ol>\n</li>\n<li><ol>\n<li>修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.)**</li>\n</ol>\n</li>\n</ul>\n<p><strong>Volatile tells the compiler not to optimize anything that has to do with the volatile variable. &lt;来自stackoverflow&gt;<br></strong></p>\n<ol>\n<li>答案是74个，在build/obj中利用<code>grep  -r -c  &#39;dummy&#39; ./* | grep &#39;\\.o:[1-9]&#39;| wc -l</code>命令得出.</li>\n<li>答案仍然是74个.</li>\n<li>两个初始化后会出现多次定义的错误:<br></li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">./include/common.h:<span class=\"hljs-number\">2</span>:<span class=\"hljs-number\">21</span>: note: previous definition of ‘dummy’ was here<br> <span class=\"hljs-keyword\">volatile</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> dummy=<span class=\"hljs-number\">0</span>;<br>                     ^~~~~<br>In file included from ./include/device/<span class=\"hljs-built_in\">map</span>.h:<span class=\"hljs-number\">4</span>:<span class=\"hljs-number\">0</span>,<br>                 from src/memory/memory.c:<span class=\"hljs-number\">2</span>:<br>./include/common.h:<span class=\"hljs-number\">2</span>:<span class=\"hljs-number\">21</span>: error: redefinition of ‘dummy’<br></code></pre></td></tr></table></figure>\n<p>原因是强弱定义的问题，当两个dummy都没有初始化的时候dummy是一个弱符号,编译器不会报错,编译器会选择占用内存最大的那个弱符号，当把两个dummy都初始化后，两个dummy就变成强符号了，链接器不允许强符号被多次定义，如果一个是强符号一个是弱符号，那么弱符号会被强符号覆盖(当然这个弱符号的占用内存大小不能大于强符号，否则会报错).<br></p>\n<p><strong>4. 了解Makefile 请描述你在nemu/目录下敲入make 后, make程序如何组织.c和.h文件, 最终生成可执行文件nemu/build/$ISA-nemu. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:</strong><br></p>\n<ul>\n<li><ol>\n<li>Makefile中使用了变量, 包含文件等特性</li>\n</ol>\n</li>\n<li><ol>\n<li>Makefile运用并重写了一些implicit rules</li>\n</ol>\n</li>\n<li><ol>\n<li>在man make中搜索-n选项, 也许会对你有帮助</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs makefile\">NAME = nemu<br><span class=\"hljs-comment\">#如果$(MAKECMDGOALS)和clean）不相等则执行ifneq ...endif内的语句</span><br><span class=\"hljs-comment\">#$MAKECMDGOALS是一个特殊参数:这个参数存放你在命令行指定的目标列表,如果什么都没指定则为空</span><br><span class=\"hljs-keyword\">ifneq</span> (<span class=\"hljs-variable\">$(MAKECMDGOALS)</span>,clean) <span class=\"hljs-comment\"># ignore check for make clean</span><br><span class=\"hljs-comment\"># ?=用来设置变量，当没有设置ISA值或者没有ISA这个变量的时候</span><br>ISA ?= x86<br><span class=\"hljs-comment\">#相当于执行一条shell命令</span><br>ISAS = <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> ls src/isa/)</span><br><span class=\"hljs-comment\">#打印信息到标准输出</span><br><span class=\"hljs-variable\">$(info Building <span class=\"hljs-variable\">$(ISA)</span>-<span class=\"hljs-variable\">$(NAME)</span>)</span><br><span class=\"hljs-comment\">#$(filter pattern…,text):</span><br><span class=\"hljs-comment\">#Returns all whitespace-separated words in text that</span><br><span class=\"hljs-comment\">#do match any of the pattern words, removing any words that do not match. </span><br><span class=\"hljs-keyword\">ifeq</span> (<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">filter</span> <span class=\"hljs-variable\">$(ISAS)</span>, <span class=\"hljs-variable\">$(ISA)</span>)</span>, ) <span class=\"hljs-comment\"># ISA must be valid</span><br><span class=\"hljs-comment\">#产生致命错误，并提示Invalid ISA. Supported: $(ISAS)给用户</span><br><span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">error</span> Invalid ISA. Supported: <span class=\"hljs-variable\">$(ISAS)</span>)</span><br><span class=\"hljs-keyword\">endif</span><br><span class=\"hljs-keyword\">endif</span><br><br>INC_DIR += ./<span class=\"hljs-keyword\">include</span> ./src/isa/<span class=\"hljs-variable\">$(ISA)</span>/<span class=\"hljs-keyword\">include</span><br>BUILD_DIR ?= ./build<br><br><span class=\"hljs-comment\">#如果SHARE的值不为空就为true</span><br><span class=\"hljs-keyword\">ifdef</span> SHARE<br>SO = -so<br><span class=\"hljs-comment\"># -D_SHARE:-Dmacro=defn  相当于 C 语言中的 #define macro=defn</span><br><span class=\"hljs-comment\"># -fPIC:生成位置无关代码</span><br>SO_CFLAGS = -fPIC -D_SHARE=1<br>SO_LDLAGS = -shared -fPIC<br><span class=\"hljs-keyword\">endif</span><br><br>OBJ_DIR ?= <span class=\"hljs-variable\">$(BUILD_DIR)</span>/obj-<span class=\"hljs-variable\">$(ISA)</span><span class=\"hljs-variable\">$(SO)</span><br>BINARY ?= <span class=\"hljs-variable\">$(BUILD_DIR)</span>/<span class=\"hljs-variable\">$(ISA)</span>-<span class=\"hljs-variable\">$(NAME)</span><span class=\"hljs-variable\">$(SO)</span><br><br><span class=\"hljs-comment\">#类似C中的#include</span><br><span class=\"hljs-keyword\">include</span> Makefile.git<br><span class=\"hljs-comment\">#设置默认目标，如果没有在命令行指定目标则使用默认目标</span><br>.DEFAULT_GOAL = app<br><br><span class=\"hljs-comment\"># Compilation flags</span><br>CC = gcc<br>LD = gcc<br><span class=\"hljs-comment\">#$(addprefix,prefix,names...):The value of prefix is prepended to the front of </span><br><span class=\"hljs-comment\"># each individual name and the resulting larger names are concatenated with single</span><br><span class=\"hljs-comment\"># spaces between them </span><br>INCLUDES  = <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">addprefix</span> -I, <span class=\"hljs-variable\">$(INC_DIR)</span>)</span><br><span class=\"hljs-comment\"># -O2:允许编译器对代码进行优化,级别为2</span><br><span class=\"hljs-comment\"># -MMD:生成文件关联信息但是忽略由#include&lt;file&gt;造成的依赖关系并且写入filename.d文件中，可以去看看-M</span><br><span class=\"hljs-comment\"># -Wall:开启所有警告信息</span><br><span class=\"hljs-comment\"># -Werror: every warning is treated as an error</span><br><span class=\"hljs-comment\"># -ggdb3:(搞不懂是什么意思)produces extra debugging information, for example: including macro definitions.</span><br><span class=\"hljs-comment\"># -D__ISA__:-Dmacro=defn  相当于 C 语言中的 #define macro=defn</span><br><span class=\"hljs-comment\"># -fomit-frame-pointer :(这个参数有关于栈指针)看这篇文章:https://stackoverflow.com/questions/14666665/trying-to-understand-gcc-option-fomit-frame-pointer</span><br>CFLAGS   += -O2 -MMD -Wall -Werror -ggdb3 <span class=\"hljs-variable\">$(INCLUDES)</span> -D__ISA__=<span class=\"hljs-variable\">$(ISA)</span> -fomit-frame-pointer<br><br>QEMU_DIFF_PATH = <span class=\"hljs-variable\">$(NEMU_HOME)</span>/tools/qemu-diff<br>QEMU_SO = <span class=\"hljs-variable\">$(QEMU_DIFF_PATH)</span>/build/<span class=\"hljs-variable\">$(ISA)</span>-qemu-so<br><br><span class=\"hljs-comment\">#执行make指令$(MAkE)是特殊变量 -C用来指定目录</span><br><span class=\"hljs-variable\">$(QEMU_SO)</span>:<br>\t<span class=\"hljs-variable\">$(MAKE)</span> -C <span class=\"hljs-variable\">$(QEMU_DIFF_PATH)</span><br><br><span class=\"hljs-comment\"># Files to be compiled</span><br><span class=\"hljs-comment\"># -v 表示不匹配“isa&quot;</span><br>SRCS = <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> find src/ -name &quot;*.c&quot; | grep -v &quot;isa&quot;)</span><br>SRCS += <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> find src/isa/<span class=\"hljs-variable\">$(ISA)</span> -name &quot;*.c&quot;)</span><br><span class=\"hljs-comment\">#$(var:a=b)，是将 var 变量中每一个单词后面的 a 替换为 b</span><br>OBJS = $(SRCS:src/%.c=<span class=\"hljs-variable\">$(OBJ_DIR)</span>/%.o)<br><br><span class=\"hljs-comment\"># Compilation patterns</span><br><span class=\"hljs-comment\">#@表示不显示执行的指令</span><br><span class=\"hljs-comment\">#$&lt;代表第一个依赖项</span><br><span class=\"hljs-comment\">#$(dir NAMES...):取出每个文件名的目录部分</span><br><span class=\"hljs-variable\">$(OBJ_DIR)</span>/%.o: src/%.c<br>\t@echo + CC <span class=\"hljs-variable\">$&lt;</span><br>\t@mkdir -p <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">dir</span> <span class=\"hljs-variable\">$@</span>)</span><br>\t@<span class=\"hljs-variable\">$(CC)</span> <span class=\"hljs-variable\">$(CFLAGS)</span> <span class=\"hljs-variable\">$(SO_CFLAGS)</span> -c -o <span class=\"hljs-variable\">$@</span> <span class=\"hljs-variable\">$&lt;</span><br><br><br><span class=\"hljs-comment\">#看这篇文章https://blog.csdn.net/xiaozhi_su/article/details/4202779</span><br><span class=\"hljs-comment\"># Depencies</span><br><span class=\"hljs-comment\">#将OBJS中的文件后缀为.o的文件然后把后缀改为.d</span><br><span class=\"hljs-keyword\">-include</span> $(OBJS:.o=.d)<br><br><span class=\"hljs-comment\"># Some convenient rules</span><br><br><span class=\"hljs-meta\"><span class=\"hljs-meta-keyword\">.PHONY</span>: app run gdb clean run-env $(QEMU_SO)</span><br><span class=\"hljs-section\">app: <span class=\"hljs-variable\">$(BINARY)</span></span><br><br><span class=\"hljs-keyword\">override</span> ARGS ?= -l <span class=\"hljs-variable\">$(BUILD_DIR)</span>/nemu-log.txt<br><span class=\"hljs-keyword\">override</span> ARGS += -d <span class=\"hljs-variable\">$(QEMU_SO)</span><br><br><span class=\"hljs-comment\"># Command to execute NEMU</span><br>IMG :=<br>NEMU_EXEC := <span class=\"hljs-variable\">$(BINARY)</span> <span class=\"hljs-variable\">$(ARGS)</span> <span class=\"hljs-variable\">$(IMG)</span><br><br><span class=\"hljs-variable\">$(BINARY)</span>: <span class=\"hljs-variable\">$(OBJS)</span><br>\t<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">call</span> git_commit, &quot;compile&quot;)</span><br>\t@echo + LD <span class=\"hljs-variable\">$@</span><br>\t@<span class=\"hljs-variable\">$(LD)</span> -O2 -rdynamic <span class=\"hljs-variable\">$(SO_LDLAGS)</span> -o <span class=\"hljs-variable\">$@</span> <span class=\"hljs-variable\">$^</span> -lSDL2 -lreadline -ldl<br><br><span class=\"hljs-section\">run-env: <span class=\"hljs-variable\">$(BINARY)</span> <span class=\"hljs-variable\">$(QEMU_SO)</span></span><br><br><span class=\"hljs-section\">run: run-env</span><br>\t<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">call</span> git_commit, &quot;run&quot;)</span><br>\t<span class=\"hljs-variable\">$(NEMU_EXEC)</span><br><br><span class=\"hljs-section\">gdb: run-env</span><br>\t<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">call</span> git_commit, &quot;gdb&quot;)</span><br>\tgdb -s <span class=\"hljs-variable\">$(BINARY)</span> --args <span class=\"hljs-variable\">$(NEMU_EXEC)</span><br><br><span class=\"hljs-section\">clean:</span><br>\t-rm -rf <span class=\"hljs-variable\">$(BUILD_DIR)</span><br>\t<span class=\"hljs-variable\">$(MAKE)</span> -C tools/gen-expr clean<br>\t<span class=\"hljs-variable\">$(MAKE)</span> -C tools/qemu-diff clean<br><span class=\"hljs-section\">count:</span><br>\t@echo  <span class=\"hljs-string\">&quot;\\e[1;32m&quot;</span><br>\t@echo <span class=\"hljs-string\">&quot;The .c and .h file total number of row equal to :&quot;</span><br>\t@find ./ -name <span class=\"hljs-string\">&quot;*.[ch]&quot;</span> | xargs wc -l | awk &#x27;END&#123;printf <span class=\"hljs-string\">&quot;%s\\n&quot;</span>,$$1&#125;&#x27;<br>\t@echo <span class=\"hljs-string\">&quot;The .c and .h file (without blank line) total number of row equal to :&quot;</span><br>\t@find ./ -name <span class=\"hljs-string\">&quot;*.[ch]&quot;</span> | xargs cat | grep -v &#x27;^\\s*$$&#x27;| wc -l<br>\t@echo <span class=\"hljs-string\">&quot;\\e[0m&quot;</span><br><br><br><br></code></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p><strong>1.RTFSC 请整理一条指令在NEMU中的执行过程. (我们其实已经在PA2.1阶段提到过这道题了)</strong><br><br>    程序在nexus-am中被交叉编译成二进制指令被装入NEMU的内存中，NEMU通过一系列函数来取指令，解码指令，执行指令<br><br>函数调用历程如图:<br></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph LR;<br>\tA[cpu_exec];<br>\tB[exec_once];<br>\tC[isa_exec];<br>\tD[update_pc];<br>\tE[instr_fetch];<br>\tF[set_width];<br>\tG[idex];<br>\tA--&gt;B;<br>\tB--&gt;C;<br>\tB--&gt;D;<br>\tC--&gt;E;<br>\tC--&gt;F;<br>\tC--&gt;G;<br></code></pre></td></tr></table></figure>\n<p>以指令0x00为例cpu执行模拟函数cpu_exec一路执行到instr_fetch在内存中取出指令0x00然后查询<em>NEMU模拟器中存储的符合x指令集规范的表opcode_table(需要我们手动实现)</em>得到对应的0x00这一条指令的执行宽度,opcode_table[0x00].width,调用宽度设置函数set_width设置宽度,然后进入idex函数运行对应的内置解码程序opcode_table[0x00].decode,和指令对于的内置执行程序opcode_table[0x00].execute,最后调用update_pc函数，更新pc寄存器.<br></p>\n<p><strong>2.编译与链接 在nemu/include/rtl/rtl.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?</strong><br></p>\n<p><strong>static:</strong>&lt;解释来自stackoverflow&gt;<br></p>\n<ul>\n<li><ol>\n<li>Static defined <strong>local</strong> variables do not lose their value between function calls. In other words they are global variables, but scoped to the local function they are defined in.&lt;函数内定义的变量用static关键字修饰就会被编译器放入静态存储区，应该是被放在.data表内，其实就相当于一个另类的全局变量了.&gt;</li>\n</ol>\n</li>\n<li><ol>\n<li>A static <strong>global</strong> variable or a function is “seen” only in the file it’s declared in.&lt;字面意思&gt;</li>\n</ol>\n</li>\n</ul>\n<p><strong>inline:</strong><br><br>每次函数调用都要执行押入参数，保存返回地址，保存寄存器等工作会让函数调用变慢,inline的作用有点像define,可以将代码直接展开到调用处直接执行就可以让函数调用变快，但是缺点是这个操作可能让可执行文件变得更大或者更小无法预测<br></p>\n<p>有了这些基础现在开始回答问题:<br></p>\n<ul>\n<li><ol>\n<li>去掉inline:<br></li>\n</ol>\n</li>\n</ul>\n<p>static 和 static inline 其实没有很大的不同,只是函数的调用方式改变了,但是我试图编译时出现了这个错误:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">./include/rtl/rtl.h:<span class=\"hljs-number\">138</span>:<span class=\"hljs-number\">14</span>: error: ‘rtl_sext’ defined but <span class=\"hljs-keyword\">not</span> used [-Werror=unused-function]<br> <span class=\"hljs-keyword\">static</span>  <span class=\"hljs-keyword\">void</span> rtl_sext(<span class=\"hljs-keyword\">rtlreg_t</span>* dest, <span class=\"hljs-keyword\">const</span> <span class=\"hljs-keyword\">rtlreg_t</span>* src1, <span class=\"hljs-keyword\">int</span> width) &#123;<br>              ^~~~~~~~<br></code></pre></td></tr></table></figure>\n<p>原因是我们在gcc中加入了-Werror把所有的警告都当成error来处理,把-Werror去掉就可以了<br></p>\n<ul>\n<li><ol>\n<li>去掉static:<br><br>因为有inline关键字的存在所以，程序就像define一样会在调用处展开所以定义在头文件中的无static有inline的函数不会出现多次定义,只要把makefile文件中的-Werror去掉就可以编译链接成功<br></li>\n</ol>\n</li>\n<li><p>3.去掉static inline:<br><br>因为头文件会被许多文件引用所以如果去掉static inline,这个函数就会被多次定义，在链接的时候会报一下错误:<br></p>\n</li>\n</ul>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">+ LD build/x86-nemu<br>build/obj-x86/isa/x86/decode/decode.o: In function `rtl_setrelopi<span class=\"hljs-number\">&#x27;</span>:<br>/home/oeoe/Documents/ICS-PA<span class=\"hljs-number\">-2019</span>/nemu/./include/rtl/rtl.h:<span class=\"hljs-number\">145</span>: multiple definition of `rtl_setrelopi<span class=\"hljs-number\">&#x27;</span><br></code></pre></td></tr></table></figure>\n<p><strong>3.编译与链接</strong></p>\n<ul>\n<li><ol>\n<li>在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?**</li>\n</ol>\n</li>\n<li><ol>\n<li>添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.**</li>\n</ol>\n</li>\n<li><ol>\n<li>修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.)**</li>\n</ol>\n</li>\n</ul>\n<p><strong>Volatile tells the compiler not to optimize anything that has to do with the volatile variable. &lt;来自stackoverflow&gt;<br></strong></p>\n<ol>\n<li>答案是74个，在build/obj中利用<code>grep  -r -c  &#39;dummy&#39; ./* | grep &#39;\\.o:[1-9]&#39;| wc -l</code>命令得出.</li>\n<li>答案仍然是74个.</li>\n<li>两个初始化后会出现多次定义的错误:<br></li>\n</ol>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">./include/common.h:<span class=\"hljs-number\">2</span>:<span class=\"hljs-number\">21</span>: note: previous definition of ‘dummy’ was here<br> <span class=\"hljs-keyword\">volatile</span> <span class=\"hljs-keyword\">static</span> <span class=\"hljs-keyword\">int</span> dummy=<span class=\"hljs-number\">0</span>;<br>                     ^~~~~<br>In file included from ./include/device/<span class=\"hljs-built_in\">map</span>.h:<span class=\"hljs-number\">4</span>:<span class=\"hljs-number\">0</span>,<br>                 from src/memory/memory.c:<span class=\"hljs-number\">2</span>:<br>./include/common.h:<span class=\"hljs-number\">2</span>:<span class=\"hljs-number\">21</span>: error: redefinition of ‘dummy’<br></code></pre></td></tr></table></figure>\n<p>原因是强弱定义的问题，当两个dummy都没有初始化的时候dummy是一个弱符号,编译器不会报错,编译器会选择占用内存最大的那个弱符号，当把两个dummy都初始化后，两个dummy就变成强符号了，链接器不允许强符号被多次定义，如果一个是强符号一个是弱符号，那么弱符号会被强符号覆盖(当然这个弱符号的占用内存大小不能大于强符号，否则会报错).<br></p>\n<p><strong>4. 了解Makefile 请描述你在nemu/目录下敲入make 后, make程序如何组织.c和.h文件, 最终生成可执行文件nemu/build/$ISA-nemu. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:</strong><br></p>\n<ul>\n<li><ol>\n<li>Makefile中使用了变量, 包含文件等特性</li>\n</ol>\n</li>\n<li><ol>\n<li>Makefile运用并重写了一些implicit rules</li>\n</ol>\n</li>\n<li><ol>\n<li>在man make中搜索-n选项, 也许会对你有帮助</li>\n</ol>\n</li>\n</ul>\n<figure class=\"highlight makefile\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs makefile\">NAME = nemu<br><span class=\"hljs-comment\">#如果$(MAKECMDGOALS)和clean）不相等则执行ifneq ...endif内的语句</span><br><span class=\"hljs-comment\">#$MAKECMDGOALS是一个特殊参数:这个参数存放你在命令行指定的目标列表,如果什么都没指定则为空</span><br><span class=\"hljs-keyword\">ifneq</span> (<span class=\"hljs-variable\">$(MAKECMDGOALS)</span>,clean) <span class=\"hljs-comment\"># ignore check for make clean</span><br><span class=\"hljs-comment\"># ?=用来设置变量，当没有设置ISA值或者没有ISA这个变量的时候</span><br>ISA ?= x86<br><span class=\"hljs-comment\">#相当于执行一条shell命令</span><br>ISAS = <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> ls src/isa/)</span><br><span class=\"hljs-comment\">#打印信息到标准输出</span><br><span class=\"hljs-variable\">$(info Building <span class=\"hljs-variable\">$(ISA)</span>-<span class=\"hljs-variable\">$(NAME)</span>)</span><br><span class=\"hljs-comment\">#$(filter pattern…,text):</span><br><span class=\"hljs-comment\">#Returns all whitespace-separated words in text that</span><br><span class=\"hljs-comment\">#do match any of the pattern words, removing any words that do not match. </span><br><span class=\"hljs-keyword\">ifeq</span> (<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">filter</span> <span class=\"hljs-variable\">$(ISAS)</span>, <span class=\"hljs-variable\">$(ISA)</span>)</span>, ) <span class=\"hljs-comment\"># ISA must be valid</span><br><span class=\"hljs-comment\">#产生致命错误，并提示Invalid ISA. Supported: $(ISAS)给用户</span><br><span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">error</span> Invalid ISA. Supported: <span class=\"hljs-variable\">$(ISAS)</span>)</span><br><span class=\"hljs-keyword\">endif</span><br><span class=\"hljs-keyword\">endif</span><br><br>INC_DIR += ./<span class=\"hljs-keyword\">include</span> ./src/isa/<span class=\"hljs-variable\">$(ISA)</span>/<span class=\"hljs-keyword\">include</span><br>BUILD_DIR ?= ./build<br><br><span class=\"hljs-comment\">#如果SHARE的值不为空就为true</span><br><span class=\"hljs-keyword\">ifdef</span> SHARE<br>SO = -so<br><span class=\"hljs-comment\"># -D_SHARE:-Dmacro=defn  相当于 C 语言中的 #define macro=defn</span><br><span class=\"hljs-comment\"># -fPIC:生成位置无关代码</span><br>SO_CFLAGS = -fPIC -D_SHARE=1<br>SO_LDLAGS = -shared -fPIC<br><span class=\"hljs-keyword\">endif</span><br><br>OBJ_DIR ?= <span class=\"hljs-variable\">$(BUILD_DIR)</span>/obj-<span class=\"hljs-variable\">$(ISA)</span><span class=\"hljs-variable\">$(SO)</span><br>BINARY ?= <span class=\"hljs-variable\">$(BUILD_DIR)</span>/<span class=\"hljs-variable\">$(ISA)</span>-<span class=\"hljs-variable\">$(NAME)</span><span class=\"hljs-variable\">$(SO)</span><br><br><span class=\"hljs-comment\">#类似C中的#include</span><br><span class=\"hljs-keyword\">include</span> Makefile.git<br><span class=\"hljs-comment\">#设置默认目标，如果没有在命令行指定目标则使用默认目标</span><br>.DEFAULT_GOAL = app<br><br><span class=\"hljs-comment\"># Compilation flags</span><br>CC = gcc<br>LD = gcc<br><span class=\"hljs-comment\">#$(addprefix,prefix,names...):The value of prefix is prepended to the front of </span><br><span class=\"hljs-comment\"># each individual name and the resulting larger names are concatenated with single</span><br><span class=\"hljs-comment\"># spaces between them </span><br>INCLUDES  = <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">addprefix</span> -I, <span class=\"hljs-variable\">$(INC_DIR)</span>)</span><br><span class=\"hljs-comment\"># -O2:允许编译器对代码进行优化,级别为2</span><br><span class=\"hljs-comment\"># -MMD:生成文件关联信息但是忽略由#include&lt;file&gt;造成的依赖关系并且写入filename.d文件中，可以去看看-M</span><br><span class=\"hljs-comment\"># -Wall:开启所有警告信息</span><br><span class=\"hljs-comment\"># -Werror: every warning is treated as an error</span><br><span class=\"hljs-comment\"># -ggdb3:(搞不懂是什么意思)produces extra debugging information, for example: including macro definitions.</span><br><span class=\"hljs-comment\"># -D__ISA__:-Dmacro=defn  相当于 C 语言中的 #define macro=defn</span><br><span class=\"hljs-comment\"># -fomit-frame-pointer :(这个参数有关于栈指针)看这篇文章:https://stackoverflow.com/questions/14666665/trying-to-understand-gcc-option-fomit-frame-pointer</span><br>CFLAGS   += -O2 -MMD -Wall -Werror -ggdb3 <span class=\"hljs-variable\">$(INCLUDES)</span> -D__ISA__=<span class=\"hljs-variable\">$(ISA)</span> -fomit-frame-pointer<br><br>QEMU_DIFF_PATH = <span class=\"hljs-variable\">$(NEMU_HOME)</span>/tools/qemu-diff<br>QEMU_SO = <span class=\"hljs-variable\">$(QEMU_DIFF_PATH)</span>/build/<span class=\"hljs-variable\">$(ISA)</span>-qemu-so<br><br><span class=\"hljs-comment\">#执行make指令$(MAkE)是特殊变量 -C用来指定目录</span><br><span class=\"hljs-variable\">$(QEMU_SO)</span>:<br>\t<span class=\"hljs-variable\">$(MAKE)</span> -C <span class=\"hljs-variable\">$(QEMU_DIFF_PATH)</span><br><br><span class=\"hljs-comment\"># Files to be compiled</span><br><span class=\"hljs-comment\"># -v 表示不匹配“isa&quot;</span><br>SRCS = <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> find src/ -name &quot;*.c&quot; | grep -v &quot;isa&quot;)</span><br>SRCS += <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">shell</span> find src/isa/<span class=\"hljs-variable\">$(ISA)</span> -name &quot;*.c&quot;)</span><br><span class=\"hljs-comment\">#$(var:a=b)，是将 var 变量中每一个单词后面的 a 替换为 b</span><br>OBJS = $(SRCS:src/%.c=<span class=\"hljs-variable\">$(OBJ_DIR)</span>/%.o)<br><br><span class=\"hljs-comment\"># Compilation patterns</span><br><span class=\"hljs-comment\">#@表示不显示执行的指令</span><br><span class=\"hljs-comment\">#$&lt;代表第一个依赖项</span><br><span class=\"hljs-comment\">#$(dir NAMES...):取出每个文件名的目录部分</span><br><span class=\"hljs-variable\">$(OBJ_DIR)</span>/%.o: src/%.c<br>\t@echo + CC <span class=\"hljs-variable\">$&lt;</span><br>\t@mkdir -p <span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">dir</span> <span class=\"hljs-variable\">$@</span>)</span><br>\t@<span class=\"hljs-variable\">$(CC)</span> <span class=\"hljs-variable\">$(CFLAGS)</span> <span class=\"hljs-variable\">$(SO_CFLAGS)</span> -c -o <span class=\"hljs-variable\">$@</span> <span class=\"hljs-variable\">$&lt;</span><br><br><br><span class=\"hljs-comment\">#看这篇文章https://blog.csdn.net/xiaozhi_su/article/details/4202779</span><br><span class=\"hljs-comment\"># Depencies</span><br><span class=\"hljs-comment\">#将OBJS中的文件后缀为.o的文件然后把后缀改为.d</span><br><span class=\"hljs-keyword\">-include</span> $(OBJS:.o=.d)<br><br><span class=\"hljs-comment\"># Some convenient rules</span><br><br><span class=\"hljs-meta\"><span class=\"hljs-meta-keyword\">.PHONY</span>: app run gdb clean run-env $(QEMU_SO)</span><br><span class=\"hljs-section\">app: <span class=\"hljs-variable\">$(BINARY)</span></span><br><br><span class=\"hljs-keyword\">override</span> ARGS ?= -l <span class=\"hljs-variable\">$(BUILD_DIR)</span>/nemu-log.txt<br><span class=\"hljs-keyword\">override</span> ARGS += -d <span class=\"hljs-variable\">$(QEMU_SO)</span><br><br><span class=\"hljs-comment\"># Command to execute NEMU</span><br>IMG :=<br>NEMU_EXEC := <span class=\"hljs-variable\">$(BINARY)</span> <span class=\"hljs-variable\">$(ARGS)</span> <span class=\"hljs-variable\">$(IMG)</span><br><br><span class=\"hljs-variable\">$(BINARY)</span>: <span class=\"hljs-variable\">$(OBJS)</span><br>\t<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">call</span> git_commit, &quot;compile&quot;)</span><br>\t@echo + LD <span class=\"hljs-variable\">$@</span><br>\t@<span class=\"hljs-variable\">$(LD)</span> -O2 -rdynamic <span class=\"hljs-variable\">$(SO_LDLAGS)</span> -o <span class=\"hljs-variable\">$@</span> <span class=\"hljs-variable\">$^</span> -lSDL2 -lreadline -ldl<br><br><span class=\"hljs-section\">run-env: <span class=\"hljs-variable\">$(BINARY)</span> <span class=\"hljs-variable\">$(QEMU_SO)</span></span><br><br><span class=\"hljs-section\">run: run-env</span><br>\t<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">call</span> git_commit, &quot;run&quot;)</span><br>\t<span class=\"hljs-variable\">$(NEMU_EXEC)</span><br><br><span class=\"hljs-section\">gdb: run-env</span><br>\t<span class=\"hljs-variable\">$(<span class=\"hljs-built_in\">call</span> git_commit, &quot;gdb&quot;)</span><br>\tgdb -s <span class=\"hljs-variable\">$(BINARY)</span> --args <span class=\"hljs-variable\">$(NEMU_EXEC)</span><br><br><span class=\"hljs-section\">clean:</span><br>\t-rm -rf <span class=\"hljs-variable\">$(BUILD_DIR)</span><br>\t<span class=\"hljs-variable\">$(MAKE)</span> -C tools/gen-expr clean<br>\t<span class=\"hljs-variable\">$(MAKE)</span> -C tools/qemu-diff clean<br><span class=\"hljs-section\">count:</span><br>\t@echo  <span class=\"hljs-string\">&quot;\\e[1;32m&quot;</span><br>\t@echo <span class=\"hljs-string\">&quot;The .c and .h file total number of row equal to :&quot;</span><br>\t@find ./ -name <span class=\"hljs-string\">&quot;*.[ch]&quot;</span> | xargs wc -l | awk &#x27;END&#123;printf <span class=\"hljs-string\">&quot;%s\\n&quot;</span>,$$1&#125;&#x27;<br>\t@echo <span class=\"hljs-string\">&quot;The .c and .h file (without blank line) total number of row equal to :&quot;</span><br>\t@find ./ -name <span class=\"hljs-string\">&quot;*.[ch]&quot;</span> | xargs cat | grep -v &#x27;^\\s*$$&#x27;| wc -l<br>\t@echo <span class=\"hljs-string\">&quot;\\e[0m&quot;</span><br><br><br><br></code></pre></td></tr></table></figure>"},{"title":"Shell入门学习","date":"2020-04-09T12:42:58.000Z","index_img":"/Picture/Bash-Shell.jpg","_content":"\n```\n#!/bin/bash\necho -e \"hello, world\\n\"\n# 1.变量的定义使用\nmy_name=lexssama\necho \"1.$my_name\"\n# 2. 另一种定义方式\ncourse=\"linux start\"\necho 2. ${course}\n# 3. 只读变量\nreadonly course\ncourse=\"linux kernel\" #readonly 不能写入(改变)\necho \"3. ${course}\" # 输出的还是linux start\n# 4.删除变量\nunset my_name \necho \"4.${my_name}\"\n# 5.export 导出一个环境变量\nexport MY_NAME=\"lexssama\"\n# 6. 查找自定义的环境变量\nenv | grep MY_NAME\n# 7. 特殊变量\necho \"文件名称: $0\" # 特殊变量$0表示脚本文件的名称\necho \"参数１: $1\" #特殊变量$1表示传入第一个参数\necho \"参数２: $2\" #特殊变量$2表示传入第二个参数\necho \"参数３: $3\" #特殊变量$3表示传入第三个参数\necho \"全部参数: $@\" #特殊参数$@表示传入的所有参数\necho \"参数个数: $#\" #特殊参数$#表示传入参数的个数\n# 8. 基本运算\n# 8.1 算术运算 (加减乘除取余，+-*/%)\na=16\nb=17\n# 加法expr 用加法举例子\nvar0=`expr $a+$b`\necho \"$a+$b=$var0\"\n# 另一种运算方式\nvar1=$[$a+$b] \necho \"$a+$b=$var1\"\n\n#8.2 关系运算\n# -eq(相等) -ne(不相等) -gt(大于) -ge(大于等于) -lt(小于) -le(小于等于)\nif [ $a -eq $b ] #注意格式是[空格$a.....$b空格]\nthen\n\techo \"$a -eq $b : a 等于 b\"\nelse\n\techo \"$a -eq $b : a 不等于 b\"\nfi\n# 8.3 布尔与逻辑运算\n# ! 非运算\n# -o 或运算\n# -a 与运算\n# && 逻辑与 (逻辑与和与运算是不一样的，一个逻辑判断true,false 一个是二进制运算\n# || 逻辑或\n# == 相等(仅仅限于数字比较)\n# != 不相等(仅仅限于数字比较)\nif [[ $a -gt 0 && $b -gt 0 ]] #注意格式是[[空格$a.....$b空格]],并且逻辑判断是[[\nthen \n\techo \"a,b都大于0\"\nfi\n# 8.4文件测试运算\n# -d 是否为目录\n# -f 是否为普通文件\n# -r -w -x 是否可读，可写，可执行\n# -s 文件是否为空\n# -e 文件是否存在\nfile=$0\nif [ -f $file ]\nthen \n\techo \"为普通文件\"\nfi\nif [ -e $file ]\nthen \n\techo \"文件存在\"\nelse\n\techo \"文件不存在\"\nfi\nif [ -r $file ]\nthen \n\techo \"文件可读\"\nelse\n\techo \"文件不可读\"\nfi \nif [ -w $file ]\nthen \n\techo \"文件可写\"\nelse\n\techo \"文件不可写\"\nfi\nif [ -x $file ]\nthen \n\techo \"文件可执行\"\nelse\n\techo \"文件不可执行\"\nfi\n# 9.字符串\n# 单引号：原样输出，变量无效\n# 双引号：可以包含变量\ncourse1=\"Linux-shell入门学习\"\n# 单引号\nquestions='Linux-shell入门学习：$course!'\necho \"$questions\"\n# 双引号\nanswer=\"请学习<<$course1>>课程!\"\necho \"$answer\"\n\n# 字符串拼接\necho -e \"拼接后一起输出:\\n\"$questions \"\\n\" $answer\n#字符串长度(命令: ${#str})\nstr=\"hello,world\"\necho \"字符串\"$str\"的长度为:\"${#str}\n#获取子串，从第一个字符开始截取三个(命令: ${str:1:3})\necho \"字符串\"$str\"子串:\"${str:1:3}\n#查找子串(命令: `expr index \"$str\" wo`)\nmatched=`expr index \"$str\" wo`\necho \"字符串\"$str\"查找wo的位置在\"$matched\n# 9.1 字符串运算符号\n# = 字符串是否相等　[ $a = $b ]\n# != 字符串是否不相等　[ $a != $b ]\n# -z 字符串长度是否为0 [ -z $a ]\n# -n 字符串长度是否不为0 [ -n \"$a\" ]\n# $　字符串是否为空　[ $a ]\n\n\n# 10. 数组\n# 10.1 数组的定义\narr=(\"aa\" \"bb\" \"cc\" \"hello world\")\n# 10.2 设置　元素\narr[2]=\"222\"\n# 10.3 读取　元素\necho \"下标为2的元素:\"${arr[2]}\n# 10.4 读取　所有元素\necho \"所有元素: \"${arr[@]}\n# 10.5 获取数组的长度\nlen=${#arr[@]}\necho \"数组长度: $len\"\necho \"数组长度: \"${#arr[@]}\n\n# 11.分支 (if else , case)\n# 11.1 if else \n\nage=20\nif [ $age -le 10 ] # <=10\nthen\n\techo \"少年\"\nelif [ $age -le 20 ]  # <=20 注意是elif\nthen\n\techo \"青年\"\nelif [ $age -le 50 ]  # <=50\nthen\n\techo \"中年\"\nelse # >50\n\techo \"老年\"\nfi\n\n# 11.2 case \nstatus=1\ncase $status in\n\t0) echo \"todo\" ;;\n\t1) echo \"doing\" ;;\n\t2) echo \"done\" ;;\nesac\n\n# 12.循环\n# for...in..do...done\n# while...do...done\n# util...do...done\n# break\nfor item in ${arr[@]}\ndo\n\techo \"$item\"\ndone\n\n# 13. 函数\n# function关键字可加可不加 \n# 函数后面的()可加可不加\nfunction myfun()\n{\n\techo \"这是shell函数!\"\n}\nmyfun\n# 函数传参和返回值\nfunction add()\n{\n\tlocal ret=$(($1+$2))\n\treturn $ret\n}\nadd 5 8\necho $?\n```\n","source":"_posts/Shell入门学习.md","raw":"---\ntitle: Shell入门学习\ndate: 2020-04-09 20:42:58\nindex_img: /Picture/Bash-Shell.jpg\ncategories:\n- 操作系统\n- Shell\ntags:\n- Shell\n---\n\n```\n#!/bin/bash\necho -e \"hello, world\\n\"\n# 1.变量的定义使用\nmy_name=lexssama\necho \"1.$my_name\"\n# 2. 另一种定义方式\ncourse=\"linux start\"\necho 2. ${course}\n# 3. 只读变量\nreadonly course\ncourse=\"linux kernel\" #readonly 不能写入(改变)\necho \"3. ${course}\" # 输出的还是linux start\n# 4.删除变量\nunset my_name \necho \"4.${my_name}\"\n# 5.export 导出一个环境变量\nexport MY_NAME=\"lexssama\"\n# 6. 查找自定义的环境变量\nenv | grep MY_NAME\n# 7. 特殊变量\necho \"文件名称: $0\" # 特殊变量$0表示脚本文件的名称\necho \"参数１: $1\" #特殊变量$1表示传入第一个参数\necho \"参数２: $2\" #特殊变量$2表示传入第二个参数\necho \"参数３: $3\" #特殊变量$3表示传入第三个参数\necho \"全部参数: $@\" #特殊参数$@表示传入的所有参数\necho \"参数个数: $#\" #特殊参数$#表示传入参数的个数\n# 8. 基本运算\n# 8.1 算术运算 (加减乘除取余，+-*/%)\na=16\nb=17\n# 加法expr 用加法举例子\nvar0=`expr $a+$b`\necho \"$a+$b=$var0\"\n# 另一种运算方式\nvar1=$[$a+$b] \necho \"$a+$b=$var1\"\n\n#8.2 关系运算\n# -eq(相等) -ne(不相等) -gt(大于) -ge(大于等于) -lt(小于) -le(小于等于)\nif [ $a -eq $b ] #注意格式是[空格$a.....$b空格]\nthen\n\techo \"$a -eq $b : a 等于 b\"\nelse\n\techo \"$a -eq $b : a 不等于 b\"\nfi\n# 8.3 布尔与逻辑运算\n# ! 非运算\n# -o 或运算\n# -a 与运算\n# && 逻辑与 (逻辑与和与运算是不一样的，一个逻辑判断true,false 一个是二进制运算\n# || 逻辑或\n# == 相等(仅仅限于数字比较)\n# != 不相等(仅仅限于数字比较)\nif [[ $a -gt 0 && $b -gt 0 ]] #注意格式是[[空格$a.....$b空格]],并且逻辑判断是[[\nthen \n\techo \"a,b都大于0\"\nfi\n# 8.4文件测试运算\n# -d 是否为目录\n# -f 是否为普通文件\n# -r -w -x 是否可读，可写，可执行\n# -s 文件是否为空\n# -e 文件是否存在\nfile=$0\nif [ -f $file ]\nthen \n\techo \"为普通文件\"\nfi\nif [ -e $file ]\nthen \n\techo \"文件存在\"\nelse\n\techo \"文件不存在\"\nfi\nif [ -r $file ]\nthen \n\techo \"文件可读\"\nelse\n\techo \"文件不可读\"\nfi \nif [ -w $file ]\nthen \n\techo \"文件可写\"\nelse\n\techo \"文件不可写\"\nfi\nif [ -x $file ]\nthen \n\techo \"文件可执行\"\nelse\n\techo \"文件不可执行\"\nfi\n# 9.字符串\n# 单引号：原样输出，变量无效\n# 双引号：可以包含变量\ncourse1=\"Linux-shell入门学习\"\n# 单引号\nquestions='Linux-shell入门学习：$course!'\necho \"$questions\"\n# 双引号\nanswer=\"请学习<<$course1>>课程!\"\necho \"$answer\"\n\n# 字符串拼接\necho -e \"拼接后一起输出:\\n\"$questions \"\\n\" $answer\n#字符串长度(命令: ${#str})\nstr=\"hello,world\"\necho \"字符串\"$str\"的长度为:\"${#str}\n#获取子串，从第一个字符开始截取三个(命令: ${str:1:3})\necho \"字符串\"$str\"子串:\"${str:1:3}\n#查找子串(命令: `expr index \"$str\" wo`)\nmatched=`expr index \"$str\" wo`\necho \"字符串\"$str\"查找wo的位置在\"$matched\n# 9.1 字符串运算符号\n# = 字符串是否相等　[ $a = $b ]\n# != 字符串是否不相等　[ $a != $b ]\n# -z 字符串长度是否为0 [ -z $a ]\n# -n 字符串长度是否不为0 [ -n \"$a\" ]\n# $　字符串是否为空　[ $a ]\n\n\n# 10. 数组\n# 10.1 数组的定义\narr=(\"aa\" \"bb\" \"cc\" \"hello world\")\n# 10.2 设置　元素\narr[2]=\"222\"\n# 10.3 读取　元素\necho \"下标为2的元素:\"${arr[2]}\n# 10.4 读取　所有元素\necho \"所有元素: \"${arr[@]}\n# 10.5 获取数组的长度\nlen=${#arr[@]}\necho \"数组长度: $len\"\necho \"数组长度: \"${#arr[@]}\n\n# 11.分支 (if else , case)\n# 11.1 if else \n\nage=20\nif [ $age -le 10 ] # <=10\nthen\n\techo \"少年\"\nelif [ $age -le 20 ]  # <=20 注意是elif\nthen\n\techo \"青年\"\nelif [ $age -le 50 ]  # <=50\nthen\n\techo \"中年\"\nelse # >50\n\techo \"老年\"\nfi\n\n# 11.2 case \nstatus=1\ncase $status in\n\t0) echo \"todo\" ;;\n\t1) echo \"doing\" ;;\n\t2) echo \"done\" ;;\nesac\n\n# 12.循环\n# for...in..do...done\n# while...do...done\n# util...do...done\n# break\nfor item in ${arr[@]}\ndo\n\techo \"$item\"\ndone\n\n# 13. 函数\n# function关键字可加可不加 \n# 函数后面的()可加可不加\nfunction myfun()\n{\n\techo \"这是shell函数!\"\n}\nmyfun\n# 函数传参和返回值\nfunction add()\n{\n\tlocal ret=$(($1+$2))\n\treturn $ret\n}\nadd 5 8\necho $?\n```\n","slug":"Shell入门学习","published":1,"updated":"2020-11-14T14:40:36.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4s2000hr8s8fmov9a6v","content":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-meta\">#!/bin/bash</span><br><span class=\"hljs-built_in\">echo</span> -e <span class=\"hljs-string\">&quot;hello, world\\n&quot;</span><br><span class=\"hljs-comment\"># 1.变量的定义使用</span><br>my_name=lexssama<br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;1.<span class=\"hljs-variable\">$my_name</span>&quot;</span><br><span class=\"hljs-comment\"># 2. 另一种定义方式</span><br>course=<span class=\"hljs-string\">&quot;linux start&quot;</span><br><span class=\"hljs-built_in\">echo</span> 2. <span class=\"hljs-variable\">$&#123;course&#125;</span><br><span class=\"hljs-comment\"># 3. 只读变量</span><br><span class=\"hljs-built_in\">readonly</span> course<br>course=<span class=\"hljs-string\">&quot;linux kernel&quot;</span> <span class=\"hljs-comment\">#readonly 不能写入(改变)</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;3. <span class=\"hljs-variable\">$&#123;course&#125;</span>&quot;</span> <span class=\"hljs-comment\"># 输出的还是linux start</span><br><span class=\"hljs-comment\"># 4.删除变量</span><br><span class=\"hljs-built_in\">unset</span> my_name <br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;4.<span class=\"hljs-variable\">$&#123;my_name&#125;</span>&quot;</span><br><span class=\"hljs-comment\"># 5.export 导出一个环境变量</span><br><span class=\"hljs-built_in\">export</span> MY_NAME=<span class=\"hljs-string\">&quot;lexssama&quot;</span><br><span class=\"hljs-comment\"># 6. 查找自定义的环境变量</span><br>env | grep MY_NAME<br><span class=\"hljs-comment\"># 7. 特殊变量</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件名称: <span class=\"hljs-variable\">$0</span>&quot;</span> <span class=\"hljs-comment\"># 特殊变量$0表示脚本文件的名称</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数１: <span class=\"hljs-variable\">$1</span>&quot;</span> <span class=\"hljs-comment\">#特殊变量$1表示传入第一个参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数２: <span class=\"hljs-variable\">$2</span>&quot;</span> <span class=\"hljs-comment\">#特殊变量$2表示传入第二个参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数３: <span class=\"hljs-variable\">$3</span>&quot;</span> <span class=\"hljs-comment\">#特殊变量$3表示传入第三个参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;全部参数: <span class=\"hljs-variable\">$@</span>&quot;</span> <span class=\"hljs-comment\">#特殊参数$@表示传入的所有参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数个数: <span class=\"hljs-variable\">$#</span>&quot;</span> <span class=\"hljs-comment\">#特殊参数$#表示传入参数的个数</span><br><span class=\"hljs-comment\"># 8. 基本运算</span><br><span class=\"hljs-comment\"># 8.1 算术运算 (加减乘除取余，+-*/%)</span><br>a=16<br>b=17<br><span class=\"hljs-comment\"># 加法expr 用加法举例子</span><br>var0=`expr <span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>`<br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>=<span class=\"hljs-variable\">$var0</span>&quot;</span><br><span class=\"hljs-comment\"># 另一种运算方式</span><br>var1=$[<span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>] <br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>=<span class=\"hljs-variable\">$var1</span>&quot;</span><br><br><span class=\"hljs-comment\">#8.2 关系运算</span><br><span class=\"hljs-comment\"># -eq(相等) -ne(不相等) -gt(大于) -ge(大于等于) -lt(小于) -le(小于等于)</span><br><span class=\"hljs-keyword\">if</span> [ <span class=\"hljs-variable\">$a</span> -eq <span class=\"hljs-variable\">$b</span> ] <span class=\"hljs-comment\">#注意格式是[空格$a.....$b空格]</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span> -eq <span class=\"hljs-variable\">$b</span> : a 等于 b&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span> -eq <span class=\"hljs-variable\">$b</span> : a 不等于 b&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-comment\"># 8.3 布尔与逻辑运算</span><br><span class=\"hljs-comment\"># ! 非运算</span><br><span class=\"hljs-comment\"># -o 或运算</span><br><span class=\"hljs-comment\"># -a 与运算</span><br><span class=\"hljs-comment\"># &amp;&amp; 逻辑与 (逻辑与和与运算是不一样的，一个逻辑判断true,false 一个是二进制运算</span><br><span class=\"hljs-comment\"># || 逻辑或</span><br><span class=\"hljs-comment\"># == 相等(仅仅限于数字比较)</span><br><span class=\"hljs-comment\"># != 不相等(仅仅限于数字比较)</span><br><span class=\"hljs-keyword\">if</span> [[ <span class=\"hljs-variable\">$a</span> -gt 0 &amp;&amp; <span class=\"hljs-variable\">$b</span> -gt 0 ]] <span class=\"hljs-comment\">#注意格式是[[空格$a.....$b空格]],并且逻辑判断是[[</span><br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;a,b都大于0&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-comment\"># 8.4文件测试运算</span><br><span class=\"hljs-comment\"># -d 是否为目录</span><br><span class=\"hljs-comment\"># -f 是否为普通文件</span><br><span class=\"hljs-comment\"># -r -w -x 是否可读，可写，可执行</span><br><span class=\"hljs-comment\"># -s 文件是否为空</span><br><span class=\"hljs-comment\"># -e 文件是否存在</span><br>file=<span class=\"hljs-variable\">$0</span><br><span class=\"hljs-keyword\">if</span> [ -f <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;为普通文件&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-keyword\">if</span> [ -e <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件存在&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不存在&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-keyword\">if</span> [ -r <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件可读&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不可读&quot;</span><br><span class=\"hljs-keyword\">fi</span> <br><span class=\"hljs-keyword\">if</span> [ -w <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件可写&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不可写&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-keyword\">if</span> [ -x <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件可执行&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不可执行&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-comment\"># 9.字符串</span><br><span class=\"hljs-comment\"># 单引号：原样输出，变量无效</span><br><span class=\"hljs-comment\"># 双引号：可以包含变量</span><br>course1=<span class=\"hljs-string\">&quot;Linux-shell入门学习&quot;</span><br><span class=\"hljs-comment\"># 单引号</span><br>questions=<span class=\"hljs-string\">&#x27;Linux-shell入门学习：$course!&#x27;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$questions</span>&quot;</span><br><span class=\"hljs-comment\"># 双引号</span><br>answer=<span class=\"hljs-string\">&quot;请学习&lt;&lt;<span class=\"hljs-variable\">$course1</span>&gt;&gt;课程!&quot;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$answer</span>&quot;</span><br><br><span class=\"hljs-comment\"># 字符串拼接</span><br><span class=\"hljs-built_in\">echo</span> -e <span class=\"hljs-string\">&quot;拼接后一起输出:\\n&quot;</span><span class=\"hljs-variable\">$questions</span> <span class=\"hljs-string\">&quot;\\n&quot;</span> <span class=\"hljs-variable\">$answer</span><br><span class=\"hljs-comment\">#字符串长度(命令: $&#123;#str&#125;)</span><br>str=<span class=\"hljs-string\">&quot;hello,world&quot;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;字符串&quot;</span><span class=\"hljs-variable\">$str</span><span class=\"hljs-string\">&quot;的长度为:&quot;</span><span class=\"hljs-variable\">$&#123;#str&#125;</span><br><span class=\"hljs-comment\">#获取子串，从第一个字符开始截取三个(命令: $&#123;str:1:3&#125;)</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;字符串&quot;</span><span class=\"hljs-variable\">$str</span><span class=\"hljs-string\">&quot;子串:&quot;</span><span class=\"hljs-variable\">$&#123;str:1:3&#125;</span><br><span class=\"hljs-comment\">#查找子串(命令: `expr index &quot;$str&quot; wo`)</span><br>matched=`expr index <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$str</span>&quot;</span> wo`<br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;字符串&quot;</span><span class=\"hljs-variable\">$str</span><span class=\"hljs-string\">&quot;查找wo的位置在&quot;</span><span class=\"hljs-variable\">$matched</span><br><span class=\"hljs-comment\"># 9.1 字符串运算符号</span><br><span class=\"hljs-comment\"># = 字符串是否相等　[ $a = $b ]</span><br><span class=\"hljs-comment\"># != 字符串是否不相等　[ $a != $b ]</span><br><span class=\"hljs-comment\"># -z 字符串长度是否为0 [ -z $a ]</span><br><span class=\"hljs-comment\"># -n 字符串长度是否不为0 [ -n &quot;$a&quot; ]</span><br><span class=\"hljs-comment\"># $　字符串是否为空　[ $a ]</span><br><br><br><span class=\"hljs-comment\"># 10. 数组</span><br><span class=\"hljs-comment\"># 10.1 数组的定义</span><br>arr=(<span class=\"hljs-string\">&quot;aa&quot;</span> <span class=\"hljs-string\">&quot;bb&quot;</span> <span class=\"hljs-string\">&quot;cc&quot;</span> <span class=\"hljs-string\">&quot;hello world&quot;</span>)<br><span class=\"hljs-comment\"># 10.2 设置　元素</span><br>arr[2]=<span class=\"hljs-string\">&quot;222&quot;</span><br><span class=\"hljs-comment\"># 10.3 读取　元素</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;下标为2的元素:&quot;</span><span class=\"hljs-variable\">$&#123;arr[2]&#125;</span><br><span class=\"hljs-comment\"># 10.4 读取　所有元素</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;所有元素: &quot;</span><span class=\"hljs-variable\">$&#123;arr[@]&#125;</span><br><span class=\"hljs-comment\"># 10.5 获取数组的长度</span><br>len=<span class=\"hljs-variable\">$&#123;#arr[@]&#125;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;数组长度: <span class=\"hljs-variable\">$len</span>&quot;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;数组长度: &quot;</span><span class=\"hljs-variable\">$&#123;#arr[@]&#125;</span><br><br><span class=\"hljs-comment\"># 11.分支 (if else , case)</span><br><span class=\"hljs-comment\"># 11.1 if else </span><br><br>age=20<br><span class=\"hljs-keyword\">if</span> [ <span class=\"hljs-variable\">$age</span> -le 10 ] <span class=\"hljs-comment\"># &lt;=10</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;少年&quot;</span><br><span class=\"hljs-keyword\">elif</span> [ <span class=\"hljs-variable\">$age</span> -le 20 ]  <span class=\"hljs-comment\"># &lt;=20 注意是elif</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;青年&quot;</span><br><span class=\"hljs-keyword\">elif</span> [ <span class=\"hljs-variable\">$age</span> -le 50 ]  <span class=\"hljs-comment\"># &lt;=50</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;中年&quot;</span><br><span class=\"hljs-keyword\">else</span> <span class=\"hljs-comment\"># &gt;50</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;老年&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><br><span class=\"hljs-comment\"># 11.2 case </span><br>status=1<br><span class=\"hljs-keyword\">case</span> <span class=\"hljs-variable\">$status</span> <span class=\"hljs-keyword\">in</span><br>\t0) <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;todo&quot;</span> ;;<br>\t1) <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;doing&quot;</span> ;;<br>\t2) <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;done&quot;</span> ;;<br><span class=\"hljs-keyword\">esac</span><br><br><span class=\"hljs-comment\"># 12.循环</span><br><span class=\"hljs-comment\"># for...in..do...done</span><br><span class=\"hljs-comment\"># while...do...done</span><br><span class=\"hljs-comment\"># util...do...done</span><br><span class=\"hljs-comment\"># break</span><br><span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable\">$&#123;arr[@]&#125;</span><br><span class=\"hljs-keyword\">do</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$item</span>&quot;</span><br><span class=\"hljs-keyword\">done</span><br><br><span class=\"hljs-comment\"># 13. 函数</span><br><span class=\"hljs-comment\"># function关键字可加可不加 </span><br><span class=\"hljs-comment\"># 函数后面的()可加可不加</span><br><span class=\"hljs-keyword\">function</span> myfun()<br>&#123;<br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;这是shell函数!&quot;</span><br>&#125;<br>myfun<br><span class=\"hljs-comment\"># 函数传参和返回值</span><br><span class=\"hljs-keyword\">function</span> add()<br>&#123;<br>\t<span class=\"hljs-built_in\">local</span> ret=$((<span class=\"hljs-variable\">$1</span>+<span class=\"hljs-variable\">$2</span>))<br>\t<span class=\"hljs-built_in\">return</span> <span class=\"hljs-variable\">$ret</span><br>&#125;<br>add 5 8<br><span class=\"hljs-built_in\">echo</span> $?<br></code></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\"><span class=\"hljs-meta\">#!/bin/bash</span><br><span class=\"hljs-built_in\">echo</span> -e <span class=\"hljs-string\">&quot;hello, world\\n&quot;</span><br><span class=\"hljs-comment\"># 1.变量的定义使用</span><br>my_name=lexssama<br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;1.<span class=\"hljs-variable\">$my_name</span>&quot;</span><br><span class=\"hljs-comment\"># 2. 另一种定义方式</span><br>course=<span class=\"hljs-string\">&quot;linux start&quot;</span><br><span class=\"hljs-built_in\">echo</span> 2. <span class=\"hljs-variable\">$&#123;course&#125;</span><br><span class=\"hljs-comment\"># 3. 只读变量</span><br><span class=\"hljs-built_in\">readonly</span> course<br>course=<span class=\"hljs-string\">&quot;linux kernel&quot;</span> <span class=\"hljs-comment\">#readonly 不能写入(改变)</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;3. <span class=\"hljs-variable\">$&#123;course&#125;</span>&quot;</span> <span class=\"hljs-comment\"># 输出的还是linux start</span><br><span class=\"hljs-comment\"># 4.删除变量</span><br><span class=\"hljs-built_in\">unset</span> my_name <br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;4.<span class=\"hljs-variable\">$&#123;my_name&#125;</span>&quot;</span><br><span class=\"hljs-comment\"># 5.export 导出一个环境变量</span><br><span class=\"hljs-built_in\">export</span> MY_NAME=<span class=\"hljs-string\">&quot;lexssama&quot;</span><br><span class=\"hljs-comment\"># 6. 查找自定义的环境变量</span><br>env | grep MY_NAME<br><span class=\"hljs-comment\"># 7. 特殊变量</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件名称: <span class=\"hljs-variable\">$0</span>&quot;</span> <span class=\"hljs-comment\"># 特殊变量$0表示脚本文件的名称</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数１: <span class=\"hljs-variable\">$1</span>&quot;</span> <span class=\"hljs-comment\">#特殊变量$1表示传入第一个参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数２: <span class=\"hljs-variable\">$2</span>&quot;</span> <span class=\"hljs-comment\">#特殊变量$2表示传入第二个参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数３: <span class=\"hljs-variable\">$3</span>&quot;</span> <span class=\"hljs-comment\">#特殊变量$3表示传入第三个参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;全部参数: <span class=\"hljs-variable\">$@</span>&quot;</span> <span class=\"hljs-comment\">#特殊参数$@表示传入的所有参数</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;参数个数: <span class=\"hljs-variable\">$#</span>&quot;</span> <span class=\"hljs-comment\">#特殊参数$#表示传入参数的个数</span><br><span class=\"hljs-comment\"># 8. 基本运算</span><br><span class=\"hljs-comment\"># 8.1 算术运算 (加减乘除取余，+-*/%)</span><br>a=16<br>b=17<br><span class=\"hljs-comment\"># 加法expr 用加法举例子</span><br>var0=`expr <span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>`<br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>=<span class=\"hljs-variable\">$var0</span>&quot;</span><br><span class=\"hljs-comment\"># 另一种运算方式</span><br>var1=$[<span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>] <br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span>+<span class=\"hljs-variable\">$b</span>=<span class=\"hljs-variable\">$var1</span>&quot;</span><br><br><span class=\"hljs-comment\">#8.2 关系运算</span><br><span class=\"hljs-comment\"># -eq(相等) -ne(不相等) -gt(大于) -ge(大于等于) -lt(小于) -le(小于等于)</span><br><span class=\"hljs-keyword\">if</span> [ <span class=\"hljs-variable\">$a</span> -eq <span class=\"hljs-variable\">$b</span> ] <span class=\"hljs-comment\">#注意格式是[空格$a.....$b空格]</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span> -eq <span class=\"hljs-variable\">$b</span> : a 等于 b&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$a</span> -eq <span class=\"hljs-variable\">$b</span> : a 不等于 b&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-comment\"># 8.3 布尔与逻辑运算</span><br><span class=\"hljs-comment\"># ! 非运算</span><br><span class=\"hljs-comment\"># -o 或运算</span><br><span class=\"hljs-comment\"># -a 与运算</span><br><span class=\"hljs-comment\"># &amp;&amp; 逻辑与 (逻辑与和与运算是不一样的，一个逻辑判断true,false 一个是二进制运算</span><br><span class=\"hljs-comment\"># || 逻辑或</span><br><span class=\"hljs-comment\"># == 相等(仅仅限于数字比较)</span><br><span class=\"hljs-comment\"># != 不相等(仅仅限于数字比较)</span><br><span class=\"hljs-keyword\">if</span> [[ <span class=\"hljs-variable\">$a</span> -gt 0 &amp;&amp; <span class=\"hljs-variable\">$b</span> -gt 0 ]] <span class=\"hljs-comment\">#注意格式是[[空格$a.....$b空格]],并且逻辑判断是[[</span><br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;a,b都大于0&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-comment\"># 8.4文件测试运算</span><br><span class=\"hljs-comment\"># -d 是否为目录</span><br><span class=\"hljs-comment\"># -f 是否为普通文件</span><br><span class=\"hljs-comment\"># -r -w -x 是否可读，可写，可执行</span><br><span class=\"hljs-comment\"># -s 文件是否为空</span><br><span class=\"hljs-comment\"># -e 文件是否存在</span><br>file=<span class=\"hljs-variable\">$0</span><br><span class=\"hljs-keyword\">if</span> [ -f <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;为普通文件&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-keyword\">if</span> [ -e <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件存在&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不存在&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-keyword\">if</span> [ -r <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件可读&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不可读&quot;</span><br><span class=\"hljs-keyword\">fi</span> <br><span class=\"hljs-keyword\">if</span> [ -w <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件可写&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不可写&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-keyword\">if</span> [ -x <span class=\"hljs-variable\">$file</span> ]<br><span class=\"hljs-keyword\">then</span> <br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件可执行&quot;</span><br><span class=\"hljs-keyword\">else</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;文件不可执行&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><span class=\"hljs-comment\"># 9.字符串</span><br><span class=\"hljs-comment\"># 单引号：原样输出，变量无效</span><br><span class=\"hljs-comment\"># 双引号：可以包含变量</span><br>course1=<span class=\"hljs-string\">&quot;Linux-shell入门学习&quot;</span><br><span class=\"hljs-comment\"># 单引号</span><br>questions=<span class=\"hljs-string\">&#x27;Linux-shell入门学习：$course!&#x27;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$questions</span>&quot;</span><br><span class=\"hljs-comment\"># 双引号</span><br>answer=<span class=\"hljs-string\">&quot;请学习&lt;&lt;<span class=\"hljs-variable\">$course1</span>&gt;&gt;课程!&quot;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$answer</span>&quot;</span><br><br><span class=\"hljs-comment\"># 字符串拼接</span><br><span class=\"hljs-built_in\">echo</span> -e <span class=\"hljs-string\">&quot;拼接后一起输出:\\n&quot;</span><span class=\"hljs-variable\">$questions</span> <span class=\"hljs-string\">&quot;\\n&quot;</span> <span class=\"hljs-variable\">$answer</span><br><span class=\"hljs-comment\">#字符串长度(命令: $&#123;#str&#125;)</span><br>str=<span class=\"hljs-string\">&quot;hello,world&quot;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;字符串&quot;</span><span class=\"hljs-variable\">$str</span><span class=\"hljs-string\">&quot;的长度为:&quot;</span><span class=\"hljs-variable\">$&#123;#str&#125;</span><br><span class=\"hljs-comment\">#获取子串，从第一个字符开始截取三个(命令: $&#123;str:1:3&#125;)</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;字符串&quot;</span><span class=\"hljs-variable\">$str</span><span class=\"hljs-string\">&quot;子串:&quot;</span><span class=\"hljs-variable\">$&#123;str:1:3&#125;</span><br><span class=\"hljs-comment\">#查找子串(命令: `expr index &quot;$str&quot; wo`)</span><br>matched=`expr index <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$str</span>&quot;</span> wo`<br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;字符串&quot;</span><span class=\"hljs-variable\">$str</span><span class=\"hljs-string\">&quot;查找wo的位置在&quot;</span><span class=\"hljs-variable\">$matched</span><br><span class=\"hljs-comment\"># 9.1 字符串运算符号</span><br><span class=\"hljs-comment\"># = 字符串是否相等　[ $a = $b ]</span><br><span class=\"hljs-comment\"># != 字符串是否不相等　[ $a != $b ]</span><br><span class=\"hljs-comment\"># -z 字符串长度是否为0 [ -z $a ]</span><br><span class=\"hljs-comment\"># -n 字符串长度是否不为0 [ -n &quot;$a&quot; ]</span><br><span class=\"hljs-comment\"># $　字符串是否为空　[ $a ]</span><br><br><br><span class=\"hljs-comment\"># 10. 数组</span><br><span class=\"hljs-comment\"># 10.1 数组的定义</span><br>arr=(<span class=\"hljs-string\">&quot;aa&quot;</span> <span class=\"hljs-string\">&quot;bb&quot;</span> <span class=\"hljs-string\">&quot;cc&quot;</span> <span class=\"hljs-string\">&quot;hello world&quot;</span>)<br><span class=\"hljs-comment\"># 10.2 设置　元素</span><br>arr[2]=<span class=\"hljs-string\">&quot;222&quot;</span><br><span class=\"hljs-comment\"># 10.3 读取　元素</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;下标为2的元素:&quot;</span><span class=\"hljs-variable\">$&#123;arr[2]&#125;</span><br><span class=\"hljs-comment\"># 10.4 读取　所有元素</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;所有元素: &quot;</span><span class=\"hljs-variable\">$&#123;arr[@]&#125;</span><br><span class=\"hljs-comment\"># 10.5 获取数组的长度</span><br>len=<span class=\"hljs-variable\">$&#123;#arr[@]&#125;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;数组长度: <span class=\"hljs-variable\">$len</span>&quot;</span><br><span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;数组长度: &quot;</span><span class=\"hljs-variable\">$&#123;#arr[@]&#125;</span><br><br><span class=\"hljs-comment\"># 11.分支 (if else , case)</span><br><span class=\"hljs-comment\"># 11.1 if else </span><br><br>age=20<br><span class=\"hljs-keyword\">if</span> [ <span class=\"hljs-variable\">$age</span> -le 10 ] <span class=\"hljs-comment\"># &lt;=10</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;少年&quot;</span><br><span class=\"hljs-keyword\">elif</span> [ <span class=\"hljs-variable\">$age</span> -le 20 ]  <span class=\"hljs-comment\"># &lt;=20 注意是elif</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;青年&quot;</span><br><span class=\"hljs-keyword\">elif</span> [ <span class=\"hljs-variable\">$age</span> -le 50 ]  <span class=\"hljs-comment\"># &lt;=50</span><br><span class=\"hljs-keyword\">then</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;中年&quot;</span><br><span class=\"hljs-keyword\">else</span> <span class=\"hljs-comment\"># &gt;50</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;老年&quot;</span><br><span class=\"hljs-keyword\">fi</span><br><br><span class=\"hljs-comment\"># 11.2 case </span><br>status=1<br><span class=\"hljs-keyword\">case</span> <span class=\"hljs-variable\">$status</span> <span class=\"hljs-keyword\">in</span><br>\t0) <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;todo&quot;</span> ;;<br>\t1) <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;doing&quot;</span> ;;<br>\t2) <span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;done&quot;</span> ;;<br><span class=\"hljs-keyword\">esac</span><br><br><span class=\"hljs-comment\"># 12.循环</span><br><span class=\"hljs-comment\"># for...in..do...done</span><br><span class=\"hljs-comment\"># while...do...done</span><br><span class=\"hljs-comment\"># util...do...done</span><br><span class=\"hljs-comment\"># break</span><br><span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable\">$&#123;arr[@]&#125;</span><br><span class=\"hljs-keyword\">do</span><br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;<span class=\"hljs-variable\">$item</span>&quot;</span><br><span class=\"hljs-keyword\">done</span><br><br><span class=\"hljs-comment\"># 13. 函数</span><br><span class=\"hljs-comment\"># function关键字可加可不加 </span><br><span class=\"hljs-comment\"># 函数后面的()可加可不加</span><br><span class=\"hljs-keyword\">function</span> myfun()<br>&#123;<br>\t<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">&quot;这是shell函数!&quot;</span><br>&#125;<br>myfun<br><span class=\"hljs-comment\"># 函数传参和返回值</span><br><span class=\"hljs-keyword\">function</span> add()<br>&#123;<br>\t<span class=\"hljs-built_in\">local</span> ret=$((<span class=\"hljs-variable\">$1</span>+<span class=\"hljs-variable\">$2</span>))<br>\t<span class=\"hljs-built_in\">return</span> <span class=\"hljs-variable\">$ret</span><br>&#125;<br>add 5 8<br><span class=\"hljs-built_in\">echo</span> $?<br></code></pre></td></tr></table></figure>"},{"title":"Spring Cloud Eureka 初入门","index_img":"/Picture/Spring-Cloud-Eureka.png","date":"2020-06-17T09:38:42.000Z","banner_img":null,"_content":"# Eureka是什么？\nEureka就是由Netflix公司开发的一款开源的服务注册和发现的的产品 SpringCloud将其集成到SpringCloud的子项目Spring-Cloud-netflix中实现SpringCloud的服务注册和发现功能\n\n# Eureka解决什么实际问题？\n**Eureka解决的是服务的硬编码问题提供服务地址的问题,也就是微服务客户端不用在代码中硬写出微服务服务端，如果微服务客户端和服务端都有很多例如100个，那么每个微服物客户端都要写下100个服务端的IP地址以及端口,如果由于业务需求增加客户端或服务端，就又需要添加相应的代码，这样很难维护.**\n# Eureka的划分\nEureka可以分为Eureka Service端和Eureka Client端<br>\nEureka Client可以建立在微服务的服务端(Application Service)和客户端(Application Client).<br>\n# Eureka的架构\n\n![eureka_architecture](eureka-architecture.png)<br>\n\n简单的解释上图: 每一个Eureka Client(包括ApplicationService和ApplicationClient)需要向Eureka Service(服务注册中心)注册，当ApplicationClient需要访问ApplicationServices时，ApplicationClient就会向Eureka Service发出GET请求获取ApplicationService的信息，然后再进行远程调用Make Remote Call<br>\n\n **这样做的好处是什么呢？**<br>\n*答:如果没有Eureka Service担任ApplicationService和ApplicationClient的第三方管理,那么ApplicationClient就需要在本地记住每一个ApplicationService的访问地址和端口，如果ApplicationService宕机或者开发者加入一个新的ApplicationService，这时就需要去修改每一个ApplicationClient的本地配置信息，如果ApplicationClient的数量很多例如100个，这样就会造成很大的工作量，另外Eureka还可以提供负载均衡的功能.*\n# Eureka的功能\n**Eureka Client:** 其实就是已经在注册中心注册了的微服务，Eureka Client内置负载均衡功能．<br>\n**Eureka Service:** 提供服务注册功能，用来记录已注册微服务的相关信息.<br>\n## Eureka的服务的基本流程\n首先要写一个Eureka Service (服务注册中心) 提交上线例如上线到localhost:8761,接着需要写两个Eureka Client 分别是(Application Service 和 Application Client) , 分别通过Rest API的形式向Eureka Service注册,Eureka Service得到两个Eureka Client的相关信息，同时两个Eureka Client也获得了已在Eureka Service 中注册过得服务注册列表信息，这是ApplicationClient就知道了ApplicationService的IP地址，就可以通过HTTP远程调度来访问ApplicationService.<br>\n\n有关RESI API 的内容可以看这篇文章:[Understanding And Using REST APIs](https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/)\n\n## Eureka Renew（服务续约)\nEureka Client默认每30秒发送一次心跳给Eureka Service 进行服务续约(告诉Eureka Service 我还活着) Eureka Service如果90秒没有收到Eureka Client的心跳，Eureka Service就会自动删除这个Eureka Client.\n\n## Eureka Fetch Registries(获取服务列表信息)\nEureka Client本地有服务注册列表的的缓存信息而且默认每30秒Eureka Client会更新一次服务注册列表信息,Eureka Service中缓存了所有的注册信息，Eureka Client和Eureka Service可以通过XML或JSON的格式来通信，默认是JSON.\n## Eureka Cancel(服务下线)\nEureka Cancel在程序关闭时可以向Eureka Service发送下线请求，Eureka Service会将该Eureka Client的相关信息删除，该功能不会自动完成，需要在Eureka Client 程序中调用相关代码．\n\n## Eureka Eviction(服务剔除)\n当Eureka Client连续默认在90秒内没有给Eureka Service的发送心跳Eureka Service会把该Eureka Client实例剔除．\n\n## Eureka的自我保护\n正常情况下如果默认90秒内Eureka Service没有收到心跳，就会删除相关Eureka Client实例，但是有时并非Eureka Client宕机，而是由于网络原因导致Eureka Service大面积丢失Eureka Client,这时如果Eureka Service收到的心跳小于某个阈值，Eureka Service就会开启自我保护机制：即Eureka Service只能读写而不能执行删除操作，当Eureka Service收到的心跳高于该阈值其就会自动退出自我保护机制．\nEureka Service的阈值默认是0.85,默认自动开启.\n\n# Eureka的优点以及不足\n*在了解Eureka的优点以及不知之前首先要先了解CAP原则．*\n\n## CAP原则\nCAP原则指的是在一个分布式系统中Consistency(一致性),Availability(可用性)\nPartition tolerance(分区容错性).<br>\n\n- **Consistency(一致性):** 分布式系统中的所有数据备份，在同一时刻是否有同样的值,例如当服务器A和服务器B中的数据应该保持一致，当服务器A中的数据改变时，服务器B应该迅速同步.\n- **Avaliability(可用性):** 意思就是服务器只要收到用户的请求，就必须立刻给用户做出回应．\n- **Partition tolerance (分区容错性):** 大多数分布式系统都分布在多个子网络中，例如一个服务器A坐落在北京一个服务器B在广州，服务器A,B之间有可能无法通信，所以分区容错在CAP中是无法避免的.\n\n**CAP中P(分区容错)是无法避免的（即一定要保证分区容错性）同时可以看出C(一致性)和A(高可用性)是没有办法兼得，因为当服务A要与服务器B同步消息的某个时刻，用户向未更新消息的服务器B发送指令此时如果要保证一致性，服务器B就会忽略用户的请求，但是如果要保证高可用性,那么服务器B就必须立刻回应用户．**<br>\n\n更详细可以看阮一峰大大的博客:\n[CAP 定理的含义](http://www.ruanyifeng.com/blog/2018/07/cap.html)\n\n## Eureka的优点\neureka 是保证AP,因此是保证可用性。Eureka Service几个节点宕机不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而eureka Client向某个eureka Service注册时如果发现连接失败，则会自动切换至其他Eureka Service。只要有一台eureka server 是正常的，就能保证服务可用(保证可用性)。不过查询到的信息可能不是最新的(不保证一致性)。\n\n## Eureka的缺点\n很明显Eureka的缺点是不保证一致性．\n\n## Eureka的竞品：Zookeeper\nZookeeper是保证CP,即保证一致性,即任何时间对Zookeeper的任何服务器访问请求都能到一致的数据结果.这个就不详细讲了.\n\n\n\n感谢:<br>\n[Eureka 与 zookeeper 的区别、原理及各自优缺点](http://www.jeepxie.net/article/667918.html)<br>\n[Spring Cloud Eureka 全解](https://zhuanlan.zhihu.com/p/34976125)<br>\n[Spring Cloud-Eureka学习笔记-简介](https://zhuanlan.zhihu.com/p/120377144)\n","source":"_posts/Spring-Cloud-Eureka-初入门.md","raw":"---\ntitle: Spring Cloud Eureka 初入门\nindex_img: /Picture/Spring-Cloud-Eureka.png\ndate: 2020-06-17 17:38:42\ntags:\n- 微服务学习\ncategories:\n- 微服务学习\nbanner_img:\n---\n# Eureka是什么？\nEureka就是由Netflix公司开发的一款开源的服务注册和发现的的产品 SpringCloud将其集成到SpringCloud的子项目Spring-Cloud-netflix中实现SpringCloud的服务注册和发现功能\n\n# Eureka解决什么实际问题？\n**Eureka解决的是服务的硬编码问题提供服务地址的问题,也就是微服务客户端不用在代码中硬写出微服务服务端，如果微服务客户端和服务端都有很多例如100个，那么每个微服物客户端都要写下100个服务端的IP地址以及端口,如果由于业务需求增加客户端或服务端，就又需要添加相应的代码，这样很难维护.**\n# Eureka的划分\nEureka可以分为Eureka Service端和Eureka Client端<br>\nEureka Client可以建立在微服务的服务端(Application Service)和客户端(Application Client).<br>\n# Eureka的架构\n\n![eureka_architecture](eureka-architecture.png)<br>\n\n简单的解释上图: 每一个Eureka Client(包括ApplicationService和ApplicationClient)需要向Eureka Service(服务注册中心)注册，当ApplicationClient需要访问ApplicationServices时，ApplicationClient就会向Eureka Service发出GET请求获取ApplicationService的信息，然后再进行远程调用Make Remote Call<br>\n\n **这样做的好处是什么呢？**<br>\n*答:如果没有Eureka Service担任ApplicationService和ApplicationClient的第三方管理,那么ApplicationClient就需要在本地记住每一个ApplicationService的访问地址和端口，如果ApplicationService宕机或者开发者加入一个新的ApplicationService，这时就需要去修改每一个ApplicationClient的本地配置信息，如果ApplicationClient的数量很多例如100个，这样就会造成很大的工作量，另外Eureka还可以提供负载均衡的功能.*\n# Eureka的功能\n**Eureka Client:** 其实就是已经在注册中心注册了的微服务，Eureka Client内置负载均衡功能．<br>\n**Eureka Service:** 提供服务注册功能，用来记录已注册微服务的相关信息.<br>\n## Eureka的服务的基本流程\n首先要写一个Eureka Service (服务注册中心) 提交上线例如上线到localhost:8761,接着需要写两个Eureka Client 分别是(Application Service 和 Application Client) , 分别通过Rest API的形式向Eureka Service注册,Eureka Service得到两个Eureka Client的相关信息，同时两个Eureka Client也获得了已在Eureka Service 中注册过得服务注册列表信息，这是ApplicationClient就知道了ApplicationService的IP地址，就可以通过HTTP远程调度来访问ApplicationService.<br>\n\n有关RESI API 的内容可以看这篇文章:[Understanding And Using REST APIs](https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/)\n\n## Eureka Renew（服务续约)\nEureka Client默认每30秒发送一次心跳给Eureka Service 进行服务续约(告诉Eureka Service 我还活着) Eureka Service如果90秒没有收到Eureka Client的心跳，Eureka Service就会自动删除这个Eureka Client.\n\n## Eureka Fetch Registries(获取服务列表信息)\nEureka Client本地有服务注册列表的的缓存信息而且默认每30秒Eureka Client会更新一次服务注册列表信息,Eureka Service中缓存了所有的注册信息，Eureka Client和Eureka Service可以通过XML或JSON的格式来通信，默认是JSON.\n## Eureka Cancel(服务下线)\nEureka Cancel在程序关闭时可以向Eureka Service发送下线请求，Eureka Service会将该Eureka Client的相关信息删除，该功能不会自动完成，需要在Eureka Client 程序中调用相关代码．\n\n## Eureka Eviction(服务剔除)\n当Eureka Client连续默认在90秒内没有给Eureka Service的发送心跳Eureka Service会把该Eureka Client实例剔除．\n\n## Eureka的自我保护\n正常情况下如果默认90秒内Eureka Service没有收到心跳，就会删除相关Eureka Client实例，但是有时并非Eureka Client宕机，而是由于网络原因导致Eureka Service大面积丢失Eureka Client,这时如果Eureka Service收到的心跳小于某个阈值，Eureka Service就会开启自我保护机制：即Eureka Service只能读写而不能执行删除操作，当Eureka Service收到的心跳高于该阈值其就会自动退出自我保护机制．\nEureka Service的阈值默认是0.85,默认自动开启.\n\n# Eureka的优点以及不足\n*在了解Eureka的优点以及不知之前首先要先了解CAP原则．*\n\n## CAP原则\nCAP原则指的是在一个分布式系统中Consistency(一致性),Availability(可用性)\nPartition tolerance(分区容错性).<br>\n\n- **Consistency(一致性):** 分布式系统中的所有数据备份，在同一时刻是否有同样的值,例如当服务器A和服务器B中的数据应该保持一致，当服务器A中的数据改变时，服务器B应该迅速同步.\n- **Avaliability(可用性):** 意思就是服务器只要收到用户的请求，就必须立刻给用户做出回应．\n- **Partition tolerance (分区容错性):** 大多数分布式系统都分布在多个子网络中，例如一个服务器A坐落在北京一个服务器B在广州，服务器A,B之间有可能无法通信，所以分区容错在CAP中是无法避免的.\n\n**CAP中P(分区容错)是无法避免的（即一定要保证分区容错性）同时可以看出C(一致性)和A(高可用性)是没有办法兼得，因为当服务A要与服务器B同步消息的某个时刻，用户向未更新消息的服务器B发送指令此时如果要保证一致性，服务器B就会忽略用户的请求，但是如果要保证高可用性,那么服务器B就必须立刻回应用户．**<br>\n\n更详细可以看阮一峰大大的博客:\n[CAP 定理的含义](http://www.ruanyifeng.com/blog/2018/07/cap.html)\n\n## Eureka的优点\neureka 是保证AP,因此是保证可用性。Eureka Service几个节点宕机不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而eureka Client向某个eureka Service注册时如果发现连接失败，则会自动切换至其他Eureka Service。只要有一台eureka server 是正常的，就能保证服务可用(保证可用性)。不过查询到的信息可能不是最新的(不保证一致性)。\n\n## Eureka的缺点\n很明显Eureka的缺点是不保证一致性．\n\n## Eureka的竞品：Zookeeper\nZookeeper是保证CP,即保证一致性,即任何时间对Zookeeper的任何服务器访问请求都能到一致的数据结果.这个就不详细讲了.\n\n\n\n感谢:<br>\n[Eureka 与 zookeeper 的区别、原理及各自优缺点](http://www.jeepxie.net/article/667918.html)<br>\n[Spring Cloud Eureka 全解](https://zhuanlan.zhihu.com/p/34976125)<br>\n[Spring Cloud-Eureka学习笔记-简介](https://zhuanlan.zhihu.com/p/120377144)\n","slug":"Spring-Cloud-Eureka-初入门","published":1,"updated":"2020-11-14T14:40:36.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4s3000jr8s85nmu9pr5","content":"<h1 id=\"Eureka是什么？\"><a href=\"#Eureka是什么？\" class=\"headerlink\" title=\"Eureka是什么？\"></a>Eureka是什么？</h1><p>Eureka就是由Netflix公司开发的一款开源的服务注册和发现的的产品 SpringCloud将其集成到SpringCloud的子项目Spring-Cloud-netflix中实现SpringCloud的服务注册和发现功能</p>\n<h1 id=\"Eureka解决什么实际问题？\"><a href=\"#Eureka解决什么实际问题？\" class=\"headerlink\" title=\"Eureka解决什么实际问题？\"></a>Eureka解决什么实际问题？</h1><p><strong>Eureka解决的是服务的硬编码问题提供服务地址的问题,也就是微服务客户端不用在代码中硬写出微服务服务端，如果微服务客户端和服务端都有很多例如100个，那么每个微服物客户端都要写下100个服务端的IP地址以及端口,如果由于业务需求增加客户端或服务端，就又需要添加相应的代码，这样很难维护.</strong></p>\n<h1 id=\"Eureka的划分\"><a href=\"#Eureka的划分\" class=\"headerlink\" title=\"Eureka的划分\"></a>Eureka的划分</h1><p>Eureka可以分为Eureka Service端和Eureka Client端<br><br>Eureka Client可以建立在微服务的服务端(Application Service)和客户端(Application Client).<br></p>\n<h1 id=\"Eureka的架构\"><a href=\"#Eureka的架构\" class=\"headerlink\" title=\"Eureka的架构\"></a>Eureka的架构</h1><p><img src=\"eureka-architecture.png\" alt=\"eureka_architecture\"><br></p>\n<p>简单的解释上图: 每一个Eureka Client(包括ApplicationService和ApplicationClient)需要向Eureka Service(服务注册中心)注册，当ApplicationClient需要访问ApplicationServices时，ApplicationClient就会向Eureka Service发出GET请求获取ApplicationService的信息，然后再进行远程调用Make Remote Call<br></p>\n<p> <strong>这样做的好处是什么呢？</strong><br><br><em>答:如果没有Eureka Service担任ApplicationService和ApplicationClient的第三方管理,那么ApplicationClient就需要在本地记住每一个ApplicationService的访问地址和端口，如果ApplicationService宕机或者开发者加入一个新的ApplicationService，这时就需要去修改每一个ApplicationClient的本地配置信息，如果ApplicationClient的数量很多例如100个，这样就会造成很大的工作量，另外Eureka还可以提供负载均衡的功能.</em></p>\n<h1 id=\"Eureka的功能\"><a href=\"#Eureka的功能\" class=\"headerlink\" title=\"Eureka的功能\"></a>Eureka的功能</h1><p><strong>Eureka Client:</strong> 其实就是已经在注册中心注册了的微服务，Eureka Client内置负载均衡功能．<br><br><strong>Eureka Service:</strong> 提供服务注册功能，用来记录已注册微服务的相关信息.<br></p>\n<h2 id=\"Eureka的服务的基本流程\"><a href=\"#Eureka的服务的基本流程\" class=\"headerlink\" title=\"Eureka的服务的基本流程\"></a>Eureka的服务的基本流程</h2><p>首先要写一个Eureka Service (服务注册中心) 提交上线例如上线到localhost:8761,接着需要写两个Eureka Client 分别是(Application Service 和 Application Client) , 分别通过Rest API的形式向Eureka Service注册,Eureka Service得到两个Eureka Client的相关信息，同时两个Eureka Client也获得了已在Eureka Service 中注册过得服务注册列表信息，这是ApplicationClient就知道了ApplicationService的IP地址，就可以通过HTTP远程调度来访问ApplicationService.<br></p>\n<p>有关RESI API 的内容可以看这篇文章:<a href=\"https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/\">Understanding And Using REST APIs</a></p>\n<h2 id=\"Eureka-Renew（服务续约\"><a href=\"#Eureka-Renew（服务续约\" class=\"headerlink\" title=\"Eureka Renew（服务续约)\"></a>Eureka Renew（服务续约)</h2><p>Eureka Client默认每30秒发送一次心跳给Eureka Service 进行服务续约(告诉Eureka Service 我还活着) Eureka Service如果90秒没有收到Eureka Client的心跳，Eureka Service就会自动删除这个Eureka Client.</p>\n<h2 id=\"Eureka-Fetch-Registries-获取服务列表信息\"><a href=\"#Eureka-Fetch-Registries-获取服务列表信息\" class=\"headerlink\" title=\"Eureka Fetch Registries(获取服务列表信息)\"></a>Eureka Fetch Registries(获取服务列表信息)</h2><p>Eureka Client本地有服务注册列表的的缓存信息而且默认每30秒Eureka Client会更新一次服务注册列表信息,Eureka Service中缓存了所有的注册信息，Eureka Client和Eureka Service可以通过XML或JSON的格式来通信，默认是JSON.</p>\n<h2 id=\"Eureka-Cancel-服务下线\"><a href=\"#Eureka-Cancel-服务下线\" class=\"headerlink\" title=\"Eureka Cancel(服务下线)\"></a>Eureka Cancel(服务下线)</h2><p>Eureka Cancel在程序关闭时可以向Eureka Service发送下线请求，Eureka Service会将该Eureka Client的相关信息删除，该功能不会自动完成，需要在Eureka Client 程序中调用相关代码．</p>\n<h2 id=\"Eureka-Eviction-服务剔除\"><a href=\"#Eureka-Eviction-服务剔除\" class=\"headerlink\" title=\"Eureka Eviction(服务剔除)\"></a>Eureka Eviction(服务剔除)</h2><p>当Eureka Client连续默认在90秒内没有给Eureka Service的发送心跳Eureka Service会把该Eureka Client实例剔除．</p>\n<h2 id=\"Eureka的自我保护\"><a href=\"#Eureka的自我保护\" class=\"headerlink\" title=\"Eureka的自我保护\"></a>Eureka的自我保护</h2><p>正常情况下如果默认90秒内Eureka Service没有收到心跳，就会删除相关Eureka Client实例，但是有时并非Eureka Client宕机，而是由于网络原因导致Eureka Service大面积丢失Eureka Client,这时如果Eureka Service收到的心跳小于某个阈值，Eureka Service就会开启自我保护机制：即Eureka Service只能读写而不能执行删除操作，当Eureka Service收到的心跳高于该阈值其就会自动退出自我保护机制．<br>Eureka Service的阈值默认是0.85,默认自动开启.</p>\n<h1 id=\"Eureka的优点以及不足\"><a href=\"#Eureka的优点以及不足\" class=\"headerlink\" title=\"Eureka的优点以及不足\"></a>Eureka的优点以及不足</h1><p><em>在了解Eureka的优点以及不知之前首先要先了解CAP原则．</em></p>\n<h2 id=\"CAP原则\"><a href=\"#CAP原则\" class=\"headerlink\" title=\"CAP原则\"></a>CAP原则</h2><p>CAP原则指的是在一个分布式系统中Consistency(一致性),Availability(可用性)<br>Partition tolerance(分区容错性).<br></p>\n<ul>\n<li><strong>Consistency(一致性):</strong> 分布式系统中的所有数据备份，在同一时刻是否有同样的值,例如当服务器A和服务器B中的数据应该保持一致，当服务器A中的数据改变时，服务器B应该迅速同步.</li>\n<li><strong>Avaliability(可用性):</strong> 意思就是服务器只要收到用户的请求，就必须立刻给用户做出回应．</li>\n<li><strong>Partition tolerance (分区容错性):</strong> 大多数分布式系统都分布在多个子网络中，例如一个服务器A坐落在北京一个服务器B在广州，服务器A,B之间有可能无法通信，所以分区容错在CAP中是无法避免的.</li>\n</ul>\n<p><strong>CAP中P(分区容错)是无法避免的（即一定要保证分区容错性）同时可以看出C(一致性)和A(高可用性)是没有办法兼得，因为当服务A要与服务器B同步消息的某个时刻，用户向未更新消息的服务器B发送指令此时如果要保证一致性，服务器B就会忽略用户的请求，但是如果要保证高可用性,那么服务器B就必须立刻回应用户．</strong><br></p>\n<p>更详细可以看阮一峰大大的博客:<br><a href=\"http://www.ruanyifeng.com/blog/2018/07/cap.html\">CAP 定理的含义</a></p>\n<h2 id=\"Eureka的优点\"><a href=\"#Eureka的优点\" class=\"headerlink\" title=\"Eureka的优点\"></a>Eureka的优点</h2><p>eureka 是保证AP,因此是保证可用性。Eureka Service几个节点宕机不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而eureka Client向某个eureka Service注册时如果发现连接失败，则会自动切换至其他Eureka Service。只要有一台eureka server 是正常的，就能保证服务可用(保证可用性)。不过查询到的信息可能不是最新的(不保证一致性)。</p>\n<h2 id=\"Eureka的缺点\"><a href=\"#Eureka的缺点\" class=\"headerlink\" title=\"Eureka的缺点\"></a>Eureka的缺点</h2><p>很明显Eureka的缺点是不保证一致性．</p>\n<h2 id=\"Eureka的竞品：Zookeeper\"><a href=\"#Eureka的竞品：Zookeeper\" class=\"headerlink\" title=\"Eureka的竞品：Zookeeper\"></a>Eureka的竞品：Zookeeper</h2><p>Zookeeper是保证CP,即保证一致性,即任何时间对Zookeeper的任何服务器访问请求都能到一致的数据结果.这个就不详细讲了.</p>\n<p>感谢:<br><br><a href=\"http://www.jeepxie.net/article/667918.html\">Eureka 与 zookeeper 的区别、原理及各自优缺点</a><br><br><a href=\"https://zhuanlan.zhihu.com/p/34976125\">Spring Cloud Eureka 全解</a><br><br><a href=\"https://zhuanlan.zhihu.com/p/120377144\">Spring Cloud-Eureka学习笔记-简介</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Eureka是什么？\"><a href=\"#Eureka是什么？\" class=\"headerlink\" title=\"Eureka是什么？\"></a>Eureka是什么？</h1><p>Eureka就是由Netflix公司开发的一款开源的服务注册和发现的的产品 SpringCloud将其集成到SpringCloud的子项目Spring-Cloud-netflix中实现SpringCloud的服务注册和发现功能</p>\n<h1 id=\"Eureka解决什么实际问题？\"><a href=\"#Eureka解决什么实际问题？\" class=\"headerlink\" title=\"Eureka解决什么实际问题？\"></a>Eureka解决什么实际问题？</h1><p><strong>Eureka解决的是服务的硬编码问题提供服务地址的问题,也就是微服务客户端不用在代码中硬写出微服务服务端，如果微服务客户端和服务端都有很多例如100个，那么每个微服物客户端都要写下100个服务端的IP地址以及端口,如果由于业务需求增加客户端或服务端，就又需要添加相应的代码，这样很难维护.</strong></p>\n<h1 id=\"Eureka的划分\"><a href=\"#Eureka的划分\" class=\"headerlink\" title=\"Eureka的划分\"></a>Eureka的划分</h1><p>Eureka可以分为Eureka Service端和Eureka Client端<br><br>Eureka Client可以建立在微服务的服务端(Application Service)和客户端(Application Client).<br></p>\n<h1 id=\"Eureka的架构\"><a href=\"#Eureka的架构\" class=\"headerlink\" title=\"Eureka的架构\"></a>Eureka的架构</h1><p><img src=\"eureka-architecture.png\" alt=\"eureka_architecture\"><br></p>\n<p>简单的解释上图: 每一个Eureka Client(包括ApplicationService和ApplicationClient)需要向Eureka Service(服务注册中心)注册，当ApplicationClient需要访问ApplicationServices时，ApplicationClient就会向Eureka Service发出GET请求获取ApplicationService的信息，然后再进行远程调用Make Remote Call<br></p>\n<p> <strong>这样做的好处是什么呢？</strong><br><br><em>答:如果没有Eureka Service担任ApplicationService和ApplicationClient的第三方管理,那么ApplicationClient就需要在本地记住每一个ApplicationService的访问地址和端口，如果ApplicationService宕机或者开发者加入一个新的ApplicationService，这时就需要去修改每一个ApplicationClient的本地配置信息，如果ApplicationClient的数量很多例如100个，这样就会造成很大的工作量，另外Eureka还可以提供负载均衡的功能.</em></p>\n<h1 id=\"Eureka的功能\"><a href=\"#Eureka的功能\" class=\"headerlink\" title=\"Eureka的功能\"></a>Eureka的功能</h1><p><strong>Eureka Client:</strong> 其实就是已经在注册中心注册了的微服务，Eureka Client内置负载均衡功能．<br><br><strong>Eureka Service:</strong> 提供服务注册功能，用来记录已注册微服务的相关信息.<br></p>\n<h2 id=\"Eureka的服务的基本流程\"><a href=\"#Eureka的服务的基本流程\" class=\"headerlink\" title=\"Eureka的服务的基本流程\"></a>Eureka的服务的基本流程</h2><p>首先要写一个Eureka Service (服务注册中心) 提交上线例如上线到localhost:8761,接着需要写两个Eureka Client 分别是(Application Service 和 Application Client) , 分别通过Rest API的形式向Eureka Service注册,Eureka Service得到两个Eureka Client的相关信息，同时两个Eureka Client也获得了已在Eureka Service 中注册过得服务注册列表信息，这是ApplicationClient就知道了ApplicationService的IP地址，就可以通过HTTP远程调度来访问ApplicationService.<br></p>\n<p>有关RESI API 的内容可以看这篇文章:<a href=\"https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/\">Understanding And Using REST APIs</a></p>\n<h2 id=\"Eureka-Renew（服务续约\"><a href=\"#Eureka-Renew（服务续约\" class=\"headerlink\" title=\"Eureka Renew（服务续约)\"></a>Eureka Renew（服务续约)</h2><p>Eureka Client默认每30秒发送一次心跳给Eureka Service 进行服务续约(告诉Eureka Service 我还活着) Eureka Service如果90秒没有收到Eureka Client的心跳，Eureka Service就会自动删除这个Eureka Client.</p>\n<h2 id=\"Eureka-Fetch-Registries-获取服务列表信息\"><a href=\"#Eureka-Fetch-Registries-获取服务列表信息\" class=\"headerlink\" title=\"Eureka Fetch Registries(获取服务列表信息)\"></a>Eureka Fetch Registries(获取服务列表信息)</h2><p>Eureka Client本地有服务注册列表的的缓存信息而且默认每30秒Eureka Client会更新一次服务注册列表信息,Eureka Service中缓存了所有的注册信息，Eureka Client和Eureka Service可以通过XML或JSON的格式来通信，默认是JSON.</p>\n<h2 id=\"Eureka-Cancel-服务下线\"><a href=\"#Eureka-Cancel-服务下线\" class=\"headerlink\" title=\"Eureka Cancel(服务下线)\"></a>Eureka Cancel(服务下线)</h2><p>Eureka Cancel在程序关闭时可以向Eureka Service发送下线请求，Eureka Service会将该Eureka Client的相关信息删除，该功能不会自动完成，需要在Eureka Client 程序中调用相关代码．</p>\n<h2 id=\"Eureka-Eviction-服务剔除\"><a href=\"#Eureka-Eviction-服务剔除\" class=\"headerlink\" title=\"Eureka Eviction(服务剔除)\"></a>Eureka Eviction(服务剔除)</h2><p>当Eureka Client连续默认在90秒内没有给Eureka Service的发送心跳Eureka Service会把该Eureka Client实例剔除．</p>\n<h2 id=\"Eureka的自我保护\"><a href=\"#Eureka的自我保护\" class=\"headerlink\" title=\"Eureka的自我保护\"></a>Eureka的自我保护</h2><p>正常情况下如果默认90秒内Eureka Service没有收到心跳，就会删除相关Eureka Client实例，但是有时并非Eureka Client宕机，而是由于网络原因导致Eureka Service大面积丢失Eureka Client,这时如果Eureka Service收到的心跳小于某个阈值，Eureka Service就会开启自我保护机制：即Eureka Service只能读写而不能执行删除操作，当Eureka Service收到的心跳高于该阈值其就会自动退出自我保护机制．<br>Eureka Service的阈值默认是0.85,默认自动开启.</p>\n<h1 id=\"Eureka的优点以及不足\"><a href=\"#Eureka的优点以及不足\" class=\"headerlink\" title=\"Eureka的优点以及不足\"></a>Eureka的优点以及不足</h1><p><em>在了解Eureka的优点以及不知之前首先要先了解CAP原则．</em></p>\n<h2 id=\"CAP原则\"><a href=\"#CAP原则\" class=\"headerlink\" title=\"CAP原则\"></a>CAP原则</h2><p>CAP原则指的是在一个分布式系统中Consistency(一致性),Availability(可用性)<br>Partition tolerance(分区容错性).<br></p>\n<ul>\n<li><strong>Consistency(一致性):</strong> 分布式系统中的所有数据备份，在同一时刻是否有同样的值,例如当服务器A和服务器B中的数据应该保持一致，当服务器A中的数据改变时，服务器B应该迅速同步.</li>\n<li><strong>Avaliability(可用性):</strong> 意思就是服务器只要收到用户的请求，就必须立刻给用户做出回应．</li>\n<li><strong>Partition tolerance (分区容错性):</strong> 大多数分布式系统都分布在多个子网络中，例如一个服务器A坐落在北京一个服务器B在广州，服务器A,B之间有可能无法通信，所以分区容错在CAP中是无法避免的.</li>\n</ul>\n<p><strong>CAP中P(分区容错)是无法避免的（即一定要保证分区容错性）同时可以看出C(一致性)和A(高可用性)是没有办法兼得，因为当服务A要与服务器B同步消息的某个时刻，用户向未更新消息的服务器B发送指令此时如果要保证一致性，服务器B就会忽略用户的请求，但是如果要保证高可用性,那么服务器B就必须立刻回应用户．</strong><br></p>\n<p>更详细可以看阮一峰大大的博客:<br><a href=\"http://www.ruanyifeng.com/blog/2018/07/cap.html\">CAP 定理的含义</a></p>\n<h2 id=\"Eureka的优点\"><a href=\"#Eureka的优点\" class=\"headerlink\" title=\"Eureka的优点\"></a>Eureka的优点</h2><p>eureka 是保证AP,因此是保证可用性。Eureka Service几个节点宕机不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而eureka Client向某个eureka Service注册时如果发现连接失败，则会自动切换至其他Eureka Service。只要有一台eureka server 是正常的，就能保证服务可用(保证可用性)。不过查询到的信息可能不是最新的(不保证一致性)。</p>\n<h2 id=\"Eureka的缺点\"><a href=\"#Eureka的缺点\" class=\"headerlink\" title=\"Eureka的缺点\"></a>Eureka的缺点</h2><p>很明显Eureka的缺点是不保证一致性．</p>\n<h2 id=\"Eureka的竞品：Zookeeper\"><a href=\"#Eureka的竞品：Zookeeper\" class=\"headerlink\" title=\"Eureka的竞品：Zookeeper\"></a>Eureka的竞品：Zookeeper</h2><p>Zookeeper是保证CP,即保证一致性,即任何时间对Zookeeper的任何服务器访问请求都能到一致的数据结果.这个就不详细讲了.</p>\n<p>感谢:<br><br><a href=\"http://www.jeepxie.net/article/667918.html\">Eureka 与 zookeeper 的区别、原理及各自优缺点</a><br><br><a href=\"https://zhuanlan.zhihu.com/p/34976125\">Spring Cloud Eureka 全解</a><br><br><a href=\"https://zhuanlan.zhihu.com/p/120377144\">Spring Cloud-Eureka学习笔记-简介</a></p>\n"},{"title":"The Network Edge","date":"2020-02-27T06:11:47.000Z","index_img":"/Picture/The-Network-Edge.png","_content":"\n# Access Networks\n\n## Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite\n\n### DSL\n\nToday, the two most prevalent types of broadband residential access are **digital subscriber line (DSL)** and cable. A residence typically obtains DSL Internet access from the same local telephone company(telco) that provides its wried local phone access.Thus, when DSL is used, a customer's telco is also its ISP.\n\nThe residential telephone line carries both data and traditional telephone signals simultaneously, which are encode at difference frequencies:\n\n- A high-speed downstream channel , in the 50 kHz to 1MHz band.\n- A medium-speed upstream channel, in the 4 kHz to 50 kHz band.\n- An ordinary two-way telephone channel, in the 0 to 4 kHz band.\n\nThis approach makes the single DSL link appear as  if there were three separate links, so that a telephone call and an Internet connection can share the DSL link at the same time\n\n![](The Network Edge/2020-02-27 14-34-38 的屏幕截图.png)\n\nOn the customer's side a splitter separates the data and telephone signals arriving to the home and forwards the data signal to the DSL modem. On the telco side ,in the **CO(Central office)**,the DSLAM separates the data and phone signals and sends the data into the Internet. Hundreds or even thousands of households connect to a single DSLAM.\n\n### Cable Internet access\n\nCable Internet access makes use of the cable television company's existing cable company that provides its cable television.\n\nAs illustrated in Figure,fiber optics connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5000 homes. Because both fiber and coaxial cable are employed in this system, **it is often referred to as hybrid fiber coax(HFC)** \n\n![](Access-Networks/2020-02-27 20-56-20 的屏幕截图.png)\n\n**Cable Internet access requires special modems, called cable modems.** As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port.\n\nAt the cable head end, **the cable modem termination system(CMTS )serves** a similar function as the DSL network's DSLAM - turning the analog signal sent from the cable modems in many downstream homes back into digital format.\n\n### FTTH(fiber to the home)\n\nAlthough DSL and cable network currently represent more than 90 percent of residential broadband access in the united States , an up-and-coming technology that promises even hight speeds is **the deployment of fiber to the home(FTTH).**\n\nAs the name suggests , the FTTH concept is simple-provide an optical fiber path from the CO directly to the home.\n\nThere are several competing technologies for optical distribution from the CO to home. The simplest optical distribution network is called direct fiber,with one fiber leaving the CO for each home. More commonly each fiber leaving the CO(central office) is actually shared by many homes. These are two competing optical-distribution network architectures that perform this splitting : **active optical networks (AONs) and passive optical networks(PONs).**\n\nHere, we briefly discuss PON, which is used in Verizon's FIOS service.\n\n![](The Network Edge/2020-02-27 21-43-25 的屏幕截图.png)\n\nEach home has an optical network terminator(ONT),which is connected by dedicated optical fiber(Optical fibers) to a neighborhood splitter. The splitter combines a number of homes(typically less than 100) onto a single, shared optical fiber,which connects to an **optical line terminator(OLT)** in the telco's CO. The OLT providing conversion between optical line and electrical signals, connects to the Internet via a telco router. In the home, users connect a home router(typically a wireless router) to the ONT and access the Internet via this home router.\n\n### Satellite\n\nIn location where DSL, cable and FTTH are not available, a satellite link can be used to connect a residence to the Internet at speed of more than 1 Mbps; StarBand and HughesNet are two such satellite access providers.\n\n### Dial-up access\n\nDial-up access over traditional phone lines is based on the same model as DSL - a home modem connect over phone line to a modem in the ISP. Compared with DSL and other broadband access networks , dial-up access is excruciatingly slow at 56 kbps.\n\n\n\n## Access in the Enterprise(and the home): Ethernet and WiFi\n\nOn corporate and university campuses and increasingly in the home setting , **a local area network(LAN)** is used to connect an end system to the edge router. Although there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university and home networks. As shown in the Figure. Ethernet users use twisted-pair copper wire to connect to an Ethernet switch.\n\n![](The Network Edge/2020-02-27 23-49-06 的屏幕截图.png)\n\nThe Ethernet switch or a network of such interconnected switch is then into the larger Internet. With Ethernet access, users typically have 100 Mbps access to the Ethernet switch, whereas servers may have 1 Gbps or even 10 Gbps access.\n\n\n\nIncreasingly, however people are accessing the Internet wirelessly from laptops, smartphones, tablets and other devices. In the a wireless LAN setting, wireless users transmit/receive packets to/from an access point that is connected into the enterprise's networks,which in turn is connected to the wired Internet. A wireless LAN user must typically be within a few ten of meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi.(A wireless LAN user must typically be within a few ten of meters of the access point.)\n\nMany home combine broadband residential access(that is cable modem or DSL) with these inexpensive wireless LAN technology to create powerful home networks. Figure shows a typically home networks. This home network consist of roaming laptop as well as wired PC; a base station(the wireless access point),which communicates with the wireless PC; a cable modem providing broadband access to the Internet; and a router,which interconnects the base station and the stationary PC with the cable modem.\n\n![](Access-Networks/2020-02-28 00-21-20 的屏幕截图.png)\n\n## Wide-Area Wireless Access: 3G and LTE\n\nIncreasingly, devices such as iphone, Blackberrys and Android devices are being used to send email, surf the Web, Tweet,and download music while on the run. These devices employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station that is operated by cellular network provider. Unlike WiFi , a user need only be within a few tens of kilometers(as opposed to a few tens of meters) of the base station.\n\nTelecommunications companies have made enormous investments in so-called third-generation(3G) wireless,which provides packet-switched wide-area wireless Internet access at speeds in excess of 1 Mbps, But even higher-speed wide-area accesss technologies - fourth-generation(4G) of wide-area wireless networks are alread being deployed. LTF(Long-Term Evolution) has its root in 3G technology and can potentially achieve rates in excess of 10 Mbps. LTF downstream rates of many tens of Mbps have been reported in commercial deployments.\n\n\n\n# Physical Media\n\nPhysical media fall into two categories: **guided media** and **unguided media** with guided media, the waves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair copper wire or a coaxial cable. with unguided media, the waves propagate in the atmosphere and in outer space, such as in a wireless LAN or a digital satellite channel.\n\n## Twisted-Pair Copper Wire\n\nThe least expensive and most commonly used guided transmission medium is twisted-pair copper wire. In fact, more than 99 percent of the wired connection from telephone handset to the local telephone switch use twisted-pair copper wire. Twisted pair consist of two insulated copper wires, each about 1 mm thick, arranged in a regular spiral patten. The wires are twisted together to reduce the electrical interference from similar pairs close by. Typically a number of pairs are bundled together in a cable by wrapping the pairs in protective shield. **Unshielded twisted pair(UTP)** is commonly used for computer networks within a building  ,that is for LAN. Data rates for LANs using twisted pair today range from 10 Mbps to 10 Gpbs. The data rates that can be achieve depend on the thickness of the wire and the distance between transmitter and receiver.\n\n\n\n## Coaxial cable\n\nCoaxial cable is quite common in cable television system. As we saw earlier, cable television system have recently been couple with cable modems to provide residential users with Internet access at rate of tens of Mbps. In cable television and cable Internet access, the transmitter shifs the digital signal to a specific frequency band, and resulting analog signal is send from the transmitter to one or more receivers. Coaxial cable can be used as a guided shared medium. Specifically , a number of end systems can be connected directly to the cable, with each of the end systems receiving whatever is send by the other end system.\n\n\n\n## Fiber Optics\n\nAn optical fiber is a thin, flexible medium that conducts pulses of light, with each pulse representing a bit. A single optical fiber can support tremendous bit rates, up to ten or even hundreds of gigabits per second. They are immune to electromagnetic interference , have  very low signal attenuation up to 100 kilometers and are very hard to tap. There characteristics have made fiber optics the preferred long-haul guided transmission media, particularly for overseas links. Many of the long-distance telephone networks in the united states and elsewhere now use fiber optics exclusively. However the high cost of optical devices- such as transmitters receivers and switches - has hindered their deployment for short-haul transport, such as in a LAN or into the home in a residential access network.\n\n\n\n## Terrestrial Radio Channels\n\nRadio channels carry signal in the electromagnetic spectrum. They require no physical wire to be installed can penetrate walls, provide connectivity to mobile user, and can potentially carry a signal for long distances. The characteristics of a radio channel depend on significantly on the propagation environment and the distance over which a signal is to be carried.\n\nTerrestrial radio channels can be broadly classified into three groups: those that operate over very short distance(e.g : with one or two meters); those that operate in local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area spanning tens of kilometers. Personal devices such as wireless headsets, keyboards and medical devices over short distances; the wireless LAN technologies use local-area radio channels; the cellular access technologies use wide-area radio channels.\n\n\n\n## Satellite Radio Channels\n\nA communications satellite links two or more Earth-based microwave transmitter/receivers, known as ground stations. The satellite receives transmissions on one frequency band, regenerates the signal using a repeater and transmits the signal on another frequency. two type of satellite are used in communications: **geostationary satellites and low-earth orbiting(LEO) satellite.**\n\nGeostationary satellites permanently remain above the same spot on Earth. This stationary presence achieve by placing the satellite in orbit at 36000 kilometers above Earth's surface. This huge distance from ground station through satellite back to ground station introduces a substantial signal propagation delay of 280 milliseconds. Nevertheless, satellite links, which can operate at speed of hundreds of Mbps , are often used in areas without access to DSL or cable-based Internet.\n\nLEO satellites are placed much closer to Earth and do not remain permanently above one spot on Earth. They rotate around Earth(just as the moon does) and may communicate with each other as well as ground stations. To provide continuous coverage to an area , many satellite need to be place in orbit. there are currently may low- altitude communications system in development. LEO satellite technology may be used for Internet access sometime in the future.\n","source":"_posts/The Network Edge.md","raw":"---\ntitle: The Network Edge\ndate: 2020-02-27 14:11:47\nindex_img: /Picture/The-Network-Edge.png\ntags: -Computer Network A Top-Down Approach\n\n\n\n---\n\n# Access Networks\n\n## Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite\n\n### DSL\n\nToday, the two most prevalent types of broadband residential access are **digital subscriber line (DSL)** and cable. A residence typically obtains DSL Internet access from the same local telephone company(telco) that provides its wried local phone access.Thus, when DSL is used, a customer's telco is also its ISP.\n\nThe residential telephone line carries both data and traditional telephone signals simultaneously, which are encode at difference frequencies:\n\n- A high-speed downstream channel , in the 50 kHz to 1MHz band.\n- A medium-speed upstream channel, in the 4 kHz to 50 kHz band.\n- An ordinary two-way telephone channel, in the 0 to 4 kHz band.\n\nThis approach makes the single DSL link appear as  if there were three separate links, so that a telephone call and an Internet connection can share the DSL link at the same time\n\n![](The Network Edge/2020-02-27 14-34-38 的屏幕截图.png)\n\nOn the customer's side a splitter separates the data and telephone signals arriving to the home and forwards the data signal to the DSL modem. On the telco side ,in the **CO(Central office)**,the DSLAM separates the data and phone signals and sends the data into the Internet. Hundreds or even thousands of households connect to a single DSLAM.\n\n### Cable Internet access\n\nCable Internet access makes use of the cable television company's existing cable company that provides its cable television.\n\nAs illustrated in Figure,fiber optics connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5000 homes. Because both fiber and coaxial cable are employed in this system, **it is often referred to as hybrid fiber coax(HFC)** \n\n![](Access-Networks/2020-02-27 20-56-20 的屏幕截图.png)\n\n**Cable Internet access requires special modems, called cable modems.** As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port.\n\nAt the cable head end, **the cable modem termination system(CMTS )serves** a similar function as the DSL network's DSLAM - turning the analog signal sent from the cable modems in many downstream homes back into digital format.\n\n### FTTH(fiber to the home)\n\nAlthough DSL and cable network currently represent more than 90 percent of residential broadband access in the united States , an up-and-coming technology that promises even hight speeds is **the deployment of fiber to the home(FTTH).**\n\nAs the name suggests , the FTTH concept is simple-provide an optical fiber path from the CO directly to the home.\n\nThere are several competing technologies for optical distribution from the CO to home. The simplest optical distribution network is called direct fiber,with one fiber leaving the CO for each home. More commonly each fiber leaving the CO(central office) is actually shared by many homes. These are two competing optical-distribution network architectures that perform this splitting : **active optical networks (AONs) and passive optical networks(PONs).**\n\nHere, we briefly discuss PON, which is used in Verizon's FIOS service.\n\n![](The Network Edge/2020-02-27 21-43-25 的屏幕截图.png)\n\nEach home has an optical network terminator(ONT),which is connected by dedicated optical fiber(Optical fibers) to a neighborhood splitter. The splitter combines a number of homes(typically less than 100) onto a single, shared optical fiber,which connects to an **optical line terminator(OLT)** in the telco's CO. The OLT providing conversion between optical line and electrical signals, connects to the Internet via a telco router. In the home, users connect a home router(typically a wireless router) to the ONT and access the Internet via this home router.\n\n### Satellite\n\nIn location where DSL, cable and FTTH are not available, a satellite link can be used to connect a residence to the Internet at speed of more than 1 Mbps; StarBand and HughesNet are two such satellite access providers.\n\n### Dial-up access\n\nDial-up access over traditional phone lines is based on the same model as DSL - a home modem connect over phone line to a modem in the ISP. Compared with DSL and other broadband access networks , dial-up access is excruciatingly slow at 56 kbps.\n\n\n\n## Access in the Enterprise(and the home): Ethernet and WiFi\n\nOn corporate and university campuses and increasingly in the home setting , **a local area network(LAN)** is used to connect an end system to the edge router. Although there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university and home networks. As shown in the Figure. Ethernet users use twisted-pair copper wire to connect to an Ethernet switch.\n\n![](The Network Edge/2020-02-27 23-49-06 的屏幕截图.png)\n\nThe Ethernet switch or a network of such interconnected switch is then into the larger Internet. With Ethernet access, users typically have 100 Mbps access to the Ethernet switch, whereas servers may have 1 Gbps or even 10 Gbps access.\n\n\n\nIncreasingly, however people are accessing the Internet wirelessly from laptops, smartphones, tablets and other devices. In the a wireless LAN setting, wireless users transmit/receive packets to/from an access point that is connected into the enterprise's networks,which in turn is connected to the wired Internet. A wireless LAN user must typically be within a few ten of meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi.(A wireless LAN user must typically be within a few ten of meters of the access point.)\n\nMany home combine broadband residential access(that is cable modem or DSL) with these inexpensive wireless LAN technology to create powerful home networks. Figure shows a typically home networks. This home network consist of roaming laptop as well as wired PC; a base station(the wireless access point),which communicates with the wireless PC; a cable modem providing broadband access to the Internet; and a router,which interconnects the base station and the stationary PC with the cable modem.\n\n![](Access-Networks/2020-02-28 00-21-20 的屏幕截图.png)\n\n## Wide-Area Wireless Access: 3G and LTE\n\nIncreasingly, devices such as iphone, Blackberrys and Android devices are being used to send email, surf the Web, Tweet,and download music while on the run. These devices employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station that is operated by cellular network provider. Unlike WiFi , a user need only be within a few tens of kilometers(as opposed to a few tens of meters) of the base station.\n\nTelecommunications companies have made enormous investments in so-called third-generation(3G) wireless,which provides packet-switched wide-area wireless Internet access at speeds in excess of 1 Mbps, But even higher-speed wide-area accesss technologies - fourth-generation(4G) of wide-area wireless networks are alread being deployed. LTF(Long-Term Evolution) has its root in 3G technology and can potentially achieve rates in excess of 10 Mbps. LTF downstream rates of many tens of Mbps have been reported in commercial deployments.\n\n\n\n# Physical Media\n\nPhysical media fall into two categories: **guided media** and **unguided media** with guided media, the waves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair copper wire or a coaxial cable. with unguided media, the waves propagate in the atmosphere and in outer space, such as in a wireless LAN or a digital satellite channel.\n\n## Twisted-Pair Copper Wire\n\nThe least expensive and most commonly used guided transmission medium is twisted-pair copper wire. In fact, more than 99 percent of the wired connection from telephone handset to the local telephone switch use twisted-pair copper wire. Twisted pair consist of two insulated copper wires, each about 1 mm thick, arranged in a regular spiral patten. The wires are twisted together to reduce the electrical interference from similar pairs close by. Typically a number of pairs are bundled together in a cable by wrapping the pairs in protective shield. **Unshielded twisted pair(UTP)** is commonly used for computer networks within a building  ,that is for LAN. Data rates for LANs using twisted pair today range from 10 Mbps to 10 Gpbs. The data rates that can be achieve depend on the thickness of the wire and the distance between transmitter and receiver.\n\n\n\n## Coaxial cable\n\nCoaxial cable is quite common in cable television system. As we saw earlier, cable television system have recently been couple with cable modems to provide residential users with Internet access at rate of tens of Mbps. In cable television and cable Internet access, the transmitter shifs the digital signal to a specific frequency band, and resulting analog signal is send from the transmitter to one or more receivers. Coaxial cable can be used as a guided shared medium. Specifically , a number of end systems can be connected directly to the cable, with each of the end systems receiving whatever is send by the other end system.\n\n\n\n## Fiber Optics\n\nAn optical fiber is a thin, flexible medium that conducts pulses of light, with each pulse representing a bit. A single optical fiber can support tremendous bit rates, up to ten or even hundreds of gigabits per second. They are immune to electromagnetic interference , have  very low signal attenuation up to 100 kilometers and are very hard to tap. There characteristics have made fiber optics the preferred long-haul guided transmission media, particularly for overseas links. Many of the long-distance telephone networks in the united states and elsewhere now use fiber optics exclusively. However the high cost of optical devices- such as transmitters receivers and switches - has hindered their deployment for short-haul transport, such as in a LAN or into the home in a residential access network.\n\n\n\n## Terrestrial Radio Channels\n\nRadio channels carry signal in the electromagnetic spectrum. They require no physical wire to be installed can penetrate walls, provide connectivity to mobile user, and can potentially carry a signal for long distances. The characteristics of a radio channel depend on significantly on the propagation environment and the distance over which a signal is to be carried.\n\nTerrestrial radio channels can be broadly classified into three groups: those that operate over very short distance(e.g : with one or two meters); those that operate in local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area spanning tens of kilometers. Personal devices such as wireless headsets, keyboards and medical devices over short distances; the wireless LAN technologies use local-area radio channels; the cellular access technologies use wide-area radio channels.\n\n\n\n## Satellite Radio Channels\n\nA communications satellite links two or more Earth-based microwave transmitter/receivers, known as ground stations. The satellite receives transmissions on one frequency band, regenerates the signal using a repeater and transmits the signal on another frequency. two type of satellite are used in communications: **geostationary satellites and low-earth orbiting(LEO) satellite.**\n\nGeostationary satellites permanently remain above the same spot on Earth. This stationary presence achieve by placing the satellite in orbit at 36000 kilometers above Earth's surface. This huge distance from ground station through satellite back to ground station introduces a substantial signal propagation delay of 280 milliseconds. Nevertheless, satellite links, which can operate at speed of hundreds of Mbps , are often used in areas without access to DSL or cable-based Internet.\n\nLEO satellites are placed much closer to Earth and do not remain permanently above one spot on Earth. They rotate around Earth(just as the moon does) and may communicate with each other as well as ground stations. To provide continuous coverage to an area , many satellite need to be place in orbit. there are currently may low- altitude communications system in development. LEO satellite technology may be used for Internet access sometime in the future.\n","slug":"The Network Edge","published":1,"updated":"2020-11-14T14:40:36.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4s5000or8s89cn2dlh8","content":"<h1 id=\"Access-Networks\"><a href=\"#Access-Networks\" class=\"headerlink\" title=\"Access Networks\"></a>Access Networks</h1><h2 id=\"Home-Access-DSL-Cable-FTTH-Dial-Up-and-Satellite\"><a href=\"#Home-Access-DSL-Cable-FTTH-Dial-Up-and-Satellite\" class=\"headerlink\" title=\"Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite\"></a>Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite</h2><h3 id=\"DSL\"><a href=\"#DSL\" class=\"headerlink\" title=\"DSL\"></a>DSL</h3><p>Today, the two most prevalent types of broadband residential access are <strong>digital subscriber line (DSL)</strong> and cable. A residence typically obtains DSL Internet access from the same local telephone company(telco) that provides its wried local phone access.Thus, when DSL is used, a customer’s telco is also its ISP.</p>\n<p>The residential telephone line carries both data and traditional telephone signals simultaneously, which are encode at difference frequencies:</p>\n<ul>\n<li>A high-speed downstream channel , in the 50 kHz to 1MHz band.</li>\n<li>A medium-speed upstream channel, in the 4 kHz to 50 kHz band.</li>\n<li>An ordinary two-way telephone channel, in the 0 to 4 kHz band.</li>\n</ul>\n<p>This approach makes the single DSL link appear as  if there were three separate links, so that a telephone call and an Internet connection can share the DSL link at the same time</p>\n<p><img src=\"The Network Edge/2020-02-27 14-34-38 的屏幕截图.png\" alt=\"\"></p>\n<p>On the customer’s side a splitter separates the data and telephone signals arriving to the home and forwards the data signal to the DSL modem. On the telco side ,in the <strong>CO(Central office)</strong>,the DSLAM separates the data and phone signals and sends the data into the Internet. Hundreds or even thousands of households connect to a single DSLAM.</p>\n<h3 id=\"Cable-Internet-access\"><a href=\"#Cable-Internet-access\" class=\"headerlink\" title=\"Cable Internet access\"></a>Cable Internet access</h3><p>Cable Internet access makes use of the cable television company’s existing cable company that provides its cable television.</p>\n<p>As illustrated in Figure,fiber optics connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5000 homes. Because both fiber and coaxial cable are employed in this system, <strong>it is often referred to as hybrid fiber coax(HFC)</strong> </p>\n<p><img src=\"Access-Networks/2020-02-27 20-56-20 的屏幕截图.png\" alt=\"\"></p>\n<p><strong>Cable Internet access requires special modems, called cable modems.</strong> As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port.</p>\n<p>At the cable head end, <strong>the cable modem termination system(CMTS )serves</strong> a similar function as the DSL network’s DSLAM - turning the analog signal sent from the cable modems in many downstream homes back into digital format.</p>\n<h3 id=\"FTTH-fiber-to-the-home\"><a href=\"#FTTH-fiber-to-the-home\" class=\"headerlink\" title=\"FTTH(fiber to the home)\"></a>FTTH(fiber to the home)</h3><p>Although DSL and cable network currently represent more than 90 percent of residential broadband access in the united States , an up-and-coming technology that promises even hight speeds is <strong>the deployment of fiber to the home(FTTH).</strong></p>\n<p>As the name suggests , the FTTH concept is simple-provide an optical fiber path from the CO directly to the home.</p>\n<p>There are several competing technologies for optical distribution from the CO to home. The simplest optical distribution network is called direct fiber,with one fiber leaving the CO for each home. More commonly each fiber leaving the CO(central office) is actually shared by many homes. These are two competing optical-distribution network architectures that perform this splitting : <strong>active optical networks (AONs) and passive optical networks(PONs).</strong></p>\n<p>Here, we briefly discuss PON, which is used in Verizon’s FIOS service.</p>\n<p><img src=\"The Network Edge/2020-02-27 21-43-25 的屏幕截图.png\" alt=\"\"></p>\n<p>Each home has an optical network terminator(ONT),which is connected by dedicated optical fiber(Optical fibers) to a neighborhood splitter. The splitter combines a number of homes(typically less than 100) onto a single, shared optical fiber,which connects to an <strong>optical line terminator(OLT)</strong> in the telco’s CO. The OLT providing conversion between optical line and electrical signals, connects to the Internet via a telco router. In the home, users connect a home router(typically a wireless router) to the ONT and access the Internet via this home router.</p>\n<h3 id=\"Satellite\"><a href=\"#Satellite\" class=\"headerlink\" title=\"Satellite\"></a>Satellite</h3><p>In location where DSL, cable and FTTH are not available, a satellite link can be used to connect a residence to the Internet at speed of more than 1 Mbps; StarBand and HughesNet are two such satellite access providers.</p>\n<h3 id=\"Dial-up-access\"><a href=\"#Dial-up-access\" class=\"headerlink\" title=\"Dial-up access\"></a>Dial-up access</h3><p>Dial-up access over traditional phone lines is based on the same model as DSL - a home modem connect over phone line to a modem in the ISP. Compared with DSL and other broadband access networks , dial-up access is excruciatingly slow at 56 kbps.</p>\n<h2 id=\"Access-in-the-Enterprise-and-the-home-Ethernet-and-WiFi\"><a href=\"#Access-in-the-Enterprise-and-the-home-Ethernet-and-WiFi\" class=\"headerlink\" title=\"Access in the Enterprise(and the home): Ethernet and WiFi\"></a>Access in the Enterprise(and the home): Ethernet and WiFi</h2><p>On corporate and university campuses and increasingly in the home setting , <strong>a local area network(LAN)</strong> is used to connect an end system to the edge router. Although there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university and home networks. As shown in the Figure. Ethernet users use twisted-pair copper wire to connect to an Ethernet switch.</p>\n<p><img src=\"The Network Edge/2020-02-27 23-49-06 的屏幕截图.png\" alt=\"\"></p>\n<p>The Ethernet switch or a network of such interconnected switch is then into the larger Internet. With Ethernet access, users typically have 100 Mbps access to the Ethernet switch, whereas servers may have 1 Gbps or even 10 Gbps access.</p>\n<p>Increasingly, however people are accessing the Internet wirelessly from laptops, smartphones, tablets and other devices. In the a wireless LAN setting, wireless users transmit/receive packets to/from an access point that is connected into the enterprise’s networks,which in turn is connected to the wired Internet. A wireless LAN user must typically be within a few ten of meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi.(A wireless LAN user must typically be within a few ten of meters of the access point.)</p>\n<p>Many home combine broadband residential access(that is cable modem or DSL) with these inexpensive wireless LAN technology to create powerful home networks. Figure shows a typically home networks. This home network consist of roaming laptop as well as wired PC; a base station(the wireless access point),which communicates with the wireless PC; a cable modem providing broadband access to the Internet; and a router,which interconnects the base station and the stationary PC with the cable modem.</p>\n<p><img src=\"Access-Networks/2020-02-28 00-21-20 的屏幕截图.png\" alt=\"\"></p>\n<h2 id=\"Wide-Area-Wireless-Access-3G-and-LTE\"><a href=\"#Wide-Area-Wireless-Access-3G-and-LTE\" class=\"headerlink\" title=\"Wide-Area Wireless Access: 3G and LTE\"></a>Wide-Area Wireless Access: 3G and LTE</h2><p>Increasingly, devices such as iphone, Blackberrys and Android devices are being used to send email, surf the Web, Tweet,and download music while on the run. These devices employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station that is operated by cellular network provider. Unlike WiFi , a user need only be within a few tens of kilometers(as opposed to a few tens of meters) of the base station.</p>\n<p>Telecommunications companies have made enormous investments in so-called third-generation(3G) wireless,which provides packet-switched wide-area wireless Internet access at speeds in excess of 1 Mbps, But even higher-speed wide-area accesss technologies - fourth-generation(4G) of wide-area wireless networks are alread being deployed. LTF(Long-Term Evolution) has its root in 3G technology and can potentially achieve rates in excess of 10 Mbps. LTF downstream rates of many tens of Mbps have been reported in commercial deployments.</p>\n<h1 id=\"Physical-Media\"><a href=\"#Physical-Media\" class=\"headerlink\" title=\"Physical Media\"></a>Physical Media</h1><p>Physical media fall into two categories: <strong>guided media</strong> and <strong>unguided media</strong> with guided media, the waves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair copper wire or a coaxial cable. with unguided media, the waves propagate in the atmosphere and in outer space, such as in a wireless LAN or a digital satellite channel.</p>\n<h2 id=\"Twisted-Pair-Copper-Wire\"><a href=\"#Twisted-Pair-Copper-Wire\" class=\"headerlink\" title=\"Twisted-Pair Copper Wire\"></a>Twisted-Pair Copper Wire</h2><p>The least expensive and most commonly used guided transmission medium is twisted-pair copper wire. In fact, more than 99 percent of the wired connection from telephone handset to the local telephone switch use twisted-pair copper wire. Twisted pair consist of two insulated copper wires, each about 1 mm thick, arranged in a regular spiral patten. The wires are twisted together to reduce the electrical interference from similar pairs close by. Typically a number of pairs are bundled together in a cable by wrapping the pairs in protective shield. <strong>Unshielded twisted pair(UTP)</strong> is commonly used for computer networks within a building  ,that is for LAN. Data rates for LANs using twisted pair today range from 10 Mbps to 10 Gpbs. The data rates that can be achieve depend on the thickness of the wire and the distance between transmitter and receiver.</p>\n<h2 id=\"Coaxial-cable\"><a href=\"#Coaxial-cable\" class=\"headerlink\" title=\"Coaxial cable\"></a>Coaxial cable</h2><p>Coaxial cable is quite common in cable television system. As we saw earlier, cable television system have recently been couple with cable modems to provide residential users with Internet access at rate of tens of Mbps. In cable television and cable Internet access, the transmitter shifs the digital signal to a specific frequency band, and resulting analog signal is send from the transmitter to one or more receivers. Coaxial cable can be used as a guided shared medium. Specifically , a number of end systems can be connected directly to the cable, with each of the end systems receiving whatever is send by the other end system.</p>\n<h2 id=\"Fiber-Optics\"><a href=\"#Fiber-Optics\" class=\"headerlink\" title=\"Fiber Optics\"></a>Fiber Optics</h2><p>An optical fiber is a thin, flexible medium that conducts pulses of light, with each pulse representing a bit. A single optical fiber can support tremendous bit rates, up to ten or even hundreds of gigabits per second. They are immune to electromagnetic interference , have  very low signal attenuation up to 100 kilometers and are very hard to tap. There characteristics have made fiber optics the preferred long-haul guided transmission media, particularly for overseas links. Many of the long-distance telephone networks in the united states and elsewhere now use fiber optics exclusively. However the high cost of optical devices- such as transmitters receivers and switches - has hindered their deployment for short-haul transport, such as in a LAN or into the home in a residential access network.</p>\n<h2 id=\"Terrestrial-Radio-Channels\"><a href=\"#Terrestrial-Radio-Channels\" class=\"headerlink\" title=\"Terrestrial Radio Channels\"></a>Terrestrial Radio Channels</h2><p>Radio channels carry signal in the electromagnetic spectrum. They require no physical wire to be installed can penetrate walls, provide connectivity to mobile user, and can potentially carry a signal for long distances. The characteristics of a radio channel depend on significantly on the propagation environment and the distance over which a signal is to be carried.</p>\n<p>Terrestrial radio channels can be broadly classified into three groups: those that operate over very short distance(e.g : with one or two meters); those that operate in local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area spanning tens of kilometers. Personal devices such as wireless headsets, keyboards and medical devices over short distances; the wireless LAN technologies use local-area radio channels; the cellular access technologies use wide-area radio channels.</p>\n<h2 id=\"Satellite-Radio-Channels\"><a href=\"#Satellite-Radio-Channels\" class=\"headerlink\" title=\"Satellite Radio Channels\"></a>Satellite Radio Channels</h2><p>A communications satellite links two or more Earth-based microwave transmitter/receivers, known as ground stations. The satellite receives transmissions on one frequency band, regenerates the signal using a repeater and transmits the signal on another frequency. two type of satellite are used in communications: <strong>geostationary satellites and low-earth orbiting(LEO) satellite.</strong></p>\n<p>Geostationary satellites permanently remain above the same spot on Earth. This stationary presence achieve by placing the satellite in orbit at 36000 kilometers above Earth’s surface. This huge distance from ground station through satellite back to ground station introduces a substantial signal propagation delay of 280 milliseconds. Nevertheless, satellite links, which can operate at speed of hundreds of Mbps , are often used in areas without access to DSL or cable-based Internet.</p>\n<p>LEO satellites are placed much closer to Earth and do not remain permanently above one spot on Earth. They rotate around Earth(just as the moon does) and may communicate with each other as well as ground stations. To provide continuous coverage to an area , many satellite need to be place in orbit. there are currently may low- altitude communications system in development. LEO satellite technology may be used for Internet access sometime in the future.</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Access-Networks\"><a href=\"#Access-Networks\" class=\"headerlink\" title=\"Access Networks\"></a>Access Networks</h1><h2 id=\"Home-Access-DSL-Cable-FTTH-Dial-Up-and-Satellite\"><a href=\"#Home-Access-DSL-Cable-FTTH-Dial-Up-and-Satellite\" class=\"headerlink\" title=\"Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite\"></a>Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite</h2><h3 id=\"DSL\"><a href=\"#DSL\" class=\"headerlink\" title=\"DSL\"></a>DSL</h3><p>Today, the two most prevalent types of broadband residential access are <strong>digital subscriber line (DSL)</strong> and cable. A residence typically obtains DSL Internet access from the same local telephone company(telco) that provides its wried local phone access.Thus, when DSL is used, a customer’s telco is also its ISP.</p>\n<p>The residential telephone line carries both data and traditional telephone signals simultaneously, which are encode at difference frequencies:</p>\n<ul>\n<li>A high-speed downstream channel , in the 50 kHz to 1MHz band.</li>\n<li>A medium-speed upstream channel, in the 4 kHz to 50 kHz band.</li>\n<li>An ordinary two-way telephone channel, in the 0 to 4 kHz band.</li>\n</ul>\n<p>This approach makes the single DSL link appear as  if there were three separate links, so that a telephone call and an Internet connection can share the DSL link at the same time</p>\n<p><img src=\"The Network Edge/2020-02-27 14-34-38 的屏幕截图.png\" alt=\"\"></p>\n<p>On the customer’s side a splitter separates the data and telephone signals arriving to the home and forwards the data signal to the DSL modem. On the telco side ,in the <strong>CO(Central office)</strong>,the DSLAM separates the data and phone signals and sends the data into the Internet. Hundreds or even thousands of households connect to a single DSLAM.</p>\n<h3 id=\"Cable-Internet-access\"><a href=\"#Cable-Internet-access\" class=\"headerlink\" title=\"Cable Internet access\"></a>Cable Internet access</h3><p>Cable Internet access makes use of the cable television company’s existing cable company that provides its cable television.</p>\n<p>As illustrated in Figure,fiber optics connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5000 homes. Because both fiber and coaxial cable are employed in this system, <strong>it is often referred to as hybrid fiber coax(HFC)</strong> </p>\n<p><img src=\"Access-Networks/2020-02-27 20-56-20 的屏幕截图.png\" alt=\"\"></p>\n<p><strong>Cable Internet access requires special modems, called cable modems.</strong> As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port.</p>\n<p>At the cable head end, <strong>the cable modem termination system(CMTS )serves</strong> a similar function as the DSL network’s DSLAM - turning the analog signal sent from the cable modems in many downstream homes back into digital format.</p>\n<h3 id=\"FTTH-fiber-to-the-home\"><a href=\"#FTTH-fiber-to-the-home\" class=\"headerlink\" title=\"FTTH(fiber to the home)\"></a>FTTH(fiber to the home)</h3><p>Although DSL and cable network currently represent more than 90 percent of residential broadband access in the united States , an up-and-coming technology that promises even hight speeds is <strong>the deployment of fiber to the home(FTTH).</strong></p>\n<p>As the name suggests , the FTTH concept is simple-provide an optical fiber path from the CO directly to the home.</p>\n<p>There are several competing technologies for optical distribution from the CO to home. The simplest optical distribution network is called direct fiber,with one fiber leaving the CO for each home. More commonly each fiber leaving the CO(central office) is actually shared by many homes. These are two competing optical-distribution network architectures that perform this splitting : <strong>active optical networks (AONs) and passive optical networks(PONs).</strong></p>\n<p>Here, we briefly discuss PON, which is used in Verizon’s FIOS service.</p>\n<p><img src=\"The Network Edge/2020-02-27 21-43-25 的屏幕截图.png\" alt=\"\"></p>\n<p>Each home has an optical network terminator(ONT),which is connected by dedicated optical fiber(Optical fibers) to a neighborhood splitter. The splitter combines a number of homes(typically less than 100) onto a single, shared optical fiber,which connects to an <strong>optical line terminator(OLT)</strong> in the telco’s CO. The OLT providing conversion between optical line and electrical signals, connects to the Internet via a telco router. In the home, users connect a home router(typically a wireless router) to the ONT and access the Internet via this home router.</p>\n<h3 id=\"Satellite\"><a href=\"#Satellite\" class=\"headerlink\" title=\"Satellite\"></a>Satellite</h3><p>In location where DSL, cable and FTTH are not available, a satellite link can be used to connect a residence to the Internet at speed of more than 1 Mbps; StarBand and HughesNet are two such satellite access providers.</p>\n<h3 id=\"Dial-up-access\"><a href=\"#Dial-up-access\" class=\"headerlink\" title=\"Dial-up access\"></a>Dial-up access</h3><p>Dial-up access over traditional phone lines is based on the same model as DSL - a home modem connect over phone line to a modem in the ISP. Compared with DSL and other broadband access networks , dial-up access is excruciatingly slow at 56 kbps.</p>\n<h2 id=\"Access-in-the-Enterprise-and-the-home-Ethernet-and-WiFi\"><a href=\"#Access-in-the-Enterprise-and-the-home-Ethernet-and-WiFi\" class=\"headerlink\" title=\"Access in the Enterprise(and the home): Ethernet and WiFi\"></a>Access in the Enterprise(and the home): Ethernet and WiFi</h2><p>On corporate and university campuses and increasingly in the home setting , <strong>a local area network(LAN)</strong> is used to connect an end system to the edge router. Although there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university and home networks. As shown in the Figure. Ethernet users use twisted-pair copper wire to connect to an Ethernet switch.</p>\n<p><img src=\"The Network Edge/2020-02-27 23-49-06 的屏幕截图.png\" alt=\"\"></p>\n<p>The Ethernet switch or a network of such interconnected switch is then into the larger Internet. With Ethernet access, users typically have 100 Mbps access to the Ethernet switch, whereas servers may have 1 Gbps or even 10 Gbps access.</p>\n<p>Increasingly, however people are accessing the Internet wirelessly from laptops, smartphones, tablets and other devices. In the a wireless LAN setting, wireless users transmit/receive packets to/from an access point that is connected into the enterprise’s networks,which in turn is connected to the wired Internet. A wireless LAN user must typically be within a few ten of meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi.(A wireless LAN user must typically be within a few ten of meters of the access point.)</p>\n<p>Many home combine broadband residential access(that is cable modem or DSL) with these inexpensive wireless LAN technology to create powerful home networks. Figure shows a typically home networks. This home network consist of roaming laptop as well as wired PC; a base station(the wireless access point),which communicates with the wireless PC; a cable modem providing broadband access to the Internet; and a router,which interconnects the base station and the stationary PC with the cable modem.</p>\n<p><img src=\"Access-Networks/2020-02-28 00-21-20 的屏幕截图.png\" alt=\"\"></p>\n<h2 id=\"Wide-Area-Wireless-Access-3G-and-LTE\"><a href=\"#Wide-Area-Wireless-Access-3G-and-LTE\" class=\"headerlink\" title=\"Wide-Area Wireless Access: 3G and LTE\"></a>Wide-Area Wireless Access: 3G and LTE</h2><p>Increasingly, devices such as iphone, Blackberrys and Android devices are being used to send email, surf the Web, Tweet,and download music while on the run. These devices employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station that is operated by cellular network provider. Unlike WiFi , a user need only be within a few tens of kilometers(as opposed to a few tens of meters) of the base station.</p>\n<p>Telecommunications companies have made enormous investments in so-called third-generation(3G) wireless,which provides packet-switched wide-area wireless Internet access at speeds in excess of 1 Mbps, But even higher-speed wide-area accesss technologies - fourth-generation(4G) of wide-area wireless networks are alread being deployed. LTF(Long-Term Evolution) has its root in 3G technology and can potentially achieve rates in excess of 10 Mbps. LTF downstream rates of many tens of Mbps have been reported in commercial deployments.</p>\n<h1 id=\"Physical-Media\"><a href=\"#Physical-Media\" class=\"headerlink\" title=\"Physical Media\"></a>Physical Media</h1><p>Physical media fall into two categories: <strong>guided media</strong> and <strong>unguided media</strong> with guided media, the waves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair copper wire or a coaxial cable. with unguided media, the waves propagate in the atmosphere and in outer space, such as in a wireless LAN or a digital satellite channel.</p>\n<h2 id=\"Twisted-Pair-Copper-Wire\"><a href=\"#Twisted-Pair-Copper-Wire\" class=\"headerlink\" title=\"Twisted-Pair Copper Wire\"></a>Twisted-Pair Copper Wire</h2><p>The least expensive and most commonly used guided transmission medium is twisted-pair copper wire. In fact, more than 99 percent of the wired connection from telephone handset to the local telephone switch use twisted-pair copper wire. Twisted pair consist of two insulated copper wires, each about 1 mm thick, arranged in a regular spiral patten. The wires are twisted together to reduce the electrical interference from similar pairs close by. Typically a number of pairs are bundled together in a cable by wrapping the pairs in protective shield. <strong>Unshielded twisted pair(UTP)</strong> is commonly used for computer networks within a building  ,that is for LAN. Data rates for LANs using twisted pair today range from 10 Mbps to 10 Gpbs. The data rates that can be achieve depend on the thickness of the wire and the distance between transmitter and receiver.</p>\n<h2 id=\"Coaxial-cable\"><a href=\"#Coaxial-cable\" class=\"headerlink\" title=\"Coaxial cable\"></a>Coaxial cable</h2><p>Coaxial cable is quite common in cable television system. As we saw earlier, cable television system have recently been couple with cable modems to provide residential users with Internet access at rate of tens of Mbps. In cable television and cable Internet access, the transmitter shifs the digital signal to a specific frequency band, and resulting analog signal is send from the transmitter to one or more receivers. Coaxial cable can be used as a guided shared medium. Specifically , a number of end systems can be connected directly to the cable, with each of the end systems receiving whatever is send by the other end system.</p>\n<h2 id=\"Fiber-Optics\"><a href=\"#Fiber-Optics\" class=\"headerlink\" title=\"Fiber Optics\"></a>Fiber Optics</h2><p>An optical fiber is a thin, flexible medium that conducts pulses of light, with each pulse representing a bit. A single optical fiber can support tremendous bit rates, up to ten or even hundreds of gigabits per second. They are immune to electromagnetic interference , have  very low signal attenuation up to 100 kilometers and are very hard to tap. There characteristics have made fiber optics the preferred long-haul guided transmission media, particularly for overseas links. Many of the long-distance telephone networks in the united states and elsewhere now use fiber optics exclusively. However the high cost of optical devices- such as transmitters receivers and switches - has hindered their deployment for short-haul transport, such as in a LAN or into the home in a residential access network.</p>\n<h2 id=\"Terrestrial-Radio-Channels\"><a href=\"#Terrestrial-Radio-Channels\" class=\"headerlink\" title=\"Terrestrial Radio Channels\"></a>Terrestrial Radio Channels</h2><p>Radio channels carry signal in the electromagnetic spectrum. They require no physical wire to be installed can penetrate walls, provide connectivity to mobile user, and can potentially carry a signal for long distances. The characteristics of a radio channel depend on significantly on the propagation environment and the distance over which a signal is to be carried.</p>\n<p>Terrestrial radio channels can be broadly classified into three groups: those that operate over very short distance(e.g : with one or two meters); those that operate in local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area spanning tens of kilometers. Personal devices such as wireless headsets, keyboards and medical devices over short distances; the wireless LAN technologies use local-area radio channels; the cellular access technologies use wide-area radio channels.</p>\n<h2 id=\"Satellite-Radio-Channels\"><a href=\"#Satellite-Radio-Channels\" class=\"headerlink\" title=\"Satellite Radio Channels\"></a>Satellite Radio Channels</h2><p>A communications satellite links two or more Earth-based microwave transmitter/receivers, known as ground stations. The satellite receives transmissions on one frequency band, regenerates the signal using a repeater and transmits the signal on another frequency. two type of satellite are used in communications: <strong>geostationary satellites and low-earth orbiting(LEO) satellite.</strong></p>\n<p>Geostationary satellites permanently remain above the same spot on Earth. This stationary presence achieve by placing the satellite in orbit at 36000 kilometers above Earth’s surface. This huge distance from ground station through satellite back to ground station introduces a substantial signal propagation delay of 280 milliseconds. Nevertheless, satellite links, which can operate at speed of hundreds of Mbps , are often used in areas without access to DSL or cable-based Internet.</p>\n<p>LEO satellites are placed much closer to Earth and do not remain permanently above one spot on Earth. They rotate around Earth(just as the moon does) and may communicate with each other as well as ground stations. To provide continuous coverage to an area , many satellite need to be place in orbit. there are currently may low- altitude communications system in development. LEO satellite technology may be used for Internet access sometime in the future.</p>\n"},{"title":"The Network Core","date":"2020-02-28T11:36:11.000Z","index_img":"/Picture/The-Network-Core.png","_content":"\n# The Network Core\n\nThe figure highlights the Network Core with thick, shaded lines.\n\n![](The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png)\n\n## Packet Switching\n\nTo send a message from a source end system to a destination end system, the source breaks long message into smaller chunks of data known as **Packets**. Between source and destination, each packet travel through **communication links and packet switches**(for which there are two predominant types, routers and link-layer switches) .\n\n### Store-and-Forward Transmission\n\nStore-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. \n\nTo explore store-and-forward transmission in more detail. Consider a simple network consisting of two end systems connected by a single router as shown as figure below.\n\nA router will typically have many incident link, since its job is to switch an incoming packet onto an outgoing link;  In this example the router has the rather simple task of transferring a packet from one(input) link to the only other attached link. In this example the source has three packets, each consisting of L bits to send to the destination. Because the router employ store-and-forwarding, at this instant of time, the router cannot transmit the bits it has received; only after the router has received all of the packet's bits can it begin to transmit the packet onto the outbound link.\n\n![s](The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png)\n\nTo gain some insight into store-and-forward transmission, let's now calculate the amount of time that elapses from when the source begins to send the packet until the destination has received the entire packet.(Here we will ignore propagation delay - the time it take for the bits to travel across the wire at near the speed of light). The source begins to transmit at time 0; at time L/R seconds, the sources has transmitted the entire packet and the entire packet has been received and store at the router(since there is no propagation delay). At time L/R seconds, since the router  has just received the entire packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2L/R, the router have transmitted the entire packet, and the entire packet has been received by the desination. Thus the total delay is 2L/R. If the switch instead forwarded bits as soon as they arrive.(without first receving store and process the entire packet before forwarding) then the total delay would be L/R since bits are not help up at the router. But as we will discuss in Section1.4 routers need to receive, store,and process the entrie packet before forwarding.\n\nlet's now consider the general case of sending one packet from source to destination over a path consisting of N link each of rate R(thus, there are N-1 routers between source and destination). Applying the same logic as above, we see that the end-to-end delay is :\n$$\nd_ {end-to-end}= N*L/R\n$$\n\n### Queuing Delays and Packet Loss\n\nEach packet switch has multiple link attached to it . For each attached link, the packet switch has an **output buffer**(also called an **output queue**),which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link,but finds the link busy with the transmission of another packet, the arriving packets must wait in the output buffer. **Thus, in addition to the store-and-forward delays,packets suffer output buffer queuing delay.** These delay are variable and depend on the level of congestion in the network. since the amount of buffer space is finite. an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, **Packet Loss will occur** - either the arriving packet or one of the already-queued packets will be dropped.\n\n### Forwarding Tables and Routing Protocols\n\nEarlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of attached communication links. But how does the router determine which link it should forward the packet onto? Packet forwarding is actually done in different ways in different types of computer networks. Here, we briefly describe how it is done in the Internet.\n\n​\tIn the Internet,every end system has an address called an **IP address.** when a source end system wants to send a packet to a destination end system, the source include the destination's IP address in the packet's header. As with postal addresses. each router has a **forwarding table** that maps destination addresses(or portions of the destination addresses) to that router's outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.\n\n​\tWe just learned that a router uses a packet's destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs yet another question: \"How do forwarding tables get set ?\", Are they configured by hand in each and every router, or does the Internet use a more automated procedure? The issue will be studied in depth in after. but we'll note now that the Internet has a number of special routing protocols that are used to automatically set the forwarding tables.\n\n## Circuit Switching\n\nIn circuit-switching networds, the resource needed along a path(buffer link transmission rate) to provide for communication between the end systems are  reserved for the duration of the communication session between the end systems. In the packet-switched networks, these resources are not reserved; a session's messages use the resources on demand and as a consequence ,may have to wait for access to a  communication link.\n\n​\tTraditional telephone networks are examples of circuit-switched network. Consider what happens when one person want to send information(voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver, for which the switches on the path between the sender and receiver maintain connection state for that connection.  In the jargon of telephony, this connection is called a **circuit**. when the network establishes the circuit , it also \n","source":"_posts/The-Network-Core.md","raw":"---\ntitle: The Network Core\ndate: 2020-02-28 19:36:11\nindex_img: /Picture/The-Network-Core.png\ntags: -Computer Network A Top-Down Approach\n\n---\n\n# The Network Core\n\nThe figure highlights the Network Core with thick, shaded lines.\n\n![](The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png)\n\n## Packet Switching\n\nTo send a message from a source end system to a destination end system, the source breaks long message into smaller chunks of data known as **Packets**. Between source and destination, each packet travel through **communication links and packet switches**(for which there are two predominant types, routers and link-layer switches) .\n\n### Store-and-Forward Transmission\n\nStore-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. \n\nTo explore store-and-forward transmission in more detail. Consider a simple network consisting of two end systems connected by a single router as shown as figure below.\n\nA router will typically have many incident link, since its job is to switch an incoming packet onto an outgoing link;  In this example the router has the rather simple task of transferring a packet from one(input) link to the only other attached link. In this example the source has three packets, each consisting of L bits to send to the destination. Because the router employ store-and-forwarding, at this instant of time, the router cannot transmit the bits it has received; only after the router has received all of the packet's bits can it begin to transmit the packet onto the outbound link.\n\n![s](The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png)\n\nTo gain some insight into store-and-forward transmission, let's now calculate the amount of time that elapses from when the source begins to send the packet until the destination has received the entire packet.(Here we will ignore propagation delay - the time it take for the bits to travel across the wire at near the speed of light). The source begins to transmit at time 0; at time L/R seconds, the sources has transmitted the entire packet and the entire packet has been received and store at the router(since there is no propagation delay). At time L/R seconds, since the router  has just received the entire packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2L/R, the router have transmitted the entire packet, and the entire packet has been received by the desination. Thus the total delay is 2L/R. If the switch instead forwarded bits as soon as they arrive.(without first receving store and process the entire packet before forwarding) then the total delay would be L/R since bits are not help up at the router. But as we will discuss in Section1.4 routers need to receive, store,and process the entrie packet before forwarding.\n\nlet's now consider the general case of sending one packet from source to destination over a path consisting of N link each of rate R(thus, there are N-1 routers between source and destination). Applying the same logic as above, we see that the end-to-end delay is :\n$$\nd_ {end-to-end}= N*L/R\n$$\n\n### Queuing Delays and Packet Loss\n\nEach packet switch has multiple link attached to it . For each attached link, the packet switch has an **output buffer**(also called an **output queue**),which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link,but finds the link busy with the transmission of another packet, the arriving packets must wait in the output buffer. **Thus, in addition to the store-and-forward delays,packets suffer output buffer queuing delay.** These delay are variable and depend on the level of congestion in the network. since the amount of buffer space is finite. an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, **Packet Loss will occur** - either the arriving packet or one of the already-queued packets will be dropped.\n\n### Forwarding Tables and Routing Protocols\n\nEarlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of attached communication links. But how does the router determine which link it should forward the packet onto? Packet forwarding is actually done in different ways in different types of computer networks. Here, we briefly describe how it is done in the Internet.\n\n​\tIn the Internet,every end system has an address called an **IP address.** when a source end system wants to send a packet to a destination end system, the source include the destination's IP address in the packet's header. As with postal addresses. each router has a **forwarding table** that maps destination addresses(or portions of the destination addresses) to that router's outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.\n\n​\tWe just learned that a router uses a packet's destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs yet another question: \"How do forwarding tables get set ?\", Are they configured by hand in each and every router, or does the Internet use a more automated procedure? The issue will be studied in depth in after. but we'll note now that the Internet has a number of special routing protocols that are used to automatically set the forwarding tables.\n\n## Circuit Switching\n\nIn circuit-switching networds, the resource needed along a path(buffer link transmission rate) to provide for communication between the end systems are  reserved for the duration of the communication session between the end systems. In the packet-switched networks, these resources are not reserved; a session's messages use the resources on demand and as a consequence ,may have to wait for access to a  communication link.\n\n​\tTraditional telephone networks are examples of circuit-switched network. Consider what happens when one person want to send information(voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver, for which the switches on the path between the sender and receiver maintain connection state for that connection.  In the jargon of telephony, this connection is called a **circuit**. when the network establishes the circuit , it also \n","slug":"The-Network-Core","published":1,"updated":"2020-11-14T14:40:36.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4s6000qr8s87a251zyl","content":"<h1 id=\"The-Network-Core\"><a href=\"#The-Network-Core\" class=\"headerlink\" title=\"The Network Core\"></a>The Network Core</h1><p>The figure highlights the Network Core with thick, shaded lines.</p>\n<p><img src=\"The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png\" alt=\"\"></p>\n<h2 id=\"Packet-Switching\"><a href=\"#Packet-Switching\" class=\"headerlink\" title=\"Packet Switching\"></a>Packet Switching</h2><p>To send a message from a source end system to a destination end system, the source breaks long message into smaller chunks of data known as <strong>Packets</strong>. Between source and destination, each packet travel through <strong>communication links and packet switches</strong>(for which there are two predominant types, routers and link-layer switches) .</p>\n<h3 id=\"Store-and-Forward-Transmission\"><a href=\"#Store-and-Forward-Transmission\" class=\"headerlink\" title=\"Store-and-Forward Transmission\"></a>Store-and-Forward Transmission</h3><p>Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. </p>\n<p>To explore store-and-forward transmission in more detail. Consider a simple network consisting of two end systems connected by a single router as shown as figure below.</p>\n<p>A router will typically have many incident link, since its job is to switch an incoming packet onto an outgoing link;  In this example the router has the rather simple task of transferring a packet from one(input) link to the only other attached link. In this example the source has three packets, each consisting of L bits to send to the destination. Because the router employ store-and-forwarding, at this instant of time, the router cannot transmit the bits it has received; only after the router has received all of the packet’s bits can it begin to transmit the packet onto the outbound link.</p>\n<p><img src=\"The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png\" alt=\"s\"></p>\n<p>To gain some insight into store-and-forward transmission, let’s now calculate the amount of time that elapses from when the source begins to send the packet until the destination has received the entire packet.(Here we will ignore propagation delay - the time it take for the bits to travel across the wire at near the speed of light). The source begins to transmit at time 0; at time L/R seconds, the sources has transmitted the entire packet and the entire packet has been received and store at the router(since there is no propagation delay). At time L/R seconds, since the router  has just received the entire packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2L/R, the router have transmitted the entire packet, and the entire packet has been received by the desination. Thus the total delay is 2L/R. If the switch instead forwarded bits as soon as they arrive.(without first receving store and process the entire packet before forwarding) then the total delay would be L/R since bits are not help up at the router. But as we will discuss in Section1.4 routers need to receive, store,and process the entrie packet before forwarding.</p>\n<p>let’s now consider the general case of sending one packet from source to destination over a path consisting of N link each of rate R(thus, there are N-1 routers between source and destination). Applying the same logic as above, we see that the end-to-end delay is :</p>\n<script type=\"math/tex; mode=display\">\nd_ {end-to-end}= N*L/R</script><h3 id=\"Queuing-Delays-and-Packet-Loss\"><a href=\"#Queuing-Delays-and-Packet-Loss\" class=\"headerlink\" title=\"Queuing Delays and Packet Loss\"></a>Queuing Delays and Packet Loss</h3><p>Each packet switch has multiple link attached to it . For each attached link, the packet switch has an <strong>output buffer</strong>(also called an <strong>output queue</strong>),which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link,but finds the link busy with the transmission of another packet, the arriving packets must wait in the output buffer. <strong>Thus, in addition to the store-and-forward delays,packets suffer output buffer queuing delay.</strong> These delay are variable and depend on the level of congestion in the network. since the amount of buffer space is finite. an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, <strong>Packet Loss will occur</strong> - either the arriving packet or one of the already-queued packets will be dropped.</p>\n<h3 id=\"Forwarding-Tables-and-Routing-Protocols\"><a href=\"#Forwarding-Tables-and-Routing-Protocols\" class=\"headerlink\" title=\"Forwarding Tables and Routing Protocols\"></a>Forwarding Tables and Routing Protocols</h3><p>Earlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of attached communication links. But how does the router determine which link it should forward the packet onto? Packet forwarding is actually done in different ways in different types of computer networks. Here, we briefly describe how it is done in the Internet.</p>\n<p>​    In the Internet,every end system has an address called an <strong>IP address.</strong> when a source end system wants to send a packet to a destination end system, the source include the destination’s IP address in the packet’s header. As with postal addresses. each router has a <strong>forwarding table</strong> that maps destination addresses(or portions of the destination addresses) to that router’s outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.</p>\n<p>​    We just learned that a router uses a packet’s destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs yet another question: “How do forwarding tables get set ?”, Are they configured by hand in each and every router, or does the Internet use a more automated procedure? The issue will be studied in depth in after. but we’ll note now that the Internet has a number of special routing protocols that are used to automatically set the forwarding tables.</p>\n<h2 id=\"Circuit-Switching\"><a href=\"#Circuit-Switching\" class=\"headerlink\" title=\"Circuit Switching\"></a>Circuit Switching</h2><p>In circuit-switching networds, the resource needed along a path(buffer link transmission rate) to provide for communication between the end systems are  reserved for the duration of the communication session between the end systems. In the packet-switched networks, these resources are not reserved; a session’s messages use the resources on demand and as a consequence ,may have to wait for access to a  communication link.</p>\n<p>​    Traditional telephone networks are examples of circuit-switched network. Consider what happens when one person want to send information(voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver, for which the switches on the path between the sender and receiver maintain connection state for that connection.  In the jargon of telephony, this connection is called a <strong>circuit</strong>. when the network establishes the circuit , it also </p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"The-Network-Core\"><a href=\"#The-Network-Core\" class=\"headerlink\" title=\"The Network Core\"></a>The Network Core</h1><p>The figure highlights the Network Core with thick, shaded lines.</p>\n<p><img src=\"The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png\" alt=\"\"></p>\n<h2 id=\"Packet-Switching\"><a href=\"#Packet-Switching\" class=\"headerlink\" title=\"Packet Switching\"></a>Packet Switching</h2><p>To send a message from a source end system to a destination end system, the source breaks long message into smaller chunks of data known as <strong>Packets</strong>. Between source and destination, each packet travel through <strong>communication links and packet switches</strong>(for which there are two predominant types, routers and link-layer switches) .</p>\n<h3 id=\"Store-and-Forward-Transmission\"><a href=\"#Store-and-Forward-Transmission\" class=\"headerlink\" title=\"Store-and-Forward Transmission\"></a>Store-and-Forward Transmission</h3><p>Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. </p>\n<p>To explore store-and-forward transmission in more detail. Consider a simple network consisting of two end systems connected by a single router as shown as figure below.</p>\n<p>A router will typically have many incident link, since its job is to switch an incoming packet onto an outgoing link;  In this example the router has the rather simple task of transferring a packet from one(input) link to the only other attached link. In this example the source has three packets, each consisting of L bits to send to the destination. Because the router employ store-and-forwarding, at this instant of time, the router cannot transmit the bits it has received; only after the router has received all of the packet’s bits can it begin to transmit the packet onto the outbound link.</p>\n<p><img src=\"The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png\" alt=\"s\"></p>\n<p>To gain some insight into store-and-forward transmission, let’s now calculate the amount of time that elapses from when the source begins to send the packet until the destination has received the entire packet.(Here we will ignore propagation delay - the time it take for the bits to travel across the wire at near the speed of light). The source begins to transmit at time 0; at time L/R seconds, the sources has transmitted the entire packet and the entire packet has been received and store at the router(since there is no propagation delay). At time L/R seconds, since the router  has just received the entire packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2L/R, the router have transmitted the entire packet, and the entire packet has been received by the desination. Thus the total delay is 2L/R. If the switch instead forwarded bits as soon as they arrive.(without first receving store and process the entire packet before forwarding) then the total delay would be L/R since bits are not help up at the router. But as we will discuss in Section1.4 routers need to receive, store,and process the entrie packet before forwarding.</p>\n<p>let’s now consider the general case of sending one packet from source to destination over a path consisting of N link each of rate R(thus, there are N-1 routers between source and destination). Applying the same logic as above, we see that the end-to-end delay is :</p>\n<script type=\"math/tex; mode=display\">\nd_ {end-to-end}= N*L/R</script><h3 id=\"Queuing-Delays-and-Packet-Loss\"><a href=\"#Queuing-Delays-and-Packet-Loss\" class=\"headerlink\" title=\"Queuing Delays and Packet Loss\"></a>Queuing Delays and Packet Loss</h3><p>Each packet switch has multiple link attached to it . For each attached link, the packet switch has an <strong>output buffer</strong>(also called an <strong>output queue</strong>),which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link,but finds the link busy with the transmission of another packet, the arriving packets must wait in the output buffer. <strong>Thus, in addition to the store-and-forward delays,packets suffer output buffer queuing delay.</strong> These delay are variable and depend on the level of congestion in the network. since the amount of buffer space is finite. an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, <strong>Packet Loss will occur</strong> - either the arriving packet or one of the already-queued packets will be dropped.</p>\n<h3 id=\"Forwarding-Tables-and-Routing-Protocols\"><a href=\"#Forwarding-Tables-and-Routing-Protocols\" class=\"headerlink\" title=\"Forwarding Tables and Routing Protocols\"></a>Forwarding Tables and Routing Protocols</h3><p>Earlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of attached communication links. But how does the router determine which link it should forward the packet onto? Packet forwarding is actually done in different ways in different types of computer networks. Here, we briefly describe how it is done in the Internet.</p>\n<p>​    In the Internet,every end system has an address called an <strong>IP address.</strong> when a source end system wants to send a packet to a destination end system, the source include the destination’s IP address in the packet’s header. As with postal addresses. each router has a <strong>forwarding table</strong> that maps destination addresses(or portions of the destination addresses) to that router’s outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.</p>\n<p>​    We just learned that a router uses a packet’s destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs yet another question: “How do forwarding tables get set ?”, Are they configured by hand in each and every router, or does the Internet use a more automated procedure? The issue will be studied in depth in after. but we’ll note now that the Internet has a number of special routing protocols that are used to automatically set the forwarding tables.</p>\n<h2 id=\"Circuit-Switching\"><a href=\"#Circuit-Switching\" class=\"headerlink\" title=\"Circuit Switching\"></a>Circuit Switching</h2><p>In circuit-switching networds, the resource needed along a path(buffer link transmission rate) to provide for communication between the end systems are  reserved for the duration of the communication session between the end systems. In the packet-switched networks, these resources are not reserved; a session’s messages use the resources on demand and as a consequence ,may have to wait for access to a  communication link.</p>\n<p>​    Traditional telephone networks are examples of circuit-switched network. Consider what happens when one person want to send information(voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver, for which the switches on the path between the sender and receiver maintain connection state for that connection.  In the jargon of telephony, this connection is called a <strong>circuit</strong>. when the network establishes the circuit , it also </p>\n"},{"title":"VIM指令学习","date":"2020-03-22T08:37:18.000Z","index_img":"/Picture/Vim.jpg","_content":"\n# vim 选中的行列递增\n\n**例如想要替换下行中10行BL1,依次递增为BL1.BL2....BL10,可以用这种方法**\n```\nBL1BL1  \nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\n```\n先用可视块选中这10行，然后ESC退到命令模式再按：输入命令<br>\n```\n:'<,'>s/BL\\zs\\d*\\ze/\\=line(\".\")-line(\"'<\")+1/g\n```\n这些指令的意思如下：\n```\n'<,'>        我们所选中的区域 (:help '<，:help '> )\ns            在选中的区域中进行替换 (:help :s )\n\\zs          指明匹配由此开始 (:help /\\zs )\n\\d*          查找任意位数的数字 (:help /\\d )\n\\ze          指明匹配到此为止 (:help /\\ze )\n\\=           指明后面是一个表达式 (:help :s\\= )\nline(\".\")    当前光标所在行的行号 (:help line() )\nline(\"'<\")   我们所选区域中第一行的行号 (:help line() )\n/g\t     代表一行内所有的BL都使用，如果没有\\g就只会对第一个BL使用命令 \n```\n最后得到的结果是：（有\\g）\n```\nBL1BL1\nBL2BL2\nBL3BL3\nBL4BL4\nBL5BL5\nBL6BL6\nBL7BL7\nBL8BL8\nBL9BL9\nBL10BL10\n```\n没有/g的情况是：<br>\n```\nBL1BL1\nBL2BL1\nBL3BL1\nBL4BL1\nBL5BL1\nBL6BL1\nBL7BL1\nBL8BL1\nBL9BL1\nBL10BL1\n```\n","source":"_posts/VIM指令学习.md","raw":"---\ntitle: VIM指令学习\ndate: 2020-03-22 16:37:18\nindex_img: /Picture/Vim.jpg\ncategories:\n- vim \ntags:\n- vim \n---\n\n# vim 选中的行列递增\n\n**例如想要替换下行中10行BL1,依次递增为BL1.BL2....BL10,可以用这种方法**\n```\nBL1BL1  \nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\nBL1BL1\n```\n先用可视块选中这10行，然后ESC退到命令模式再按：输入命令<br>\n```\n:'<,'>s/BL\\zs\\d*\\ze/\\=line(\".\")-line(\"'<\")+1/g\n```\n这些指令的意思如下：\n```\n'<,'>        我们所选中的区域 (:help '<，:help '> )\ns            在选中的区域中进行替换 (:help :s )\n\\zs          指明匹配由此开始 (:help /\\zs )\n\\d*          查找任意位数的数字 (:help /\\d )\n\\ze          指明匹配到此为止 (:help /\\ze )\n\\=           指明后面是一个表达式 (:help :s\\= )\nline(\".\")    当前光标所在行的行号 (:help line() )\nline(\"'<\")   我们所选区域中第一行的行号 (:help line() )\n/g\t     代表一行内所有的BL都使用，如果没有\\g就只会对第一个BL使用命令 \n```\n最后得到的结果是：（有\\g）\n```\nBL1BL1\nBL2BL2\nBL3BL3\nBL4BL4\nBL5BL5\nBL6BL6\nBL7BL7\nBL8BL8\nBL9BL9\nBL10BL10\n```\n没有/g的情况是：<br>\n```\nBL1BL1\nBL2BL1\nBL3BL1\nBL4BL1\nBL5BL1\nBL6BL1\nBL7BL1\nBL8BL1\nBL9BL1\nBL10BL1\n```\n","slug":"VIM指令学习","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4s8000ur8s8gk3gg8hy","content":"<h1 id=\"vim-选中的行列递增\"><a href=\"#vim-选中的行列递增\" class=\"headerlink\" title=\"vim 选中的行列递增\"></a>vim 选中的行列递增</h1><p><strong>例如想要替换下行中10行BL1,依次递增为BL1.BL2….BL10,可以用这种方法</strong><br><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-keyword\">BL1BL1 </span> <br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br></code></pre></td></tr></table></figure><br>先用可视块选中这10行，然后ESC退到命令模式再按：输入命令<br><br><figure class=\"highlight perl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs perl\">:<span class=\"hljs-string\">&#x27;&lt;,&#x27;</span>&gt;<span class=\"hljs-regexp\">s/BL\\zs\\d*\\ze/\\=line(&quot;.&quot;)-line(&quot;&#x27;&lt;&quot;)+1/</span>g<br></code></pre></td></tr></table></figure><br>这些指令的意思如下：<br><figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\"><span class=\"hljs-string\">&#x27;&lt;,&#x27;</span>&gt;        我们所选中的区域 (:<span class=\"hljs-keyword\">help</span> <span class=\"hljs-string\">&#x27;&lt;，:help &#x27;</span>&gt; )<br>s            在选中的区域中进行替换 (:<span class=\"hljs-keyword\">help</span> :s )<br>\\zs          指明匹配由此开始 (:<span class=\"hljs-keyword\">help</span> /\\zs )<br>\\d*          查找任意位数的数字 (:<span class=\"hljs-keyword\">help</span> /\\d )<br>\\ze          指明匹配到此为止 (:<span class=\"hljs-keyword\">help</span> /\\ze )<br>\\=           指明后面是一个表达式 (:<span class=\"hljs-keyword\">help</span> :s\\= )<br><span class=\"hljs-built_in\">line</span>(<span class=\"hljs-string\">&quot;.&quot;</span>)    当前光标所在行的行号 (:<span class=\"hljs-keyword\">help</span> <span class=\"hljs-built_in\">line</span>() )<br><span class=\"hljs-built_in\">line</span>(<span class=\"hljs-string\">&quot;&#x27;&lt;&quot;</span>)   我们所选区域中第一行的行号 (:<span class=\"hljs-keyword\">help</span> <span class=\"hljs-built_in\">line</span>() )<br>/g\t     代表一行内所有的BL都使用，如果没有\\g就只会对第一个BL使用命令 <br></code></pre></td></tr></table></figure><br>最后得到的结果是：（有\\g）<br><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL2BL2</span><br><span class=\"hljs-keyword\">BL3BL3</span><br><span class=\"hljs-keyword\">BL4BL4</span><br><span class=\"hljs-keyword\">BL5BL5</span><br><span class=\"hljs-keyword\">BL6BL6</span><br><span class=\"hljs-keyword\">BL7BL7</span><br><span class=\"hljs-keyword\">BL8BL8</span><br><span class=\"hljs-keyword\">BL9BL9</span><br><span class=\"hljs-keyword\">BL10BL10</span><br></code></pre></td></tr></table></figure><br>没有/g的情况是：<br><br><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL2BL1</span><br><span class=\"hljs-keyword\">BL3BL1</span><br><span class=\"hljs-keyword\">BL4BL1</span><br><span class=\"hljs-keyword\">BL5BL1</span><br><span class=\"hljs-keyword\">BL6BL1</span><br><span class=\"hljs-keyword\">BL7BL1</span><br><span class=\"hljs-keyword\">BL8BL1</span><br><span class=\"hljs-keyword\">BL9BL1</span><br><span class=\"hljs-keyword\">BL10BL1</span><br></code></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"vim-选中的行列递增\"><a href=\"#vim-选中的行列递增\" class=\"headerlink\" title=\"vim 选中的行列递增\"></a>vim 选中的行列递增</h1><p><strong>例如想要替换下行中10行BL1,依次递增为BL1.BL2….BL10,可以用这种方法</strong><br><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-keyword\">BL1BL1 </span> <br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL1BL1</span><br></code></pre></td></tr></table></figure><br>先用可视块选中这10行，然后ESC退到命令模式再按：输入命令<br><br><figure class=\"highlight perl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs perl\">:<span class=\"hljs-string\">&#x27;&lt;,&#x27;</span>&gt;<span class=\"hljs-regexp\">s/BL\\zs\\d*\\ze/\\=line(&quot;.&quot;)-line(&quot;&#x27;&lt;&quot;)+1/</span>g<br></code></pre></td></tr></table></figure><br>这些指令的意思如下：<br><figure class=\"highlight vim\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs vim\"><span class=\"hljs-string\">&#x27;&lt;,&#x27;</span>&gt;        我们所选中的区域 (:<span class=\"hljs-keyword\">help</span> <span class=\"hljs-string\">&#x27;&lt;，:help &#x27;</span>&gt; )<br>s            在选中的区域中进行替换 (:<span class=\"hljs-keyword\">help</span> :s )<br>\\zs          指明匹配由此开始 (:<span class=\"hljs-keyword\">help</span> /\\zs )<br>\\d*          查找任意位数的数字 (:<span class=\"hljs-keyword\">help</span> /\\d )<br>\\ze          指明匹配到此为止 (:<span class=\"hljs-keyword\">help</span> /\\ze )<br>\\=           指明后面是一个表达式 (:<span class=\"hljs-keyword\">help</span> :s\\= )<br><span class=\"hljs-built_in\">line</span>(<span class=\"hljs-string\">&quot;.&quot;</span>)    当前光标所在行的行号 (:<span class=\"hljs-keyword\">help</span> <span class=\"hljs-built_in\">line</span>() )<br><span class=\"hljs-built_in\">line</span>(<span class=\"hljs-string\">&quot;&#x27;&lt;&quot;</span>)   我们所选区域中第一行的行号 (:<span class=\"hljs-keyword\">help</span> <span class=\"hljs-built_in\">line</span>() )<br>/g\t     代表一行内所有的BL都使用，如果没有\\g就只会对第一个BL使用命令 <br></code></pre></td></tr></table></figure><br>最后得到的结果是：（有\\g）<br><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL2BL2</span><br><span class=\"hljs-keyword\">BL3BL3</span><br><span class=\"hljs-keyword\">BL4BL4</span><br><span class=\"hljs-keyword\">BL5BL5</span><br><span class=\"hljs-keyword\">BL6BL6</span><br><span class=\"hljs-keyword\">BL7BL7</span><br><span class=\"hljs-keyword\">BL8BL8</span><br><span class=\"hljs-keyword\">BL9BL9</span><br><span class=\"hljs-keyword\">BL10BL10</span><br></code></pre></td></tr></table></figure><br>没有/g的情况是：<br><br><figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\"><span class=\"hljs-keyword\">BL1BL1</span><br><span class=\"hljs-keyword\">BL2BL1</span><br><span class=\"hljs-keyword\">BL3BL1</span><br><span class=\"hljs-keyword\">BL4BL1</span><br><span class=\"hljs-keyword\">BL5BL1</span><br><span class=\"hljs-keyword\">BL6BL1</span><br><span class=\"hljs-keyword\">BL7BL1</span><br><span class=\"hljs-keyword\">BL8BL1</span><br><span class=\"hljs-keyword\">BL9BL1</span><br><span class=\"hljs-keyword\">BL10BL1</span><br></code></pre></td></tr></table></figure></p>\n"},{"title":"chapter4-Homework-problems-and-Questions ","index_img":"/Picture/Question-Mark.jpg","date":"2020-05-28T08:00:15.000Z","banner_img":null,"_content":"![1.png](1.png)<br>\n![2.png](2.png)<br>\n![3.png](3.png)<br>\n![4.png](4.png)<br>\n![5.png](5.png)<br>\n![6.png](6.png)<br>\n![7.png](7.png)<br>\n","source":"_posts/chapter4-Homework-problems-and-Questions.md","raw":"---\ntitle: 'chapter4-Homework-problems-and-Questions '\nindex_img: /Picture/Question-Mark.jpg\ndate: 2020-05-28 16:00:15\ntags:\n- Computer Network A Top-Down Approach\ncategories:\n- Computer Network A Top-Down Approach\nbanner_img:\n---\n![1.png](1.png)<br>\n![2.png](2.png)<br>\n![3.png](3.png)<br>\n![4.png](4.png)<br>\n![5.png](5.png)<br>\n![6.png](6.png)<br>\n![7.png](7.png)<br>\n","slug":"chapter4-Homework-problems-and-Questions","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4s9000wr8s8h1y6e8du","content":"<p><img src=\"1.png\" alt=\"1.png\"><br><br><img src=\"2.png\" alt=\"2.png\"><br><br><img src=\"3.png\" alt=\"3.png\"><br><br><img src=\"4.png\" alt=\"4.png\"><br><br><img src=\"5.png\" alt=\"5.png\"><br><br><img src=\"6.png\" alt=\"6.png\"><br><br><img src=\"7.png\" alt=\"7.png\"><br></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"1.png\" alt=\"1.png\"><br><br><img src=\"2.png\" alt=\"2.png\"><br><br><img src=\"3.png\" alt=\"3.png\"><br><br><img src=\"4.png\" alt=\"4.png\"><br><br><img src=\"5.png\" alt=\"5.png\"><br><br><img src=\"6.png\" alt=\"6.png\"><br><br><img src=\"7.png\" alt=\"7.png\"><br></p>\n"},{"title":"chapter2 :Homework problems and Questions","date":"2020-03-30T22:23:55.000Z","index_img":"/Picture/Question-Mark.jpg","_content":"下面提到的的文档都收藏在 https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中<br>\n\n课本是：computer network a top-down approach<br>\n\n**1.列出5个(非专有)的互联网应用，并说明他们使用的应用层协议**<br>\n*查过一些资料，好像有一个技术叫做Deep packet inspection (DPI)可以查到软件使用的协议，github上也有一个开源软件nDPI，还有一个软件叫做wireshark,但是因为有点复杂，我现在暂且不深入研究，下面答案都来着互联网*\n- 1 . Chrome (谷歌浏览器貌似不是开源的．．．,不管了用的最多,下面答案来自stackoverflow)<br>\n\tin term of what protocol you can use in the chrome browser bar you can use: HTTP,HTTPS,FILE and FTP.SSH is not implemented by chrome,but rather it implements SSL, it also does nit implement SMTP,but rather when you visiting a website(via HTTP or hopefully HTTPS).That website is not at all connecting to an SMTP server to display you you emails, but is merely serving up web pages and conneting to API's to display/edit/compose your email (by then which the email client's backend is connected to their SMTP server).<br>\nAlso chrome does implement FTP,like you can visit an IP address that has FTP enable such as : ftp://123.34.45.890 and you can use the directory listings as a webpage. An example of this would the CentOS mirrors [here](https://www.centos.org/download/mirrors/).on the right column they have FTP sites. You can access the FIP director via web browser that supports FTP or you can fire up a terminal and do ftp ftp://ftp.is.co.za/mirror/centos/.<br>\n- 2 .  网易云音乐<br>\n在应用层使用的是HTTP协议\n- 3 . 微信<br>\n微信是应用层是使用HTTP协议（来源是: 利用Wireshark软件对微信协议的分析——QPIC）\n- 4 . 大部分软件都需要使用DNS协议,例如上面文章有提到微信就需要使用DNS来进行域名解析\n- 5 . QQ <br>\n应用层使用的是QICQ协议\n\n**2.网络体系结构和应用程序的体系结构有什么不同?**\n- 应用程序体系结构（application architecture）<br>\n1. 客户－服务器体系结构（client-servers architecture）\n答：<br>\n2. P2P（peer to peer）\n3. 混合体系结构 (hybind architecture)\n- 网络体系结构(network architecture)\n1. 应用层(application layer)\n2. 传输层(transport layer)\n3. 网络层(network layer)\n4. 链路层(link layer)\n5. 物理层(physical layer)\n\n所以有什么不同呢？<br>\n\n|Network architecture|Application architecture|\n|:-----:|:-----:|\n|Network architecture refers to the organization of the communication process into layers.|Application architecture, on the other hand, is designed by an application developer and dictates the broad structure of the application.|\n|How any network of any local area or wide area is built is  called the Network Architecture.|How any application is built is called the application architecture|\n|Example -  The five-layer Internet architecture, Servers. |Example - Client-server or P2P.|\n\n(来源是：[What is the difference between network architecture and application architecture?](http://computer-science-solutions.blogspot.com/2017/05/what-is-difference-between-network.html))<br>\n我感觉这个比较没有意义啊，要比较也是P2P和client-servers architecture之间有什么不同吧．．<br>\n\n**3. 在两个进程的通信会话中哪个进程是客户端，那个进程是服务端**<br>\n答：In the context of communication session between a pair of process,the process that initiates the communication session is labeled as client and the process that wait to be contacted is labeled as server.(来自课本) <br>\n\n**4.对于P2P的协议你是否同意在通信会话时没有客户端－服务端的概念，请说明理由**<br>\n答：不同意，P2P协议也存在客户端－服务端的概念，但是与client-servers架构稍有不同的是，P2P中的peer即当客户端也当服务端，当peer接受数据的时候为客户端，上传数据的时候就是服务端，上传下载也可以同时进行,此时peer即是客户端，也是服务端.<br>\n\n**5.一个运行在源主机的进程如何识别确认运行的目标主机和运行在目标主机上的进程**<br>\n答：通过目标主机的IP地址可以确认目标主机，通过目标主机程序占用的套接字端口号可以确认目标主机程序<br>\n\n**6.假如你想做一个交易(do a transation)从远端的客户端到服务端，要求尽可能的快，你会选择用TCP还是UDP,说明理由**<br>\n答：我会选择UDP,因为UDP只需要一次RTT（round-trip-time），而TCP至少两次RTT,所以用UDP更快<br>\n- **TCP:**\n![TCP-handshake](TCP-handshake.png)\n\n**7.课本2.4提及到的应用程序都是no data loss and timing(没有数据丢失，以及不规定时间的)能不能构想一个应用程序要求没有数据丢失并且对时间有很高的敏感性**<br>\n答：网络游戏．<br>\n\n**8.列出传输层协议能提供的４类服务，对于每项服务指出是由TCP还是UDP(或者两者都可以)提供**<br>\n答：We have organized transfer protocol services along four dismensions : **reliable date transfer**,**throughput**,**timing**,**security**(来自课本)<br>\n- reliable data transfer : TCP do,UDP not.\n- throughput: TCP have congestion-control mechanism,UDP not.\n- timing :Neither TCP nor UDP.\n- security: Neither TCP nor UDP.<br>\n**9.TCP可以增强为SSL(Secure Socket Layer)去提供进程之间的安全服务，例如加密，SSL的操作是在传输层还是在应用层，如果软件开发者想要将TCP增强为SSL，他应该怎么做．**<br>\n\n答：We emphasize that SSL is not a third internet transport protocol, on the same level as TCP and UDP but instead is an enhancement of TCP, with the emhancement being implemented in the application layer,In particular, if an application wants to use the services of SSL, it needs to include SSL code(exiting highly optimized libraries and classes) in both the client and server side of the application.  SSL has its own socket API that is similar to the trandition of TCP socket API, When an application uses SSL, the sending process passes cleartext data to the SSL socket; SSL in the sending host then encrypts the data and passes the encrypted data to the TCP socket; The encrypted data travels over the internet to the TCP socket in the receiving process. The receiving socket passes the encrypted data to SSL,which decrypts the data. Finally.SSL passes the cleartext data through its SSL socket to receiving process.(来自课本)<br>\n\n**10. 什么是握手协议？**<br>\n答:握手协议就是两端在首次建立TCP链接时互相发送的三次消息,如第六题的图．<br>\n\n**11.为什么HTTP,FTP,SMTP,POP3,都是基于TCP,而不是UDP**<br>\n答：因为上面这些协议都需要得到的数据都是按照顺序，TCP可以提供这个功能而UDP不行<br>\n\n**12.想象电子商务网站想要保持每一个用户的购买记录，描述用用cookie怎么做到**<br>\n答：当你首次访问网站时，网站会给你创建一个独一无二的ID(cookie码),这个码会存放在你的浏览器中，也会存放在网站的后台数据库中，网站会把你选择的商品存入你cookie码的相应存储中，当你下次访问相同网站的时候，你发出的请求会夹带相应的cookie码，这时网站数据库就能匹配到你，从而展现你的购买记录．<br>\n\n**13.描述Web缓存怎么降低接收请求对象的延迟，Web缓存是能降低所以请求对象的延迟还是仅仅降低部分请求对象的延迟，为什么？**<br>\n答：Web缓存是在大学，企业，ISP 之类的在局域网中建立一个基础设施，用来存储最近局域网内用户访问过的网站，当在短时间内，用户再次访问该网站，Web缓存就可以在直接返回数据给用户，而不用请求网站的服务器，从而降低延迟,**Web缓存是可以降低所有请求对象的延迟的，因为有缓存的存在，降低了局域网向外部互联网的请求流量，所以降低了所有请求对象的延迟．**<br>\n\n**14. Telnet一个Web服务器然后发生一些请求指令标题行要包括`If-modified-since:`去让强制服务器响应`304 Not Modified`status code.消息**<br>\n答：下面是google的答案，但是我对www.baidu.com照做得到的200,没办法得到304，所以...\n```\n“telnet” command:\n\n It is a command used in windows (also in linux) to connect to the web server.\nThe server responds to the HTTP GET requests.\nIt reply to the client with the requested information.\n\nCommand to open the connection with web server:\n\n        telnet <domain name of web server> <port number>\n\n example: telnet www.sr2jr.com 23\n\nAfter establishing the connection with the web server\nit is possible to request a specified page from the web server.\n\nCommand to request the page web server:\n\n        GET <page name> HTTP/1.0\n\nIf the page is available then the server sends the page details.\nIt include the “If-modified-since” message with the 304 Not Modified\nstatus code in the response.\n```\n\n**15.为什么说FTP发送带外控制信息.**<br>\n答：因为FTP（文件传输协议）会建立两个TCP连接（端口为20,21），一个是用来传输文件数据(20)，一个是用来传输控制信息(21)，因为FTP协议传输控制信息是用额外的一个连接传送，而不是文件传输的连接所以叫做带外(out-of-band)<br>\n\n**16.假设Alice用基于Web的e-mail的站帐户例如（Hotmail 和 gmail)发送文件给Bob.Bob访问其邮箱服务器用POP3协议，描述消息是怎么从Alice发送到Bob这边，明确的表示出发送途中使用的应用层协议．**<br>\n```\ngraph LR\nid1(Alice)==HTTP==>id2(Web e-mail server)\n==SMTP==>id3(Bob's mail server)==POP3==>id4(Bob)\n```\n\n**17.打印出你最近收到的邮件的标题(header of e-mail),一共有多少行，分析每一行的的作用.**<br>\n答：\n- **Message header:**\n![messageheader](Messagesheader.png)<br>\n分析：Messageld,Created at,From,To,Subject字段就不说了．<br>\nSPF: sender policy framework (发送方策略架构)是一直email的认证协议，主要用来检测伪造的email地址．<br>\nDKIM: Domain Key Identify Mail(域密钥识别邮件),允许接受者通过数字签名去检查是否发件人的域名是否真正发生和认证过该邮件．<br>\nDMARC: Domain Message Authentication,Reporting and Comformance,是一种email的认证协议，用来保护邮件域名所有者的邮件域名免受未授权使用．<br>\n\n**18.从用户的角度，阐述一下POP3的download-and-delete-mode和download-and-keep-mode的不同之处.**<br>\n答:不同之处就在于download-and-delete-mode下载完了就删除，当换一个设备(终端)再次访问的时候，就无法看到删除的消息了，这样消息的移动性就很差．\n而download-and-keep-mode下载然后保留，当换一个设备再次登录邮箱服务器下载时，还可以看到，消息的移动性很好.<br>\n\n**19.是否可能组织的Web server 和mail server有相同的主机别名,如果可能，mail server的RR类型是什么？**<br>\n答:可以做到，mail server的类型是MX(Mail Exchange Record).<br>\n\n**20.是否可能根据邮件的头部信息地址(例如什么.edu)中确定信息发送的IP地址．对Gmail做同样的操作．**<br>\n答：You should be able to see the sender's IP address for a user with an .edu email address. But you will not be able to see the sender's IP address if the user uses a gmail account．\n\n**21.在BitTorrent中假设Alicer在30秒中始终提供块给Bob,Bob是否有必要在这30秒内同样给Alice提供块呢?请说明理由**<br>\n答:没有必要，因为在BitTorrent中，没30秒选出一个而外的peer给其发送块是为了帮助新进入的peer以后可以有块去交易，当然如果Alice是Bob的top four neighboring 的话Bob也会给Alice发送块．\n\n**22.思考一下，如果一个新进入的peer Alice，没有任何块，所以她不能成为邻居peer的Top four neighboring peer，也没有块可以上传，所以他是怎么样得到她的首块的呢?**<br>\n答:这道题其实21题时已经回答了，在BitTorrent中其他有块的peer每30秒就会选出一个幸运peer(optimistically unchocked)然后给其发送块，所以Alice有可能被选中然后就可以得到第一个块\n\n**23.什么是覆盖网络(overlay network),它是否包括路由，它的网络边缘是什么.**<br>\n答:覆盖网络就是在P2P文件分享中两个peer的一种逻辑链接，即不是真实的在物理上的连接，它不包括路由，网络的边缘就每个peer.\n\n**24.描述一下every peer keep tracks all peer 的DHT结构的优缺点，和circular DHT (no shortcut)的优点和缺点．**<br>\n答:\n- Every peer keep tracks all peer 这种结构的优点就是你可以马上就知道你需要的东西的位置，但是缺点就是当peer量巨大的时候，每个peer都存储其他peer的踪迹实在是太耗存储资源了，而且很难维护．\n- circular DHT(no shortcut)的优点就是它只需要记住两个peer就可以了，缺点就是peer数量N巨大的时候，peer的询问请求的平均时间是N/2.\n\n**25.列出至少4个不同的适合使用p2p架构的应用程序.**\n答:文件分发，即时信息，视频流，分布式计算\n\n**26.在章节2.7的描述中UDP服务器仅仅需要一个套接字，而TCP服务器需要两个套接字，为什么，如果TCP服务器支持n个用户同时连接，每个用户来自不同的客户端主机，TCP服务器需要的多少个套接字.**<br>\n答:在TCP服务器一端有一个wecoming socket,用来进行握手协议的,握手协议结束后TCP会新开一个端口叫做connecting socket进行数据的传输,所以TCP服务器支持n个客户端同时连接就会有n+1个socket,而UDP没有wecoming socket仅仅需要一个套接字．\n\n**27.在章节2.7中的客户－服务端应用程序中，TCP连接为什么服务端一定要在客户端之前先启动，而UDP相反，必须服务端先在客户端之前启动．**<br>\n答:因为TCP在传输数据之前必须进行三次握手，而UDP可以直接传输数据\n","source":"_posts/chapter2-Homework-problems-and-Questions.md","raw":"---\ntitle: 'chapter2 :Homework problems and Questions'\ndate: 2020-03-31 06:23:55\nindex_img: /Picture/Question-Mark.jpg\ncategories:\n- Computer Network A Top-Down Approach\ntags:\n- Computer Network A Top-Down Approach\n---\n下面提到的的文档都收藏在 https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中<br>\n\n课本是：computer network a top-down approach<br>\n\n**1.列出5个(非专有)的互联网应用，并说明他们使用的应用层协议**<br>\n*查过一些资料，好像有一个技术叫做Deep packet inspection (DPI)可以查到软件使用的协议，github上也有一个开源软件nDPI，还有一个软件叫做wireshark,但是因为有点复杂，我现在暂且不深入研究，下面答案都来着互联网*\n- 1 . Chrome (谷歌浏览器貌似不是开源的．．．,不管了用的最多,下面答案来自stackoverflow)<br>\n\tin term of what protocol you can use in the chrome browser bar you can use: HTTP,HTTPS,FILE and FTP.SSH is not implemented by chrome,but rather it implements SSL, it also does nit implement SMTP,but rather when you visiting a website(via HTTP or hopefully HTTPS).That website is not at all connecting to an SMTP server to display you you emails, but is merely serving up web pages and conneting to API's to display/edit/compose your email (by then which the email client's backend is connected to their SMTP server).<br>\nAlso chrome does implement FTP,like you can visit an IP address that has FTP enable such as : ftp://123.34.45.890 and you can use the directory listings as a webpage. An example of this would the CentOS mirrors [here](https://www.centos.org/download/mirrors/).on the right column they have FTP sites. You can access the FIP director via web browser that supports FTP or you can fire up a terminal and do ftp ftp://ftp.is.co.za/mirror/centos/.<br>\n- 2 .  网易云音乐<br>\n在应用层使用的是HTTP协议\n- 3 . 微信<br>\n微信是应用层是使用HTTP协议（来源是: 利用Wireshark软件对微信协议的分析——QPIC）\n- 4 . 大部分软件都需要使用DNS协议,例如上面文章有提到微信就需要使用DNS来进行域名解析\n- 5 . QQ <br>\n应用层使用的是QICQ协议\n\n**2.网络体系结构和应用程序的体系结构有什么不同?**\n- 应用程序体系结构（application architecture）<br>\n1. 客户－服务器体系结构（client-servers architecture）\n答：<br>\n2. P2P（peer to peer）\n3. 混合体系结构 (hybind architecture)\n- 网络体系结构(network architecture)\n1. 应用层(application layer)\n2. 传输层(transport layer)\n3. 网络层(network layer)\n4. 链路层(link layer)\n5. 物理层(physical layer)\n\n所以有什么不同呢？<br>\n\n|Network architecture|Application architecture|\n|:-----:|:-----:|\n|Network architecture refers to the organization of the communication process into layers.|Application architecture, on the other hand, is designed by an application developer and dictates the broad structure of the application.|\n|How any network of any local area or wide area is built is  called the Network Architecture.|How any application is built is called the application architecture|\n|Example -  The five-layer Internet architecture, Servers. |Example - Client-server or P2P.|\n\n(来源是：[What is the difference between network architecture and application architecture?](http://computer-science-solutions.blogspot.com/2017/05/what-is-difference-between-network.html))<br>\n我感觉这个比较没有意义啊，要比较也是P2P和client-servers architecture之间有什么不同吧．．<br>\n\n**3. 在两个进程的通信会话中哪个进程是客户端，那个进程是服务端**<br>\n答：In the context of communication session between a pair of process,the process that initiates the communication session is labeled as client and the process that wait to be contacted is labeled as server.(来自课本) <br>\n\n**4.对于P2P的协议你是否同意在通信会话时没有客户端－服务端的概念，请说明理由**<br>\n答：不同意，P2P协议也存在客户端－服务端的概念，但是与client-servers架构稍有不同的是，P2P中的peer即当客户端也当服务端，当peer接受数据的时候为客户端，上传数据的时候就是服务端，上传下载也可以同时进行,此时peer即是客户端，也是服务端.<br>\n\n**5.一个运行在源主机的进程如何识别确认运行的目标主机和运行在目标主机上的进程**<br>\n答：通过目标主机的IP地址可以确认目标主机，通过目标主机程序占用的套接字端口号可以确认目标主机程序<br>\n\n**6.假如你想做一个交易(do a transation)从远端的客户端到服务端，要求尽可能的快，你会选择用TCP还是UDP,说明理由**<br>\n答：我会选择UDP,因为UDP只需要一次RTT（round-trip-time），而TCP至少两次RTT,所以用UDP更快<br>\n- **TCP:**\n![TCP-handshake](TCP-handshake.png)\n\n**7.课本2.4提及到的应用程序都是no data loss and timing(没有数据丢失，以及不规定时间的)能不能构想一个应用程序要求没有数据丢失并且对时间有很高的敏感性**<br>\n答：网络游戏．<br>\n\n**8.列出传输层协议能提供的４类服务，对于每项服务指出是由TCP还是UDP(或者两者都可以)提供**<br>\n答：We have organized transfer protocol services along four dismensions : **reliable date transfer**,**throughput**,**timing**,**security**(来自课本)<br>\n- reliable data transfer : TCP do,UDP not.\n- throughput: TCP have congestion-control mechanism,UDP not.\n- timing :Neither TCP nor UDP.\n- security: Neither TCP nor UDP.<br>\n**9.TCP可以增强为SSL(Secure Socket Layer)去提供进程之间的安全服务，例如加密，SSL的操作是在传输层还是在应用层，如果软件开发者想要将TCP增强为SSL，他应该怎么做．**<br>\n\n答：We emphasize that SSL is not a third internet transport protocol, on the same level as TCP and UDP but instead is an enhancement of TCP, with the emhancement being implemented in the application layer,In particular, if an application wants to use the services of SSL, it needs to include SSL code(exiting highly optimized libraries and classes) in both the client and server side of the application.  SSL has its own socket API that is similar to the trandition of TCP socket API, When an application uses SSL, the sending process passes cleartext data to the SSL socket; SSL in the sending host then encrypts the data and passes the encrypted data to the TCP socket; The encrypted data travels over the internet to the TCP socket in the receiving process. The receiving socket passes the encrypted data to SSL,which decrypts the data. Finally.SSL passes the cleartext data through its SSL socket to receiving process.(来自课本)<br>\n\n**10. 什么是握手协议？**<br>\n答:握手协议就是两端在首次建立TCP链接时互相发送的三次消息,如第六题的图．<br>\n\n**11.为什么HTTP,FTP,SMTP,POP3,都是基于TCP,而不是UDP**<br>\n答：因为上面这些协议都需要得到的数据都是按照顺序，TCP可以提供这个功能而UDP不行<br>\n\n**12.想象电子商务网站想要保持每一个用户的购买记录，描述用用cookie怎么做到**<br>\n答：当你首次访问网站时，网站会给你创建一个独一无二的ID(cookie码),这个码会存放在你的浏览器中，也会存放在网站的后台数据库中，网站会把你选择的商品存入你cookie码的相应存储中，当你下次访问相同网站的时候，你发出的请求会夹带相应的cookie码，这时网站数据库就能匹配到你，从而展现你的购买记录．<br>\n\n**13.描述Web缓存怎么降低接收请求对象的延迟，Web缓存是能降低所以请求对象的延迟还是仅仅降低部分请求对象的延迟，为什么？**<br>\n答：Web缓存是在大学，企业，ISP 之类的在局域网中建立一个基础设施，用来存储最近局域网内用户访问过的网站，当在短时间内，用户再次访问该网站，Web缓存就可以在直接返回数据给用户，而不用请求网站的服务器，从而降低延迟,**Web缓存是可以降低所有请求对象的延迟的，因为有缓存的存在，降低了局域网向外部互联网的请求流量，所以降低了所有请求对象的延迟．**<br>\n\n**14. Telnet一个Web服务器然后发生一些请求指令标题行要包括`If-modified-since:`去让强制服务器响应`304 Not Modified`status code.消息**<br>\n答：下面是google的答案，但是我对www.baidu.com照做得到的200,没办法得到304，所以...\n```\n“telnet” command:\n\n It is a command used in windows (also in linux) to connect to the web server.\nThe server responds to the HTTP GET requests.\nIt reply to the client with the requested information.\n\nCommand to open the connection with web server:\n\n        telnet <domain name of web server> <port number>\n\n example: telnet www.sr2jr.com 23\n\nAfter establishing the connection with the web server\nit is possible to request a specified page from the web server.\n\nCommand to request the page web server:\n\n        GET <page name> HTTP/1.0\n\nIf the page is available then the server sends the page details.\nIt include the “If-modified-since” message with the 304 Not Modified\nstatus code in the response.\n```\n\n**15.为什么说FTP发送带外控制信息.**<br>\n答：因为FTP（文件传输协议）会建立两个TCP连接（端口为20,21），一个是用来传输文件数据(20)，一个是用来传输控制信息(21)，因为FTP协议传输控制信息是用额外的一个连接传送，而不是文件传输的连接所以叫做带外(out-of-band)<br>\n\n**16.假设Alice用基于Web的e-mail的站帐户例如（Hotmail 和 gmail)发送文件给Bob.Bob访问其邮箱服务器用POP3协议，描述消息是怎么从Alice发送到Bob这边，明确的表示出发送途中使用的应用层协议．**<br>\n```\ngraph LR\nid1(Alice)==HTTP==>id2(Web e-mail server)\n==SMTP==>id3(Bob's mail server)==POP3==>id4(Bob)\n```\n\n**17.打印出你最近收到的邮件的标题(header of e-mail),一共有多少行，分析每一行的的作用.**<br>\n答：\n- **Message header:**\n![messageheader](Messagesheader.png)<br>\n分析：Messageld,Created at,From,To,Subject字段就不说了．<br>\nSPF: sender policy framework (发送方策略架构)是一直email的认证协议，主要用来检测伪造的email地址．<br>\nDKIM: Domain Key Identify Mail(域密钥识别邮件),允许接受者通过数字签名去检查是否发件人的域名是否真正发生和认证过该邮件．<br>\nDMARC: Domain Message Authentication,Reporting and Comformance,是一种email的认证协议，用来保护邮件域名所有者的邮件域名免受未授权使用．<br>\n\n**18.从用户的角度，阐述一下POP3的download-and-delete-mode和download-and-keep-mode的不同之处.**<br>\n答:不同之处就在于download-and-delete-mode下载完了就删除，当换一个设备(终端)再次访问的时候，就无法看到删除的消息了，这样消息的移动性就很差．\n而download-and-keep-mode下载然后保留，当换一个设备再次登录邮箱服务器下载时，还可以看到，消息的移动性很好.<br>\n\n**19.是否可能组织的Web server 和mail server有相同的主机别名,如果可能，mail server的RR类型是什么？**<br>\n答:可以做到，mail server的类型是MX(Mail Exchange Record).<br>\n\n**20.是否可能根据邮件的头部信息地址(例如什么.edu)中确定信息发送的IP地址．对Gmail做同样的操作．**<br>\n答：You should be able to see the sender's IP address for a user with an .edu email address. But you will not be able to see the sender's IP address if the user uses a gmail account．\n\n**21.在BitTorrent中假设Alicer在30秒中始终提供块给Bob,Bob是否有必要在这30秒内同样给Alice提供块呢?请说明理由**<br>\n答:没有必要，因为在BitTorrent中，没30秒选出一个而外的peer给其发送块是为了帮助新进入的peer以后可以有块去交易，当然如果Alice是Bob的top four neighboring 的话Bob也会给Alice发送块．\n\n**22.思考一下，如果一个新进入的peer Alice，没有任何块，所以她不能成为邻居peer的Top four neighboring peer，也没有块可以上传，所以他是怎么样得到她的首块的呢?**<br>\n答:这道题其实21题时已经回答了，在BitTorrent中其他有块的peer每30秒就会选出一个幸运peer(optimistically unchocked)然后给其发送块，所以Alice有可能被选中然后就可以得到第一个块\n\n**23.什么是覆盖网络(overlay network),它是否包括路由，它的网络边缘是什么.**<br>\n答:覆盖网络就是在P2P文件分享中两个peer的一种逻辑链接，即不是真实的在物理上的连接，它不包括路由，网络的边缘就每个peer.\n\n**24.描述一下every peer keep tracks all peer 的DHT结构的优缺点，和circular DHT (no shortcut)的优点和缺点．**<br>\n答:\n- Every peer keep tracks all peer 这种结构的优点就是你可以马上就知道你需要的东西的位置，但是缺点就是当peer量巨大的时候，每个peer都存储其他peer的踪迹实在是太耗存储资源了，而且很难维护．\n- circular DHT(no shortcut)的优点就是它只需要记住两个peer就可以了，缺点就是peer数量N巨大的时候，peer的询问请求的平均时间是N/2.\n\n**25.列出至少4个不同的适合使用p2p架构的应用程序.**\n答:文件分发，即时信息，视频流，分布式计算\n\n**26.在章节2.7的描述中UDP服务器仅仅需要一个套接字，而TCP服务器需要两个套接字，为什么，如果TCP服务器支持n个用户同时连接，每个用户来自不同的客户端主机，TCP服务器需要的多少个套接字.**<br>\n答:在TCP服务器一端有一个wecoming socket,用来进行握手协议的,握手协议结束后TCP会新开一个端口叫做connecting socket进行数据的传输,所以TCP服务器支持n个客户端同时连接就会有n+1个socket,而UDP没有wecoming socket仅仅需要一个套接字．\n\n**27.在章节2.7中的客户－服务端应用程序中，TCP连接为什么服务端一定要在客户端之前先启动，而UDP相反，必须服务端先在客户端之前启动．**<br>\n答:因为TCP在传输数据之前必须进行三次握手，而UDP可以直接传输数据\n","slug":"chapter2-Homework-problems-and-Questions","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4sa0010r8s86q91dy1j","content":"<p>下面提到的的文档都收藏在 <a href=\"https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中\">https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中</a><br></p>\n<p>课本是：computer network a top-down approach<br></p>\n<p><strong>1.列出5个(非专有)的互联网应用，并说明他们使用的应用层协议</strong><br><br><em>查过一些资料，好像有一个技术叫做Deep packet inspection (DPI)可以查到软件使用的协议，github上也有一个开源软件nDPI，还有一个软件叫做wireshark,但是因为有点复杂，我现在暂且不深入研究，下面答案都来着互联网</em></p>\n<ul>\n<li>1 . Chrome (谷歌浏览器貌似不是开源的．．．,不管了用的最多,下面答案来自stackoverflow)<br><br>  in term of what protocol you can use in the chrome browser bar you can use: HTTP,HTTPS,FILE and FTP.SSH is not implemented by chrome,but rather it implements SSL, it also does nit implement SMTP,but rather when you visiting a website(via HTTP or hopefully HTTPS).That website is not at all connecting to an SMTP server to display you you emails, but is merely serving up web pages and conneting to API’s to display/edit/compose your email (by then which the email client’s backend is connected to their SMTP server).<br><br>Also chrome does implement FTP,like you can visit an IP address that has FTP enable such as : ftp://123.34.45.890 and you can use the directory listings as a webpage. An example of this would the CentOS mirrors <a href=\"https://www.centos.org/download/mirrors/\">here</a>.on the right column they have FTP sites. You can access the FIP director via web browser that supports FTP or you can fire up a terminal and do ftp ftp://ftp.is.co.za/mirror/centos/.<br></li>\n<li>2 .  网易云音乐<br><br>在应用层使用的是HTTP协议</li>\n<li>3 . 微信<br><br>微信是应用层是使用HTTP协议（来源是: 利用Wireshark软件对微信协议的分析——QPIC）</li>\n<li>4 . 大部分软件都需要使用DNS协议,例如上面文章有提到微信就需要使用DNS来进行域名解析</li>\n<li>5 . QQ <br><br>应用层使用的是QICQ协议</li>\n</ul>\n<p><strong>2.网络体系结构和应用程序的体系结构有什么不同?</strong></p>\n<ul>\n<li>应用程序体系结构（application architecture）<br></li>\n</ul>\n<ol>\n<li>客户－服务器体系结构（client-servers architecture）<br>答：<br></li>\n<li>P2P（peer to peer）</li>\n<li>混合体系结构 (hybind architecture)</li>\n</ol>\n<ul>\n<li>网络体系结构(network architecture)</li>\n</ul>\n<ol>\n<li>应用层(application layer)</li>\n<li>传输层(transport layer)</li>\n<li>网络层(network layer)</li>\n<li>链路层(link layer)</li>\n<li>物理层(physical layer)</li>\n</ol>\n<p>所以有什么不同呢？<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Network architecture</th>\n<th style=\"text-align:center\">Application architecture</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Network architecture refers to the organization of the communication process into layers.</td>\n<td style=\"text-align:center\">Application architecture, on the other hand, is designed by an application developer and dictates the broad structure of the application.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">How any network of any local area or wide area is built is  called the Network Architecture.</td>\n<td style=\"text-align:center\">How any application is built is called the application architecture</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Example -  The five-layer Internet architecture, Servers.</td>\n<td style=\"text-align:center\">Example - Client-server or P2P.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>(来源是：<a href=\"http://computer-science-solutions.blogspot.com/2017/05/what-is-difference-between-network.html\">What is the difference between network architecture and application architecture?</a>)<br><br>我感觉这个比较没有意义啊，要比较也是P2P和client-servers architecture之间有什么不同吧．．<br></p>\n<p><strong>3. 在两个进程的通信会话中哪个进程是客户端，那个进程是服务端</strong><br><br>答：In the context of communication session between a pair of process,the process that initiates the communication session is labeled as client and the process that wait to be contacted is labeled as server.(来自课本) <br></p>\n<p><strong>4.对于P2P的协议你是否同意在通信会话时没有客户端－服务端的概念，请说明理由</strong><br><br>答：不同意，P2P协议也存在客户端－服务端的概念，但是与client-servers架构稍有不同的是，P2P中的peer即当客户端也当服务端，当peer接受数据的时候为客户端，上传数据的时候就是服务端，上传下载也可以同时进行,此时peer即是客户端，也是服务端.<br></p>\n<p><strong>5.一个运行在源主机的进程如何识别确认运行的目标主机和运行在目标主机上的进程</strong><br><br>答：通过目标主机的IP地址可以确认目标主机，通过目标主机程序占用的套接字端口号可以确认目标主机程序<br></p>\n<p><strong>6.假如你想做一个交易(do a transation)从远端的客户端到服务端，要求尽可能的快，你会选择用TCP还是UDP,说明理由</strong><br><br>答：我会选择UDP,因为UDP只需要一次RTT（round-trip-time），而TCP至少两次RTT,所以用UDP更快<br></p>\n<ul>\n<li><strong>TCP:</strong><br><img src=\"TCP-handshake.png\" alt=\"TCP-handshake\"></li>\n</ul>\n<p><strong>7.课本2.4提及到的应用程序都是no data loss and timing(没有数据丢失，以及不规定时间的)能不能构想一个应用程序要求没有数据丢失并且对时间有很高的敏感性</strong><br><br>答：网络游戏．<br></p>\n<p><strong>8.列出传输层协议能提供的４类服务，对于每项服务指出是由TCP还是UDP(或者两者都可以)提供</strong><br><br>答：We have organized transfer protocol services along four dismensions : <strong>reliable date transfer</strong>,<strong>throughput</strong>,<strong>timing</strong>,<strong>security</strong>(来自课本)<br></p>\n<ul>\n<li>reliable data transfer : TCP do,UDP not.</li>\n<li>throughput: TCP have congestion-control mechanism,UDP not.</li>\n<li>timing :Neither TCP nor UDP.</li>\n<li>security: Neither TCP nor UDP.<br><br><strong>9.TCP可以增强为SSL(Secure Socket Layer)去提供进程之间的安全服务，例如加密，SSL的操作是在传输层还是在应用层，如果软件开发者想要将TCP增强为SSL，他应该怎么做．</strong><br></li>\n</ul>\n<p>答：We emphasize that SSL is not a third internet transport protocol, on the same level as TCP and UDP but instead is an enhancement of TCP, with the emhancement being implemented in the application layer,In particular, if an application wants to use the services of SSL, it needs to include SSL code(exiting highly optimized libraries and classes) in both the client and server side of the application.  SSL has its own socket API that is similar to the trandition of TCP socket API, When an application uses SSL, the sending process passes cleartext data to the SSL socket; SSL in the sending host then encrypts the data and passes the encrypted data to the TCP socket; The encrypted data travels over the internet to the TCP socket in the receiving process. The receiving socket passes the encrypted data to SSL,which decrypts the data. Finally.SSL passes the cleartext data through its SSL socket to receiving process.(来自课本)<br></p>\n<p><strong>10. 什么是握手协议？</strong><br><br>答:握手协议就是两端在首次建立TCP链接时互相发送的三次消息,如第六题的图．<br></p>\n<p><strong>11.为什么HTTP,FTP,SMTP,POP3,都是基于TCP,而不是UDP</strong><br><br>答：因为上面这些协议都需要得到的数据都是按照顺序，TCP可以提供这个功能而UDP不行<br></p>\n<p><strong>12.想象电子商务网站想要保持每一个用户的购买记录，描述用用cookie怎么做到</strong><br><br>答：当你首次访问网站时，网站会给你创建一个独一无二的ID(cookie码),这个码会存放在你的浏览器中，也会存放在网站的后台数据库中，网站会把你选择的商品存入你cookie码的相应存储中，当你下次访问相同网站的时候，你发出的请求会夹带相应的cookie码，这时网站数据库就能匹配到你，从而展现你的购买记录．<br></p>\n<p><strong>13.描述Web缓存怎么降低接收请求对象的延迟，Web缓存是能降低所以请求对象的延迟还是仅仅降低部分请求对象的延迟，为什么？</strong><br><br>答：Web缓存是在大学，企业，ISP 之类的在局域网中建立一个基础设施，用来存储最近局域网内用户访问过的网站，当在短时间内，用户再次访问该网站，Web缓存就可以在直接返回数据给用户，而不用请求网站的服务器，从而降低延迟,<strong>Web缓存是可以降低所有请求对象的延迟的，因为有缓存的存在，降低了局域网向外部互联网的请求流量，所以降低了所有请求对象的延迟．</strong><br></p>\n<p><strong>14. Telnet一个Web服务器然后发生一些请求指令标题行要包括<code>If-modified-since:</code>去让强制服务器响应<code>304 Not Modified</code>status code.消息</strong><br><br>答：下面是google的答案，但是我对www.baidu.com照做得到的200,没办法得到304，所以…<br><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\">“telnet” <span class=\"hljs-keyword\">command</span>:<br><br> It is <span class=\"hljs-keyword\">a</span> <span class=\"hljs-keyword\">command</span> <span class=\"hljs-title\">used</span> <span class=\"hljs-title\">in</span> <span class=\"hljs-title\">windows</span> (<span class=\"hljs-title\">also</span> <span class=\"hljs-title\">in</span> <span class=\"hljs-title\">linux</span>) <span class=\"hljs-title\">to</span> <span class=\"hljs-title\">connect</span> <span class=\"hljs-title\">to</span> <span class=\"hljs-title\">the</span> <span class=\"hljs-title\">web</span> <span class=\"hljs-title\">server</span>.<br>The server responds <span class=\"hljs-built_in\">to</span> <span class=\"hljs-keyword\">the</span> HTTP GET requests.<br>It reply <span class=\"hljs-built_in\">to</span> <span class=\"hljs-keyword\">the</span> client <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">the</span> requested information.<br><br>Command <span class=\"hljs-built_in\">to</span> <span class=\"hljs-built_in\">open</span> <span class=\"hljs-keyword\">the</span> connection <span class=\"hljs-keyword\">with</span> web server:<br><br>        telnet &lt;domain name <span class=\"hljs-keyword\">of</span> web server&gt; &lt;port <span class=\"hljs-built_in\">number</span>&gt;<br><br> example: telnet www.sr2jr.com <span class=\"hljs-number\">23</span><br><br>After establishing <span class=\"hljs-keyword\">the</span> connection <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">the</span> web server<br><span class=\"hljs-keyword\">it</span> is possible <span class=\"hljs-built_in\">to</span> request <span class=\"hljs-keyword\">a</span> specified page <span class=\"hljs-built_in\">from</span> <span class=\"hljs-keyword\">the</span> web server.<br><br>Command <span class=\"hljs-built_in\">to</span> request <span class=\"hljs-keyword\">the</span> page web server:<br><br>        GET &lt;page name&gt; HTTP/<span class=\"hljs-number\">1.0</span><br><br>If <span class=\"hljs-keyword\">the</span> page is available <span class=\"hljs-keyword\">then</span> <span class=\"hljs-keyword\">the</span> server sends <span class=\"hljs-keyword\">the</span> page details.<br>It <span class=\"hljs-built_in\">include</span> <span class=\"hljs-keyword\">the</span> “If-modified-since” message <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">the</span> <span class=\"hljs-number\">304</span> Not Modified<br>status code <span class=\"hljs-keyword\">in</span> <span class=\"hljs-keyword\">the</span> response.<br></code></pre></td></tr></table></figure><br><strong>15.为什么说FTP发送带外控制信息.</strong><br><br>答：因为FTP（文件传输协议）会建立两个TCP连接（端口为20,21），一个是用来传输文件数据(20)，一个是用来传输控制信息(21)，因为FTP协议传输控制信息是用额外的一个连接传送，而不是文件传输的连接所以叫做带外(out-of-band)<br></p>\n<p><strong>16.假设Alice用基于Web的e-mail的站帐户例如（Hotmail 和 gmail)发送文件给Bob.Bob访问其邮箱服务器用POP3协议，描述消息是怎么从Alice发送到Bob这边，明确的表示出发送途中使用的应用层协议．</strong><br><br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">graph LR<br>id1(Alice)==<span class=\"hljs-attribute\">HTTP</span>==&gt;id2(Web<span class=\"hljs-built_in\"> e-mail </span>server)<br>==<span class=\"hljs-attribute\">SMTP</span>==&gt;id3(Bob&#x27;s mail server)==<span class=\"hljs-attribute\">POP3</span>==&gt;id4(Bob)<br></code></pre></td></tr></table></figure><br><strong>17.打印出你最近收到的邮件的标题(header of e-mail),一共有多少行，分析每一行的的作用.</strong><br><br>答：</p>\n<ul>\n<li><strong>Message header:</strong><br><img src=\"Messagesheader.png\" alt=\"messageheader\"><br><br>分析：Messageld,Created at,From,To,Subject字段就不说了．<br><br>SPF: sender policy framework (发送方策略架构)是一直email的认证协议，主要用来检测伪造的email地址．<br><br>DKIM: Domain Key Identify Mail(域密钥识别邮件),允许接受者通过数字签名去检查是否发件人的域名是否真正发生和认证过该邮件．<br><br>DMARC: Domain Message Authentication,Reporting and Comformance,是一种email的认证协议，用来保护邮件域名所有者的邮件域名免受未授权使用．<br></li>\n</ul>\n<p><strong>18.从用户的角度，阐述一下POP3的download-and-delete-mode和download-and-keep-mode的不同之处.</strong><br><br>答:不同之处就在于download-and-delete-mode下载完了就删除，当换一个设备(终端)再次访问的时候，就无法看到删除的消息了，这样消息的移动性就很差．<br>而download-and-keep-mode下载然后保留，当换一个设备再次登录邮箱服务器下载时，还可以看到，消息的移动性很好.<br></p>\n<p><strong>19.是否可能组织的Web server 和mail server有相同的主机别名,如果可能，mail server的RR类型是什么？</strong><br><br>答:可以做到，mail server的类型是MX(Mail Exchange Record).<br></p>\n<p><strong>20.是否可能根据邮件的头部信息地址(例如什么.edu)中确定信息发送的IP地址．对Gmail做同样的操作．</strong><br><br>答：You should be able to see the sender’s IP address for a user with an .edu email address. But you will not be able to see the sender’s IP address if the user uses a gmail account．</p>\n<p><strong>21.在BitTorrent中假设Alicer在30秒中始终提供块给Bob,Bob是否有必要在这30秒内同样给Alice提供块呢?请说明理由</strong><br><br>答:没有必要，因为在BitTorrent中，没30秒选出一个而外的peer给其发送块是为了帮助新进入的peer以后可以有块去交易，当然如果Alice是Bob的top four neighboring 的话Bob也会给Alice发送块．</p>\n<p><strong>22.思考一下，如果一个新进入的peer Alice，没有任何块，所以她不能成为邻居peer的Top four neighboring peer，也没有块可以上传，所以他是怎么样得到她的首块的呢?</strong><br><br>答:这道题其实21题时已经回答了，在BitTorrent中其他有块的peer每30秒就会选出一个幸运peer(optimistically unchocked)然后给其发送块，所以Alice有可能被选中然后就可以得到第一个块</p>\n<p><strong>23.什么是覆盖网络(overlay network),它是否包括路由，它的网络边缘是什么.</strong><br><br>答:覆盖网络就是在P2P文件分享中两个peer的一种逻辑链接，即不是真实的在物理上的连接，它不包括路由，网络的边缘就每个peer.</p>\n<p><strong>24.描述一下every peer keep tracks all peer 的DHT结构的优缺点，和circular DHT (no shortcut)的优点和缺点．</strong><br><br>答:</p>\n<ul>\n<li>Every peer keep tracks all peer 这种结构的优点就是你可以马上就知道你需要的东西的位置，但是缺点就是当peer量巨大的时候，每个peer都存储其他peer的踪迹实在是太耗存储资源了，而且很难维护．</li>\n<li>circular DHT(no shortcut)的优点就是它只需要记住两个peer就可以了，缺点就是peer数量N巨大的时候，peer的询问请求的平均时间是N/2.</li>\n</ul>\n<p><strong>25.列出至少4个不同的适合使用p2p架构的应用程序.</strong><br>答:文件分发，即时信息，视频流，分布式计算</p>\n<p><strong>26.在章节2.7的描述中UDP服务器仅仅需要一个套接字，而TCP服务器需要两个套接字，为什么，如果TCP服务器支持n个用户同时连接，每个用户来自不同的客户端主机，TCP服务器需要的多少个套接字.</strong><br><br>答:在TCP服务器一端有一个wecoming socket,用来进行握手协议的,握手协议结束后TCP会新开一个端口叫做connecting socket进行数据的传输,所以TCP服务器支持n个客户端同时连接就会有n+1个socket,而UDP没有wecoming socket仅仅需要一个套接字．</p>\n<p><strong>27.在章节2.7中的客户－服务端应用程序中，TCP连接为什么服务端一定要在客户端之前先启动，而UDP相反，必须服务端先在客户端之前启动．</strong><br><br>答:因为TCP在传输数据之前必须进行三次握手，而UDP可以直接传输数据</p>\n","site":{"data":{}},"excerpt":"","more":"<p>下面提到的的文档都收藏在 <a href=\"https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中\">https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中</a><br></p>\n<p>课本是：computer network a top-down approach<br></p>\n<p><strong>1.列出5个(非专有)的互联网应用，并说明他们使用的应用层协议</strong><br><br><em>查过一些资料，好像有一个技术叫做Deep packet inspection (DPI)可以查到软件使用的协议，github上也有一个开源软件nDPI，还有一个软件叫做wireshark,但是因为有点复杂，我现在暂且不深入研究，下面答案都来着互联网</em></p>\n<ul>\n<li>1 . Chrome (谷歌浏览器貌似不是开源的．．．,不管了用的最多,下面答案来自stackoverflow)<br><br>  in term of what protocol you can use in the chrome browser bar you can use: HTTP,HTTPS,FILE and FTP.SSH is not implemented by chrome,but rather it implements SSL, it also does nit implement SMTP,but rather when you visiting a website(via HTTP or hopefully HTTPS).That website is not at all connecting to an SMTP server to display you you emails, but is merely serving up web pages and conneting to API’s to display/edit/compose your email (by then which the email client’s backend is connected to their SMTP server).<br><br>Also chrome does implement FTP,like you can visit an IP address that has FTP enable such as : ftp://123.34.45.890 and you can use the directory listings as a webpage. An example of this would the CentOS mirrors <a href=\"https://www.centos.org/download/mirrors/\">here</a>.on the right column they have FTP sites. You can access the FIP director via web browser that supports FTP or you can fire up a terminal and do ftp ftp://ftp.is.co.za/mirror/centos/.<br></li>\n<li>2 .  网易云音乐<br><br>在应用层使用的是HTTP协议</li>\n<li>3 . 微信<br><br>微信是应用层是使用HTTP协议（来源是: 利用Wireshark软件对微信协议的分析——QPIC）</li>\n<li>4 . 大部分软件都需要使用DNS协议,例如上面文章有提到微信就需要使用DNS来进行域名解析</li>\n<li>5 . QQ <br><br>应用层使用的是QICQ协议</li>\n</ul>\n<p><strong>2.网络体系结构和应用程序的体系结构有什么不同?</strong></p>\n<ul>\n<li>应用程序体系结构（application architecture）<br></li>\n</ul>\n<ol>\n<li>客户－服务器体系结构（client-servers architecture）<br>答：<br></li>\n<li>P2P（peer to peer）</li>\n<li>混合体系结构 (hybind architecture)</li>\n</ol>\n<ul>\n<li>网络体系结构(network architecture)</li>\n</ul>\n<ol>\n<li>应用层(application layer)</li>\n<li>传输层(transport layer)</li>\n<li>网络层(network layer)</li>\n<li>链路层(link layer)</li>\n<li>物理层(physical layer)</li>\n</ol>\n<p>所以有什么不同呢？<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Network architecture</th>\n<th style=\"text-align:center\">Application architecture</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">Network architecture refers to the organization of the communication process into layers.</td>\n<td style=\"text-align:center\">Application architecture, on the other hand, is designed by an application developer and dictates the broad structure of the application.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">How any network of any local area or wide area is built is  called the Network Architecture.</td>\n<td style=\"text-align:center\">How any application is built is called the application architecture</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Example -  The five-layer Internet architecture, Servers.</td>\n<td style=\"text-align:center\">Example - Client-server or P2P.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>(来源是：<a href=\"http://computer-science-solutions.blogspot.com/2017/05/what-is-difference-between-network.html\">What is the difference between network architecture and application architecture?</a>)<br><br>我感觉这个比较没有意义啊，要比较也是P2P和client-servers architecture之间有什么不同吧．．<br></p>\n<p><strong>3. 在两个进程的通信会话中哪个进程是客户端，那个进程是服务端</strong><br><br>答：In the context of communication session between a pair of process,the process that initiates the communication session is labeled as client and the process that wait to be contacted is labeled as server.(来自课本) <br></p>\n<p><strong>4.对于P2P的协议你是否同意在通信会话时没有客户端－服务端的概念，请说明理由</strong><br><br>答：不同意，P2P协议也存在客户端－服务端的概念，但是与client-servers架构稍有不同的是，P2P中的peer即当客户端也当服务端，当peer接受数据的时候为客户端，上传数据的时候就是服务端，上传下载也可以同时进行,此时peer即是客户端，也是服务端.<br></p>\n<p><strong>5.一个运行在源主机的进程如何识别确认运行的目标主机和运行在目标主机上的进程</strong><br><br>答：通过目标主机的IP地址可以确认目标主机，通过目标主机程序占用的套接字端口号可以确认目标主机程序<br></p>\n<p><strong>6.假如你想做一个交易(do a transation)从远端的客户端到服务端，要求尽可能的快，你会选择用TCP还是UDP,说明理由</strong><br><br>答：我会选择UDP,因为UDP只需要一次RTT（round-trip-time），而TCP至少两次RTT,所以用UDP更快<br></p>\n<ul>\n<li><strong>TCP:</strong><br><img src=\"TCP-handshake.png\" alt=\"TCP-handshake\"></li>\n</ul>\n<p><strong>7.课本2.4提及到的应用程序都是no data loss and timing(没有数据丢失，以及不规定时间的)能不能构想一个应用程序要求没有数据丢失并且对时间有很高的敏感性</strong><br><br>答：网络游戏．<br></p>\n<p><strong>8.列出传输层协议能提供的４类服务，对于每项服务指出是由TCP还是UDP(或者两者都可以)提供</strong><br><br>答：We have organized transfer protocol services along four dismensions : <strong>reliable date transfer</strong>,<strong>throughput</strong>,<strong>timing</strong>,<strong>security</strong>(来自课本)<br></p>\n<ul>\n<li>reliable data transfer : TCP do,UDP not.</li>\n<li>throughput: TCP have congestion-control mechanism,UDP not.</li>\n<li>timing :Neither TCP nor UDP.</li>\n<li>security: Neither TCP nor UDP.<br><br><strong>9.TCP可以增强为SSL(Secure Socket Layer)去提供进程之间的安全服务，例如加密，SSL的操作是在传输层还是在应用层，如果软件开发者想要将TCP增强为SSL，他应该怎么做．</strong><br></li>\n</ul>\n<p>答：We emphasize that SSL is not a third internet transport protocol, on the same level as TCP and UDP but instead is an enhancement of TCP, with the emhancement being implemented in the application layer,In particular, if an application wants to use the services of SSL, it needs to include SSL code(exiting highly optimized libraries and classes) in both the client and server side of the application.  SSL has its own socket API that is similar to the trandition of TCP socket API, When an application uses SSL, the sending process passes cleartext data to the SSL socket; SSL in the sending host then encrypts the data and passes the encrypted data to the TCP socket; The encrypted data travels over the internet to the TCP socket in the receiving process. The receiving socket passes the encrypted data to SSL,which decrypts the data. Finally.SSL passes the cleartext data through its SSL socket to receiving process.(来自课本)<br></p>\n<p><strong>10. 什么是握手协议？</strong><br><br>答:握手协议就是两端在首次建立TCP链接时互相发送的三次消息,如第六题的图．<br></p>\n<p><strong>11.为什么HTTP,FTP,SMTP,POP3,都是基于TCP,而不是UDP</strong><br><br>答：因为上面这些协议都需要得到的数据都是按照顺序，TCP可以提供这个功能而UDP不行<br></p>\n<p><strong>12.想象电子商务网站想要保持每一个用户的购买记录，描述用用cookie怎么做到</strong><br><br>答：当你首次访问网站时，网站会给你创建一个独一无二的ID(cookie码),这个码会存放在你的浏览器中，也会存放在网站的后台数据库中，网站会把你选择的商品存入你cookie码的相应存储中，当你下次访问相同网站的时候，你发出的请求会夹带相应的cookie码，这时网站数据库就能匹配到你，从而展现你的购买记录．<br></p>\n<p><strong>13.描述Web缓存怎么降低接收请求对象的延迟，Web缓存是能降低所以请求对象的延迟还是仅仅降低部分请求对象的延迟，为什么？</strong><br><br>答：Web缓存是在大学，企业，ISP 之类的在局域网中建立一个基础设施，用来存储最近局域网内用户访问过的网站，当在短时间内，用户再次访问该网站，Web缓存就可以在直接返回数据给用户，而不用请求网站的服务器，从而降低延迟,<strong>Web缓存是可以降低所有请求对象的延迟的，因为有缓存的存在，降低了局域网向外部互联网的请求流量，所以降低了所有请求对象的延迟．</strong><br></p>\n<p><strong>14. Telnet一个Web服务器然后发生一些请求指令标题行要包括<code>If-modified-since:</code>去让强制服务器响应<code>304 Not Modified</code>status code.消息</strong><br><br>答：下面是google的答案，但是我对www.baidu.com照做得到的200,没办法得到304，所以…<br><figure class=\"highlight livecodeserver\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs livecodeserver\">“telnet” <span class=\"hljs-keyword\">command</span>:<br><br> It is <span class=\"hljs-keyword\">a</span> <span class=\"hljs-keyword\">command</span> <span class=\"hljs-title\">used</span> <span class=\"hljs-title\">in</span> <span class=\"hljs-title\">windows</span> (<span class=\"hljs-title\">also</span> <span class=\"hljs-title\">in</span> <span class=\"hljs-title\">linux</span>) <span class=\"hljs-title\">to</span> <span class=\"hljs-title\">connect</span> <span class=\"hljs-title\">to</span> <span class=\"hljs-title\">the</span> <span class=\"hljs-title\">web</span> <span class=\"hljs-title\">server</span>.<br>The server responds <span class=\"hljs-built_in\">to</span> <span class=\"hljs-keyword\">the</span> HTTP GET requests.<br>It reply <span class=\"hljs-built_in\">to</span> <span class=\"hljs-keyword\">the</span> client <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">the</span> requested information.<br><br>Command <span class=\"hljs-built_in\">to</span> <span class=\"hljs-built_in\">open</span> <span class=\"hljs-keyword\">the</span> connection <span class=\"hljs-keyword\">with</span> web server:<br><br>        telnet &lt;domain name <span class=\"hljs-keyword\">of</span> web server&gt; &lt;port <span class=\"hljs-built_in\">number</span>&gt;<br><br> example: telnet www.sr2jr.com <span class=\"hljs-number\">23</span><br><br>After establishing <span class=\"hljs-keyword\">the</span> connection <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">the</span> web server<br><span class=\"hljs-keyword\">it</span> is possible <span class=\"hljs-built_in\">to</span> request <span class=\"hljs-keyword\">a</span> specified page <span class=\"hljs-built_in\">from</span> <span class=\"hljs-keyword\">the</span> web server.<br><br>Command <span class=\"hljs-built_in\">to</span> request <span class=\"hljs-keyword\">the</span> page web server:<br><br>        GET &lt;page name&gt; HTTP/<span class=\"hljs-number\">1.0</span><br><br>If <span class=\"hljs-keyword\">the</span> page is available <span class=\"hljs-keyword\">then</span> <span class=\"hljs-keyword\">the</span> server sends <span class=\"hljs-keyword\">the</span> page details.<br>It <span class=\"hljs-built_in\">include</span> <span class=\"hljs-keyword\">the</span> “If-modified-since” message <span class=\"hljs-keyword\">with</span> <span class=\"hljs-keyword\">the</span> <span class=\"hljs-number\">304</span> Not Modified<br>status code <span class=\"hljs-keyword\">in</span> <span class=\"hljs-keyword\">the</span> response.<br></code></pre></td></tr></table></figure><br><strong>15.为什么说FTP发送带外控制信息.</strong><br><br>答：因为FTP（文件传输协议）会建立两个TCP连接（端口为20,21），一个是用来传输文件数据(20)，一个是用来传输控制信息(21)，因为FTP协议传输控制信息是用额外的一个连接传送，而不是文件传输的连接所以叫做带外(out-of-band)<br></p>\n<p><strong>16.假设Alice用基于Web的e-mail的站帐户例如（Hotmail 和 gmail)发送文件给Bob.Bob访问其邮箱服务器用POP3协议，描述消息是怎么从Alice发送到Bob这边，明确的表示出发送途中使用的应用层协议．</strong><br><br><figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">graph LR<br>id1(Alice)==<span class=\"hljs-attribute\">HTTP</span>==&gt;id2(Web<span class=\"hljs-built_in\"> e-mail </span>server)<br>==<span class=\"hljs-attribute\">SMTP</span>==&gt;id3(Bob&#x27;s mail server)==<span class=\"hljs-attribute\">POP3</span>==&gt;id4(Bob)<br></code></pre></td></tr></table></figure><br><strong>17.打印出你最近收到的邮件的标题(header of e-mail),一共有多少行，分析每一行的的作用.</strong><br><br>答：</p>\n<ul>\n<li><strong>Message header:</strong><br><img src=\"Messagesheader.png\" alt=\"messageheader\"><br><br>分析：Messageld,Created at,From,To,Subject字段就不说了．<br><br>SPF: sender policy framework (发送方策略架构)是一直email的认证协议，主要用来检测伪造的email地址．<br><br>DKIM: Domain Key Identify Mail(域密钥识别邮件),允许接受者通过数字签名去检查是否发件人的域名是否真正发生和认证过该邮件．<br><br>DMARC: Domain Message Authentication,Reporting and Comformance,是一种email的认证协议，用来保护邮件域名所有者的邮件域名免受未授权使用．<br></li>\n</ul>\n<p><strong>18.从用户的角度，阐述一下POP3的download-and-delete-mode和download-and-keep-mode的不同之处.</strong><br><br>答:不同之处就在于download-and-delete-mode下载完了就删除，当换一个设备(终端)再次访问的时候，就无法看到删除的消息了，这样消息的移动性就很差．<br>而download-and-keep-mode下载然后保留，当换一个设备再次登录邮箱服务器下载时，还可以看到，消息的移动性很好.<br></p>\n<p><strong>19.是否可能组织的Web server 和mail server有相同的主机别名,如果可能，mail server的RR类型是什么？</strong><br><br>答:可以做到，mail server的类型是MX(Mail Exchange Record).<br></p>\n<p><strong>20.是否可能根据邮件的头部信息地址(例如什么.edu)中确定信息发送的IP地址．对Gmail做同样的操作．</strong><br><br>答：You should be able to see the sender’s IP address for a user with an .edu email address. But you will not be able to see the sender’s IP address if the user uses a gmail account．</p>\n<p><strong>21.在BitTorrent中假设Alicer在30秒中始终提供块给Bob,Bob是否有必要在这30秒内同样给Alice提供块呢?请说明理由</strong><br><br>答:没有必要，因为在BitTorrent中，没30秒选出一个而外的peer给其发送块是为了帮助新进入的peer以后可以有块去交易，当然如果Alice是Bob的top four neighboring 的话Bob也会给Alice发送块．</p>\n<p><strong>22.思考一下，如果一个新进入的peer Alice，没有任何块，所以她不能成为邻居peer的Top four neighboring peer，也没有块可以上传，所以他是怎么样得到她的首块的呢?</strong><br><br>答:这道题其实21题时已经回答了，在BitTorrent中其他有块的peer每30秒就会选出一个幸运peer(optimistically unchocked)然后给其发送块，所以Alice有可能被选中然后就可以得到第一个块</p>\n<p><strong>23.什么是覆盖网络(overlay network),它是否包括路由，它的网络边缘是什么.</strong><br><br>答:覆盖网络就是在P2P文件分享中两个peer的一种逻辑链接，即不是真实的在物理上的连接，它不包括路由，网络的边缘就每个peer.</p>\n<p><strong>24.描述一下every peer keep tracks all peer 的DHT结构的优缺点，和circular DHT (no shortcut)的优点和缺点．</strong><br><br>答:</p>\n<ul>\n<li>Every peer keep tracks all peer 这种结构的优点就是你可以马上就知道你需要的东西的位置，但是缺点就是当peer量巨大的时候，每个peer都存储其他peer的踪迹实在是太耗存储资源了，而且很难维护．</li>\n<li>circular DHT(no shortcut)的优点就是它只需要记住两个peer就可以了，缺点就是peer数量N巨大的时候，peer的询问请求的平均时间是N/2.</li>\n</ul>\n<p><strong>25.列出至少4个不同的适合使用p2p架构的应用程序.</strong><br>答:文件分发，即时信息，视频流，分布式计算</p>\n<p><strong>26.在章节2.7的描述中UDP服务器仅仅需要一个套接字，而TCP服务器需要两个套接字，为什么，如果TCP服务器支持n个用户同时连接，每个用户来自不同的客户端主机，TCP服务器需要的多少个套接字.</strong><br><br>答:在TCP服务器一端有一个wecoming socket,用来进行握手协议的,握手协议结束后TCP会新开一个端口叫做connecting socket进行数据的传输,所以TCP服务器支持n个客户端同时连接就会有n+1个socket,而UDP没有wecoming socket仅仅需要一个套接字．</p>\n<p><strong>27.在章节2.7中的客户－服务端应用程序中，TCP连接为什么服务端一定要在客户端之前先启动，而UDP相反，必须服务端先在客户端之前启动．</strong><br><br>答:因为TCP在传输数据之前必须进行三次握手，而UDP可以直接传输数据</p>\n"},{"title":"二元组和图形描述逻辑结构","date":"2020-03-20T05:56:16.000Z","index_img":"/Picture/wallhaven-q6q2e5.jpg","_content":"\n# 数据结构\n**数据结构分为：数据的逻辑结构和数据的存储结构**<br>\n逻辑结构:集合，线性结构，树状结构，图形结构.即线性表，栈，队列，树，图等逻辑结构.其中线性表，栈，队列为线性结构，树，图为非线性结构．<br>\n\n1.集合结构：数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系<br>\n2.线性结构：数据结构中的元素存在一对一的相互关系 <br>\n3.树形结构：数据结构中的元素存在一对多的相互关系<br>\n4.图形结构：数据结构中的元素存在多对多的相互关系<br>\n\n**存储结构：分为顺序存储和链式存储**<br>\n*逻辑结构和存储结构之间没有关系，只是抽象出来的数学模型方便理解*\n\n##  描述逻辑结构的两种方法：<br>\n\n**1. 二元组 DS=(D,S)** <br>\n其中D是数据元素的集合，S是数据元素之间的关系集合，并且数据元素之间的关系是使用序偶来表示．<br>\n序偶：是由两个元素x和y按一定的顺序排列而成的二元组，记作<x,y> ,x是它的第一元素，y是它的第二元素．　<br>\n\n\n**2.用图形来表示**<br>\n\n就是画图．．．\n\n## 分别用两种表示方法来逻辑结构 \n<1>.<br>\n\n如果D =!null, S =null,表明DS是**集合结构**，元素相互之间没有关系．<br>\n如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5)},表明DS是**线性结构**，元素相互之间存在一对一的关系<br>\n\n如果D = {0,1,2,3,4,5}, S = {(0,1),(0,3),(1,2),(1,6)},表明DS是**树状结构**，元素相互之间存在一对多的关系<br>\n\n如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5),(3,2),(3,1),(5,4),(2,4),(4,2)},表明DS是**图结构**，元素相互之间存在多对多的关系<br>\n\n**其实只要懂得根据元素的对应关系S画图，就可以知道，相应的逻辑结构是什么了**\n\n<2>. <br>\n\n![逻辑结构图像表示](870358-20160102224630526-1483051229.jpg)\n","source":"_posts/二元组和图形描述逻辑结构.md","raw":"---\ntitle: 二元组和图形描述逻辑结构\ndate: 2020-03-20 13:56:16\nindex_img: /Picture/wallhaven-q6q2e5.jpg\ncategories:\n- 数据结构\ntags:\n- 数据结构\n---\n\n# 数据结构\n**数据结构分为：数据的逻辑结构和数据的存储结构**<br>\n逻辑结构:集合，线性结构，树状结构，图形结构.即线性表，栈，队列，树，图等逻辑结构.其中线性表，栈，队列为线性结构，树，图为非线性结构．<br>\n\n1.集合结构：数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系<br>\n2.线性结构：数据结构中的元素存在一对一的相互关系 <br>\n3.树形结构：数据结构中的元素存在一对多的相互关系<br>\n4.图形结构：数据结构中的元素存在多对多的相互关系<br>\n\n**存储结构：分为顺序存储和链式存储**<br>\n*逻辑结构和存储结构之间没有关系，只是抽象出来的数学模型方便理解*\n\n##  描述逻辑结构的两种方法：<br>\n\n**1. 二元组 DS=(D,S)** <br>\n其中D是数据元素的集合，S是数据元素之间的关系集合，并且数据元素之间的关系是使用序偶来表示．<br>\n序偶：是由两个元素x和y按一定的顺序排列而成的二元组，记作<x,y> ,x是它的第一元素，y是它的第二元素．　<br>\n\n\n**2.用图形来表示**<br>\n\n就是画图．．．\n\n## 分别用两种表示方法来逻辑结构 \n<1>.<br>\n\n如果D =!null, S =null,表明DS是**集合结构**，元素相互之间没有关系．<br>\n如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5)},表明DS是**线性结构**，元素相互之间存在一对一的关系<br>\n\n如果D = {0,1,2,3,4,5}, S = {(0,1),(0,3),(1,2),(1,6)},表明DS是**树状结构**，元素相互之间存在一对多的关系<br>\n\n如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5),(3,2),(3,1),(5,4),(2,4),(4,2)},表明DS是**图结构**，元素相互之间存在多对多的关系<br>\n\n**其实只要懂得根据元素的对应关系S画图，就可以知道，相应的逻辑结构是什么了**\n\n<2>. <br>\n\n![逻辑结构图像表示](870358-20160102224630526-1483051229.jpg)\n","slug":"二元组和图形描述逻辑结构","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4sb0012r8s81jek38a2","content":"<h1 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h1><p><strong>数据结构分为：数据的逻辑结构和数据的存储结构</strong><br><br>逻辑结构:集合，线性结构，树状结构，图形结构.即线性表，栈，队列，树，图等逻辑结构.其中线性表，栈，队列为线性结构，树，图为非线性结构．<br></p>\n<p>1.集合结构：数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系<br><br>2.线性结构：数据结构中的元素存在一对一的相互关系 <br><br>3.树形结构：数据结构中的元素存在一对多的相互关系<br><br>4.图形结构：数据结构中的元素存在多对多的相互关系<br></p>\n<p><strong>存储结构：分为顺序存储和链式存储</strong><br><br><em>逻辑结构和存储结构之间没有关系，只是抽象出来的数学模型方便理解</em></p>\n<h2 id=\"描述逻辑结构的两种方法：\"><a href=\"#描述逻辑结构的两种方法：\" class=\"headerlink\" title=\"描述逻辑结构的两种方法：\"></a>描述逻辑结构的两种方法：<br></h2><p><strong>1. 二元组 DS=(D,S)</strong> <br><br>其中D是数据元素的集合，S是数据元素之间的关系集合，并且数据元素之间的关系是使用序偶来表示．<br><br>序偶：是由两个元素x和y按一定的顺序排列而成的二元组，记作<x,y> ,x是它的第一元素，y是它的第二元素．　<br></p>\n<p><strong>2.用图形来表示</strong><br></p>\n<p>就是画图．．．</p>\n<h2 id=\"分别用两种表示方法来逻辑结构\"><a href=\"#分别用两种表示方法来逻辑结构\" class=\"headerlink\" title=\"分别用两种表示方法来逻辑结构\"></a>分别用两种表示方法来逻辑结构</h2><p><1>.<br></p>\n<p>如果D =!null, S =null,表明DS是<strong>集合结构</strong>，元素相互之间没有关系．<br><br>如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5)},表明DS是<strong>线性结构</strong>，元素相互之间存在一对一的关系<br></p>\n<p>如果D = {0,1,2,3,4,5}, S = {(0,1),(0,3),(1,2),(1,6)},表明DS是<strong>树状结构</strong>，元素相互之间存在一对多的关系<br></p>\n<p>如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5),(3,2),(3,1),(5,4),(2,4),(4,2)},表明DS是<strong>图结构</strong>，元素相互之间存在多对多的关系<br></p>\n<p><strong>其实只要懂得根据元素的对应关系S画图，就可以知道，相应的逻辑结构是什么了</strong></p>\n<p><2>. <br></p>\n<p><img src=\"870358-20160102224630526-1483051229.jpg\" alt=\"逻辑结构图像表示\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h1><p><strong>数据结构分为：数据的逻辑结构和数据的存储结构</strong><br><br>逻辑结构:集合，线性结构，树状结构，图形结构.即线性表，栈，队列，树，图等逻辑结构.其中线性表，栈，队列为线性结构，树，图为非线性结构．<br></p>\n<p>1.集合结构：数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系<br><br>2.线性结构：数据结构中的元素存在一对一的相互关系 <br><br>3.树形结构：数据结构中的元素存在一对多的相互关系<br><br>4.图形结构：数据结构中的元素存在多对多的相互关系<br></p>\n<p><strong>存储结构：分为顺序存储和链式存储</strong><br><br><em>逻辑结构和存储结构之间没有关系，只是抽象出来的数学模型方便理解</em></p>\n<h2 id=\"描述逻辑结构的两种方法：\"><a href=\"#描述逻辑结构的两种方法：\" class=\"headerlink\" title=\"描述逻辑结构的两种方法：\"></a>描述逻辑结构的两种方法：<br></h2><p><strong>1. 二元组 DS=(D,S)</strong> <br><br>其中D是数据元素的集合，S是数据元素之间的关系集合，并且数据元素之间的关系是使用序偶来表示．<br><br>序偶：是由两个元素x和y按一定的顺序排列而成的二元组，记作<x,y> ,x是它的第一元素，y是它的第二元素．　<br></p>\n<p><strong>2.用图形来表示</strong><br></p>\n<p>就是画图．．．</p>\n<h2 id=\"分别用两种表示方法来逻辑结构\"><a href=\"#分别用两种表示方法来逻辑结构\" class=\"headerlink\" title=\"分别用两种表示方法来逻辑结构\"></a>分别用两种表示方法来逻辑结构</h2><p><1>.<br></p>\n<p>如果D =!null, S =null,表明DS是<strong>集合结构</strong>，元素相互之间没有关系．<br><br>如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5)},表明DS是<strong>线性结构</strong>，元素相互之间存在一对一的关系<br></p>\n<p>如果D = {0,1,2,3,4,5}, S = {(0,1),(0,3),(1,2),(1,6)},表明DS是<strong>树状结构</strong>，元素相互之间存在一对多的关系<br></p>\n<p>如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5),(3,2),(3,1),(5,4),(2,4),(4,2)},表明DS是<strong>图结构</strong>，元素相互之间存在多对多的关系<br></p>\n<p><strong>其实只要懂得根据元素的对应关系S画图，就可以知道，相应的逻辑结构是什么了</strong></p>\n<p><2>. <br></p>\n<p><img src=\"870358-20160102224630526-1483051229.jpg\" alt=\"逻辑结构图像表示\"></p>\n"},{"title":"关于汇编中EFLAGS寄存器中CF和OF标志位","index_img":"/Picture/EFLAGS.jpg","date":"2020-11-15T02:10:31.000Z","banner_img":null,"_content":"# 前言\n近来在写项目过程中遇到了EFLAGS的OF和CF标志位，这两个功能有点相似，有点搞不清楚，所以去搜索一下，以下的内容是我对回答的粗略的翻译，原回答在此: [about assembly CF(Carry) and OF(Overflow) flag](https://stackoverflow.com/questions/791991/about-assembly-cfcarry-and-ofoverflow-flag)<br>\n\n# 疑问\n我知道CF用来解释无符号数的进位，OF解释有符号数的溢出,所以对于有符号数和无符号数都是一串01序列,汇编程序是如何进行区分(differntiate)的？(通过用额外的存储空间记录类型信息?或是通过位置信息？) 还有就是OF和CF两个标志位能否互换(interchangeably)来使用.<br>\n\n# 回答\n\n**有符号数和无符号数的区别在于用什么指令来操作数据，而非数据本身** , 现代计算机(自1970以来)用补码来表示整型数据，所以有符号数和无符号数的加法和减法的其实操作是一样的<br>\n- 有符号数和无符号数的不同关键在于如何对最高有效位 (sign bit) 解释，对于有符号数sign bit 用来代表正负(0代表正,1代表负),无符号数则正常计算。\n \n- 不同的指令可能对同一个bit的解释不同。\n \n- **OF(overflow flag)标志位告诉进位是否将结果最高有效位的符号翻转，以使其与原变量的最高有效位不同,对于无符号数OF标志位没有意义,但是对于有符号数,OF可以表示两数运算是否有溢出(例如:Positive + Positive = Negative)**\n \n- **CF(carry flag)标志位用来表示计算时是否存在超过算数逻辑单元长度的进位/借位。<br>\n例如:两个8bits的数相加产生超出算数逻辑单元长度的进位,CF被置为1<br>**\n\n|| 11111111 |CF|\n| :---: | :----------: | :---: |\n| +     | 00000001     | 0     |\n| =     | 00000000     | 1     |\n\n**所以对于无符号数来说CF位可以解释为另类的溢出,对于有符号数CF标志位无意义**<br>\n\n","source":"_posts/关于汇编中EFLAGS寄存器中CF和OF标志位.md","raw":"---\ntitle: 关于汇编中EFLAGS寄存器中CF和OF标志位\nindex_img: /Picture/EFLAGS.jpg\ndate: 2020-11-15 10:10:31\ntags:\n- 计算机组成原理\ncategories:\n- 计算机组成原理\nbanner_img:\n---\n# 前言\n近来在写项目过程中遇到了EFLAGS的OF和CF标志位，这两个功能有点相似，有点搞不清楚，所以去搜索一下，以下的内容是我对回答的粗略的翻译，原回答在此: [about assembly CF(Carry) and OF(Overflow) flag](https://stackoverflow.com/questions/791991/about-assembly-cfcarry-and-ofoverflow-flag)<br>\n\n# 疑问\n我知道CF用来解释无符号数的进位，OF解释有符号数的溢出,所以对于有符号数和无符号数都是一串01序列,汇编程序是如何进行区分(differntiate)的？(通过用额外的存储空间记录类型信息?或是通过位置信息？) 还有就是OF和CF两个标志位能否互换(interchangeably)来使用.<br>\n\n# 回答\n\n**有符号数和无符号数的区别在于用什么指令来操作数据，而非数据本身** , 现代计算机(自1970以来)用补码来表示整型数据，所以有符号数和无符号数的加法和减法的其实操作是一样的<br>\n- 有符号数和无符号数的不同关键在于如何对最高有效位 (sign bit) 解释，对于有符号数sign bit 用来代表正负(0代表正,1代表负),无符号数则正常计算。\n \n- 不同的指令可能对同一个bit的解释不同。\n \n- **OF(overflow flag)标志位告诉进位是否将结果最高有效位的符号翻转，以使其与原变量的最高有效位不同,对于无符号数OF标志位没有意义,但是对于有符号数,OF可以表示两数运算是否有溢出(例如:Positive + Positive = Negative)**\n \n- **CF(carry flag)标志位用来表示计算时是否存在超过算数逻辑单元长度的进位/借位。<br>\n例如:两个8bits的数相加产生超出算数逻辑单元长度的进位,CF被置为1<br>**\n\n|| 11111111 |CF|\n| :---: | :----------: | :---: |\n| +     | 00000001     | 0     |\n| =     | 00000000     | 1     |\n\n**所以对于无符号数来说CF位可以解释为另类的溢出,对于有符号数CF标志位无意义**<br>\n\n","slug":"关于汇编中EFLAGS寄存器中CF和OF标志位","published":1,"updated":"2020-11-15T05:32:01.456Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4sc0017r8s873nhgwn0","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>近来在写项目过程中遇到了EFLAGS的OF和CF标志位，这两个功能有点相似，有点搞不清楚，所以去搜索一下，以下的内容是我对回答的粗略的翻译，原回答在此: <a href=\"https://stackoverflow.com/questions/791991/about-assembly-cfcarry-and-ofoverflow-flag\">about assembly CF(Carry) and OF(Overflow) flag</a><br></p>\n<h1 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h1><p>我知道CF用来解释无符号数的进位，OF解释有符号数的溢出,所以对于有符号数和无符号数都是一串01序列,汇编程序是如何进行区分(differntiate)的？(通过用额外的存储空间记录类型信息?或是通过位置信息？) 还有就是OF和CF两个标志位能否互换(interchangeably)来使用.<br></p>\n<h1 id=\"回答\"><a href=\"#回答\" class=\"headerlink\" title=\"回答\"></a>回答</h1><p><strong>有符号数和无符号数的区别在于用什么指令来操作数据，而非数据本身</strong> , 现代计算机(自1970以来)用补码来表示整型数据，所以有符号数和无符号数的加法和减法的其实操作是一样的<br></p>\n<ul>\n<li><p>有符号数和无符号数的不同关键在于如何对最高有效位 (sign bit) 解释，对于有符号数sign bit 用来代表正负(0代表正,1代表负),无符号数则正常计算。</p>\n</li>\n<li><p>不同的指令可能对同一个bit的解释不同。</p>\n</li>\n<li><p><strong>OF(overflow flag)标志位告诉进位是否将结果最高有效位的符号翻转，以使其与原变量的最高有效位不同,对于无符号数OF标志位没有意义,但是对于有符号数,OF可以表示两数运算是否有溢出(例如:Positive + Positive = Negative)</strong></p>\n</li>\n<li><p><strong>CF(carry flag)标志位用来表示计算时是否存在超过算数逻辑单元长度的进位/借位。<br><br>例如:两个8bits的数相加产生超出算数逻辑单元长度的进位,CF被置为1<br></strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">11111111</th>\n<th style=\"text-align:center\">CF</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">+</td>\n<td style=\"text-align:center\">00000001</td>\n<td style=\"text-align:center\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">=</td>\n<td style=\"text-align:center\">00000000</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>所以对于无符号数来说CF位可以解释为另类的溢出,对于有符号数CF标志位无意义</strong><br></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><p>近来在写项目过程中遇到了EFLAGS的OF和CF标志位，这两个功能有点相似，有点搞不清楚，所以去搜索一下，以下的内容是我对回答的粗略的翻译，原回答在此: <a href=\"https://stackoverflow.com/questions/791991/about-assembly-cfcarry-and-ofoverflow-flag\">about assembly CF(Carry) and OF(Overflow) flag</a><br></p>\n<h1 id=\"疑问\"><a href=\"#疑问\" class=\"headerlink\" title=\"疑问\"></a>疑问</h1><p>我知道CF用来解释无符号数的进位，OF解释有符号数的溢出,所以对于有符号数和无符号数都是一串01序列,汇编程序是如何进行区分(differntiate)的？(通过用额外的存储空间记录类型信息?或是通过位置信息？) 还有就是OF和CF两个标志位能否互换(interchangeably)来使用.<br></p>\n<h1 id=\"回答\"><a href=\"#回答\" class=\"headerlink\" title=\"回答\"></a>回答</h1><p><strong>有符号数和无符号数的区别在于用什么指令来操作数据，而非数据本身</strong> , 现代计算机(自1970以来)用补码来表示整型数据，所以有符号数和无符号数的加法和减法的其实操作是一样的<br></p>\n<ul>\n<li><p>有符号数和无符号数的不同关键在于如何对最高有效位 (sign bit) 解释，对于有符号数sign bit 用来代表正负(0代表正,1代表负),无符号数则正常计算。</p>\n</li>\n<li><p>不同的指令可能对同一个bit的解释不同。</p>\n</li>\n<li><p><strong>OF(overflow flag)标志位告诉进位是否将结果最高有效位的符号翻转，以使其与原变量的最高有效位不同,对于无符号数OF标志位没有意义,但是对于有符号数,OF可以表示两数运算是否有溢出(例如:Positive + Positive = Negative)</strong></p>\n</li>\n<li><p><strong>CF(carry flag)标志位用来表示计算时是否存在超过算数逻辑单元长度的进位/借位。<br><br>例如:两个8bits的数相加产生超出算数逻辑单元长度的进位,CF被置为1<br></strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">11111111</th>\n<th style=\"text-align:center\">CF</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">+</td>\n<td style=\"text-align:center\">00000001</td>\n<td style=\"text-align:center\">0</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">=</td>\n<td style=\"text-align:center\">00000000</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>所以对于无符号数来说CF位可以解释为另类的溢出,对于有符号数CF标志位无意义</strong><br></p>\n"},{"title":"对于指针的一些理解","date":"2020-04-20T08:44:24.000Z","index_img":"/Picture/point.png","_content":"在复习数据结构链表那一章时对创建**头指针**然后指向**首元节点**或者**头节点**(两者是不同的东西)的具体实现过程有些许疑问，它们在内存中是怎么工作的呢？<br>\n于是我写了个小程序来验证了一下<br>\n\n```c\n#include<stdio.h>\n#include<stdlib.h>\n\nstruct test\n{\n\tstruct test* next;\n\tint data;\n};\n\nint main ()\n{\n\tstruct test* temp=NULL ;\n\tstruct test* address;\n\tprintf(\"未申请内存时的&address=%p\\n\",&address);\n\taddress=(struct test*)malloc(sizeof(struct test));\n\taddress->data=10;\n\taddress->next=NULL;\n\ttemp=address;\n\tprintf(\"&address=%p\\n\",&address);\n\tprintf(\"address=%p\\n\",address);\n\tprintf(\"temp=%p\\n\",temp);\n\tprintf(\"用%%x来打印地址，在64位机器中会被截断\\n\");\n\tprintf(\"address=%#x\\n\",address);\n\tprintf(\"temp=%#x\\n\",temp);\n\n\treturn 0;\n}\n```\n**执行结果**<br>\n![指针](指针.png)<br>\n`struct test* address`计算机会给变量address分配一个内存，然后当`address=(struct test*)malloc(sizeof(struct test));` 执行后，计算机就会给指针address的内存中填入新申请的大小为(sizeof(struct test))的内存的地址．`temp=address`就是将address的内存装载的内容赋值给temp.<br>\n\n**本质是有两个指针同时指向一个结构内存(struct test). 而不是address指向结构内存，temp再指向address**\n\n*一个有趣的发现就是在64位机上面%x打印16进制只能打印出32位数而%p能够完美打印出48位地址(64位机用48位地址)，所以打印地址还是老老实实用%p*\n","source":"_posts/对于指针的一些理解.md","raw":"---\ntitle: 对于指针的一些理解\ndate: 2020-04-20 16:44:24\nindex_img: /Picture/point.png\ncategories:\n- 数据结构\ntags:\n- 数据结构\n---\n在复习数据结构链表那一章时对创建**头指针**然后指向**首元节点**或者**头节点**(两者是不同的东西)的具体实现过程有些许疑问，它们在内存中是怎么工作的呢？<br>\n于是我写了个小程序来验证了一下<br>\n\n```c\n#include<stdio.h>\n#include<stdlib.h>\n\nstruct test\n{\n\tstruct test* next;\n\tint data;\n};\n\nint main ()\n{\n\tstruct test* temp=NULL ;\n\tstruct test* address;\n\tprintf(\"未申请内存时的&address=%p\\n\",&address);\n\taddress=(struct test*)malloc(sizeof(struct test));\n\taddress->data=10;\n\taddress->next=NULL;\n\ttemp=address;\n\tprintf(\"&address=%p\\n\",&address);\n\tprintf(\"address=%p\\n\",address);\n\tprintf(\"temp=%p\\n\",temp);\n\tprintf(\"用%%x来打印地址，在64位机器中会被截断\\n\");\n\tprintf(\"address=%#x\\n\",address);\n\tprintf(\"temp=%#x\\n\",temp);\n\n\treturn 0;\n}\n```\n**执行结果**<br>\n![指针](指针.png)<br>\n`struct test* address`计算机会给变量address分配一个内存，然后当`address=(struct test*)malloc(sizeof(struct test));` 执行后，计算机就会给指针address的内存中填入新申请的大小为(sizeof(struct test))的内存的地址．`temp=address`就是将address的内存装载的内容赋值给temp.<br>\n\n**本质是有两个指针同时指向一个结构内存(struct test). 而不是address指向结构内存，temp再指向address**\n\n*一个有趣的发现就是在64位机上面%x打印16进制只能打印出32位数而%p能够完美打印出48位地址(64位机用48位地址)，所以打印地址还是老老实实用%p*\n","slug":"对于指针的一些理解","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4sd001ar8s8c8lucdj1","content":"<p>在复习数据结构链表那一章时对创建<strong>头指针</strong>然后指向<strong>首元节点</strong>或者<strong>头节点</strong>(两者是不同的东西)的具体实现过程有些许疑问，它们在内存中是怎么工作的呢？<br><br>于是我写了个小程序来验证了一下<br></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;stdlib.h&gt;</span></span><br><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span></span><br><span class=\"hljs-class\">&#123;</span><br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span>* <span class=\"hljs-title\">next</span>;</span><br>\t<span class=\"hljs-keyword\">int</span> data;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span> <span class=\"hljs-params\">()</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span>* <span class=\"hljs-title\">temp</span>=</span><span class=\"hljs-literal\">NULL</span> ;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span>* <span class=\"hljs-title\">address</span>;</span><br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;未申请内存时的&amp;address=%p\\n&quot;</span>,&amp;address);<br>\taddress=(struct test*)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-keyword\">sizeof</span>(struct test));<br>\taddress-&gt;data=<span class=\"hljs-number\">10</span>;<br>\taddress-&gt;next=<span class=\"hljs-literal\">NULL</span>;<br>\ttemp=address;<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;&amp;address=%p\\n&quot;</span>,&amp;address);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;address=%p\\n&quot;</span>,address);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;temp=%p\\n&quot;</span>,temp);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;用%%x来打印地址，在64位机器中会被截断\\n&quot;</span>);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;address=%#x\\n&quot;</span>,address);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;temp=%#x\\n&quot;</span>,temp);<br><br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>执行结果</strong><br><br><img src=\"指针.png\" alt=\"指针\"><br><br><code>struct test* address</code>计算机会给变量address分配一个内存，然后当<code>address=(struct test*)malloc(sizeof(struct test));</code> 执行后，计算机就会给指针address的内存中填入新申请的大小为(sizeof(struct test))的内存的地址．<code>temp=address</code>就是将address的内存装载的内容赋值给temp.<br></p>\n<p><strong>本质是有两个指针同时指向一个结构内存(struct test). 而不是address指向结构内存，temp再指向address</strong></p>\n<p><em>一个有趣的发现就是在64位机上面%x打印16进制只能打印出32位数而%p能够完美打印出48位地址(64位机用48位地址)，所以打印地址还是老老实实用%p</em></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在复习数据结构链表那一章时对创建<strong>头指针</strong>然后指向<strong>首元节点</strong>或者<strong>头节点</strong>(两者是不同的东西)的具体实现过程有些许疑问，它们在内存中是怎么工作的呢？<br><br>于是我写了个小程序来验证了一下<br></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;stdio.h&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;stdlib.h&gt;</span></span><br><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span></span><br><span class=\"hljs-class\">&#123;</span><br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span>* <span class=\"hljs-title\">next</span>;</span><br>\t<span class=\"hljs-keyword\">int</span> data;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span> <span class=\"hljs-params\">()</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span>* <span class=\"hljs-title\">temp</span>=</span><span class=\"hljs-literal\">NULL</span> ;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">test</span>* <span class=\"hljs-title\">address</span>;</span><br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;未申请内存时的&amp;address=%p\\n&quot;</span>,&amp;address);<br>\taddress=(struct test*)<span class=\"hljs-built_in\">malloc</span>(<span class=\"hljs-keyword\">sizeof</span>(struct test));<br>\taddress-&gt;data=<span class=\"hljs-number\">10</span>;<br>\taddress-&gt;next=<span class=\"hljs-literal\">NULL</span>;<br>\ttemp=address;<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;&amp;address=%p\\n&quot;</span>,&amp;address);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;address=%p\\n&quot;</span>,address);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;temp=%p\\n&quot;</span>,temp);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;用%%x来打印地址，在64位机器中会被截断\\n&quot;</span>);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;address=%#x\\n&quot;</span>,address);<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;temp=%#x\\n&quot;</span>,temp);<br><br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>执行结果</strong><br><br><img src=\"指针.png\" alt=\"指针\"><br><br><code>struct test* address</code>计算机会给变量address分配一个内存，然后当<code>address=(struct test*)malloc(sizeof(struct test));</code> 执行后，计算机就会给指针address的内存中填入新申请的大小为(sizeof(struct test))的内存的地址．<code>temp=address</code>就是将address的内存装载的内容赋值给temp.<br></p>\n<p><strong>本质是有两个指针同时指向一个结构内存(struct test). 而不是address指向结构内存，temp再指向address</strong></p>\n<p><em>一个有趣的发现就是在64位机上面%x打印16进制只能打印出32位数而%p能够完美打印出48位地址(64位机用48位地址)，所以打印地址还是老老实实用%p</em></p>\n"},{"title":"关于进程Process的一篇写的很好的文章 ","index_img":"/Picture/process.png","date":"2020-11-14T15:04:29.000Z","banner_img":null,"_content":"# Process\n本来想翻译一下的，但是文章太长了，我又太懒，所以就贴一下网址吧<br>\n[Process](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html);\n","source":"_posts/关于进程Process的一篇写的很好的文章.md","raw":"---\ntitle: '关于进程Process的一篇写的很好的文章 '\nindex_img: /Picture/process.png\ndate: 2020-11-14 23:04:29\ntags:\n- 操作系统\ncategories:\n- 操作系统\nbanner_img:\n---\n# Process\n本来想翻译一下的，但是文章太长了，我又太懒，所以就贴一下网址吧<br>\n[Process](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html);\n","slug":"关于进程Process的一篇写的很好的文章","published":1,"updated":"2020-11-14T15:18:10.537Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4se001dr8s8dbhy0dwe","content":"<h1 id=\"Process\"><a href=\"#Process\" class=\"headerlink\" title=\"Process\"></a>Process</h1><p>本来想翻译一下的，但是文章太长了，我又太懒，所以就贴一下网址吧<br><br><a href=\"https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html\">Process</a>;</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Process\"><a href=\"#Process\" class=\"headerlink\" title=\"Process\"></a>Process</h1><p>本来想翻译一下的，但是文章太长了，我又太懒，所以就贴一下网址吧<br><br><a href=\"https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html\">Process</a>;</p>\n"},{"title":"有符号数右移32位","index_img":"/Picture/C++log.jpg","date":"2020-11-28T15:17:33.000Z","banner_img":null,"_content":"\n在做项目的过程中把右移31位写成了右移32位，造成了大错，找了好久的bug，心累!!<br>\n于是我发现一个我无法理解的情况，**有符号右移32位得到的数和原来未移动的数相同。**<br>\n```c++\n#include<iostream>\nusing namespace std;\nint main() {\n\tint n = 0x11;\n\tint n1 = n>>32;\n\tprintf(\"n1==0x%x\\n\",n1);\n\treturn 0;\n}\n```\n**Output:**<br>\n``n1==0x11``<br>\n\n*为什么会发生这样的事情呢?*<br>\n\n**原因是: 对于32-bit的int,`n>>32`这一指令是未定义行为(undefined behaviour),所以处理器做出32%32的处理，所以最终`n>>32`就相当于`n>>0`,所以移动后的数和未移动的数相等。<br>**\n\n下面我们做一下验证:`n>>33`<br>\n```c++\n#include<iostream>\nusing namespace std;\nint main() {\n\tint n = 0x11;\n\tint n1 = n>>33;\n\tprintf(\"n1==0x%x\\n\",n1);\n\treturn 0;\n}\n```\nOutput:<br>\n`n1==0x8`<br>\n\nn>>33 就相当与n>>1;<br>\n","source":"_posts/有符号数右移32位.md","raw":"---\ntitle: 有符号数右移32位\nindex_img: /Picture/C++log.jpg\ndate: 2020-11-28 23:17:33\ntags:\n- C/C++\ncategories:\n- C/C++\nbanner_img:\n---\n\n在做项目的过程中把右移31位写成了右移32位，造成了大错，找了好久的bug，心累!!<br>\n于是我发现一个我无法理解的情况，**有符号右移32位得到的数和原来未移动的数相同。**<br>\n```c++\n#include<iostream>\nusing namespace std;\nint main() {\n\tint n = 0x11;\n\tint n1 = n>>32;\n\tprintf(\"n1==0x%x\\n\",n1);\n\treturn 0;\n}\n```\n**Output:**<br>\n``n1==0x11``<br>\n\n*为什么会发生这样的事情呢?*<br>\n\n**原因是: 对于32-bit的int,`n>>32`这一指令是未定义行为(undefined behaviour),所以处理器做出32%32的处理，所以最终`n>>32`就相当于`n>>0`,所以移动后的数和未移动的数相等。<br>**\n\n下面我们做一下验证:`n>>33`<br>\n```c++\n#include<iostream>\nusing namespace std;\nint main() {\n\tint n = 0x11;\n\tint n1 = n>>33;\n\tprintf(\"n1==0x%x\\n\",n1);\n\treturn 0;\n}\n```\nOutput:<br>\n`n1==0x8`<br>\n\nn>>33 就相当与n>>1;<br>\n","slug":"有符号数右移32位","published":1,"updated":"2020-11-28T15:33:12.769Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4sh001ir8s83e5dd86n","content":"<p>在做项目的过程中把右移31位写成了右移32位，造成了大错，找了好久的bug，心累!!<br><br>于是我发现一个我无法理解的情况，<strong>有符号右移32位得到的数和原来未移动的数相同。</strong><br><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> n = <span class=\"hljs-number\">0x11</span>;<br>\t<span class=\"hljs-keyword\">int</span> n1 = n&gt;&gt;<span class=\"hljs-number\">32</span>;<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;n1==0x%x\\n&quot;</span>,n1);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br><strong>Output:</strong><br><br><code>n1==0x11</code><br></p>\n<p><em>为什么会发生这样的事情呢?</em><br></p>\n<p><strong>原因是: 对于32-bit的int,<code>n&gt;&gt;32</code>这一指令是未定义行为(undefined behaviour),所以处理器做出32%32的处理，所以最终<code>n&gt;&gt;32</code>就相当于<code>n&gt;&gt;0</code>,所以移动后的数和未移动的数相等。<br></strong></p>\n<p>下面我们做一下验证:<code>n&gt;&gt;33</code><br><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> n = <span class=\"hljs-number\">0x11</span>;<br>\t<span class=\"hljs-keyword\">int</span> n1 = n&gt;&gt;<span class=\"hljs-number\">33</span>;<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;n1==0x%x\\n&quot;</span>,n1);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br>Output:<br><br><code>n1==0x8</code><br></p>\n<p>n&gt;&gt;33 就相当与n&gt;&gt;1;<br></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在做项目的过程中把右移31位写成了右移32位，造成了大错，找了好久的bug，心累!!<br><br>于是我发现一个我无法理解的情况，<strong>有符号右移32位得到的数和原来未移动的数相同。</strong><br><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> n = <span class=\"hljs-number\">0x11</span>;<br>\t<span class=\"hljs-keyword\">int</span> n1 = n&gt;&gt;<span class=\"hljs-number\">32</span>;<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;n1==0x%x\\n&quot;</span>,n1);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br><strong>Output:</strong><br><br><code>n1==0x11</code><br></p>\n<p><em>为什么会发生这样的事情呢?</em><br></p>\n<p><strong>原因是: 对于32-bit的int,<code>n&gt;&gt;32</code>这一指令是未定义行为(undefined behaviour),所以处理器做出32%32的处理，所以最终<code>n&gt;&gt;32</code>就相当于<code>n&gt;&gt;0</code>,所以移动后的数和未移动的数相等。<br></strong></p>\n<p>下面我们做一下验证:<code>n&gt;&gt;33</code><br><br><figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">include</span><span class=\"hljs-meta-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-keyword\">using</span> <span class=\"hljs-keyword\">namespace</span> <span class=\"hljs-built_in\">std</span>;<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> n = <span class=\"hljs-number\">0x11</span>;<br>\t<span class=\"hljs-keyword\">int</span> n1 = n&gt;&gt;<span class=\"hljs-number\">33</span>;<br>\t<span class=\"hljs-built_in\">printf</span>(<span class=\"hljs-string\">&quot;n1==0x%x\\n&quot;</span>,n1);<br>\t<span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><br>Output:<br><br><code>n1==0x8</code><br></p>\n<p>n&gt;&gt;33 就相当与n&gt;&gt;1;<br></p>\n"},{"title":"计算机网络自顶向下有意思的单词","date":"2020-03-03T09:47:04.000Z","index_img":"/Picture/abandon.jpg","_content":"\n\n# Computer Networking A Top-Down Approach\n\n- desirable to : 希望\n- To gain further insight into ... :获得进一步深入的....\n- scenario:情景\n- In this ideal scenario : (idea n:点子，ideal adj: 理想的）\n- Clearly : 明显的\n- among ：在...中 （among  + 时间）\n- no longer ： 不再\n- nonetheless : 尽管如此，然而\n- In particular ： 尤其是，特别是\n- It is a apparent that ....: 这是清晰可见的 .....\n- deplane: 下飞机\n- turn out attention to: ...\n- responsible for : 负责....\n- referred to as : 被称为是....\n- impact .... : 影响...\n- additional: 额外的\n- so-called ： 所谓的，被叫做...的\n- via ： 通过...\n- wreak havoc : 肆虐，造成严重破坏；\n- upcoming： 即将来临，即将发生的\n- In essence: 在本质上\n- the strengths and weaknesses : 长处和短处\n- throughout : 遍及，从始至终， 贯彻\n- namely ： 即 ，也就是说\n- hence: 因此\n- diving into: 跳进，潜进\n- draw on : 利用，借鉴\n- drawback : 缺点，弱点\n- is analogous to : 类似于...\n- It is also referrd to as : 这个也被称为．．．\n- we can think of as : 我们可以认为是....\n- This imformation is needed : 这个消息是必需的....\n- in general : 一般来说，通常...\n- acceptable : 可以接受的\n- lead to : 导致了．．．．\n- result in : 造成，导致．．．\n- albeit : 尽管\n- straightforward : 直接了当的\n- essentially : 实际上，本质上．．\n- on the scene : 在当时．\n- caught(catch的过去式)general public's eye :抓住了公众的眼睛，引起公众的注意．\n- perhap :也许\n- general idea :总体思路，总体大意．．．\n- somewhat : 有些，稍微有点\n- in which case : 在这种情况下　．．\n- elapses: V:（随着时间的）流逝．\n- shortcoming : 缺点．．\n- moreover : 而且，加之，此外，再者．\n- back-to-back :背靠背，连续，一个接着一个．．\n- taking a close look :仔细看看．．\n- first of all : 首先\n- otherwise : 除此之外，否则．\n- leave out : 省略，忽略．．\n- indicate : 表明，表示，显示\n- associated : 有关联的，相关的．．\n- highly recommended : 强烈建议．．\n- thereby : 从而．．\n- substantially : 实质上．．\n- the rest of : 其余的．．\n- neglect : 忽略｀\n- clearly something must be done : 显然．．一定要去做一些事情．．\n- up to date : 现代的，最新的\n- significantly : 显著的．\n- coordinate with sb/sth : 与．．．配合，配合．．．\n- launch : 启动．．发射．．\n- authenticate : 认证\n- principal : 最重要的\n- restriction :限制\n- retrieves :　取回，拉回\n- mean :有手段的意思\n- invoke :引用\n- key aspects :关键的方面\n- vast : 巨大的\n- take place :发生　\n- alternatively: 或者，两者中选一个 \n- alternative : 另类的，替代的\n- primary,secondary :主要的，次要的\n- backup :后备\n- desire :欲望，渴望\n- desirable : 想要拥有的，期望的\n- overview :　概述，概观\n- brief: 简要的\n- authoritative : 命令式的，权威的\n- alias :别名\n- a number of ... : 一些．．．\n- display :　显示\n- in the frist place ：首先\n- content :内容,满足的，知足的\n- contention : 论点，竞争，争夺\n- context :背景，语境，上下文\n- startup :新启动，新成立的\n- monopoly：垄断\n- accredit :　认证\n- make sure : 确定，保证\n- legitemate :合法的\n- scale,large-scale: 规模，大规模 \n- bypass :　绕过\n- bogus : 虚假，假冒的\n- trick :欺骗，欺诈\n- intercept : 拦截\n- exploit : 利用，漏洞利用\n- appropriate：适当的，恰当的\n- just as : 就像．．．\n- justify :证明...\n- aid　：　帮助\n- assist ：助攻\n- somewhat :有些，有些许，有少许\n- as time evolves: 随着时间的流逝\n- with this ... :　有了．．．，根据．．．（不要用Have this ..了．）\n- equalize : 均衡｀\n- reciprocate :互换，报答，酬答\n- lingo :　行话\n- satisfied : 满意\n- earn other : 彼此\n- chunks : 块\n- tit-for-tat :以牙还牙，针锋相对\n- locate :定位\n- more specifically :更进一步..\n- naive :天真的\n- requires ... to :　要求..要...\n- elegant : 高雅的,优雅的\n- likelihood : 可能性\n- Henceforth :因此\n- scheme: 方案\n- conventions :约定\n- convert : 转换\n- convenience :方便\n- circle :圈,圆｀\n- clockwise :顺时针\n- successor :继承者，接班人\n- aware :意识到的,明白的\n- be aware of  :意识到\n- refine :提炼，精炼\n- acceptable :　可接受的\n- shortcuts : 捷径\n- expedite :加快\n- accomplished :完成\n- verify : 检验，证明\n- periodically :定期的\n- abruptly : 突然\n- depart ：离开\n- replace :取代　（replace..with..）\n- explicitly : 明确的\n- churn : 流失\n- phase : 阶段，时期\n- frightened : 害怕的，受惊的(feel fear or worry)\n- reference : 参考资料\n- identifier : 识别码\n- As you might expect :如你所料\n- uppercase : 大写\n- emphasize :注重\n- intentionally :故意\n- invisible : 无形的\n- dedicate : 专用\n- demonstrate : 展示\n- vice versa : 反之毅然\n- accumulate : 累计，积累\n- as far as i know :据我所知\n- in term of :　就..而言\n- merely :仅仅\n- column : 栏，柱\n- concidence: 巧合\n- confront : 面对(V)\n- embody: 体现在(V)\n- numerous : 许多的\n- effort: 努力\n- best-effor : 最大努力\n- foremost: 最重要的\n- mitigate: 使缓和，减轻\n- inform: 告知\n- suited: 适合\n- regard: 注重，把．．看作，考虑\n- regardless: 不注重，不考虑\n- preliminary: 初步的,起始的\n- precisely :精准地，准确地\n- conferenc: 会议\n- controversial: 有争议的,引起争议的\n- induce: 诱发，诱导 \n- dramatically: 显著地\n- lack: 缺乏\n- trivial: 微不足道的\n- nontrivial: 不平凡的\n- impose: 强加\n- subject: 主题，科目(n) , 受支配的(adj),委托，使唤(v)\n- constraint: 约束，限制(n)\n- occupy: 占用\n- redundant: 多余的\n- fundamentally: 根本上的,重大性的\n- framework: 框架\n- corrupt: 腐化的，损坏的,毁坏的\n- abstraction: 抽象，抽象化\n- beneath: 在．．．下方\n- incrementally: 递增的\n- tedious: 冗长的，罗嗦的\n- flaw: 缺陷\n- flawless: 完美无暇\n- finite: 有限的\n- infinite: 无限的\n- separate: 单独的，间隔的\n- transition: 过渡，转变\n- feedback: 反馈\n- dictate: 听写\n- correct:　正确的，准确无误的(adj), 纠正,修正,改正(v)\n- leftmost: 最左边\n- notation: 符号系统，数学符号\n- fatal: 致命的，灾难性的\n- oversight: 失察，疏忽\n- clearly, we're heading down a difficult path.: 明显的，我们真正走在一条艰难的路上\n- garbled:　混乱不清的，含糊不清的\n- argument: 参数\n- estimate:　估计\n- though, even though: 尽管\n- pipelined: 流水线\n- pipeline: 管道\n- emerging:　新兴的，出现\n- utilization: 利用率\n- dismal: 惨淡,悲伤绝望的\n- fortune: 大量财产，一大笔钱\n- triple: 三倍\n- presumably: 据推测,可能\n- synchronization: 同步化\n- silly: 愚蠢\n- it is worth noting :值得注意\n- encounter: 遭遇\n- incorporate: 合并\n- reiterated: 重申，重复的,反复的\n- itemize: 逐个记载，逐个列出\n- consecutively: 连续的\n- coincide: 重合\n- figurative: 比喻的，形象的\n- curtain: 窗帘\n- Companion: 同伴，伴侣\n- conclude: 以．．．结束(讲话，会议，文章),推断，最后决定\n- manifestation: 显示，表示，表明\n- manifest: 显示，表示（V）\n- preliminary: 初步的，起始的\n- many of: 许多\n- oblivious: (对周围的事情)毫不在意的，毫无知觉的\n- suffice: 足够，满足要求\n- payload: 有效载重量,净载重量\n- entrenched: 根深蒂固的\n- teardown: 带拆房屋，拆卸\n- urgent: 紧急\n- vulnerable:　易受影响的，易受伤的，脆弱的，\n- evaesdrop: 偷听，窃听\n- character: 写入，刻入\n- estimated: 估计的\n- statistic: 统计数据，统计资料\n- decay: 衰变\n- deviate: 脱离，偏离\n- margin: 边缘，差额，余地，界限\n- filp: 翻转\n- considerable: 相当大的，相当重要的\n- present: 礼物，目前(名词),显示，介绍(动词)\n- expiry: 到期，期满\n- subtlety: 微妙;巧妙\n- depict: 描绘\n- likely: 很可能的，可能要发生的\n- most likely: 最有可能发生的\n- convince: 说服\n- interchangeably: 可互换\n- savvy: 了解，实际知识(n), 懂得，领悟(v),有见识的，通情达理的(adj)\n- see the forest for the tree :透过一棵树看森林\n- dynamic: 动态的，思维活跃的，活泼的\n- assured: 确定的，自信的，有把握的\n- minor: 较不重要的，次要的\n- advertising: 广告\n- advertise : 广告\n- perceive: 察觉，领悟，看出\n- ascent: 上升，攀登\n- deallocated: 释放\n- reclaim: 回收，取回，拿回\n- deluge: 暴雨，洪水\n- exhausted: 筋疲力尽的，疲惫不堪的\n- exhaust : 用尽\n- deny: 否认，拒绝\n- denied: 被否认，被拒绝\n- craft:手工艺品,精心制作的东西\n- manifest: 体现，显露，表现\n- in the first place : 首先，最初，第一\n- upper limit: 上限\n- consequence: 后果\n- steady: 稳定的，持续的\n- available: 可用的\n- aggregate: 合计\n- ideal: 理想的\n- far from ideal : 离理想很远，远远不够\n- virtually: 实际上，实质上\n- evident: 显而易见的;明白的\n- embody: 体现，包含，使形象化\n- assistance: 帮助，协助\n- explicit: 显性的\n- sophisticated: 见多识广的，复杂的\n- in a general context: 在通常情况\n- latter: 后者\n- symptom : 症状\n- operate: 操作，运行\n- infer: 推断,推论\n- proposal : 提案\n- choke: 窒息，阻塞\n- stress : 强调,压力\n- intersperse: 点缀，散布\n- convey: 表达，运送，传送\n- tunable: 可调的，可调试的，可调试组件\n- perceive : 感知,认识到，知觉\n- trigger: 触发\n- that is : 放在两个句子中间的时候可以翻译为＂也就是说＂\n- coordinated: 协调一致的\n- mandatory : 强制的;法定的;义务的\n- roughly: 大概，大致，差不多\n- mitigate : 减轻\n- conservative: 保守的，守旧的\n- identical: 相同的，完全一样的\n- inextricably :　密不可分\n- retrospetive: 回顾性\n- factor : 因子，因素\n- probing :　探测，探寻，探讨\n- variation :变化,变动\n- imminent: 即将发生的，临近的\n- flavor: 风味,气味\n- tremendous: 巨大的，惊人的，可怕的\n- macroscopic : 宏观的，肉眼可见的\n- saw-toothed :　锯齿状\n- fairness: 公平，公正\n- cooperate: 合作, 配合\n- blissfully : 惬意的，幸福的\n- gridlocked: 僵局,水泄不通\n- anew: 重新\n- just around the corner : 就在拐角处，意思是很接近了，指日可待\n- adopt: 采用\n- conservative: 保守的\n- Hint : 暗示\n- have nothing to do with ... : 与...无关\n- utilize : 利用\n- fragmentation :碎片，分裂，分片\n- prevalent : 流行的，盛行的，普遍的\n- deceptive : 欺骗性的，骗人的，造成假象的\n- centralize: 使集中，集中的，中央集权的\n- delve : 探索，深入查找，搜寻\n- successive: 连续的，连接的\n- confidentiality :秘密的，机密的\n- integrity : 完整性，诚信，正直\n- eventual :最终的，最后的\n- satisfy : 满足\n- scope: 范围\n- aim : 目标\n- substantial : 实质的，牢固的，大量的\n- oblivious : 遗忘的，忘却的，健忘的\n- look up : 查阅，查找\n- brute : 畜生，禽兽，残忍的\n- evolution : 演化，进化，发展，渐进\n- notion : 概念\n- chips: 芯片,晶片\n- roundabout: 圆环的，拐弯抹角的，不直接的\n- blazingly: 极度的\n- attendant: 服务员，侍者\n- concreteness : 具体化，具体性\n- ensure : 随后的\n- adopter :(新技术的）的接受者，收养人\n- headquarters :总部，司令部\n- revenue: (政府的)税收，(公司的)收入\n- venture : 冒险者\n- embed : 嵌入式，嵌入的\n- arguably : 大概，可能\n- criteria : 准则，条件，标准\n- intervention : 干预，调停，介入\n- Nonetheless: 尽管如此\n- overcome : 克服，压倒，征服\n- vertical : 垂直，垂直方向\n- intersect : 交叉，横断\n- extent : 程度，范围\n- extensive : 广泛的，大面积的\n- negligible : 微不足道的，可以忽略的\n- destined : 命中注定的，注定的\n- in the time : 在这个时候\n- in which case : 在这种情况下\n- fluctuation : 波动，起起伏伏\n- absorb : 吸收\n- theoretical : 理论上的，纯理论的\n- standpoint : 立场,观点\n- threshold : 阀值，临界值\n- as long as : 只要\n- phenomenon : 奇迹，珍品，事件\n- foray : 偷袭，进军，涉足\n- syntax : 句法，语法\n- semantics : 语义，语意\n- interpret : 解释，翻译\n- remainder : 剩余部分，其余部分\n- glue : 胶水\n- overhead : 开销，间接费用\n- whereas : 然而，而\n- squeeze : 挤压，压榨，紧缩\n- fragment : 断片，片段，碎块\n- reassembly : 重新组装\n- proper : 适当的，恰当的，正确的\n- does away with sth : 摆脱，摒弃，废除\n- contiguous : 相近的，邻近的\n- nonprofit :非盈利的，非盈利组织\n- attractive : 诱人的，有魅力的\n- dormitory : (寄宿学校的)宿舍\n- enviable : 令人羡慕的，引人妒忌的\n- lease : 租凭，租契，租期\n- expertise : 专业知识（专长），专业技能\n- patch : 补丁，打补丁\n- external : 外部的，外表的\n- nemesis : 克星(主要敌人)，报应\n- savior : 救主，救星\n- seldom : 很少，极少，几乎不\n- inspect : 检查，进行检查\n- malicious : 恶意的\n- intrusion : 侵入，入侵\n- approved :  核对的，已认可的\n- alert : 警报，警告，机灵的\n- shield : 盾牌，屏障，护盾\n- breathtaking : 极其刺激的，美的惊人的\n- augment : 提高，增强，增大\n- excellent : 优秀的\n- grain : 古粒，粒\n- sand : 沙，沙粒\n- streamline : 简化的，精简的，流线型的\n- counterpart : 副本，配对物\n- tunnel : 隧道,坑道\n- portable : 手提式的，可携带的\n- mutually : 相互的，互相的\n- mutually-trusted : 相互信任的\n- possess : 拥有，具有\n- consult : 商量，商议\n- boil down to sth : (形式与问题)主要原因在于，归结为\n- short-haul : 短层，短途路线\n- precise : 精确的，精准的\n- mandate : 命令，委任，要求\n- even if : 即使，纵然，就算\n- relieve : 缓解,减轻\n- skepticism : 怀疑，怀疑主义\n- miraculously : 奇迹般的，奇迹般地\n- quiescent : 静止的，静态的\n- poison: 中毒;下毒，中毒的\n- prohibitive : 高昂到难以承受的\n- enormous: 巨大的\n- sketch : 草图，示意图，素描图\n- cause and effect : 因果关系\n- nevertheless :不过，仍然，虽然如此\n- rudimentary : 基础的，基本的，初级的\n- semipermanent : 暂时的,半永久的\n- elimination : 淘汰,去除\n- calamitous : 多灾难的，多灾多难的\n- redundant : 多余的，过剩的，过多的\n","source":"_posts/计算机网络自顶向下有意思的单词.md","raw":"---\ntitle: 计算机网络自顶向下有意思的单词\ndate: 2020-03-03 17:47:04\nindex_img: /Picture/abandon.jpg\ntags: -英语学习 \n\n---\n\n\n# Computer Networking A Top-Down Approach\n\n- desirable to : 希望\n- To gain further insight into ... :获得进一步深入的....\n- scenario:情景\n- In this ideal scenario : (idea n:点子，ideal adj: 理想的）\n- Clearly : 明显的\n- among ：在...中 （among  + 时间）\n- no longer ： 不再\n- nonetheless : 尽管如此，然而\n- In particular ： 尤其是，特别是\n- It is a apparent that ....: 这是清晰可见的 .....\n- deplane: 下飞机\n- turn out attention to: ...\n- responsible for : 负责....\n- referred to as : 被称为是....\n- impact .... : 影响...\n- additional: 额外的\n- so-called ： 所谓的，被叫做...的\n- via ： 通过...\n- wreak havoc : 肆虐，造成严重破坏；\n- upcoming： 即将来临，即将发生的\n- In essence: 在本质上\n- the strengths and weaknesses : 长处和短处\n- throughout : 遍及，从始至终， 贯彻\n- namely ： 即 ，也就是说\n- hence: 因此\n- diving into: 跳进，潜进\n- draw on : 利用，借鉴\n- drawback : 缺点，弱点\n- is analogous to : 类似于...\n- It is also referrd to as : 这个也被称为．．．\n- we can think of as : 我们可以认为是....\n- This imformation is needed : 这个消息是必需的....\n- in general : 一般来说，通常...\n- acceptable : 可以接受的\n- lead to : 导致了．．．．\n- result in : 造成，导致．．．\n- albeit : 尽管\n- straightforward : 直接了当的\n- essentially : 实际上，本质上．．\n- on the scene : 在当时．\n- caught(catch的过去式)general public's eye :抓住了公众的眼睛，引起公众的注意．\n- perhap :也许\n- general idea :总体思路，总体大意．．．\n- somewhat : 有些，稍微有点\n- in which case : 在这种情况下　．．\n- elapses: V:（随着时间的）流逝．\n- shortcoming : 缺点．．\n- moreover : 而且，加之，此外，再者．\n- back-to-back :背靠背，连续，一个接着一个．．\n- taking a close look :仔细看看．．\n- first of all : 首先\n- otherwise : 除此之外，否则．\n- leave out : 省略，忽略．．\n- indicate : 表明，表示，显示\n- associated : 有关联的，相关的．．\n- highly recommended : 强烈建议．．\n- thereby : 从而．．\n- substantially : 实质上．．\n- the rest of : 其余的．．\n- neglect : 忽略｀\n- clearly something must be done : 显然．．一定要去做一些事情．．\n- up to date : 现代的，最新的\n- significantly : 显著的．\n- coordinate with sb/sth : 与．．．配合，配合．．．\n- launch : 启动．．发射．．\n- authenticate : 认证\n- principal : 最重要的\n- restriction :限制\n- retrieves :　取回，拉回\n- mean :有手段的意思\n- invoke :引用\n- key aspects :关键的方面\n- vast : 巨大的\n- take place :发生　\n- alternatively: 或者，两者中选一个 \n- alternative : 另类的，替代的\n- primary,secondary :主要的，次要的\n- backup :后备\n- desire :欲望，渴望\n- desirable : 想要拥有的，期望的\n- overview :　概述，概观\n- brief: 简要的\n- authoritative : 命令式的，权威的\n- alias :别名\n- a number of ... : 一些．．．\n- display :　显示\n- in the frist place ：首先\n- content :内容,满足的，知足的\n- contention : 论点，竞争，争夺\n- context :背景，语境，上下文\n- startup :新启动，新成立的\n- monopoly：垄断\n- accredit :　认证\n- make sure : 确定，保证\n- legitemate :合法的\n- scale,large-scale: 规模，大规模 \n- bypass :　绕过\n- bogus : 虚假，假冒的\n- trick :欺骗，欺诈\n- intercept : 拦截\n- exploit : 利用，漏洞利用\n- appropriate：适当的，恰当的\n- just as : 就像．．．\n- justify :证明...\n- aid　：　帮助\n- assist ：助攻\n- somewhat :有些，有些许，有少许\n- as time evolves: 随着时间的流逝\n- with this ... :　有了．．．，根据．．．（不要用Have this ..了．）\n- equalize : 均衡｀\n- reciprocate :互换，报答，酬答\n- lingo :　行话\n- satisfied : 满意\n- earn other : 彼此\n- chunks : 块\n- tit-for-tat :以牙还牙，针锋相对\n- locate :定位\n- more specifically :更进一步..\n- naive :天真的\n- requires ... to :　要求..要...\n- elegant : 高雅的,优雅的\n- likelihood : 可能性\n- Henceforth :因此\n- scheme: 方案\n- conventions :约定\n- convert : 转换\n- convenience :方便\n- circle :圈,圆｀\n- clockwise :顺时针\n- successor :继承者，接班人\n- aware :意识到的,明白的\n- be aware of  :意识到\n- refine :提炼，精炼\n- acceptable :　可接受的\n- shortcuts : 捷径\n- expedite :加快\n- accomplished :完成\n- verify : 检验，证明\n- periodically :定期的\n- abruptly : 突然\n- depart ：离开\n- replace :取代　（replace..with..）\n- explicitly : 明确的\n- churn : 流失\n- phase : 阶段，时期\n- frightened : 害怕的，受惊的(feel fear or worry)\n- reference : 参考资料\n- identifier : 识别码\n- As you might expect :如你所料\n- uppercase : 大写\n- emphasize :注重\n- intentionally :故意\n- invisible : 无形的\n- dedicate : 专用\n- demonstrate : 展示\n- vice versa : 反之毅然\n- accumulate : 累计，积累\n- as far as i know :据我所知\n- in term of :　就..而言\n- merely :仅仅\n- column : 栏，柱\n- concidence: 巧合\n- confront : 面对(V)\n- embody: 体现在(V)\n- numerous : 许多的\n- effort: 努力\n- best-effor : 最大努力\n- foremost: 最重要的\n- mitigate: 使缓和，减轻\n- inform: 告知\n- suited: 适合\n- regard: 注重，把．．看作，考虑\n- regardless: 不注重，不考虑\n- preliminary: 初步的,起始的\n- precisely :精准地，准确地\n- conferenc: 会议\n- controversial: 有争议的,引起争议的\n- induce: 诱发，诱导 \n- dramatically: 显著地\n- lack: 缺乏\n- trivial: 微不足道的\n- nontrivial: 不平凡的\n- impose: 强加\n- subject: 主题，科目(n) , 受支配的(adj),委托，使唤(v)\n- constraint: 约束，限制(n)\n- occupy: 占用\n- redundant: 多余的\n- fundamentally: 根本上的,重大性的\n- framework: 框架\n- corrupt: 腐化的，损坏的,毁坏的\n- abstraction: 抽象，抽象化\n- beneath: 在．．．下方\n- incrementally: 递增的\n- tedious: 冗长的，罗嗦的\n- flaw: 缺陷\n- flawless: 完美无暇\n- finite: 有限的\n- infinite: 无限的\n- separate: 单独的，间隔的\n- transition: 过渡，转变\n- feedback: 反馈\n- dictate: 听写\n- correct:　正确的，准确无误的(adj), 纠正,修正,改正(v)\n- leftmost: 最左边\n- notation: 符号系统，数学符号\n- fatal: 致命的，灾难性的\n- oversight: 失察，疏忽\n- clearly, we're heading down a difficult path.: 明显的，我们真正走在一条艰难的路上\n- garbled:　混乱不清的，含糊不清的\n- argument: 参数\n- estimate:　估计\n- though, even though: 尽管\n- pipelined: 流水线\n- pipeline: 管道\n- emerging:　新兴的，出现\n- utilization: 利用率\n- dismal: 惨淡,悲伤绝望的\n- fortune: 大量财产，一大笔钱\n- triple: 三倍\n- presumably: 据推测,可能\n- synchronization: 同步化\n- silly: 愚蠢\n- it is worth noting :值得注意\n- encounter: 遭遇\n- incorporate: 合并\n- reiterated: 重申，重复的,反复的\n- itemize: 逐个记载，逐个列出\n- consecutively: 连续的\n- coincide: 重合\n- figurative: 比喻的，形象的\n- curtain: 窗帘\n- Companion: 同伴，伴侣\n- conclude: 以．．．结束(讲话，会议，文章),推断，最后决定\n- manifestation: 显示，表示，表明\n- manifest: 显示，表示（V）\n- preliminary: 初步的，起始的\n- many of: 许多\n- oblivious: (对周围的事情)毫不在意的，毫无知觉的\n- suffice: 足够，满足要求\n- payload: 有效载重量,净载重量\n- entrenched: 根深蒂固的\n- teardown: 带拆房屋，拆卸\n- urgent: 紧急\n- vulnerable:　易受影响的，易受伤的，脆弱的，\n- evaesdrop: 偷听，窃听\n- character: 写入，刻入\n- estimated: 估计的\n- statistic: 统计数据，统计资料\n- decay: 衰变\n- deviate: 脱离，偏离\n- margin: 边缘，差额，余地，界限\n- filp: 翻转\n- considerable: 相当大的，相当重要的\n- present: 礼物，目前(名词),显示，介绍(动词)\n- expiry: 到期，期满\n- subtlety: 微妙;巧妙\n- depict: 描绘\n- likely: 很可能的，可能要发生的\n- most likely: 最有可能发生的\n- convince: 说服\n- interchangeably: 可互换\n- savvy: 了解，实际知识(n), 懂得，领悟(v),有见识的，通情达理的(adj)\n- see the forest for the tree :透过一棵树看森林\n- dynamic: 动态的，思维活跃的，活泼的\n- assured: 确定的，自信的，有把握的\n- minor: 较不重要的，次要的\n- advertising: 广告\n- advertise : 广告\n- perceive: 察觉，领悟，看出\n- ascent: 上升，攀登\n- deallocated: 释放\n- reclaim: 回收，取回，拿回\n- deluge: 暴雨，洪水\n- exhausted: 筋疲力尽的，疲惫不堪的\n- exhaust : 用尽\n- deny: 否认，拒绝\n- denied: 被否认，被拒绝\n- craft:手工艺品,精心制作的东西\n- manifest: 体现，显露，表现\n- in the first place : 首先，最初，第一\n- upper limit: 上限\n- consequence: 后果\n- steady: 稳定的，持续的\n- available: 可用的\n- aggregate: 合计\n- ideal: 理想的\n- far from ideal : 离理想很远，远远不够\n- virtually: 实际上，实质上\n- evident: 显而易见的;明白的\n- embody: 体现，包含，使形象化\n- assistance: 帮助，协助\n- explicit: 显性的\n- sophisticated: 见多识广的，复杂的\n- in a general context: 在通常情况\n- latter: 后者\n- symptom : 症状\n- operate: 操作，运行\n- infer: 推断,推论\n- proposal : 提案\n- choke: 窒息，阻塞\n- stress : 强调,压力\n- intersperse: 点缀，散布\n- convey: 表达，运送，传送\n- tunable: 可调的，可调试的，可调试组件\n- perceive : 感知,认识到，知觉\n- trigger: 触发\n- that is : 放在两个句子中间的时候可以翻译为＂也就是说＂\n- coordinated: 协调一致的\n- mandatory : 强制的;法定的;义务的\n- roughly: 大概，大致，差不多\n- mitigate : 减轻\n- conservative: 保守的，守旧的\n- identical: 相同的，完全一样的\n- inextricably :　密不可分\n- retrospetive: 回顾性\n- factor : 因子，因素\n- probing :　探测，探寻，探讨\n- variation :变化,变动\n- imminent: 即将发生的，临近的\n- flavor: 风味,气味\n- tremendous: 巨大的，惊人的，可怕的\n- macroscopic : 宏观的，肉眼可见的\n- saw-toothed :　锯齿状\n- fairness: 公平，公正\n- cooperate: 合作, 配合\n- blissfully : 惬意的，幸福的\n- gridlocked: 僵局,水泄不通\n- anew: 重新\n- just around the corner : 就在拐角处，意思是很接近了，指日可待\n- adopt: 采用\n- conservative: 保守的\n- Hint : 暗示\n- have nothing to do with ... : 与...无关\n- utilize : 利用\n- fragmentation :碎片，分裂，分片\n- prevalent : 流行的，盛行的，普遍的\n- deceptive : 欺骗性的，骗人的，造成假象的\n- centralize: 使集中，集中的，中央集权的\n- delve : 探索，深入查找，搜寻\n- successive: 连续的，连接的\n- confidentiality :秘密的，机密的\n- integrity : 完整性，诚信，正直\n- eventual :最终的，最后的\n- satisfy : 满足\n- scope: 范围\n- aim : 目标\n- substantial : 实质的，牢固的，大量的\n- oblivious : 遗忘的，忘却的，健忘的\n- look up : 查阅，查找\n- brute : 畜生，禽兽，残忍的\n- evolution : 演化，进化，发展，渐进\n- notion : 概念\n- chips: 芯片,晶片\n- roundabout: 圆环的，拐弯抹角的，不直接的\n- blazingly: 极度的\n- attendant: 服务员，侍者\n- concreteness : 具体化，具体性\n- ensure : 随后的\n- adopter :(新技术的）的接受者，收养人\n- headquarters :总部，司令部\n- revenue: (政府的)税收，(公司的)收入\n- venture : 冒险者\n- embed : 嵌入式，嵌入的\n- arguably : 大概，可能\n- criteria : 准则，条件，标准\n- intervention : 干预，调停，介入\n- Nonetheless: 尽管如此\n- overcome : 克服，压倒，征服\n- vertical : 垂直，垂直方向\n- intersect : 交叉，横断\n- extent : 程度，范围\n- extensive : 广泛的，大面积的\n- negligible : 微不足道的，可以忽略的\n- destined : 命中注定的，注定的\n- in the time : 在这个时候\n- in which case : 在这种情况下\n- fluctuation : 波动，起起伏伏\n- absorb : 吸收\n- theoretical : 理论上的，纯理论的\n- standpoint : 立场,观点\n- threshold : 阀值，临界值\n- as long as : 只要\n- phenomenon : 奇迹，珍品，事件\n- foray : 偷袭，进军，涉足\n- syntax : 句法，语法\n- semantics : 语义，语意\n- interpret : 解释，翻译\n- remainder : 剩余部分，其余部分\n- glue : 胶水\n- overhead : 开销，间接费用\n- whereas : 然而，而\n- squeeze : 挤压，压榨，紧缩\n- fragment : 断片，片段，碎块\n- reassembly : 重新组装\n- proper : 适当的，恰当的，正确的\n- does away with sth : 摆脱，摒弃，废除\n- contiguous : 相近的，邻近的\n- nonprofit :非盈利的，非盈利组织\n- attractive : 诱人的，有魅力的\n- dormitory : (寄宿学校的)宿舍\n- enviable : 令人羡慕的，引人妒忌的\n- lease : 租凭，租契，租期\n- expertise : 专业知识（专长），专业技能\n- patch : 补丁，打补丁\n- external : 外部的，外表的\n- nemesis : 克星(主要敌人)，报应\n- savior : 救主，救星\n- seldom : 很少，极少，几乎不\n- inspect : 检查，进行检查\n- malicious : 恶意的\n- intrusion : 侵入，入侵\n- approved :  核对的，已认可的\n- alert : 警报，警告，机灵的\n- shield : 盾牌，屏障，护盾\n- breathtaking : 极其刺激的，美的惊人的\n- augment : 提高，增强，增大\n- excellent : 优秀的\n- grain : 古粒，粒\n- sand : 沙，沙粒\n- streamline : 简化的，精简的，流线型的\n- counterpart : 副本，配对物\n- tunnel : 隧道,坑道\n- portable : 手提式的，可携带的\n- mutually : 相互的，互相的\n- mutually-trusted : 相互信任的\n- possess : 拥有，具有\n- consult : 商量，商议\n- boil down to sth : (形式与问题)主要原因在于，归结为\n- short-haul : 短层，短途路线\n- precise : 精确的，精准的\n- mandate : 命令，委任，要求\n- even if : 即使，纵然，就算\n- relieve : 缓解,减轻\n- skepticism : 怀疑，怀疑主义\n- miraculously : 奇迹般的，奇迹般地\n- quiescent : 静止的，静态的\n- poison: 中毒;下毒，中毒的\n- prohibitive : 高昂到难以承受的\n- enormous: 巨大的\n- sketch : 草图，示意图，素描图\n- cause and effect : 因果关系\n- nevertheless :不过，仍然，虽然如此\n- rudimentary : 基础的，基本的，初级的\n- semipermanent : 暂时的,半永久的\n- elimination : 淘汰,去除\n- calamitous : 多灾难的，多灾多难的\n- redundant : 多余的，过剩的，过多的\n","slug":"计算机网络自顶向下有意思的单词","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4si001lr8s87ummfq2v","content":"<h1 id=\"Computer-Networking-A-Top-Down-Approach\"><a href=\"#Computer-Networking-A-Top-Down-Approach\" class=\"headerlink\" title=\"Computer Networking A Top-Down Approach\"></a>Computer Networking A Top-Down Approach</h1><ul>\n<li>desirable to : 希望</li>\n<li>To gain further insight into … :获得进一步深入的….</li>\n<li>scenario:情景</li>\n<li>In this ideal scenario : (idea n:点子，ideal adj: 理想的）</li>\n<li>Clearly : 明显的</li>\n<li>among ：在…中 （among  + 时间）</li>\n<li>no longer ： 不再</li>\n<li>nonetheless : 尽管如此，然而</li>\n<li>In particular ： 尤其是，特别是</li>\n<li>It is a apparent that ….: 这是清晰可见的 …..</li>\n<li>deplane: 下飞机</li>\n<li>turn out attention to: …</li>\n<li>responsible for : 负责….</li>\n<li>referred to as : 被称为是….</li>\n<li>impact …. : 影响…</li>\n<li>additional: 额外的</li>\n<li>so-called ： 所谓的，被叫做…的</li>\n<li>via ： 通过…</li>\n<li>wreak havoc : 肆虐，造成严重破坏；</li>\n<li>upcoming： 即将来临，即将发生的</li>\n<li>In essence: 在本质上</li>\n<li>the strengths and weaknesses : 长处和短处</li>\n<li>throughout : 遍及，从始至终， 贯彻</li>\n<li>namely ： 即 ，也就是说</li>\n<li>hence: 因此</li>\n<li>diving into: 跳进，潜进</li>\n<li>draw on : 利用，借鉴</li>\n<li>drawback : 缺点，弱点</li>\n<li>is analogous to : 类似于…</li>\n<li>It is also referrd to as : 这个也被称为．．．</li>\n<li>we can think of as : 我们可以认为是….</li>\n<li>This imformation is needed : 这个消息是必需的….</li>\n<li>in general : 一般来说，通常…</li>\n<li>acceptable : 可以接受的</li>\n<li>lead to : 导致了．．．．</li>\n<li>result in : 造成，导致．．．</li>\n<li>albeit : 尽管</li>\n<li>straightforward : 直接了当的</li>\n<li>essentially : 实际上，本质上．．</li>\n<li>on the scene : 在当时．</li>\n<li>caught(catch的过去式)general public’s eye :抓住了公众的眼睛，引起公众的注意．</li>\n<li>perhap :也许</li>\n<li>general idea :总体思路，总体大意．．．</li>\n<li>somewhat : 有些，稍微有点</li>\n<li>in which case : 在这种情况下　．．</li>\n<li>elapses: V:（随着时间的）流逝．</li>\n<li>shortcoming : 缺点．．</li>\n<li>moreover : 而且，加之，此外，再者．</li>\n<li>back-to-back :背靠背，连续，一个接着一个．．</li>\n<li>taking a close look :仔细看看．．</li>\n<li>first of all : 首先</li>\n<li>otherwise : 除此之外，否则．</li>\n<li>leave out : 省略，忽略．．</li>\n<li>indicate : 表明，表示，显示</li>\n<li>associated : 有关联的，相关的．．</li>\n<li>highly recommended : 强烈建议．．</li>\n<li>thereby : 从而．．</li>\n<li>substantially : 实质上．．</li>\n<li>the rest of : 其余的．．</li>\n<li>neglect : 忽略｀</li>\n<li>clearly something must be done : 显然．．一定要去做一些事情．．</li>\n<li>up to date : 现代的，最新的</li>\n<li>significantly : 显著的．</li>\n<li>coordinate with sb/sth : 与．．．配合，配合．．．</li>\n<li>launch : 启动．．发射．．</li>\n<li>authenticate : 认证</li>\n<li>principal : 最重要的</li>\n<li>restriction :限制</li>\n<li>retrieves :　取回，拉回</li>\n<li>mean :有手段的意思</li>\n<li>invoke :引用</li>\n<li>key aspects :关键的方面</li>\n<li>vast : 巨大的</li>\n<li>take place :发生　</li>\n<li>alternatively: 或者，两者中选一个 </li>\n<li>alternative : 另类的，替代的</li>\n<li>primary,secondary :主要的，次要的</li>\n<li>backup :后备</li>\n<li>desire :欲望，渴望</li>\n<li>desirable : 想要拥有的，期望的</li>\n<li>overview :　概述，概观</li>\n<li>brief: 简要的</li>\n<li>authoritative : 命令式的，权威的</li>\n<li>alias :别名</li>\n<li>a number of … : 一些．．．</li>\n<li>display :　显示</li>\n<li>in the frist place ：首先</li>\n<li>content :内容,满足的，知足的</li>\n<li>contention : 论点，竞争，争夺</li>\n<li>context :背景，语境，上下文</li>\n<li>startup :新启动，新成立的</li>\n<li>monopoly：垄断</li>\n<li>accredit :　认证</li>\n<li>make sure : 确定，保证</li>\n<li>legitemate :合法的</li>\n<li>scale,large-scale: 规模，大规模 </li>\n<li>bypass :　绕过</li>\n<li>bogus : 虚假，假冒的</li>\n<li>trick :欺骗，欺诈</li>\n<li>intercept : 拦截</li>\n<li>exploit : 利用，漏洞利用</li>\n<li>appropriate：适当的，恰当的</li>\n<li>just as : 就像．．．</li>\n<li>justify :证明…</li>\n<li>aid　：　帮助</li>\n<li>assist ：助攻</li>\n<li>somewhat :有些，有些许，有少许</li>\n<li>as time evolves: 随着时间的流逝</li>\n<li>with this … :　有了．．．，根据．．．（不要用Have this ..了．）</li>\n<li>equalize : 均衡｀</li>\n<li>reciprocate :互换，报答，酬答</li>\n<li>lingo :　行话</li>\n<li>satisfied : 满意</li>\n<li>earn other : 彼此</li>\n<li>chunks : 块</li>\n<li>tit-for-tat :以牙还牙，针锋相对</li>\n<li>locate :定位</li>\n<li>more specifically :更进一步..</li>\n<li>naive :天真的</li>\n<li>requires … to :　要求..要…</li>\n<li>elegant : 高雅的,优雅的</li>\n<li>likelihood : 可能性</li>\n<li>Henceforth :因此</li>\n<li>scheme: 方案</li>\n<li>conventions :约定</li>\n<li>convert : 转换</li>\n<li>convenience :方便</li>\n<li>circle :圈,圆｀</li>\n<li>clockwise :顺时针</li>\n<li>successor :继承者，接班人</li>\n<li>aware :意识到的,明白的</li>\n<li>be aware of  :意识到</li>\n<li>refine :提炼，精炼</li>\n<li>acceptable :　可接受的</li>\n<li>shortcuts : 捷径</li>\n<li>expedite :加快</li>\n<li>accomplished :完成</li>\n<li>verify : 检验，证明</li>\n<li>periodically :定期的</li>\n<li>abruptly : 突然</li>\n<li>depart ：离开</li>\n<li>replace :取代　（replace..with..）</li>\n<li>explicitly : 明确的</li>\n<li>churn : 流失</li>\n<li>phase : 阶段，时期</li>\n<li>frightened : 害怕的，受惊的(feel fear or worry)</li>\n<li>reference : 参考资料</li>\n<li>identifier : 识别码</li>\n<li>As you might expect :如你所料</li>\n<li>uppercase : 大写</li>\n<li>emphasize :注重</li>\n<li>intentionally :故意</li>\n<li>invisible : 无形的</li>\n<li>dedicate : 专用</li>\n<li>demonstrate : 展示</li>\n<li>vice versa : 反之毅然</li>\n<li>accumulate : 累计，积累</li>\n<li>as far as i know :据我所知</li>\n<li>in term of :　就..而言</li>\n<li>merely :仅仅</li>\n<li>column : 栏，柱</li>\n<li>concidence: 巧合</li>\n<li>confront : 面对(V)</li>\n<li>embody: 体现在(V)</li>\n<li>numerous : 许多的</li>\n<li>effort: 努力</li>\n<li>best-effor : 最大努力</li>\n<li>foremost: 最重要的</li>\n<li>mitigate: 使缓和，减轻</li>\n<li>inform: 告知</li>\n<li>suited: 适合</li>\n<li>regard: 注重，把．．看作，考虑</li>\n<li>regardless: 不注重，不考虑</li>\n<li>preliminary: 初步的,起始的</li>\n<li>precisely :精准地，准确地</li>\n<li>conferenc: 会议</li>\n<li>controversial: 有争议的,引起争议的</li>\n<li>induce: 诱发，诱导 </li>\n<li>dramatically: 显著地</li>\n<li>lack: 缺乏</li>\n<li>trivial: 微不足道的</li>\n<li>nontrivial: 不平凡的</li>\n<li>impose: 强加</li>\n<li>subject: 主题，科目(n) , 受支配的(adj),委托，使唤(v)</li>\n<li>constraint: 约束，限制(n)</li>\n<li>occupy: 占用</li>\n<li>redundant: 多余的</li>\n<li>fundamentally: 根本上的,重大性的</li>\n<li>framework: 框架</li>\n<li>corrupt: 腐化的，损坏的,毁坏的</li>\n<li>abstraction: 抽象，抽象化</li>\n<li>beneath: 在．．．下方</li>\n<li>incrementally: 递增的</li>\n<li>tedious: 冗长的，罗嗦的</li>\n<li>flaw: 缺陷</li>\n<li>flawless: 完美无暇</li>\n<li>finite: 有限的</li>\n<li>infinite: 无限的</li>\n<li>separate: 单独的，间隔的</li>\n<li>transition: 过渡，转变</li>\n<li>feedback: 反馈</li>\n<li>dictate: 听写</li>\n<li>correct:　正确的，准确无误的(adj), 纠正,修正,改正(v)</li>\n<li>leftmost: 最左边</li>\n<li>notation: 符号系统，数学符号</li>\n<li>fatal: 致命的，灾难性的</li>\n<li>oversight: 失察，疏忽</li>\n<li>clearly, we’re heading down a difficult path.: 明显的，我们真正走在一条艰难的路上</li>\n<li>garbled:　混乱不清的，含糊不清的</li>\n<li>argument: 参数</li>\n<li>estimate:　估计</li>\n<li>though, even though: 尽管</li>\n<li>pipelined: 流水线</li>\n<li>pipeline: 管道</li>\n<li>emerging:　新兴的，出现</li>\n<li>utilization: 利用率</li>\n<li>dismal: 惨淡,悲伤绝望的</li>\n<li>fortune: 大量财产，一大笔钱</li>\n<li>triple: 三倍</li>\n<li>presumably: 据推测,可能</li>\n<li>synchronization: 同步化</li>\n<li>silly: 愚蠢</li>\n<li>it is worth noting :值得注意</li>\n<li>encounter: 遭遇</li>\n<li>incorporate: 合并</li>\n<li>reiterated: 重申，重复的,反复的</li>\n<li>itemize: 逐个记载，逐个列出</li>\n<li>consecutively: 连续的</li>\n<li>coincide: 重合</li>\n<li>figurative: 比喻的，形象的</li>\n<li>curtain: 窗帘</li>\n<li>Companion: 同伴，伴侣</li>\n<li>conclude: 以．．．结束(讲话，会议，文章),推断，最后决定</li>\n<li>manifestation: 显示，表示，表明</li>\n<li>manifest: 显示，表示（V）</li>\n<li>preliminary: 初步的，起始的</li>\n<li>many of: 许多</li>\n<li>oblivious: (对周围的事情)毫不在意的，毫无知觉的</li>\n<li>suffice: 足够，满足要求</li>\n<li>payload: 有效载重量,净载重量</li>\n<li>entrenched: 根深蒂固的</li>\n<li>teardown: 带拆房屋，拆卸</li>\n<li>urgent: 紧急</li>\n<li>vulnerable:　易受影响的，易受伤的，脆弱的，</li>\n<li>evaesdrop: 偷听，窃听</li>\n<li>character: 写入，刻入</li>\n<li>estimated: 估计的</li>\n<li>statistic: 统计数据，统计资料</li>\n<li>decay: 衰变</li>\n<li>deviate: 脱离，偏离</li>\n<li>margin: 边缘，差额，余地，界限</li>\n<li>filp: 翻转</li>\n<li>considerable: 相当大的，相当重要的</li>\n<li>present: 礼物，目前(名词),显示，介绍(动词)</li>\n<li>expiry: 到期，期满</li>\n<li>subtlety: 微妙;巧妙</li>\n<li>depict: 描绘</li>\n<li>likely: 很可能的，可能要发生的</li>\n<li>most likely: 最有可能发生的</li>\n<li>convince: 说服</li>\n<li>interchangeably: 可互换</li>\n<li>savvy: 了解，实际知识(n), 懂得，领悟(v),有见识的，通情达理的(adj)</li>\n<li>see the forest for the tree :透过一棵树看森林</li>\n<li>dynamic: 动态的，思维活跃的，活泼的</li>\n<li>assured: 确定的，自信的，有把握的</li>\n<li>minor: 较不重要的，次要的</li>\n<li>advertising: 广告</li>\n<li>advertise : 广告</li>\n<li>perceive: 察觉，领悟，看出</li>\n<li>ascent: 上升，攀登</li>\n<li>deallocated: 释放</li>\n<li>reclaim: 回收，取回，拿回</li>\n<li>deluge: 暴雨，洪水</li>\n<li>exhausted: 筋疲力尽的，疲惫不堪的</li>\n<li>exhaust : 用尽</li>\n<li>deny: 否认，拒绝</li>\n<li>denied: 被否认，被拒绝</li>\n<li>craft:手工艺品,精心制作的东西</li>\n<li>manifest: 体现，显露，表现</li>\n<li>in the first place : 首先，最初，第一</li>\n<li>upper limit: 上限</li>\n<li>consequence: 后果</li>\n<li>steady: 稳定的，持续的</li>\n<li>available: 可用的</li>\n<li>aggregate: 合计</li>\n<li>ideal: 理想的</li>\n<li>far from ideal : 离理想很远，远远不够</li>\n<li>virtually: 实际上，实质上</li>\n<li>evident: 显而易见的;明白的</li>\n<li>embody: 体现，包含，使形象化</li>\n<li>assistance: 帮助，协助</li>\n<li>explicit: 显性的</li>\n<li>sophisticated: 见多识广的，复杂的</li>\n<li>in a general context: 在通常情况</li>\n<li>latter: 后者</li>\n<li>symptom : 症状</li>\n<li>operate: 操作，运行</li>\n<li>infer: 推断,推论</li>\n<li>proposal : 提案</li>\n<li>choke: 窒息，阻塞</li>\n<li>stress : 强调,压力</li>\n<li>intersperse: 点缀，散布</li>\n<li>convey: 表达，运送，传送</li>\n<li>tunable: 可调的，可调试的，可调试组件</li>\n<li>perceive : 感知,认识到，知觉</li>\n<li>trigger: 触发</li>\n<li>that is : 放在两个句子中间的时候可以翻译为＂也就是说＂</li>\n<li>coordinated: 协调一致的</li>\n<li>mandatory : 强制的;法定的;义务的</li>\n<li>roughly: 大概，大致，差不多</li>\n<li>mitigate : 减轻</li>\n<li>conservative: 保守的，守旧的</li>\n<li>identical: 相同的，完全一样的</li>\n<li>inextricably :　密不可分</li>\n<li>retrospetive: 回顾性</li>\n<li>factor : 因子，因素</li>\n<li>probing :　探测，探寻，探讨</li>\n<li>variation :变化,变动</li>\n<li>imminent: 即将发生的，临近的</li>\n<li>flavor: 风味,气味</li>\n<li>tremendous: 巨大的，惊人的，可怕的</li>\n<li>macroscopic : 宏观的，肉眼可见的</li>\n<li>saw-toothed :　锯齿状</li>\n<li>fairness: 公平，公正</li>\n<li>cooperate: 合作, 配合</li>\n<li>blissfully : 惬意的，幸福的</li>\n<li>gridlocked: 僵局,水泄不通</li>\n<li>anew: 重新</li>\n<li>just around the corner : 就在拐角处，意思是很接近了，指日可待</li>\n<li>adopt: 采用</li>\n<li>conservative: 保守的</li>\n<li>Hint : 暗示</li>\n<li>have nothing to do with … : 与…无关</li>\n<li>utilize : 利用</li>\n<li>fragmentation :碎片，分裂，分片</li>\n<li>prevalent : 流行的，盛行的，普遍的</li>\n<li>deceptive : 欺骗性的，骗人的，造成假象的</li>\n<li>centralize: 使集中，集中的，中央集权的</li>\n<li>delve : 探索，深入查找，搜寻</li>\n<li>successive: 连续的，连接的</li>\n<li>confidentiality :秘密的，机密的</li>\n<li>integrity : 完整性，诚信，正直</li>\n<li>eventual :最终的，最后的</li>\n<li>satisfy : 满足</li>\n<li>scope: 范围</li>\n<li>aim : 目标</li>\n<li>substantial : 实质的，牢固的，大量的</li>\n<li>oblivious : 遗忘的，忘却的，健忘的</li>\n<li>look up : 查阅，查找</li>\n<li>brute : 畜生，禽兽，残忍的</li>\n<li>evolution : 演化，进化，发展，渐进</li>\n<li>notion : 概念</li>\n<li>chips: 芯片,晶片</li>\n<li>roundabout: 圆环的，拐弯抹角的，不直接的</li>\n<li>blazingly: 极度的</li>\n<li>attendant: 服务员，侍者</li>\n<li>concreteness : 具体化，具体性</li>\n<li>ensure : 随后的</li>\n<li>adopter :(新技术的）的接受者，收养人</li>\n<li>headquarters :总部，司令部</li>\n<li>revenue: (政府的)税收，(公司的)收入</li>\n<li>venture : 冒险者</li>\n<li>embed : 嵌入式，嵌入的</li>\n<li>arguably : 大概，可能</li>\n<li>criteria : 准则，条件，标准</li>\n<li>intervention : 干预，调停，介入</li>\n<li>Nonetheless: 尽管如此</li>\n<li>overcome : 克服，压倒，征服</li>\n<li>vertical : 垂直，垂直方向</li>\n<li>intersect : 交叉，横断</li>\n<li>extent : 程度，范围</li>\n<li>extensive : 广泛的，大面积的</li>\n<li>negligible : 微不足道的，可以忽略的</li>\n<li>destined : 命中注定的，注定的</li>\n<li>in the time : 在这个时候</li>\n<li>in which case : 在这种情况下</li>\n<li>fluctuation : 波动，起起伏伏</li>\n<li>absorb : 吸收</li>\n<li>theoretical : 理论上的，纯理论的</li>\n<li>standpoint : 立场,观点</li>\n<li>threshold : 阀值，临界值</li>\n<li>as long as : 只要</li>\n<li>phenomenon : 奇迹，珍品，事件</li>\n<li>foray : 偷袭，进军，涉足</li>\n<li>syntax : 句法，语法</li>\n<li>semantics : 语义，语意</li>\n<li>interpret : 解释，翻译</li>\n<li>remainder : 剩余部分，其余部分</li>\n<li>glue : 胶水</li>\n<li>overhead : 开销，间接费用</li>\n<li>whereas : 然而，而</li>\n<li>squeeze : 挤压，压榨，紧缩</li>\n<li>fragment : 断片，片段，碎块</li>\n<li>reassembly : 重新组装</li>\n<li>proper : 适当的，恰当的，正确的</li>\n<li>does away with sth : 摆脱，摒弃，废除</li>\n<li>contiguous : 相近的，邻近的</li>\n<li>nonprofit :非盈利的，非盈利组织</li>\n<li>attractive : 诱人的，有魅力的</li>\n<li>dormitory : (寄宿学校的)宿舍</li>\n<li>enviable : 令人羡慕的，引人妒忌的</li>\n<li>lease : 租凭，租契，租期</li>\n<li>expertise : 专业知识（专长），专业技能</li>\n<li>patch : 补丁，打补丁</li>\n<li>external : 外部的，外表的</li>\n<li>nemesis : 克星(主要敌人)，报应</li>\n<li>savior : 救主，救星</li>\n<li>seldom : 很少，极少，几乎不</li>\n<li>inspect : 检查，进行检查</li>\n<li>malicious : 恶意的</li>\n<li>intrusion : 侵入，入侵</li>\n<li>approved :  核对的，已认可的</li>\n<li>alert : 警报，警告，机灵的</li>\n<li>shield : 盾牌，屏障，护盾</li>\n<li>breathtaking : 极其刺激的，美的惊人的</li>\n<li>augment : 提高，增强，增大</li>\n<li>excellent : 优秀的</li>\n<li>grain : 古粒，粒</li>\n<li>sand : 沙，沙粒</li>\n<li>streamline : 简化的，精简的，流线型的</li>\n<li>counterpart : 副本，配对物</li>\n<li>tunnel : 隧道,坑道</li>\n<li>portable : 手提式的，可携带的</li>\n<li>mutually : 相互的，互相的</li>\n<li>mutually-trusted : 相互信任的</li>\n<li>possess : 拥有，具有</li>\n<li>consult : 商量，商议</li>\n<li>boil down to sth : (形式与问题)主要原因在于，归结为</li>\n<li>short-haul : 短层，短途路线</li>\n<li>precise : 精确的，精准的</li>\n<li>mandate : 命令，委任，要求</li>\n<li>even if : 即使，纵然，就算</li>\n<li>relieve : 缓解,减轻</li>\n<li>skepticism : 怀疑，怀疑主义</li>\n<li>miraculously : 奇迹般的，奇迹般地</li>\n<li>quiescent : 静止的，静态的</li>\n<li>poison: 中毒;下毒，中毒的</li>\n<li>prohibitive : 高昂到难以承受的</li>\n<li>enormous: 巨大的</li>\n<li>sketch : 草图，示意图，素描图</li>\n<li>cause and effect : 因果关系</li>\n<li>nevertheless :不过，仍然，虽然如此</li>\n<li>rudimentary : 基础的，基本的，初级的</li>\n<li>semipermanent : 暂时的,半永久的</li>\n<li>elimination : 淘汰,去除</li>\n<li>calamitous : 多灾难的，多灾多难的</li>\n<li>redundant : 多余的，过剩的，过多的</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Computer-Networking-A-Top-Down-Approach\"><a href=\"#Computer-Networking-A-Top-Down-Approach\" class=\"headerlink\" title=\"Computer Networking A Top-Down Approach\"></a>Computer Networking A Top-Down Approach</h1><ul>\n<li>desirable to : 希望</li>\n<li>To gain further insight into … :获得进一步深入的….</li>\n<li>scenario:情景</li>\n<li>In this ideal scenario : (idea n:点子，ideal adj: 理想的）</li>\n<li>Clearly : 明显的</li>\n<li>among ：在…中 （among  + 时间）</li>\n<li>no longer ： 不再</li>\n<li>nonetheless : 尽管如此，然而</li>\n<li>In particular ： 尤其是，特别是</li>\n<li>It is a apparent that ….: 这是清晰可见的 …..</li>\n<li>deplane: 下飞机</li>\n<li>turn out attention to: …</li>\n<li>responsible for : 负责….</li>\n<li>referred to as : 被称为是….</li>\n<li>impact …. : 影响…</li>\n<li>additional: 额外的</li>\n<li>so-called ： 所谓的，被叫做…的</li>\n<li>via ： 通过…</li>\n<li>wreak havoc : 肆虐，造成严重破坏；</li>\n<li>upcoming： 即将来临，即将发生的</li>\n<li>In essence: 在本质上</li>\n<li>the strengths and weaknesses : 长处和短处</li>\n<li>throughout : 遍及，从始至终， 贯彻</li>\n<li>namely ： 即 ，也就是说</li>\n<li>hence: 因此</li>\n<li>diving into: 跳进，潜进</li>\n<li>draw on : 利用，借鉴</li>\n<li>drawback : 缺点，弱点</li>\n<li>is analogous to : 类似于…</li>\n<li>It is also referrd to as : 这个也被称为．．．</li>\n<li>we can think of as : 我们可以认为是….</li>\n<li>This imformation is needed : 这个消息是必需的….</li>\n<li>in general : 一般来说，通常…</li>\n<li>acceptable : 可以接受的</li>\n<li>lead to : 导致了．．．．</li>\n<li>result in : 造成，导致．．．</li>\n<li>albeit : 尽管</li>\n<li>straightforward : 直接了当的</li>\n<li>essentially : 实际上，本质上．．</li>\n<li>on the scene : 在当时．</li>\n<li>caught(catch的过去式)general public’s eye :抓住了公众的眼睛，引起公众的注意．</li>\n<li>perhap :也许</li>\n<li>general idea :总体思路，总体大意．．．</li>\n<li>somewhat : 有些，稍微有点</li>\n<li>in which case : 在这种情况下　．．</li>\n<li>elapses: V:（随着时间的）流逝．</li>\n<li>shortcoming : 缺点．．</li>\n<li>moreover : 而且，加之，此外，再者．</li>\n<li>back-to-back :背靠背，连续，一个接着一个．．</li>\n<li>taking a close look :仔细看看．．</li>\n<li>first of all : 首先</li>\n<li>otherwise : 除此之外，否则．</li>\n<li>leave out : 省略，忽略．．</li>\n<li>indicate : 表明，表示，显示</li>\n<li>associated : 有关联的，相关的．．</li>\n<li>highly recommended : 强烈建议．．</li>\n<li>thereby : 从而．．</li>\n<li>substantially : 实质上．．</li>\n<li>the rest of : 其余的．．</li>\n<li>neglect : 忽略｀</li>\n<li>clearly something must be done : 显然．．一定要去做一些事情．．</li>\n<li>up to date : 现代的，最新的</li>\n<li>significantly : 显著的．</li>\n<li>coordinate with sb/sth : 与．．．配合，配合．．．</li>\n<li>launch : 启动．．发射．．</li>\n<li>authenticate : 认证</li>\n<li>principal : 最重要的</li>\n<li>restriction :限制</li>\n<li>retrieves :　取回，拉回</li>\n<li>mean :有手段的意思</li>\n<li>invoke :引用</li>\n<li>key aspects :关键的方面</li>\n<li>vast : 巨大的</li>\n<li>take place :发生　</li>\n<li>alternatively: 或者，两者中选一个 </li>\n<li>alternative : 另类的，替代的</li>\n<li>primary,secondary :主要的，次要的</li>\n<li>backup :后备</li>\n<li>desire :欲望，渴望</li>\n<li>desirable : 想要拥有的，期望的</li>\n<li>overview :　概述，概观</li>\n<li>brief: 简要的</li>\n<li>authoritative : 命令式的，权威的</li>\n<li>alias :别名</li>\n<li>a number of … : 一些．．．</li>\n<li>display :　显示</li>\n<li>in the frist place ：首先</li>\n<li>content :内容,满足的，知足的</li>\n<li>contention : 论点，竞争，争夺</li>\n<li>context :背景，语境，上下文</li>\n<li>startup :新启动，新成立的</li>\n<li>monopoly：垄断</li>\n<li>accredit :　认证</li>\n<li>make sure : 确定，保证</li>\n<li>legitemate :合法的</li>\n<li>scale,large-scale: 规模，大规模 </li>\n<li>bypass :　绕过</li>\n<li>bogus : 虚假，假冒的</li>\n<li>trick :欺骗，欺诈</li>\n<li>intercept : 拦截</li>\n<li>exploit : 利用，漏洞利用</li>\n<li>appropriate：适当的，恰当的</li>\n<li>just as : 就像．．．</li>\n<li>justify :证明…</li>\n<li>aid　：　帮助</li>\n<li>assist ：助攻</li>\n<li>somewhat :有些，有些许，有少许</li>\n<li>as time evolves: 随着时间的流逝</li>\n<li>with this … :　有了．．．，根据．．．（不要用Have this ..了．）</li>\n<li>equalize : 均衡｀</li>\n<li>reciprocate :互换，报答，酬答</li>\n<li>lingo :　行话</li>\n<li>satisfied : 满意</li>\n<li>earn other : 彼此</li>\n<li>chunks : 块</li>\n<li>tit-for-tat :以牙还牙，针锋相对</li>\n<li>locate :定位</li>\n<li>more specifically :更进一步..</li>\n<li>naive :天真的</li>\n<li>requires … to :　要求..要…</li>\n<li>elegant : 高雅的,优雅的</li>\n<li>likelihood : 可能性</li>\n<li>Henceforth :因此</li>\n<li>scheme: 方案</li>\n<li>conventions :约定</li>\n<li>convert : 转换</li>\n<li>convenience :方便</li>\n<li>circle :圈,圆｀</li>\n<li>clockwise :顺时针</li>\n<li>successor :继承者，接班人</li>\n<li>aware :意识到的,明白的</li>\n<li>be aware of  :意识到</li>\n<li>refine :提炼，精炼</li>\n<li>acceptable :　可接受的</li>\n<li>shortcuts : 捷径</li>\n<li>expedite :加快</li>\n<li>accomplished :完成</li>\n<li>verify : 检验，证明</li>\n<li>periodically :定期的</li>\n<li>abruptly : 突然</li>\n<li>depart ：离开</li>\n<li>replace :取代　（replace..with..）</li>\n<li>explicitly : 明确的</li>\n<li>churn : 流失</li>\n<li>phase : 阶段，时期</li>\n<li>frightened : 害怕的，受惊的(feel fear or worry)</li>\n<li>reference : 参考资料</li>\n<li>identifier : 识别码</li>\n<li>As you might expect :如你所料</li>\n<li>uppercase : 大写</li>\n<li>emphasize :注重</li>\n<li>intentionally :故意</li>\n<li>invisible : 无形的</li>\n<li>dedicate : 专用</li>\n<li>demonstrate : 展示</li>\n<li>vice versa : 反之毅然</li>\n<li>accumulate : 累计，积累</li>\n<li>as far as i know :据我所知</li>\n<li>in term of :　就..而言</li>\n<li>merely :仅仅</li>\n<li>column : 栏，柱</li>\n<li>concidence: 巧合</li>\n<li>confront : 面对(V)</li>\n<li>embody: 体现在(V)</li>\n<li>numerous : 许多的</li>\n<li>effort: 努力</li>\n<li>best-effor : 最大努力</li>\n<li>foremost: 最重要的</li>\n<li>mitigate: 使缓和，减轻</li>\n<li>inform: 告知</li>\n<li>suited: 适合</li>\n<li>regard: 注重，把．．看作，考虑</li>\n<li>regardless: 不注重，不考虑</li>\n<li>preliminary: 初步的,起始的</li>\n<li>precisely :精准地，准确地</li>\n<li>conferenc: 会议</li>\n<li>controversial: 有争议的,引起争议的</li>\n<li>induce: 诱发，诱导 </li>\n<li>dramatically: 显著地</li>\n<li>lack: 缺乏</li>\n<li>trivial: 微不足道的</li>\n<li>nontrivial: 不平凡的</li>\n<li>impose: 强加</li>\n<li>subject: 主题，科目(n) , 受支配的(adj),委托，使唤(v)</li>\n<li>constraint: 约束，限制(n)</li>\n<li>occupy: 占用</li>\n<li>redundant: 多余的</li>\n<li>fundamentally: 根本上的,重大性的</li>\n<li>framework: 框架</li>\n<li>corrupt: 腐化的，损坏的,毁坏的</li>\n<li>abstraction: 抽象，抽象化</li>\n<li>beneath: 在．．．下方</li>\n<li>incrementally: 递增的</li>\n<li>tedious: 冗长的，罗嗦的</li>\n<li>flaw: 缺陷</li>\n<li>flawless: 完美无暇</li>\n<li>finite: 有限的</li>\n<li>infinite: 无限的</li>\n<li>separate: 单独的，间隔的</li>\n<li>transition: 过渡，转变</li>\n<li>feedback: 反馈</li>\n<li>dictate: 听写</li>\n<li>correct:　正确的，准确无误的(adj), 纠正,修正,改正(v)</li>\n<li>leftmost: 最左边</li>\n<li>notation: 符号系统，数学符号</li>\n<li>fatal: 致命的，灾难性的</li>\n<li>oversight: 失察，疏忽</li>\n<li>clearly, we’re heading down a difficult path.: 明显的，我们真正走在一条艰难的路上</li>\n<li>garbled:　混乱不清的，含糊不清的</li>\n<li>argument: 参数</li>\n<li>estimate:　估计</li>\n<li>though, even though: 尽管</li>\n<li>pipelined: 流水线</li>\n<li>pipeline: 管道</li>\n<li>emerging:　新兴的，出现</li>\n<li>utilization: 利用率</li>\n<li>dismal: 惨淡,悲伤绝望的</li>\n<li>fortune: 大量财产，一大笔钱</li>\n<li>triple: 三倍</li>\n<li>presumably: 据推测,可能</li>\n<li>synchronization: 同步化</li>\n<li>silly: 愚蠢</li>\n<li>it is worth noting :值得注意</li>\n<li>encounter: 遭遇</li>\n<li>incorporate: 合并</li>\n<li>reiterated: 重申，重复的,反复的</li>\n<li>itemize: 逐个记载，逐个列出</li>\n<li>consecutively: 连续的</li>\n<li>coincide: 重合</li>\n<li>figurative: 比喻的，形象的</li>\n<li>curtain: 窗帘</li>\n<li>Companion: 同伴，伴侣</li>\n<li>conclude: 以．．．结束(讲话，会议，文章),推断，最后决定</li>\n<li>manifestation: 显示，表示，表明</li>\n<li>manifest: 显示，表示（V）</li>\n<li>preliminary: 初步的，起始的</li>\n<li>many of: 许多</li>\n<li>oblivious: (对周围的事情)毫不在意的，毫无知觉的</li>\n<li>suffice: 足够，满足要求</li>\n<li>payload: 有效载重量,净载重量</li>\n<li>entrenched: 根深蒂固的</li>\n<li>teardown: 带拆房屋，拆卸</li>\n<li>urgent: 紧急</li>\n<li>vulnerable:　易受影响的，易受伤的，脆弱的，</li>\n<li>evaesdrop: 偷听，窃听</li>\n<li>character: 写入，刻入</li>\n<li>estimated: 估计的</li>\n<li>statistic: 统计数据，统计资料</li>\n<li>decay: 衰变</li>\n<li>deviate: 脱离，偏离</li>\n<li>margin: 边缘，差额，余地，界限</li>\n<li>filp: 翻转</li>\n<li>considerable: 相当大的，相当重要的</li>\n<li>present: 礼物，目前(名词),显示，介绍(动词)</li>\n<li>expiry: 到期，期满</li>\n<li>subtlety: 微妙;巧妙</li>\n<li>depict: 描绘</li>\n<li>likely: 很可能的，可能要发生的</li>\n<li>most likely: 最有可能发生的</li>\n<li>convince: 说服</li>\n<li>interchangeably: 可互换</li>\n<li>savvy: 了解，实际知识(n), 懂得，领悟(v),有见识的，通情达理的(adj)</li>\n<li>see the forest for the tree :透过一棵树看森林</li>\n<li>dynamic: 动态的，思维活跃的，活泼的</li>\n<li>assured: 确定的，自信的，有把握的</li>\n<li>minor: 较不重要的，次要的</li>\n<li>advertising: 广告</li>\n<li>advertise : 广告</li>\n<li>perceive: 察觉，领悟，看出</li>\n<li>ascent: 上升，攀登</li>\n<li>deallocated: 释放</li>\n<li>reclaim: 回收，取回，拿回</li>\n<li>deluge: 暴雨，洪水</li>\n<li>exhausted: 筋疲力尽的，疲惫不堪的</li>\n<li>exhaust : 用尽</li>\n<li>deny: 否认，拒绝</li>\n<li>denied: 被否认，被拒绝</li>\n<li>craft:手工艺品,精心制作的东西</li>\n<li>manifest: 体现，显露，表现</li>\n<li>in the first place : 首先，最初，第一</li>\n<li>upper limit: 上限</li>\n<li>consequence: 后果</li>\n<li>steady: 稳定的，持续的</li>\n<li>available: 可用的</li>\n<li>aggregate: 合计</li>\n<li>ideal: 理想的</li>\n<li>far from ideal : 离理想很远，远远不够</li>\n<li>virtually: 实际上，实质上</li>\n<li>evident: 显而易见的;明白的</li>\n<li>embody: 体现，包含，使形象化</li>\n<li>assistance: 帮助，协助</li>\n<li>explicit: 显性的</li>\n<li>sophisticated: 见多识广的，复杂的</li>\n<li>in a general context: 在通常情况</li>\n<li>latter: 后者</li>\n<li>symptom : 症状</li>\n<li>operate: 操作，运行</li>\n<li>infer: 推断,推论</li>\n<li>proposal : 提案</li>\n<li>choke: 窒息，阻塞</li>\n<li>stress : 强调,压力</li>\n<li>intersperse: 点缀，散布</li>\n<li>convey: 表达，运送，传送</li>\n<li>tunable: 可调的，可调试的，可调试组件</li>\n<li>perceive : 感知,认识到，知觉</li>\n<li>trigger: 触发</li>\n<li>that is : 放在两个句子中间的时候可以翻译为＂也就是说＂</li>\n<li>coordinated: 协调一致的</li>\n<li>mandatory : 强制的;法定的;义务的</li>\n<li>roughly: 大概，大致，差不多</li>\n<li>mitigate : 减轻</li>\n<li>conservative: 保守的，守旧的</li>\n<li>identical: 相同的，完全一样的</li>\n<li>inextricably :　密不可分</li>\n<li>retrospetive: 回顾性</li>\n<li>factor : 因子，因素</li>\n<li>probing :　探测，探寻，探讨</li>\n<li>variation :变化,变动</li>\n<li>imminent: 即将发生的，临近的</li>\n<li>flavor: 风味,气味</li>\n<li>tremendous: 巨大的，惊人的，可怕的</li>\n<li>macroscopic : 宏观的，肉眼可见的</li>\n<li>saw-toothed :　锯齿状</li>\n<li>fairness: 公平，公正</li>\n<li>cooperate: 合作, 配合</li>\n<li>blissfully : 惬意的，幸福的</li>\n<li>gridlocked: 僵局,水泄不通</li>\n<li>anew: 重新</li>\n<li>just around the corner : 就在拐角处，意思是很接近了，指日可待</li>\n<li>adopt: 采用</li>\n<li>conservative: 保守的</li>\n<li>Hint : 暗示</li>\n<li>have nothing to do with … : 与…无关</li>\n<li>utilize : 利用</li>\n<li>fragmentation :碎片，分裂，分片</li>\n<li>prevalent : 流行的，盛行的，普遍的</li>\n<li>deceptive : 欺骗性的，骗人的，造成假象的</li>\n<li>centralize: 使集中，集中的，中央集权的</li>\n<li>delve : 探索，深入查找，搜寻</li>\n<li>successive: 连续的，连接的</li>\n<li>confidentiality :秘密的，机密的</li>\n<li>integrity : 完整性，诚信，正直</li>\n<li>eventual :最终的，最后的</li>\n<li>satisfy : 满足</li>\n<li>scope: 范围</li>\n<li>aim : 目标</li>\n<li>substantial : 实质的，牢固的，大量的</li>\n<li>oblivious : 遗忘的，忘却的，健忘的</li>\n<li>look up : 查阅，查找</li>\n<li>brute : 畜生，禽兽，残忍的</li>\n<li>evolution : 演化，进化，发展，渐进</li>\n<li>notion : 概念</li>\n<li>chips: 芯片,晶片</li>\n<li>roundabout: 圆环的，拐弯抹角的，不直接的</li>\n<li>blazingly: 极度的</li>\n<li>attendant: 服务员，侍者</li>\n<li>concreteness : 具体化，具体性</li>\n<li>ensure : 随后的</li>\n<li>adopter :(新技术的）的接受者，收养人</li>\n<li>headquarters :总部，司令部</li>\n<li>revenue: (政府的)税收，(公司的)收入</li>\n<li>venture : 冒险者</li>\n<li>embed : 嵌入式，嵌入的</li>\n<li>arguably : 大概，可能</li>\n<li>criteria : 准则，条件，标准</li>\n<li>intervention : 干预，调停，介入</li>\n<li>Nonetheless: 尽管如此</li>\n<li>overcome : 克服，压倒，征服</li>\n<li>vertical : 垂直，垂直方向</li>\n<li>intersect : 交叉，横断</li>\n<li>extent : 程度，范围</li>\n<li>extensive : 广泛的，大面积的</li>\n<li>negligible : 微不足道的，可以忽略的</li>\n<li>destined : 命中注定的，注定的</li>\n<li>in the time : 在这个时候</li>\n<li>in which case : 在这种情况下</li>\n<li>fluctuation : 波动，起起伏伏</li>\n<li>absorb : 吸收</li>\n<li>theoretical : 理论上的，纯理论的</li>\n<li>standpoint : 立场,观点</li>\n<li>threshold : 阀值，临界值</li>\n<li>as long as : 只要</li>\n<li>phenomenon : 奇迹，珍品，事件</li>\n<li>foray : 偷袭，进军，涉足</li>\n<li>syntax : 句法，语法</li>\n<li>semantics : 语义，语意</li>\n<li>interpret : 解释，翻译</li>\n<li>remainder : 剩余部分，其余部分</li>\n<li>glue : 胶水</li>\n<li>overhead : 开销，间接费用</li>\n<li>whereas : 然而，而</li>\n<li>squeeze : 挤压，压榨，紧缩</li>\n<li>fragment : 断片，片段，碎块</li>\n<li>reassembly : 重新组装</li>\n<li>proper : 适当的，恰当的，正确的</li>\n<li>does away with sth : 摆脱，摒弃，废除</li>\n<li>contiguous : 相近的，邻近的</li>\n<li>nonprofit :非盈利的，非盈利组织</li>\n<li>attractive : 诱人的，有魅力的</li>\n<li>dormitory : (寄宿学校的)宿舍</li>\n<li>enviable : 令人羡慕的，引人妒忌的</li>\n<li>lease : 租凭，租契，租期</li>\n<li>expertise : 专业知识（专长），专业技能</li>\n<li>patch : 补丁，打补丁</li>\n<li>external : 外部的，外表的</li>\n<li>nemesis : 克星(主要敌人)，报应</li>\n<li>savior : 救主，救星</li>\n<li>seldom : 很少，极少，几乎不</li>\n<li>inspect : 检查，进行检查</li>\n<li>malicious : 恶意的</li>\n<li>intrusion : 侵入，入侵</li>\n<li>approved :  核对的，已认可的</li>\n<li>alert : 警报，警告，机灵的</li>\n<li>shield : 盾牌，屏障，护盾</li>\n<li>breathtaking : 极其刺激的，美的惊人的</li>\n<li>augment : 提高，增强，增大</li>\n<li>excellent : 优秀的</li>\n<li>grain : 古粒，粒</li>\n<li>sand : 沙，沙粒</li>\n<li>streamline : 简化的，精简的，流线型的</li>\n<li>counterpart : 副本，配对物</li>\n<li>tunnel : 隧道,坑道</li>\n<li>portable : 手提式的，可携带的</li>\n<li>mutually : 相互的，互相的</li>\n<li>mutually-trusted : 相互信任的</li>\n<li>possess : 拥有，具有</li>\n<li>consult : 商量，商议</li>\n<li>boil down to sth : (形式与问题)主要原因在于，归结为</li>\n<li>short-haul : 短层，短途路线</li>\n<li>precise : 精确的，精准的</li>\n<li>mandate : 命令，委任，要求</li>\n<li>even if : 即使，纵然，就算</li>\n<li>relieve : 缓解,减轻</li>\n<li>skepticism : 怀疑，怀疑主义</li>\n<li>miraculously : 奇迹般的，奇迹般地</li>\n<li>quiescent : 静止的，静态的</li>\n<li>poison: 中毒;下毒，中毒的</li>\n<li>prohibitive : 高昂到难以承受的</li>\n<li>enormous: 巨大的</li>\n<li>sketch : 草图，示意图，素描图</li>\n<li>cause and effect : 因果关系</li>\n<li>nevertheless :不过，仍然，虽然如此</li>\n<li>rudimentary : 基础的，基本的，初级的</li>\n<li>semipermanent : 暂时的,半永久的</li>\n<li>elimination : 淘汰,去除</li>\n<li>calamitous : 多灾难的，多灾多难的</li>\n<li>redundant : 多余的，过剩的，过多的</li>\n</ul>\n"},{"title":"面试题35. 复杂链表的复制","date":"2020-04-26T16:55:45.000Z","index_img":"/Picture/line.png","_content":"\n题目在此[面试题35．复杂的链表的复制](https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/)<br>\n\n有三种方法可以做这一道题<br>\n- 迭代法\n- BFS\n- DFS\nunordered_map<key,value>是无序的哈希函数<br>\t\n*unordered_map<Node\\*,Node\\*> copylist 其实是用来同步复制结点和原结点，例如，原结点到达了head.那么head的复制结点就是copylist\\[head\\],相当于把原结点和复制节点绑定了起来*<br>\n\t**这样做的好处是:**<br>\n举个例子若不使用unordered_map函数，我们创建3个复制结点就需要创建3个指针(例如：p1,p2,p3)去指向它，以备后续建立结点相互链接关系时再次访问，但是如果我原节点有10000个，那么我就需要手动创建10000个指针，而用了unordered_map就可以将创建的复制结点与原结点绑定起来，结点间建立链接关系时只需要通过原节点就可以访问相应的复制结点(原结点head的复制节点copylist\\[head\\])<br>\n\n*下面方法除了优化迭代法的时间复杂度为O(n)，空间复杂度为O(1)，其他的时间空间复杂度都为O(n)*\n\n### 迭代法<br>\n```\nclass Solution {\npublic:\n    Node* copyRandomList(Node* head) {\n       if(head==NULL) //防止传入head就是NULL\n       return head;\n       unordered_map<Node*,Node*>copylist;\n       Node* temp = head;\n       while(temp!=NULL) //先把所有结点复制一遍\n       {\n           copylist[temp]=new Node(temp->val);\n           temp=temp->next;\n       }\n       temp=head;\n       while(temp!=NULL) //复制每个结点的next关系\n       {\n               copylist[temp]->next=copylist[temp->next];\n               temp=temp->next;\n       } \n       temp=head;\n       while(temp!=NULL){ //复制每个结点的random关系\n           copylist[temp]->random=copylist[temp->random];\n           temp=temp->next;\n       }\n       return copylist[head];\n    }\n};\n```\n### 优化版迭代\n![优化版迭代](优化迭代法-图解.png)<br>\n\n**这个版本的迭代和普通的迭代有什么区别呢？**<br>\n*其实这个版本的用原节点的next指针代替了unordered_map，用来绑定(定位)复制结点*<br>\n```\nclass Solution {\npublic:\n    Node* copyRandomList(Node* head) {\n        if(head==NULL)\n        return head;\n        Node* cphead;\n        Node* start;\n        Node* end;\n        Node* temp=head;\n        while(temp!=NULL)\n        {\n            Node* copyhead=new Node(temp->val);\n            copyhead->next=temp->next;\n            temp->next=copyhead;\n            temp=temp->next->next;\n        }\n        //建立random链接\n        temp=head;\n        while(temp!=NULL)\n        {\n            if(temp->random!=NULL)\n            temp->next->random=temp->random->next;\n            else\n            temp->next->random=NULL;\n            temp=temp->next->next;\n        }\n        //建立next链接\n        cphead=head->next; //记录复制头节点的位置，以便return\n        start=head;\n        end=head->next;\n        while(end!=NULL)\n        {\n            start->next=end->next;\n            start=end;\n            end=end->next;\n        }\n        return cphead;\n    }\n};\n```\n\n### DFS<br>\n因为链表可以变相的可以看为一个图，所以我们可以用DFS解决，DFS递归就相当于保存了上一个节点的信息　(递归就像是一个另类的栈，隐藏的栈和linux0.11进程切换的隐藏栈差不多)．<br>\nDFS传递进去的参数是**DFS(期望建立链接的结点，哈希表)**<br>\nDFS递归的创建复杂结点，在返回的时候用copylist\\[head\\]->next 和 copylist\\[head\\]->random 来建立前后结点的链接关系．<br>\n```\nclass Solution {\npublic:\n //注意unordered_map<Node*,Node*> &copylist这里使用了引用\n    Node* DFS(Node* head,unordered_map<Node*,Node*> &copylist)\n    {\n        if(head==NULL)\n        return head;\n        //copylist[head].count用来计算head在哈希表中出现几次，因为unordered_map是不允许重复的所以只会返回0或１.\n\t\t\t\tif(copylist.count(head)) return copylist[head];  //如果已经创建过了所以就直接返回\n        copylist[head]=new Node(head->val);\n\t\t\t\tcopylist[head]->next=DFS(head->next,copylist); //这一句和下面一句就是结点之间建立链接关系的语句．\n        copylist[head]->random=DFS(head->random,copylist);\n        return copylist[head];\n    }\n\n   Node* copyRandomList(Node* head) {\n       unordered_map<Node*,Node*>copylist;\n       return DFS(head,copylist);\n    }\n};\n```\n### BFS<br>\n*其实和DFS差不多，就是换了一种遍历的方法，有一点和DFS不同就是BFS是在便利途中结点之间就建立了链接，但是DFS是在遍历完结后回退的过程中建立链接*<br>\n\n```\nclass Solution {\npublic:\n    Node* BFS(Node*head)\n    {\n        if(head==NULL)\n        return head;\n        unordered_map<Node*,Node*>copylist;\n        copylist[head]=new Node(head->val);\n\t\t\t\tqueue<Node*> q; //队列\n        q.push(head);\n        while(!q.empty()){\n            Node* temp=q.front();\n            q.pop();\n\t\t\t\t\t\t//建立next链接\n            if(temp->next!=NULL && copylist.count(temp->next))　//首先要判断下一个结点存不存在(存在则直接建立链接，不存在则是NULL或者还没建立)\n            {\n                copylist[temp]->next=copylist[temp->next];\n            }\n            else\n            {\n                if(temp->next!=NULL){　//下一个结点非NULL而是还没遍历到\n                copylist[temp->next]=new Node(temp->next->val);\n                copylist[temp]->next=copylist[temp->next];\n                q.push(temp->next);\n                }\n\t\t\t\t\t\t\t\telse　//下一个结点为NULL\n                copylist[temp]->next=NULL;\n            }\n\t\t\t\t\t\t//建立random 链接\n            if(temp->random!=NULL && copylist.count(temp->random))\n            {\n                copylist[temp]->random=copylist[temp->random];\n            }\n            else\n            {\n                if(temp->random!=NULL){\n                copylist[temp->random]=new Node(temp->random->val);\n                copylist[temp]->random= copylist[temp->random];\n                q.push(temp->random);\n                }\n                else\n                copylist[temp]->random=NULL;\n            }\n        }\n        return copylist[head];\n    }\n\n    Node* copyRandomList(Node* head) {\n        return BFS(head);\n    }\n};\n```\n","source":"_posts/面试题35-复杂链表的复制.md","raw":"---\ntitle: 面试题35. 复杂链表的复制\ndate: 2020-04-27 00:55:45\nindex_img: /Picture/line.png\ncategories:\n- 力扣\ntags:\n- 力扣\n---\n\n题目在此[面试题35．复杂的链表的复制](https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/)<br>\n\n有三种方法可以做这一道题<br>\n- 迭代法\n- BFS\n- DFS\nunordered_map<key,value>是无序的哈希函数<br>\t\n*unordered_map<Node\\*,Node\\*> copylist 其实是用来同步复制结点和原结点，例如，原结点到达了head.那么head的复制结点就是copylist\\[head\\],相当于把原结点和复制节点绑定了起来*<br>\n\t**这样做的好处是:**<br>\n举个例子若不使用unordered_map函数，我们创建3个复制结点就需要创建3个指针(例如：p1,p2,p3)去指向它，以备后续建立结点相互链接关系时再次访问，但是如果我原节点有10000个，那么我就需要手动创建10000个指针，而用了unordered_map就可以将创建的复制结点与原结点绑定起来，结点间建立链接关系时只需要通过原节点就可以访问相应的复制结点(原结点head的复制节点copylist\\[head\\])<br>\n\n*下面方法除了优化迭代法的时间复杂度为O(n)，空间复杂度为O(1)，其他的时间空间复杂度都为O(n)*\n\n### 迭代法<br>\n```\nclass Solution {\npublic:\n    Node* copyRandomList(Node* head) {\n       if(head==NULL) //防止传入head就是NULL\n       return head;\n       unordered_map<Node*,Node*>copylist;\n       Node* temp = head;\n       while(temp!=NULL) //先把所有结点复制一遍\n       {\n           copylist[temp]=new Node(temp->val);\n           temp=temp->next;\n       }\n       temp=head;\n       while(temp!=NULL) //复制每个结点的next关系\n       {\n               copylist[temp]->next=copylist[temp->next];\n               temp=temp->next;\n       } \n       temp=head;\n       while(temp!=NULL){ //复制每个结点的random关系\n           copylist[temp]->random=copylist[temp->random];\n           temp=temp->next;\n       }\n       return copylist[head];\n    }\n};\n```\n### 优化版迭代\n![优化版迭代](优化迭代法-图解.png)<br>\n\n**这个版本的迭代和普通的迭代有什么区别呢？**<br>\n*其实这个版本的用原节点的next指针代替了unordered_map，用来绑定(定位)复制结点*<br>\n```\nclass Solution {\npublic:\n    Node* copyRandomList(Node* head) {\n        if(head==NULL)\n        return head;\n        Node* cphead;\n        Node* start;\n        Node* end;\n        Node* temp=head;\n        while(temp!=NULL)\n        {\n            Node* copyhead=new Node(temp->val);\n            copyhead->next=temp->next;\n            temp->next=copyhead;\n            temp=temp->next->next;\n        }\n        //建立random链接\n        temp=head;\n        while(temp!=NULL)\n        {\n            if(temp->random!=NULL)\n            temp->next->random=temp->random->next;\n            else\n            temp->next->random=NULL;\n            temp=temp->next->next;\n        }\n        //建立next链接\n        cphead=head->next; //记录复制头节点的位置，以便return\n        start=head;\n        end=head->next;\n        while(end!=NULL)\n        {\n            start->next=end->next;\n            start=end;\n            end=end->next;\n        }\n        return cphead;\n    }\n};\n```\n\n### DFS<br>\n因为链表可以变相的可以看为一个图，所以我们可以用DFS解决，DFS递归就相当于保存了上一个节点的信息　(递归就像是一个另类的栈，隐藏的栈和linux0.11进程切换的隐藏栈差不多)．<br>\nDFS传递进去的参数是**DFS(期望建立链接的结点，哈希表)**<br>\nDFS递归的创建复杂结点，在返回的时候用copylist\\[head\\]->next 和 copylist\\[head\\]->random 来建立前后结点的链接关系．<br>\n```\nclass Solution {\npublic:\n //注意unordered_map<Node*,Node*> &copylist这里使用了引用\n    Node* DFS(Node* head,unordered_map<Node*,Node*> &copylist)\n    {\n        if(head==NULL)\n        return head;\n        //copylist[head].count用来计算head在哈希表中出现几次，因为unordered_map是不允许重复的所以只会返回0或１.\n\t\t\t\tif(copylist.count(head)) return copylist[head];  //如果已经创建过了所以就直接返回\n        copylist[head]=new Node(head->val);\n\t\t\t\tcopylist[head]->next=DFS(head->next,copylist); //这一句和下面一句就是结点之间建立链接关系的语句．\n        copylist[head]->random=DFS(head->random,copylist);\n        return copylist[head];\n    }\n\n   Node* copyRandomList(Node* head) {\n       unordered_map<Node*,Node*>copylist;\n       return DFS(head,copylist);\n    }\n};\n```\n### BFS<br>\n*其实和DFS差不多，就是换了一种遍历的方法，有一点和DFS不同就是BFS是在便利途中结点之间就建立了链接，但是DFS是在遍历完结后回退的过程中建立链接*<br>\n\n```\nclass Solution {\npublic:\n    Node* BFS(Node*head)\n    {\n        if(head==NULL)\n        return head;\n        unordered_map<Node*,Node*>copylist;\n        copylist[head]=new Node(head->val);\n\t\t\t\tqueue<Node*> q; //队列\n        q.push(head);\n        while(!q.empty()){\n            Node* temp=q.front();\n            q.pop();\n\t\t\t\t\t\t//建立next链接\n            if(temp->next!=NULL && copylist.count(temp->next))　//首先要判断下一个结点存不存在(存在则直接建立链接，不存在则是NULL或者还没建立)\n            {\n                copylist[temp]->next=copylist[temp->next];\n            }\n            else\n            {\n                if(temp->next!=NULL){　//下一个结点非NULL而是还没遍历到\n                copylist[temp->next]=new Node(temp->next->val);\n                copylist[temp]->next=copylist[temp->next];\n                q.push(temp->next);\n                }\n\t\t\t\t\t\t\t\telse　//下一个结点为NULL\n                copylist[temp]->next=NULL;\n            }\n\t\t\t\t\t\t//建立random 链接\n            if(temp->random!=NULL && copylist.count(temp->random))\n            {\n                copylist[temp]->random=copylist[temp->random];\n            }\n            else\n            {\n                if(temp->random!=NULL){\n                copylist[temp->random]=new Node(temp->random->val);\n                copylist[temp]->random= copylist[temp->random];\n                q.push(temp->random);\n                }\n                else\n                copylist[temp]->random=NULL;\n            }\n        }\n        return copylist[head];\n    }\n\n    Node* copyRandomList(Node* head) {\n        return BFS(head);\n    }\n};\n```\n","slug":"面试题35-复杂链表的复制","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4ss002jr8s8ccxkf2tn","content":"<p>题目在此<a href=\"https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/\">面试题35．复杂的链表的复制</a><br></p>\n<p>有三种方法可以做这一道题<br></p>\n<ul>\n<li>迭代法</li>\n<li>BFS</li>\n<li>DFS<br>unordered_map<key,value>是无序的哈希函数<br><br><em>unordered_map&lt;Node\\</em>,Node*&gt; copylist 其实是用来同步复制结点和原结点，例如，原结点到达了head.那么head的复制结点就是copylist[head],相当于把原结点和复制节点绑定了起来<em><br><br>  <em>*这样做的好处是:</em></em><br><br>举个例子若不使用unordered_map函数，我们创建3个复制结点就需要创建3个指针(例如：p1,p2,p3)去指向它，以备后续建立结点相互链接关系时再次访问，但是如果我原节点有10000个，那么我就需要手动创建10000个指针，而用了unordered_map就可以将创建的复制结点与原结点绑定起来，结点间建立链接关系时只需要通过原节点就可以访问相应的复制结点(原结点head的复制节点copylist[head])<br></li>\n</ul>\n<p><em>下面方法除了优化迭代法的时间复杂度为O(n)，空间复杂度为O(1)，其他的时间空间复杂度都为O(n)</em></p>\n<h3 id=\"迭代法\"><a href=\"#迭代法\" class=\"headerlink\" title=\"迭代法\"></a>迭代法<br></h3><figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs php\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> </span>&#123;<br><span class=\"hljs-keyword\">public</span>:<br>    Node* copyRandomList(Node* head) &#123;<br>       <span class=\"hljs-keyword\">if</span>(head==<span class=\"hljs-literal\">NULL</span>) <span class=\"hljs-comment\">//防止传入head就是NULL</span><br>       <span class=\"hljs-keyword\">return</span> head;<br>       unordered_map&lt;Node*,Node*&gt;copylist;<br>       Node* temp = head;<br>       <span class=\"hljs-keyword\">while</span>(temp!=<span class=\"hljs-literal\">NULL</span>) <span class=\"hljs-comment\">//先把所有结点复制一遍</span><br>       &#123;<br>           copylist[temp]=<span class=\"hljs-keyword\">new</span> Node(temp-&gt;val);<br>           temp=temp-&gt;next;<br>       &#125;<br>       temp=head;<br>       <span class=\"hljs-keyword\">while</span>(temp!=<span class=\"hljs-literal\">NULL</span>) <span class=\"hljs-comment\">//复制每个结点的next关系</span><br>       &#123;<br>               copylist[temp]-&gt;next=copylist[temp-&gt;next];<br>               temp=temp-&gt;next;<br>       &#125; <br>       temp=head;<br>       <span class=\"hljs-keyword\">while</span>(temp!=<span class=\"hljs-literal\">NULL</span>)&#123; <span class=\"hljs-comment\">//复制每个结点的random关系</span><br>           copylist[temp]-&gt;random=copylist[temp-&gt;random];<br>           temp=temp-&gt;next;<br>       &#125;<br>       <span class=\"hljs-keyword\">return</span> copylist[head];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"优化版迭代\"><a href=\"#优化版迭代\" class=\"headerlink\" title=\"优化版迭代\"></a>优化版迭代</h3><p><img src=\"优化迭代法-图解.png\" alt=\"优化版迭代\"><br></p>\n<p><strong>这个版本的迭代和普通的迭代有什么区别呢？</strong><br><br><em>其实这个版本的用原节点的next指针代替了unordered_map，用来绑定(定位)复制结点</em><br><br><figure class=\"highlight xl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xl\">class Solution &#123;<br>public:<br>    Node* copyRandomList(Node* head) &#123;<br>        <span class=\"hljs-keyword\">if</span>(head==NULL)<br>        return head;<br>        Node* cphead;<br>        Node* start;<br>        Node* end;<br>        Node* temp=head;<br>        <span class=\"hljs-keyword\">while</span>(temp!=NULL)<br>        &#123;<br>            N<span class=\"hljs-function\"><span class=\"hljs-title\">ode</span>* copyhead=new Node(temp-&gt;</span>val);<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">copyhead</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=temp-&gt;</span>next;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>-&gt;</span>next=copyhead;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>=temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>next;<br>        &#125;<br>        <span class=\"hljs-comment\">//建立random链接</span><br>        temp=head;<br>        <span class=\"hljs-keyword\">while</span>(temp!=NULL)<br>        &#123;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span>random!=NULL)<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>=temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>-&gt;</span>next;<br>            <span class=\"hljs-keyword\">else</span><br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>random=NULL;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>=temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>next;<br>        &#125;<br>        <span class=\"hljs-comment\">//建立next链接</span><br>        <span class=\"hljs-function\"><span class=\"hljs-title\">cphead</span>=head-&gt;</span>next; <span class=\"hljs-comment\">//记录复制头节点的位置，以便return</span><br>        start=head;<br>        <span class=\"hljs-function\"><span class=\"hljs-title\">end</span>=head-&gt;</span>next;<br>        <span class=\"hljs-keyword\">while</span>(end!=NULL)<br>        &#123;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">start</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=end-&gt;</span>next;<br>            start=end;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">end</span>=end-&gt;</span>next;<br>        &#125;<br>        return cphead;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure></p>\n<h3 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS<br></h3><p>因为链表可以变相的可以看为一个图，所以我们可以用DFS解决，DFS递归就相当于保存了上一个节点的信息　(递归就像是一个另类的栈，隐藏的栈和linux0.11进程切换的隐藏栈差不多)．<br><br>DFS传递进去的参数是<strong>DFS(期望建立链接的结点，哈希表)</strong><br><br>DFS递归的创建复杂结点，在返回的时候用copylist[head]-&gt;next 和 copylist[head]-&gt;random 来建立前后结点的链接关系．<br><br><figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\"><span class=\"hljs-keyword\">class</span> Solution &#123;<br>public:<br> <span class=\"hljs-comment\">//注意unordered_map&lt;Node*,Node*&gt; &amp;copylist这里使用了引用</span><br>    Node* <span class=\"hljs-constructor\">DFS(Node<span class=\"hljs-operator\">*</span> <span class=\"hljs-params\">head</span>,<span class=\"hljs-params\">unordered_map</span>&lt;Node<span class=\"hljs-operator\">*</span>,Node<span class=\"hljs-operator\">*</span>&gt; &amp;<span class=\"hljs-params\">copylist</span>)</span><br>    &#123;<br>        <span class=\"hljs-keyword\">if</span>(head==NULL)<br>        return head;<br>        <span class=\"hljs-comment\">//copylist[head].count用来计算head在哈希表中出现几次，因为unordered_map是不允许重复的所以只会返回0或１.</span><br>\t\t\t\t<span class=\"hljs-keyword\">if</span>(copylist.count(head)) return copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>;  <span class=\"hljs-comment\">//如果已经创建过了所以就直接返回</span><br>        copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>=<span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">Node(<span class=\"hljs-params\">head</span>-&gt;<span class=\"hljs-params\">val</span>)</span>;<br>\t\t\t\tcopylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>-&gt;next=<span class=\"hljs-constructor\">DFS(<span class=\"hljs-params\">head</span>-&gt;<span class=\"hljs-params\">next</span>,<span class=\"hljs-params\">copylist</span>)</span>; <span class=\"hljs-comment\">//这一句和下面一句就是结点之间建立链接关系的语句．</span><br>        copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>-&gt;random=<span class=\"hljs-constructor\">DFS(<span class=\"hljs-params\">head</span>-&gt;<span class=\"hljs-params\">random</span>,<span class=\"hljs-params\">copylist</span>)</span>;<br>        return copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>;<br>    &#125;<br><br>   Node* copy<span class=\"hljs-constructor\">RandomList(Node<span class=\"hljs-operator\">*</span> <span class=\"hljs-params\">head</span>)</span> &#123;<br>       unordered_map&lt;Node*,Node*&gt;copylist;<br>       return <span class=\"hljs-constructor\">DFS(<span class=\"hljs-params\">head</span>,<span class=\"hljs-params\">copylist</span>)</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure></p>\n<h3 id=\"BFS\"><a href=\"#BFS\" class=\"headerlink\" title=\"BFS\"></a>BFS<br></h3><p><em>其实和DFS差不多，就是换了一种遍历的方法，有一点和DFS不同就是BFS是在便利途中结点之间就建立了链接，但是DFS是在遍历完结后回退的过程中建立链接</em><br></p>\n<figure class=\"highlight xl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xl\">class Solution &#123;<br>public:<br>    Node* BFS(Node*head)<br>    &#123;<br>        <span class=\"hljs-keyword\">if</span>(head==NULL)<br>        return head;<br>        unordered_map&lt;Node*,Node*&gt;copylist;<br>        <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[head]=new Node(head-&gt;</span>val);<br>\t\t\t\tqueue&lt;Node*&gt; q; <span class=\"hljs-comment\">//队列</span><br>        q.push(head);<br>        <span class=\"hljs-keyword\">while</span>(!q.empty())&#123;<br>            Node* temp=q.front();<br>            q.pop();<br>\t\t\t\t\t\t<span class=\"hljs-comment\">//建立next链接</span><br>            <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>!=NULL &amp;&amp; copylist.count(temp-&gt;</span>next))　<span class=\"hljs-comment\">//首先要判断下一个结点存不存在(存在则直接建立链接，不存在则是NULL或者还没建立)</span><br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=copylist[temp-&gt;</span>next];<br>            &#125;<br>            <span class=\"hljs-keyword\">else</span><br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span>next!=NULL)&#123;　<span class=\"hljs-comment\">//下一个结点非NULL而是还没遍历到</span><br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>]=new Node(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>val);<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=copylist[temp-&gt;</span>next];<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">q</span>.push(temp-&gt;</span>next);<br>                &#125;<br>\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">else</span>　<span class=\"hljs-comment\">//下一个结点为NULL</span><br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span>next=NULL;<br>            &#125;<br>\t\t\t\t\t\t<span class=\"hljs-comment\">//建立random 链接</span><br>            <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>!=NULL &amp;&amp; copylist.count(temp-&gt;</span>random))<br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>=copylist[temp-&gt;</span>random];<br>            &#125;<br>            <span class=\"hljs-keyword\">else</span><br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span>random!=NULL)&#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>]=new Node(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>-&gt;</span>val);<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>= copylist[temp-&gt;</span>random];<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">q</span>.push(temp-&gt;</span>random);<br>                &#125;<br>                <span class=\"hljs-keyword\">else</span><br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span>random=NULL;<br>            &#125;<br>        &#125;<br>        return copylist[head];<br>    &#125;<br><br>    Node* copyRandomList(Node* head) &#123;<br>        return BFS(head);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<p>题目在此<a href=\"https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/\">面试题35．复杂的链表的复制</a><br></p>\n<p>有三种方法可以做这一道题<br></p>\n<ul>\n<li>迭代法</li>\n<li>BFS</li>\n<li>DFS<br>unordered_map<key,value>是无序的哈希函数<br><br><em>unordered_map&lt;Node\\</em>,Node*&gt; copylist 其实是用来同步复制结点和原结点，例如，原结点到达了head.那么head的复制结点就是copylist[head],相当于把原结点和复制节点绑定了起来<em><br><br>  <em>*这样做的好处是:</em></em><br><br>举个例子若不使用unordered_map函数，我们创建3个复制结点就需要创建3个指针(例如：p1,p2,p3)去指向它，以备后续建立结点相互链接关系时再次访问，但是如果我原节点有10000个，那么我就需要手动创建10000个指针，而用了unordered_map就可以将创建的复制结点与原结点绑定起来，结点间建立链接关系时只需要通过原节点就可以访问相应的复制结点(原结点head的复制节点copylist[head])<br></li>\n</ul>\n<p><em>下面方法除了优化迭代法的时间复杂度为O(n)，空间复杂度为O(1)，其他的时间空间复杂度都为O(n)</em></p>\n<h3 id=\"迭代法\"><a href=\"#迭代法\" class=\"headerlink\" title=\"迭代法\"></a>迭代法<br></h3><figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs php\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Solution</span> </span>&#123;<br><span class=\"hljs-keyword\">public</span>:<br>    Node* copyRandomList(Node* head) &#123;<br>       <span class=\"hljs-keyword\">if</span>(head==<span class=\"hljs-literal\">NULL</span>) <span class=\"hljs-comment\">//防止传入head就是NULL</span><br>       <span class=\"hljs-keyword\">return</span> head;<br>       unordered_map&lt;Node*,Node*&gt;copylist;<br>       Node* temp = head;<br>       <span class=\"hljs-keyword\">while</span>(temp!=<span class=\"hljs-literal\">NULL</span>) <span class=\"hljs-comment\">//先把所有结点复制一遍</span><br>       &#123;<br>           copylist[temp]=<span class=\"hljs-keyword\">new</span> Node(temp-&gt;val);<br>           temp=temp-&gt;next;<br>       &#125;<br>       temp=head;<br>       <span class=\"hljs-keyword\">while</span>(temp!=<span class=\"hljs-literal\">NULL</span>) <span class=\"hljs-comment\">//复制每个结点的next关系</span><br>       &#123;<br>               copylist[temp]-&gt;next=copylist[temp-&gt;next];<br>               temp=temp-&gt;next;<br>       &#125; <br>       temp=head;<br>       <span class=\"hljs-keyword\">while</span>(temp!=<span class=\"hljs-literal\">NULL</span>)&#123; <span class=\"hljs-comment\">//复制每个结点的random关系</span><br>           copylist[temp]-&gt;random=copylist[temp-&gt;random];<br>           temp=temp-&gt;next;<br>       &#125;<br>       <span class=\"hljs-keyword\">return</span> copylist[head];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>\n<h3 id=\"优化版迭代\"><a href=\"#优化版迭代\" class=\"headerlink\" title=\"优化版迭代\"></a>优化版迭代</h3><p><img src=\"优化迭代法-图解.png\" alt=\"优化版迭代\"><br></p>\n<p><strong>这个版本的迭代和普通的迭代有什么区别呢？</strong><br><br><em>其实这个版本的用原节点的next指针代替了unordered_map，用来绑定(定位)复制结点</em><br><br><figure class=\"highlight xl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xl\">class Solution &#123;<br>public:<br>    Node* copyRandomList(Node* head) &#123;<br>        <span class=\"hljs-keyword\">if</span>(head==NULL)<br>        return head;<br>        Node* cphead;<br>        Node* start;<br>        Node* end;<br>        Node* temp=head;<br>        <span class=\"hljs-keyword\">while</span>(temp!=NULL)<br>        &#123;<br>            N<span class=\"hljs-function\"><span class=\"hljs-title\">ode</span>* copyhead=new Node(temp-&gt;</span>val);<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">copyhead</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=temp-&gt;</span>next;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>-&gt;</span>next=copyhead;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>=temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>next;<br>        &#125;<br>        <span class=\"hljs-comment\">//建立random链接</span><br>        temp=head;<br>        <span class=\"hljs-keyword\">while</span>(temp!=NULL)<br>        &#123;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span>random!=NULL)<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>=temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>-&gt;</span>next;<br>            <span class=\"hljs-keyword\">else</span><br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>random=NULL;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">temp</span>=temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>next;<br>        &#125;<br>        <span class=\"hljs-comment\">//建立next链接</span><br>        <span class=\"hljs-function\"><span class=\"hljs-title\">cphead</span>=head-&gt;</span>next; <span class=\"hljs-comment\">//记录复制头节点的位置，以便return</span><br>        start=head;<br>        <span class=\"hljs-function\"><span class=\"hljs-title\">end</span>=head-&gt;</span>next;<br>        <span class=\"hljs-keyword\">while</span>(end!=NULL)<br>        &#123;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">start</span>-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=end-&gt;</span>next;<br>            start=end;<br>            <span class=\"hljs-function\"><span class=\"hljs-title\">end</span>=end-&gt;</span>next;<br>        &#125;<br>        return cphead;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure></p>\n<h3 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS<br></h3><p>因为链表可以变相的可以看为一个图，所以我们可以用DFS解决，DFS递归就相当于保存了上一个节点的信息　(递归就像是一个另类的栈，隐藏的栈和linux0.11进程切换的隐藏栈差不多)．<br><br>DFS传递进去的参数是<strong>DFS(期望建立链接的结点，哈希表)</strong><br><br>DFS递归的创建复杂结点，在返回的时候用copylist[head]-&gt;next 和 copylist[head]-&gt;random 来建立前后结点的链接关系．<br><br><figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\"><span class=\"hljs-keyword\">class</span> Solution &#123;<br>public:<br> <span class=\"hljs-comment\">//注意unordered_map&lt;Node*,Node*&gt; &amp;copylist这里使用了引用</span><br>    Node* <span class=\"hljs-constructor\">DFS(Node<span class=\"hljs-operator\">*</span> <span class=\"hljs-params\">head</span>,<span class=\"hljs-params\">unordered_map</span>&lt;Node<span class=\"hljs-operator\">*</span>,Node<span class=\"hljs-operator\">*</span>&gt; &amp;<span class=\"hljs-params\">copylist</span>)</span><br>    &#123;<br>        <span class=\"hljs-keyword\">if</span>(head==NULL)<br>        return head;<br>        <span class=\"hljs-comment\">//copylist[head].count用来计算head在哈希表中出现几次，因为unordered_map是不允许重复的所以只会返回0或１.</span><br>\t\t\t\t<span class=\"hljs-keyword\">if</span>(copylist.count(head)) return copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>;  <span class=\"hljs-comment\">//如果已经创建过了所以就直接返回</span><br>        copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>=<span class=\"hljs-keyword\">new</span> <span class=\"hljs-constructor\">Node(<span class=\"hljs-params\">head</span>-&gt;<span class=\"hljs-params\">val</span>)</span>;<br>\t\t\t\tcopylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>-&gt;next=<span class=\"hljs-constructor\">DFS(<span class=\"hljs-params\">head</span>-&gt;<span class=\"hljs-params\">next</span>,<span class=\"hljs-params\">copylist</span>)</span>; <span class=\"hljs-comment\">//这一句和下面一句就是结点之间建立链接关系的语句．</span><br>        copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>-&gt;random=<span class=\"hljs-constructor\">DFS(<span class=\"hljs-params\">head</span>-&gt;<span class=\"hljs-params\">random</span>,<span class=\"hljs-params\">copylist</span>)</span>;<br>        return copylist<span class=\"hljs-literal\">[<span class=\"hljs-identifier\">head</span>]</span>;<br>    &#125;<br><br>   Node* copy<span class=\"hljs-constructor\">RandomList(Node<span class=\"hljs-operator\">*</span> <span class=\"hljs-params\">head</span>)</span> &#123;<br>       unordered_map&lt;Node*,Node*&gt;copylist;<br>       return <span class=\"hljs-constructor\">DFS(<span class=\"hljs-params\">head</span>,<span class=\"hljs-params\">copylist</span>)</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure></p>\n<h3 id=\"BFS\"><a href=\"#BFS\" class=\"headerlink\" title=\"BFS\"></a>BFS<br></h3><p><em>其实和DFS差不多，就是换了一种遍历的方法，有一点和DFS不同就是BFS是在便利途中结点之间就建立了链接，但是DFS是在遍历完结后回退的过程中建立链接</em><br></p>\n<figure class=\"highlight xl\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xl\">class Solution &#123;<br>public:<br>    Node* BFS(Node*head)<br>    &#123;<br>        <span class=\"hljs-keyword\">if</span>(head==NULL)<br>        return head;<br>        unordered_map&lt;Node*,Node*&gt;copylist;<br>        <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[head]=new Node(head-&gt;</span>val);<br>\t\t\t\tqueue&lt;Node*&gt; q; <span class=\"hljs-comment\">//队列</span><br>        q.push(head);<br>        <span class=\"hljs-keyword\">while</span>(!q.empty())&#123;<br>            Node* temp=q.front();<br>            q.pop();<br>\t\t\t\t\t\t<span class=\"hljs-comment\">//建立next链接</span><br>            <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>!=NULL &amp;&amp; copylist.count(temp-&gt;</span>next))　<span class=\"hljs-comment\">//首先要判断下一个结点存不存在(存在则直接建立链接，不存在则是NULL或者还没建立)</span><br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=copylist[temp-&gt;</span>next];<br>            &#125;<br>            <span class=\"hljs-keyword\">else</span><br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span>next!=NULL)&#123;　<span class=\"hljs-comment\">//下一个结点非NULL而是还没遍历到</span><br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>]=new Node(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>-&gt;</span>val);<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">next</span>=copylist[temp-&gt;</span>next];<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">q</span>.push(temp-&gt;</span>next);<br>                &#125;<br>\t\t\t\t\t\t\t\t<span class=\"hljs-keyword\">else</span>　<span class=\"hljs-comment\">//下一个结点为NULL</span><br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span>next=NULL;<br>            &#125;<br>\t\t\t\t\t\t<span class=\"hljs-comment\">//建立random 链接</span><br>            <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>!=NULL &amp;&amp; copylist.count(temp-&gt;</span>random))<br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>=copylist[temp-&gt;</span>random];<br>            &#125;<br>            <span class=\"hljs-keyword\">else</span><br>            &#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">if</span>(temp-&gt;</span>random!=NULL)&#123;<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>]=new Node(temp-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>-&gt;</span>val);<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span><span class=\"hljs-function\"><span class=\"hljs-title\">random</span>= copylist[temp-&gt;</span>random];<br>                <span class=\"hljs-function\"><span class=\"hljs-title\">q</span>.push(temp-&gt;</span>random);<br>                &#125;<br>                <span class=\"hljs-keyword\">else</span><br>                <span class=\"hljs-function\"><span class=\"hljs-title\">copylist</span>[temp]-&gt;</span>random=NULL;<br>            &#125;<br>        &#125;<br>        return copylist[head];<br>    &#125;<br><br>    Node* copyRandomList(Node* head) &#123;<br>        return BFS(head);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>"},{"title":"Chapter 2: Application Layer","date":"2020-03-28T15:51:42.000Z","index_img":"/Picture/Application-layer.png","_content":"**The questions is provided below,we can find the answer in the Computer Network A Top-down Approach**\n# HTTP\n- HTTP is said to be a stateless protocol\n##  no-persistent-connections and persistent-connections\nno-persistent-connections:Client obtains the 10 JPEGs over 10 serial TCP connections or whether JEPGs are obtained over parallel TCP connections?<br>\n\nAdvantage of persistent-connections(or disadvantage of no-persistent-connections):NO-persistent-connection has some shortcoming.First, a brand-new connection must be established and maintained for each requires objects. For earn TCP connections, TCP buffer must be allocated and TCP variable keeps between client and servers, This is a significant burden on the web servers. But persistent-connections don't need to establish so many connections, just establish once connections can work.<br>\n## HTTP Require and Response\n**HTTP-Require**\n![HTTP-Require](HTTP_requires.png)\n\n**HTTP-Response**\n![HTTP-Response](HTTP_respont.png)\n## Cookie\nCookie allow web site to keep track of users.<br>\nCookie technology has four components: <br>\n- a cookie header line in the HTTP response message.\n- a cookie header line in the HTTP require message.\n- a cookie file kept on user's end system and managed by user's browser\n- a cookie back-end database at the web site.\n\n![HTTP-Cookie](Cookie-process.png)\n## Web cache\nWeb cache also called proxy servers,Web cache can increasing response speed and reduce the cost of throughput.\n\n![HTTP-Web cache](Web-cache.png)\n## The condition GET\nAt explore above ,We already have cache ,We now face a problem is that if the informations  of requirements have been modified but the cache still stored the old information ,How to solve this problem?<br>\nThe answer is **The condition GET** ,. We can see details at the Computer network a Top-Down Approach<br>\n# File Transfer Protocol (FTP)\n## control connection and data connection<br>\n**Control connection** is used for sending control informations between two host, such as identification, password, commands<br>\n**Data connection** is used for actually send a file .<br>\n\nFTP use port 21 as Control connection and use port 20 as Data connection<br>\n![FTP-TCP](FTP-TCP-connections.png)\nAs you see,FTP is established two TCP connections<br>\n\nIn the typically FTP sessions, Users initial access remote hosts, namely establish TCP control connection used port 21, then provide identifications and passwords through port 21. After providing this authorization information. Users can transfer files from localhost to remote host vice versa.\n\n![FTP-transfer-file](FTP-transfer-file.png)\nIf user wanna to transfer another files during the same sessions,FTP will opens the another **data connections**(The data connections is no-persistent)<br>\nThroughout a sessions,the FTP servers must maintain state about the user. In particularly, The servers must be associate the **control connections** with a specific user and must keep track of user's current directory as user's wanders about the remote directory tree.<br>\n\n## FTP Commands and Replies\nThe FTP Commands and Replies sent across the control connection in 7-bits ASCLL format.<br>\nWe can see details at computer-network-a-top-down-approach.\n\n# SMTP(Simple Mail Transfer Protocol)\nSMTP is a principal application layer protocol for electronic mail. As most application layer protocol, SMTP base on TCP provides reliable data transfer service and SMTP also has two side , client side which executes on the sender's mail server, servers side which executes on recipient's mail servers. When the mail server send mail to other mail servers , it act as a SMTP client, when the mail server receive mail from other mail server, it act as SMTP server.\n![SMTP-transfer](SMTP-transfer.png)\n1. Alice provides Bob's email-address and composes a message then instruct Alice's agent  send the message to Bob.<br>\n2. Alice's send the message to Alice's mail servers,where it is placeing in message queue.<br>\n3. Alice's mail server established TCP connections to port 25 at Bob's mail server. <br>\n4. After initail SMTP handshaking, the SMTP client (Alice's mail server) send the message to Bob's server through TCP connection.<br>\n5. The recipient side receives the message and places the message in Bob mailbox.<br>\n6. Bob invoke his user agent to read the message at his convenience.<br>\n\n*In particular , if Bob's mail server is down . The message can't send to Bob's mail server, the message will remain in Alice's mail server and wait for a new attempt -- the message do not get place in any other intermediate mail server, Reattempt done for every 30 minutes , if\nresend  not success after several day , Alice's mail server remove the message and notice Alice with e-mail message*<br> **More details of SMTP handshake or SMTP commands please see the Computer Network A Top-Down Approach** <br>\n ## Comparison with HTTP\n1. HTTP and SMTP both use persistent connections\n2. HTTP is mainly a pull protocol -- Some one load information with browser on web servers or use HTTP to pull some information from the server at their convenience. SMTP is mainly a push protocol -- The sending mail server push file to other receiving mail server . <br> \n3. SMTP requires each message include body of each message that must be encode be 7-bit-ASCLL , so that The SMTP is a bit of pain to send the large attachment ,video, image, audio. But HTTP data does not impose this restriction. <br>\n4. HTTP encapsulate each object in it own HTTP response message , SMTP place all message's object into one message. \n## Mail Access Protocol\nBob can't obtain the message through SMTP from the Bob's mail server. Because SMTP is push protocol,obtain message is pull operation. To solve this problem by introducing a special mail access protocol that transfer messages from Bob's mail server to Bob's host .There are currently a number of mail access protocol including **Post Office Protocol - version 3 (POP3),Internet Mail Access Protocol (IMAP) and HTTP**\n![SMTP-access-mail](SMTP-access-mail.png)\n\n### POP3 (Post Office Protocol -Version 3)\nPOP3 Bob's agent use port 110 establish TCP connection with Bob's mail servers , With the TCP connections established , POP3 through three phase: **authorization**, **transaction**, **Update**.<br>\n1. **authorization**: Bob's agent send the username and password to authenticate the user 2. **transaction**: During this phase , user agent can mark retrieves the message also can mark message for deletion (or remove the mask) ,and obtain mail statistic .  3. **Update**: Update occurs after user agent issued the *quit* command ending this POP3 session ,at this time, mail server will delete messages that were marked for deletion.<br>\n\n*more details about POP3 commands or process can see in the textbook*<br>\n\n**During the POP3 sessions, the user agent and mail server maintain some state information. For example, maintain mark information for deletion during this POP3 session. However, POP3 doesn't carry state information across POP3 sessions. (As I think, that's mean POP3 maintain state information only occurs at POP3 sessions phase ,the state information will be deleted,if user agent ending the session)**\n### IMAP (Internet Mail Access Protocol)\nThe IMAP is significantly complex than POP3,and more feature than POP3<br>\n**The most significantly difference is IMAP can carry the state informations across IMAP sessions, but POP3 can't**<br>\n\n### Web-base Email (use HTTP)\nWeb-base Email also famous today, for example gmail . Web browser and user communicates with its mailbox via HTTP.\n\n# DNS (domain name system)\n**The DNS protocols run over UDP and uses port 53.** <br>\n\nThe DNS is commonly employed by other application-layer protocol --including HTTP,SMTP, and FTP --to translate the user-supplied hostnames to IP address.<br>\n\nWe see example above the DNS adds an additional delay, but ,fortunately the DNS cache will help reduce this delay. <br>\n\nDNS provide features: **Host aliasing** , **Mail server aliasing** , **Load distribution**\n- host aliasing and mail server aliasing make hostnames more mnemonic.<br>\n- load distribution : For replicated web server , a numbers set of IP address associated with one canonical hostname . It can make server easier to handle the large access .<br>\n## overview of how DNS work\n**Let's take closer to look at these three classes of DNS servers** <br>\n- Root DNS servers.\n- Top-level domain(TLD) server.\n- Authoritative DNS server.\n\nTake a look a simple example : **www.amazon.com.** (Don't forget we have a . at the end) <br>\n- The **.** is Root DNS servers.\n- The **com.** is Top-lever domain (TLD) server\n- The **amazon.com.** is Authoritative DNS server.\n- The **www** is hostname \n![DNS-hierarchy](DNS-hierarchy.png)\nWe also have a another critically important DNS servers is **Local DNS server** that does not strictly belong to the hierarchy of DNS server.<br>\nWhen the host make a DNS query, the query is send to Local DNS server which act as proxy forwarding the query into the DNS hierarchy server.<br>\n## Two way for send DNS queries\n- **iterative queries** \n![DNS-iterative-queries](DNS-server-iterative-queries.png)\n- **recursive queries**\n![DNS-recursive-queries](DNS-server-recursive-queries.png)\n## DNS caching\nWe reduce the delay of DNS server by DNS cache technology.<br>\n\n**The DNS server receives a DNS reply (for example the mapping of IP address and hostname) it can cache the mapping into the local memory(also can cache the mapping of TLD servers). For example , the local DNS server can cache the mapping of each host queries,When the user's host send a query to local DNS server frequently at the short period of time . The local DNS server can send the reply to user's host instantly**.<br>\n\n*The DNS servers discard the cache information after a period time (Often set to one or two day)*<br>\n## DNS Records and Messages\n### DNS Records\nThe DNS distributed database store **resource records (RRs)**<br>\nThe RRs provide Hostname-to-IP address mappings.Each DNS reply carries one or more RRs .<br>\n#### DNS Records Format\nThe DNS Record have four fields that provide following below.<br>\n\n|Name|Value|Type|TTL|\n|:-----|:-----|:-----|:-----|\n\nThe TTL is live time of Records in the RRs . The meaning of Name and Value is depend on Type. <br>\n\nIn following example we will ignore the TTL filed.<br>\n\n|Type|Name|Value|Description|\n|:-----:|:-----:|:-----:|:-----:|\n|A|Hostname|IP address|Address record|\n|NS|Domain|Hostname of authoritative|Name server record|\n|CNAME|Alisa hostname|Canonical name|Canonical name record|\n|MX|Alisa hostname of mail server|Canonical name of mail server|Mail exchange record|\n\n\n**If a DNS server is authoritative for particular hostname ,then the DNS server will contain type A record for the hostname.**<br>\n\n**If a DNS server is not authoritative for a hostname ,then it will contain a type NS record for domain that include hostname, it also contain a type A record that provide IP address of DNS server in the value field of the NS record.**<br>\n- For example in the TLD server<br>\n\n|Type|Name|Value|\n|:-----:|:-----:|:-----:|\n|NS|umass.edu|dns.umass.edu|\n|A|dns.umass.edu|128.119.40.111|\n\n\n\n## DNS Messages\nThe DNS query and DNS reply have same Messages format as shown in Figure below .<br>\n- **DNS-Messages-Format** \n![DNS-Messages](DNS-Messages.png)\n\n- **We can use dig command to see DNS reply messages**\n\n![DNS-Messages-dig](DNS-Messagas-dig.png)\nID:30379 is 16-bit number that identifies the query corresponding **identification** of figure above .This identifies is copied into the reply messages allowing the client match receive messages with sent queries. <br>\n**Let's see more detail about header flags format**<br>\n\n|Flag field|Description|Length(bits)|\n|:----:|:----:|:----:|\n|OR|indicate message is reply(1) or query(0) |1|\n|OPCODE|The type can be QUERY(standard query ,0),IQUERY(inverse query,1) or STATUS(server status request,2)|4|\n|AA|Authoritative Answer, in the response,indicates if the DNS server is authoritative for queried hostname|1|\n|TC|Truncation, indicates that this messages was truncated due excessive length|1|\n|RD|Recursion desired indicate if client means a recursion query.|1|\n|RA|Recursion Available indicate if reply messages supports recursion|1|\n|Z|zero ,reserved for future use|3|\n|RCODE|Response code, can be NOERROR(0),FORMERR(format error,1),SERVFAIL(2),NXDOMAIN(nonexistent domain 3),etc|4|\n\n\n# Peer-to-Peer Applications\n## BitTorrent\nBitTorrent is popular P2P protocol for file distribution.<br>\n\nIn BItTorrent lingo, the collection of all peer in the distribution is called torrent.<br>\n\nEach torrent has a infrastructure called tracker.When a peer join in a torrent, it must register itself with tracker and periodically informs the tracker that it is still in the torrent. In this manner the tracker can keep the track of the peers that participating in the torrent. <br> \n\n**Let we see a example to know more detail about how does p2p work.**<br>\nWhen a new peer Alice  want to join in torrent,what does it need to do.\n1. Alice must register herself with tracker.\n2. The tracker will randomly select a subset of peers from a set of participating peers and send the all IP address of subset peers to Alice\n3. Alice attempts concurrent establish TCP connection with subset peers. The succeed establish TCP connection peer is called **\"neighboring peers\"**. The neighboring peer probably leave at any time .\n4. Periodically Alice will ask (over the TCP connection)neighboring peer for list of chucks they have. If Alice have L neighboring peers ,Alice will obtain L list of chuck that neighboring peers have, with this knowledge, Alice can issue(over the TCP connection) require for chucks she current doesn't have .\n5. Along with time pass .Alice have a set of chuck and know which chuck her neighboring peers have . At this instant of time .**Alice will issue require for chucks her doesn't have and rarest among her neighboring peers** and **Use clever trading algorithm determine which require her need to response namely which neighboring peer she need send the chuck(about the clever trading algorithm we discuss below)** <br>\n### Incentive mechanism: Clever trading algorithm\nTo determine which require  need to response , BitTorrent use clever trading algorithm.<br>\n\nSpecifically. For each of her neighboring peers , Alice will continuity measures the rate at which she receive bits and determine the four peer that feed her bit at the highest rate. Alice will reciprocates by send the chucks to these same four peers.<br>\n\nIn the BitTorrent lingo , the four peers is said to be **unchoked**.\nEvery 10 seconds , Alice will recalculates the rate and possibly modifies the set of four peers.<br> \n\nIn specially, every 30 seconds , Alice will select a addition neighboring peer at random and send it chuck, The peer is said to be **optimistically unchocked** , The optimistically unchocked may become one of Alice's top four peer , if it rate which send chuck to Alice is high enough.<br>\nThe optimistically unchocked allow new peer to get chuck so that they can have something to trade. All the other neighboring peers beside the five peers (one optimistically unchoked and four unchoked) can't received any chucks from Alice.\n# distributed Hash Table (DHTs)\nDistributed Hash Table is referred to a distributed P2P version database.<br>\n## Circular DHT\nEach peer only award two peers ,immediate successor and predecessor<br>\n\nWe use a hash function map each key to a integer in the ranger [0-2^n-1]. For example suppose n = 4 ,we get the ranger is [0-15]. Further suppose that these are eight peer in the system 1,3,4,5,8,10,12,15. Suppose we want to stored a pair (format:key value) (11,johnny wu) to one of peers in the system. Using out closest conventions ,since peer 12 is closest successor for key 11. We therefore store the pair into peer 12.<br>\n**Let's see more detail about the example that we mentioned above.**<br>\n\nIf the peer 3 (in figure below) want to know \"who is responsible for key 11\", it only send the messages to clockwise around the circle , namely pass the message to peer 4 , if peer 4 don't responsible key 11, it just passes the message to peer 5 , This process continues until the message arrives at the peer 12 , peer 12 receive the message will send response back to peer 3.\n\n![circle](Circle-DHT.png)<br>\n\nThis circular arrangement of the peers is a special case of an overlay network. In an overlay network, the peers form an abstract logical network which resides above the “underlay” computer network consisting of physical links, routers,and hosts. The links in an overlay network are not physical links, but are simply vir-tual liaisons between pairs of peers. In the overlay in Figure(a) above, there are eightpeers and eight overlay links; in the overlay in Figure (b) there are eight peersand 16 overlay links. A single overlay link typically uses many physical links and physical routers in the underlay network.<br>\n\nThe circular DHT provide a elegant way to build the database , but all N peer in the system , we have to forward the message around the circle , N/2 message are send average.<br>\n\nFortunately we can refine the circular DHT, we can add a number of **shortcut** to each peer in the system . So that the each peer not only keep track of successor and predecessor but also keep track of a small number of shortcut like figure(b) above.<br>\n\nThus,when the peer 4 receives message passes from peer 3 asking about key 11, it can determine the closer peer to key is its shortcut peer 10,then forward message directly to peer 10. Clearly the shortcut can significantly reduce the number of messages used to query<br>\n\nThe next native question is \"How many shortcut should the peer have and which peer should be these neighboring shortcut. \"<br>\nThe answer doesn't referred in the textbook (computer-network-a-top-down-approach),we can only search with network use google.<br>\n## peer churn\nAbout peer churn we can learn in textbook page 155.\n","source":"_posts/Chapter-2-Application-Layer.md","raw":"---\ntitle: 'Chapter 2: Application Layer'\ndate: 2020-03-28 23:51:42\nindex_img: /Picture/Application-layer.png\ncategories:\n- Computer Network A Top-Down Approach\ntags:\n- Computer Network A Top-Down Approach\n---\n**The questions is provided below,we can find the answer in the Computer Network A Top-down Approach**\n# HTTP\n- HTTP is said to be a stateless protocol\n##  no-persistent-connections and persistent-connections\nno-persistent-connections:Client obtains the 10 JPEGs over 10 serial TCP connections or whether JEPGs are obtained over parallel TCP connections?<br>\n\nAdvantage of persistent-connections(or disadvantage of no-persistent-connections):NO-persistent-connection has some shortcoming.First, a brand-new connection must be established and maintained for each requires objects. For earn TCP connections, TCP buffer must be allocated and TCP variable keeps between client and servers, This is a significant burden on the web servers. But persistent-connections don't need to establish so many connections, just establish once connections can work.<br>\n## HTTP Require and Response\n**HTTP-Require**\n![HTTP-Require](HTTP_requires.png)\n\n**HTTP-Response**\n![HTTP-Response](HTTP_respont.png)\n## Cookie\nCookie allow web site to keep track of users.<br>\nCookie technology has four components: <br>\n- a cookie header line in the HTTP response message.\n- a cookie header line in the HTTP require message.\n- a cookie file kept on user's end system and managed by user's browser\n- a cookie back-end database at the web site.\n\n![HTTP-Cookie](Cookie-process.png)\n## Web cache\nWeb cache also called proxy servers,Web cache can increasing response speed and reduce the cost of throughput.\n\n![HTTP-Web cache](Web-cache.png)\n## The condition GET\nAt explore above ,We already have cache ,We now face a problem is that if the informations  of requirements have been modified but the cache still stored the old information ,How to solve this problem?<br>\nThe answer is **The condition GET** ,. We can see details at the Computer network a Top-Down Approach<br>\n# File Transfer Protocol (FTP)\n## control connection and data connection<br>\n**Control connection** is used for sending control informations between two host, such as identification, password, commands<br>\n**Data connection** is used for actually send a file .<br>\n\nFTP use port 21 as Control connection and use port 20 as Data connection<br>\n![FTP-TCP](FTP-TCP-connections.png)\nAs you see,FTP is established two TCP connections<br>\n\nIn the typically FTP sessions, Users initial access remote hosts, namely establish TCP control connection used port 21, then provide identifications and passwords through port 21. After providing this authorization information. Users can transfer files from localhost to remote host vice versa.\n\n![FTP-transfer-file](FTP-transfer-file.png)\nIf user wanna to transfer another files during the same sessions,FTP will opens the another **data connections**(The data connections is no-persistent)<br>\nThroughout a sessions,the FTP servers must maintain state about the user. In particularly, The servers must be associate the **control connections** with a specific user and must keep track of user's current directory as user's wanders about the remote directory tree.<br>\n\n## FTP Commands and Replies\nThe FTP Commands and Replies sent across the control connection in 7-bits ASCLL format.<br>\nWe can see details at computer-network-a-top-down-approach.\n\n# SMTP(Simple Mail Transfer Protocol)\nSMTP is a principal application layer protocol for electronic mail. As most application layer protocol, SMTP base on TCP provides reliable data transfer service and SMTP also has two side , client side which executes on the sender's mail server, servers side which executes on recipient's mail servers. When the mail server send mail to other mail servers , it act as a SMTP client, when the mail server receive mail from other mail server, it act as SMTP server.\n![SMTP-transfer](SMTP-transfer.png)\n1. Alice provides Bob's email-address and composes a message then instruct Alice's agent  send the message to Bob.<br>\n2. Alice's send the message to Alice's mail servers,where it is placeing in message queue.<br>\n3. Alice's mail server established TCP connections to port 25 at Bob's mail server. <br>\n4. After initail SMTP handshaking, the SMTP client (Alice's mail server) send the message to Bob's server through TCP connection.<br>\n5. The recipient side receives the message and places the message in Bob mailbox.<br>\n6. Bob invoke his user agent to read the message at his convenience.<br>\n\n*In particular , if Bob's mail server is down . The message can't send to Bob's mail server, the message will remain in Alice's mail server and wait for a new attempt -- the message do not get place in any other intermediate mail server, Reattempt done for every 30 minutes , if\nresend  not success after several day , Alice's mail server remove the message and notice Alice with e-mail message*<br> **More details of SMTP handshake or SMTP commands please see the Computer Network A Top-Down Approach** <br>\n ## Comparison with HTTP\n1. HTTP and SMTP both use persistent connections\n2. HTTP is mainly a pull protocol -- Some one load information with browser on web servers or use HTTP to pull some information from the server at their convenience. SMTP is mainly a push protocol -- The sending mail server push file to other receiving mail server . <br> \n3. SMTP requires each message include body of each message that must be encode be 7-bit-ASCLL , so that The SMTP is a bit of pain to send the large attachment ,video, image, audio. But HTTP data does not impose this restriction. <br>\n4. HTTP encapsulate each object in it own HTTP response message , SMTP place all message's object into one message. \n## Mail Access Protocol\nBob can't obtain the message through SMTP from the Bob's mail server. Because SMTP is push protocol,obtain message is pull operation. To solve this problem by introducing a special mail access protocol that transfer messages from Bob's mail server to Bob's host .There are currently a number of mail access protocol including **Post Office Protocol - version 3 (POP3),Internet Mail Access Protocol (IMAP) and HTTP**\n![SMTP-access-mail](SMTP-access-mail.png)\n\n### POP3 (Post Office Protocol -Version 3)\nPOP3 Bob's agent use port 110 establish TCP connection with Bob's mail servers , With the TCP connections established , POP3 through three phase: **authorization**, **transaction**, **Update**.<br>\n1. **authorization**: Bob's agent send the username and password to authenticate the user 2. **transaction**: During this phase , user agent can mark retrieves the message also can mark message for deletion (or remove the mask) ,and obtain mail statistic .  3. **Update**: Update occurs after user agent issued the *quit* command ending this POP3 session ,at this time, mail server will delete messages that were marked for deletion.<br>\n\n*more details about POP3 commands or process can see in the textbook*<br>\n\n**During the POP3 sessions, the user agent and mail server maintain some state information. For example, maintain mark information for deletion during this POP3 session. However, POP3 doesn't carry state information across POP3 sessions. (As I think, that's mean POP3 maintain state information only occurs at POP3 sessions phase ,the state information will be deleted,if user agent ending the session)**\n### IMAP (Internet Mail Access Protocol)\nThe IMAP is significantly complex than POP3,and more feature than POP3<br>\n**The most significantly difference is IMAP can carry the state informations across IMAP sessions, but POP3 can't**<br>\n\n### Web-base Email (use HTTP)\nWeb-base Email also famous today, for example gmail . Web browser and user communicates with its mailbox via HTTP.\n\n# DNS (domain name system)\n**The DNS protocols run over UDP and uses port 53.** <br>\n\nThe DNS is commonly employed by other application-layer protocol --including HTTP,SMTP, and FTP --to translate the user-supplied hostnames to IP address.<br>\n\nWe see example above the DNS adds an additional delay, but ,fortunately the DNS cache will help reduce this delay. <br>\n\nDNS provide features: **Host aliasing** , **Mail server aliasing** , **Load distribution**\n- host aliasing and mail server aliasing make hostnames more mnemonic.<br>\n- load distribution : For replicated web server , a numbers set of IP address associated with one canonical hostname . It can make server easier to handle the large access .<br>\n## overview of how DNS work\n**Let's take closer to look at these three classes of DNS servers** <br>\n- Root DNS servers.\n- Top-level domain(TLD) server.\n- Authoritative DNS server.\n\nTake a look a simple example : **www.amazon.com.** (Don't forget we have a . at the end) <br>\n- The **.** is Root DNS servers.\n- The **com.** is Top-lever domain (TLD) server\n- The **amazon.com.** is Authoritative DNS server.\n- The **www** is hostname \n![DNS-hierarchy](DNS-hierarchy.png)\nWe also have a another critically important DNS servers is **Local DNS server** that does not strictly belong to the hierarchy of DNS server.<br>\nWhen the host make a DNS query, the query is send to Local DNS server which act as proxy forwarding the query into the DNS hierarchy server.<br>\n## Two way for send DNS queries\n- **iterative queries** \n![DNS-iterative-queries](DNS-server-iterative-queries.png)\n- **recursive queries**\n![DNS-recursive-queries](DNS-server-recursive-queries.png)\n## DNS caching\nWe reduce the delay of DNS server by DNS cache technology.<br>\n\n**The DNS server receives a DNS reply (for example the mapping of IP address and hostname) it can cache the mapping into the local memory(also can cache the mapping of TLD servers). For example , the local DNS server can cache the mapping of each host queries,When the user's host send a query to local DNS server frequently at the short period of time . The local DNS server can send the reply to user's host instantly**.<br>\n\n*The DNS servers discard the cache information after a period time (Often set to one or two day)*<br>\n## DNS Records and Messages\n### DNS Records\nThe DNS distributed database store **resource records (RRs)**<br>\nThe RRs provide Hostname-to-IP address mappings.Each DNS reply carries one or more RRs .<br>\n#### DNS Records Format\nThe DNS Record have four fields that provide following below.<br>\n\n|Name|Value|Type|TTL|\n|:-----|:-----|:-----|:-----|\n\nThe TTL is live time of Records in the RRs . The meaning of Name and Value is depend on Type. <br>\n\nIn following example we will ignore the TTL filed.<br>\n\n|Type|Name|Value|Description|\n|:-----:|:-----:|:-----:|:-----:|\n|A|Hostname|IP address|Address record|\n|NS|Domain|Hostname of authoritative|Name server record|\n|CNAME|Alisa hostname|Canonical name|Canonical name record|\n|MX|Alisa hostname of mail server|Canonical name of mail server|Mail exchange record|\n\n\n**If a DNS server is authoritative for particular hostname ,then the DNS server will contain type A record for the hostname.**<br>\n\n**If a DNS server is not authoritative for a hostname ,then it will contain a type NS record for domain that include hostname, it also contain a type A record that provide IP address of DNS server in the value field of the NS record.**<br>\n- For example in the TLD server<br>\n\n|Type|Name|Value|\n|:-----:|:-----:|:-----:|\n|NS|umass.edu|dns.umass.edu|\n|A|dns.umass.edu|128.119.40.111|\n\n\n\n## DNS Messages\nThe DNS query and DNS reply have same Messages format as shown in Figure below .<br>\n- **DNS-Messages-Format** \n![DNS-Messages](DNS-Messages.png)\n\n- **We can use dig command to see DNS reply messages**\n\n![DNS-Messages-dig](DNS-Messagas-dig.png)\nID:30379 is 16-bit number that identifies the query corresponding **identification** of figure above .This identifies is copied into the reply messages allowing the client match receive messages with sent queries. <br>\n**Let's see more detail about header flags format**<br>\n\n|Flag field|Description|Length(bits)|\n|:----:|:----:|:----:|\n|OR|indicate message is reply(1) or query(0) |1|\n|OPCODE|The type can be QUERY(standard query ,0),IQUERY(inverse query,1) or STATUS(server status request,2)|4|\n|AA|Authoritative Answer, in the response,indicates if the DNS server is authoritative for queried hostname|1|\n|TC|Truncation, indicates that this messages was truncated due excessive length|1|\n|RD|Recursion desired indicate if client means a recursion query.|1|\n|RA|Recursion Available indicate if reply messages supports recursion|1|\n|Z|zero ,reserved for future use|3|\n|RCODE|Response code, can be NOERROR(0),FORMERR(format error,1),SERVFAIL(2),NXDOMAIN(nonexistent domain 3),etc|4|\n\n\n# Peer-to-Peer Applications\n## BitTorrent\nBitTorrent is popular P2P protocol for file distribution.<br>\n\nIn BItTorrent lingo, the collection of all peer in the distribution is called torrent.<br>\n\nEach torrent has a infrastructure called tracker.When a peer join in a torrent, it must register itself with tracker and periodically informs the tracker that it is still in the torrent. In this manner the tracker can keep the track of the peers that participating in the torrent. <br> \n\n**Let we see a example to know more detail about how does p2p work.**<br>\nWhen a new peer Alice  want to join in torrent,what does it need to do.\n1. Alice must register herself with tracker.\n2. The tracker will randomly select a subset of peers from a set of participating peers and send the all IP address of subset peers to Alice\n3. Alice attempts concurrent establish TCP connection with subset peers. The succeed establish TCP connection peer is called **\"neighboring peers\"**. The neighboring peer probably leave at any time .\n4. Periodically Alice will ask (over the TCP connection)neighboring peer for list of chucks they have. If Alice have L neighboring peers ,Alice will obtain L list of chuck that neighboring peers have, with this knowledge, Alice can issue(over the TCP connection) require for chucks she current doesn't have .\n5. Along with time pass .Alice have a set of chuck and know which chuck her neighboring peers have . At this instant of time .**Alice will issue require for chucks her doesn't have and rarest among her neighboring peers** and **Use clever trading algorithm determine which require her need to response namely which neighboring peer she need send the chuck(about the clever trading algorithm we discuss below)** <br>\n### Incentive mechanism: Clever trading algorithm\nTo determine which require  need to response , BitTorrent use clever trading algorithm.<br>\n\nSpecifically. For each of her neighboring peers , Alice will continuity measures the rate at which she receive bits and determine the four peer that feed her bit at the highest rate. Alice will reciprocates by send the chucks to these same four peers.<br>\n\nIn the BitTorrent lingo , the four peers is said to be **unchoked**.\nEvery 10 seconds , Alice will recalculates the rate and possibly modifies the set of four peers.<br> \n\nIn specially, every 30 seconds , Alice will select a addition neighboring peer at random and send it chuck, The peer is said to be **optimistically unchocked** , The optimistically unchocked may become one of Alice's top four peer , if it rate which send chuck to Alice is high enough.<br>\nThe optimistically unchocked allow new peer to get chuck so that they can have something to trade. All the other neighboring peers beside the five peers (one optimistically unchoked and four unchoked) can't received any chucks from Alice.\n# distributed Hash Table (DHTs)\nDistributed Hash Table is referred to a distributed P2P version database.<br>\n## Circular DHT\nEach peer only award two peers ,immediate successor and predecessor<br>\n\nWe use a hash function map each key to a integer in the ranger [0-2^n-1]. For example suppose n = 4 ,we get the ranger is [0-15]. Further suppose that these are eight peer in the system 1,3,4,5,8,10,12,15. Suppose we want to stored a pair (format:key value) (11,johnny wu) to one of peers in the system. Using out closest conventions ,since peer 12 is closest successor for key 11. We therefore store the pair into peer 12.<br>\n**Let's see more detail about the example that we mentioned above.**<br>\n\nIf the peer 3 (in figure below) want to know \"who is responsible for key 11\", it only send the messages to clockwise around the circle , namely pass the message to peer 4 , if peer 4 don't responsible key 11, it just passes the message to peer 5 , This process continues until the message arrives at the peer 12 , peer 12 receive the message will send response back to peer 3.\n\n![circle](Circle-DHT.png)<br>\n\nThis circular arrangement of the peers is a special case of an overlay network. In an overlay network, the peers form an abstract logical network which resides above the “underlay” computer network consisting of physical links, routers,and hosts. The links in an overlay network are not physical links, but are simply vir-tual liaisons between pairs of peers. In the overlay in Figure(a) above, there are eightpeers and eight overlay links; in the overlay in Figure (b) there are eight peersand 16 overlay links. A single overlay link typically uses many physical links and physical routers in the underlay network.<br>\n\nThe circular DHT provide a elegant way to build the database , but all N peer in the system , we have to forward the message around the circle , N/2 message are send average.<br>\n\nFortunately we can refine the circular DHT, we can add a number of **shortcut** to each peer in the system . So that the each peer not only keep track of successor and predecessor but also keep track of a small number of shortcut like figure(b) above.<br>\n\nThus,when the peer 4 receives message passes from peer 3 asking about key 11, it can determine the closer peer to key is its shortcut peer 10,then forward message directly to peer 10. Clearly the shortcut can significantly reduce the number of messages used to query<br>\n\nThe next native question is \"How many shortcut should the peer have and which peer should be these neighboring shortcut. \"<br>\nThe answer doesn't referred in the textbook (computer-network-a-top-down-approach),we can only search with network use google.<br>\n## peer churn\nAbout peer churn we can learn in textbook page 155.\n","slug":"Chapter-2-Application-Layer","published":1,"updated":"2020-11-14T14:40:36.588Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4st002kr8s83wq73z1v","content":"<p><strong>The questions is provided below,we can find the answer in the Computer Network A Top-down Approach</strong></p>\n<h1 id=\"HTTP\"><a href=\"#HTTP\" class=\"headerlink\" title=\"HTTP\"></a>HTTP</h1><ul>\n<li>HTTP is said to be a stateless protocol<h2 id=\"no-persistent-connections-and-persistent-connections\"><a href=\"#no-persistent-connections-and-persistent-connections\" class=\"headerlink\" title=\"no-persistent-connections and persistent-connections\"></a>no-persistent-connections and persistent-connections</h2>no-persistent-connections:Client obtains the 10 JPEGs over 10 serial TCP connections or whether JEPGs are obtained over parallel TCP connections?<br></li>\n</ul>\n<p>Advantage of persistent-connections(or disadvantage of no-persistent-connections):NO-persistent-connection has some shortcoming.First, a brand-new connection must be established and maintained for each requires objects. For earn TCP connections, TCP buffer must be allocated and TCP variable keeps between client and servers, This is a significant burden on the web servers. But persistent-connections don’t need to establish so many connections, just establish once connections can work.<br></p>\n<h2 id=\"HTTP-Require-and-Response\"><a href=\"#HTTP-Require-and-Response\" class=\"headerlink\" title=\"HTTP Require and Response\"></a>HTTP Require and Response</h2><p><strong>HTTP-Require</strong><br><img src=\"HTTP_requires.png\" alt=\"HTTP-Require\"></p>\n<p><strong>HTTP-Response</strong><br><img src=\"HTTP_respont.png\" alt=\"HTTP-Response\"></p>\n<h2 id=\"Cookie\"><a href=\"#Cookie\" class=\"headerlink\" title=\"Cookie\"></a>Cookie</h2><p>Cookie allow web site to keep track of users.<br><br>Cookie technology has four components: <br></p>\n<ul>\n<li>a cookie header line in the HTTP response message.</li>\n<li>a cookie header line in the HTTP require message.</li>\n<li>a cookie file kept on user’s end system and managed by user’s browser</li>\n<li>a cookie back-end database at the web site.</li>\n</ul>\n<p><img src=\"Cookie-process.png\" alt=\"HTTP-Cookie\"></p>\n<h2 id=\"Web-cache\"><a href=\"#Web-cache\" class=\"headerlink\" title=\"Web cache\"></a>Web cache</h2><p>Web cache also called proxy servers,Web cache can increasing response speed and reduce the cost of throughput.</p>\n<p><img src=\"Web-cache.png\" alt=\"HTTP-Web cache\"></p>\n<h2 id=\"The-condition-GET\"><a href=\"#The-condition-GET\" class=\"headerlink\" title=\"The condition GET\"></a>The condition GET</h2><p>At explore above ,We already have cache ,We now face a problem is that if the informations  of requirements have been modified but the cache still stored the old information ,How to solve this problem?<br><br>The answer is <strong>The condition GET</strong> ,. We can see details at the Computer network a Top-Down Approach<br></p>\n<h1 id=\"File-Transfer-Protocol-FTP\"><a href=\"#File-Transfer-Protocol-FTP\" class=\"headerlink\" title=\"File Transfer Protocol (FTP)\"></a>File Transfer Protocol (FTP)</h1><h2 id=\"control-connection-and-data-connection\"><a href=\"#control-connection-and-data-connection\" class=\"headerlink\" title=\"control connection and data connection\"></a>control connection and data connection<br></h2><p><strong>Control connection</strong> is used for sending control informations between two host, such as identification, password, commands<br><br><strong>Data connection</strong> is used for actually send a file .<br></p>\n<p>FTP use port 21 as Control connection and use port 20 as Data connection<br><br><img src=\"FTP-TCP-connections.png\" alt=\"FTP-TCP\"><br>As you see,FTP is established two TCP connections<br></p>\n<p>In the typically FTP sessions, Users initial access remote hosts, namely establish TCP control connection used port 21, then provide identifications and passwords through port 21. After providing this authorization information. Users can transfer files from localhost to remote host vice versa.</p>\n<p><img src=\"FTP-transfer-file.png\" alt=\"FTP-transfer-file\"><br>If user wanna to transfer another files during the same sessions,FTP will opens the another <strong>data connections</strong>(The data connections is no-persistent)<br><br>Throughout a sessions,the FTP servers must maintain state about the user. In particularly, The servers must be associate the <strong>control connections</strong> with a specific user and must keep track of user’s current directory as user’s wanders about the remote directory tree.<br></p>\n<h2 id=\"FTP-Commands-and-Replies\"><a href=\"#FTP-Commands-and-Replies\" class=\"headerlink\" title=\"FTP Commands and Replies\"></a>FTP Commands and Replies</h2><p>The FTP Commands and Replies sent across the control connection in 7-bits ASCLL format.<br><br>We can see details at computer-network-a-top-down-approach.</p>\n<h1 id=\"SMTP-Simple-Mail-Transfer-Protocol\"><a href=\"#SMTP-Simple-Mail-Transfer-Protocol\" class=\"headerlink\" title=\"SMTP(Simple Mail Transfer Protocol)\"></a>SMTP(Simple Mail Transfer Protocol)</h1><p>SMTP is a principal application layer protocol for electronic mail. As most application layer protocol, SMTP base on TCP provides reliable data transfer service and SMTP also has two side , client side which executes on the sender’s mail server, servers side which executes on recipient’s mail servers. When the mail server send mail to other mail servers , it act as a SMTP client, when the mail server receive mail from other mail server, it act as SMTP server.<br><img src=\"SMTP-transfer.png\" alt=\"SMTP-transfer\"></p>\n<ol>\n<li>Alice provides Bob’s email-address and composes a message then instruct Alice’s agent  send the message to Bob.<br></li>\n<li>Alice’s send the message to Alice’s mail servers,where it is placeing in message queue.<br></li>\n<li>Alice’s mail server established TCP connections to port 25 at Bob’s mail server. <br></li>\n<li>After initail SMTP handshaking, the SMTP client (Alice’s mail server) send the message to Bob’s server through TCP connection.<br></li>\n<li>The recipient side receives the message and places the message in Bob mailbox.<br></li>\n<li>Bob invoke his user agent to read the message at his convenience.<br></li>\n</ol>\n<p><em>In particular , if Bob’s mail server is down . The message can’t send to Bob’s mail server, the message will remain in Alice’s mail server and wait for a new attempt — the message do not get place in any other intermediate mail server, Reattempt done for every 30 minutes , if<br>resend  not success after several day , Alice’s mail server remove the message and notice Alice with e-mail message</em><br> <strong>More details of SMTP handshake or SMTP commands please see the Computer Network A Top-Down Approach</strong> <br></p>\n<h2 id=\"Comparison-with-HTTP\"><a href=\"#Comparison-with-HTTP\" class=\"headerlink\" title=\"Comparison with HTTP\"></a>Comparison with HTTP</h2><ol>\n<li>HTTP and SMTP both use persistent connections</li>\n<li>HTTP is mainly a pull protocol — Some one load information with browser on web servers or use HTTP to pull some information from the server at their convenience. SMTP is mainly a push protocol — The sending mail server push file to other receiving mail server . <br> </li>\n<li>SMTP requires each message include body of each message that must be encode be 7-bit-ASCLL , so that The SMTP is a bit of pain to send the large attachment ,video, image, audio. But HTTP data does not impose this restriction. <br></li>\n<li>HTTP encapsulate each object in it own HTTP response message , SMTP place all message’s object into one message. <h2 id=\"Mail-Access-Protocol\"><a href=\"#Mail-Access-Protocol\" class=\"headerlink\" title=\"Mail Access Protocol\"></a>Mail Access Protocol</h2>Bob can’t obtain the message through SMTP from the Bob’s mail server. Because SMTP is push protocol,obtain message is pull operation. To solve this problem by introducing a special mail access protocol that transfer messages from Bob’s mail server to Bob’s host .There are currently a number of mail access protocol including <strong>Post Office Protocol - version 3 (POP3),Internet Mail Access Protocol (IMAP) and HTTP</strong><br><img src=\"SMTP-access-mail.png\" alt=\"SMTP-access-mail\"></li>\n</ol>\n<h3 id=\"POP3-Post-Office-Protocol-Version-3\"><a href=\"#POP3-Post-Office-Protocol-Version-3\" class=\"headerlink\" title=\"POP3 (Post Office Protocol -Version 3)\"></a>POP3 (Post Office Protocol -Version 3)</h3><p>POP3 Bob’s agent use port 110 establish TCP connection with Bob’s mail servers , With the TCP connections established , POP3 through three phase: <strong>authorization</strong>, <strong>transaction</strong>, <strong>Update</strong>.<br></p>\n<ol>\n<li><strong>authorization</strong>: Bob’s agent send the username and password to authenticate the user 2. <strong>transaction</strong>: During this phase , user agent can mark retrieves the message also can mark message for deletion (or remove the mask) ,and obtain mail statistic .  3. <strong>Update</strong>: Update occurs after user agent issued the <em>quit</em> command ending this POP3 session ,at this time, mail server will delete messages that were marked for deletion.<br></li>\n</ol>\n<p><em>more details about POP3 commands or process can see in the textbook</em><br></p>\n<p><strong>During the POP3 sessions, the user agent and mail server maintain some state information. For example, maintain mark information for deletion during this POP3 session. However, POP3 doesn’t carry state information across POP3 sessions. (As I think, that’s mean POP3 maintain state information only occurs at POP3 sessions phase ,the state information will be deleted,if user agent ending the session)</strong></p>\n<h3 id=\"IMAP-Internet-Mail-Access-Protocol\"><a href=\"#IMAP-Internet-Mail-Access-Protocol\" class=\"headerlink\" title=\"IMAP (Internet Mail Access Protocol)\"></a>IMAP (Internet Mail Access Protocol)</h3><p>The IMAP is significantly complex than POP3,and more feature than POP3<br><br><strong>The most significantly difference is IMAP can carry the state informations across IMAP sessions, but POP3 can’t</strong><br></p>\n<h3 id=\"Web-base-Email-use-HTTP\"><a href=\"#Web-base-Email-use-HTTP\" class=\"headerlink\" title=\"Web-base Email (use HTTP)\"></a>Web-base Email (use HTTP)</h3><p>Web-base Email also famous today, for example gmail . Web browser and user communicates with its mailbox via HTTP.</p>\n<h1 id=\"DNS-domain-name-system\"><a href=\"#DNS-domain-name-system\" class=\"headerlink\" title=\"DNS (domain name system)\"></a>DNS (domain name system)</h1><p><strong>The DNS protocols run over UDP and uses port 53.</strong> <br></p>\n<p>The DNS is commonly employed by other application-layer protocol —including HTTP,SMTP, and FTP —to translate the user-supplied hostnames to IP address.<br></p>\n<p>We see example above the DNS adds an additional delay, but ,fortunately the DNS cache will help reduce this delay. <br></p>\n<p>DNS provide features: <strong>Host aliasing</strong> , <strong>Mail server aliasing</strong> , <strong>Load distribution</strong></p>\n<ul>\n<li>host aliasing and mail server aliasing make hostnames more mnemonic.<br></li>\n<li>load distribution : For replicated web server , a numbers set of IP address associated with one canonical hostname . It can make server easier to handle the large access .<br><h2 id=\"overview-of-how-DNS-work\"><a href=\"#overview-of-how-DNS-work\" class=\"headerlink\" title=\"overview of how DNS work\"></a>overview of how DNS work</h2><strong>Let’s take closer to look at these three classes of DNS servers</strong> <br></li>\n<li>Root DNS servers.</li>\n<li>Top-level domain(TLD) server.</li>\n<li>Authoritative DNS server.</li>\n</ul>\n<p>Take a look a simple example : <strong>www.amazon.com.</strong> (Don’t forget we have a . at the end) <br></p>\n<ul>\n<li>The <strong>.</strong> is Root DNS servers.</li>\n<li>The <strong>com.</strong> is Top-lever domain (TLD) server</li>\n<li>The <strong>amazon.com.</strong> is Authoritative DNS server.</li>\n<li>The <strong>www</strong> is hostname<br><img src=\"DNS-hierarchy.png\" alt=\"DNS-hierarchy\"><br>We also have a another critically important DNS servers is <strong>Local DNS server</strong> that does not strictly belong to the hierarchy of DNS server.<br><br>When the host make a DNS query, the query is send to Local DNS server which act as proxy forwarding the query into the DNS hierarchy server.<br><h2 id=\"Two-way-for-send-DNS-queries\"><a href=\"#Two-way-for-send-DNS-queries\" class=\"headerlink\" title=\"Two way for send DNS queries\"></a>Two way for send DNS queries</h2></li>\n<li><strong>iterative queries</strong><br><img src=\"DNS-server-iterative-queries.png\" alt=\"DNS-iterative-queries\"></li>\n<li><strong>recursive queries</strong><br><img src=\"DNS-server-recursive-queries.png\" alt=\"DNS-recursive-queries\"><h2 id=\"DNS-caching\"><a href=\"#DNS-caching\" class=\"headerlink\" title=\"DNS caching\"></a>DNS caching</h2>We reduce the delay of DNS server by DNS cache technology.<br></li>\n</ul>\n<p><strong>The DNS server receives a DNS reply (for example the mapping of IP address and hostname) it can cache the mapping into the local memory(also can cache the mapping of TLD servers). For example , the local DNS server can cache the mapping of each host queries,When the user’s host send a query to local DNS server frequently at the short period of time . The local DNS server can send the reply to user’s host instantly</strong>.<br></p>\n<p><em>The DNS servers discard the cache information after a period time (Often set to one or two day)</em><br></p>\n<h2 id=\"DNS-Records-and-Messages\"><a href=\"#DNS-Records-and-Messages\" class=\"headerlink\" title=\"DNS Records and Messages\"></a>DNS Records and Messages</h2><h3 id=\"DNS-Records\"><a href=\"#DNS-Records\" class=\"headerlink\" title=\"DNS Records\"></a>DNS Records</h3><p>The DNS distributed database store <strong>resource records (RRs)</strong><br><br>The RRs provide Hostname-to-IP address mappings.Each DNS reply carries one or more RRs .<br></p>\n<h4 id=\"DNS-Records-Format\"><a href=\"#DNS-Records-Format\" class=\"headerlink\" title=\"DNS Records Format\"></a>DNS Records Format</h4><p>The DNS Record have four fields that provide following below.<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Name</th>\n<th style=\"text-align:left\">Value</th>\n<th style=\"text-align:left\">Type</th>\n<th style=\"text-align:left\">TTL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>The TTL is live time of Records in the RRs . The meaning of Name and Value is depend on Type. <br></p>\n<p>In following example we will ignore the TTL filed.<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Type</th>\n<th style=\"text-align:center\">Name</th>\n<th style=\"text-align:center\">Value</th>\n<th style=\"text-align:center\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">Hostname</td>\n<td style=\"text-align:center\">IP address</td>\n<td style=\"text-align:center\">Address record</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">NS</td>\n<td style=\"text-align:center\">Domain</td>\n<td style=\"text-align:center\">Hostname of authoritative</td>\n<td style=\"text-align:center\">Name server record</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CNAME</td>\n<td style=\"text-align:center\">Alisa hostname</td>\n<td style=\"text-align:center\">Canonical name</td>\n<td style=\"text-align:center\">Canonical name record</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">MX</td>\n<td style=\"text-align:center\">Alisa hostname of mail server</td>\n<td style=\"text-align:center\">Canonical name of mail server</td>\n<td style=\"text-align:center\">Mail exchange record</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>If a DNS server is authoritative for particular hostname ,then the DNS server will contain type A record for the hostname.</strong><br></p>\n<p><strong>If a DNS server is not authoritative for a hostname ,then it will contain a type NS record for domain that include hostname, it also contain a type A record that provide IP address of DNS server in the value field of the NS record.</strong><br></p>\n<ul>\n<li>For example in the TLD server<br></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Type</th>\n<th style=\"text-align:center\">Name</th>\n<th style=\"text-align:center\">Value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">NS</td>\n<td style=\"text-align:center\">umass.edu</td>\n<td style=\"text-align:center\">dns.umass.edu</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">dns.umass.edu</td>\n<td style=\"text-align:center\">128.119.40.111</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"DNS-Messages\"><a href=\"#DNS-Messages\" class=\"headerlink\" title=\"DNS Messages\"></a>DNS Messages</h2><p>The DNS query and DNS reply have same Messages format as shown in Figure below .<br></p>\n<ul>\n<li><p><strong>DNS-Messages-Format</strong><br><img src=\"DNS-Messages.png\" alt=\"DNS-Messages\"></p>\n</li>\n<li><p><strong>We can use dig command to see DNS reply messages</strong></p>\n</li>\n</ul>\n<p><img src=\"DNS-Messagas-dig.png\" alt=\"DNS-Messages-dig\"><br>ID:30379 is 16-bit number that identifies the query corresponding <strong>identification</strong> of figure above .This identifies is copied into the reply messages allowing the client match receive messages with sent queries. <br><br><strong>Let’s see more detail about header flags format</strong><br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Flag field</th>\n<th style=\"text-align:center\">Description</th>\n<th style=\"text-align:center\">Length(bits)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">OR</td>\n<td style=\"text-align:center\">indicate message is reply(1) or query(0)</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">OPCODE</td>\n<td style=\"text-align:center\">The type can be QUERY(standard query ,0),IQUERY(inverse query,1) or STATUS(server status request,2)</td>\n<td style=\"text-align:center\">4</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">AA</td>\n<td style=\"text-align:center\">Authoritative Answer, in the response,indicates if the DNS server is authoritative for queried hostname</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">TC</td>\n<td style=\"text-align:center\">Truncation, indicates that this messages was truncated due excessive length</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RD</td>\n<td style=\"text-align:center\">Recursion desired indicate if client means a recursion query.</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RA</td>\n<td style=\"text-align:center\">Recursion Available indicate if reply messages supports recursion</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Z</td>\n<td style=\"text-align:center\">zero ,reserved for future use</td>\n<td style=\"text-align:center\">3</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RCODE</td>\n<td style=\"text-align:center\">Response code, can be NOERROR(0),FORMERR(format error,1),SERVFAIL(2),NXDOMAIN(nonexistent domain 3),etc</td>\n<td style=\"text-align:center\">4</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"Peer-to-Peer-Applications\"><a href=\"#Peer-to-Peer-Applications\" class=\"headerlink\" title=\"Peer-to-Peer Applications\"></a>Peer-to-Peer Applications</h1><h2 id=\"BitTorrent\"><a href=\"#BitTorrent\" class=\"headerlink\" title=\"BitTorrent\"></a>BitTorrent</h2><p>BitTorrent is popular P2P protocol for file distribution.<br></p>\n<p>In BItTorrent lingo, the collection of all peer in the distribution is called torrent.<br></p>\n<p>Each torrent has a infrastructure called tracker.When a peer join in a torrent, it must register itself with tracker and periodically informs the tracker that it is still in the torrent. In this manner the tracker can keep the track of the peers that participating in the torrent. <br> </p>\n<p><strong>Let we see a example to know more detail about how does p2p work.</strong><br><br>When a new peer Alice  want to join in torrent,what does it need to do.</p>\n<ol>\n<li>Alice must register herself with tracker.</li>\n<li>The tracker will randomly select a subset of peers from a set of participating peers and send the all IP address of subset peers to Alice</li>\n<li>Alice attempts concurrent establish TCP connection with subset peers. The succeed establish TCP connection peer is called <strong>“neighboring peers”</strong>. The neighboring peer probably leave at any time .</li>\n<li>Periodically Alice will ask (over the TCP connection)neighboring peer for list of chucks they have. If Alice have L neighboring peers ,Alice will obtain L list of chuck that neighboring peers have, with this knowledge, Alice can issue(over the TCP connection) require for chucks she current doesn’t have .</li>\n<li>Along with time pass .Alice have a set of chuck and know which chuck her neighboring peers have . At this instant of time .<strong>Alice will issue require for chucks her doesn’t have and rarest among her neighboring peers</strong> and <strong>Use clever trading algorithm determine which require her need to response namely which neighboring peer she need send the chuck(about the clever trading algorithm we discuss below)</strong> <br><h3 id=\"Incentive-mechanism-Clever-trading-algorithm\"><a href=\"#Incentive-mechanism-Clever-trading-algorithm\" class=\"headerlink\" title=\"Incentive mechanism: Clever trading algorithm\"></a>Incentive mechanism: Clever trading algorithm</h3>To determine which require  need to response , BitTorrent use clever trading algorithm.<br></li>\n</ol>\n<p>Specifically. For each of her neighboring peers , Alice will continuity measures the rate at which she receive bits and determine the four peer that feed her bit at the highest rate. Alice will reciprocates by send the chucks to these same four peers.<br></p>\n<p>In the BitTorrent lingo , the four peers is said to be <strong>unchoked</strong>.<br>Every 10 seconds , Alice will recalculates the rate and possibly modifies the set of four peers.<br> </p>\n<p>In specially, every 30 seconds , Alice will select a addition neighboring peer at random and send it chuck, The peer is said to be <strong>optimistically unchocked</strong> , The optimistically unchocked may become one of Alice’s top four peer , if it rate which send chuck to Alice is high enough.<br><br>The optimistically unchocked allow new peer to get chuck so that they can have something to trade. All the other neighboring peers beside the five peers (one optimistically unchoked and four unchoked) can’t received any chucks from Alice.</p>\n<h1 id=\"distributed-Hash-Table-DHTs\"><a href=\"#distributed-Hash-Table-DHTs\" class=\"headerlink\" title=\"distributed Hash Table (DHTs)\"></a>distributed Hash Table (DHTs)</h1><p>Distributed Hash Table is referred to a distributed P2P version database.<br></p>\n<h2 id=\"Circular-DHT\"><a href=\"#Circular-DHT\" class=\"headerlink\" title=\"Circular DHT\"></a>Circular DHT</h2><p>Each peer only award two peers ,immediate successor and predecessor<br></p>\n<p>We use a hash function map each key to a integer in the ranger [0-2^n-1]. For example suppose n = 4 ,we get the ranger is [0-15]. Further suppose that these are eight peer in the system 1,3,4,5,8,10,12,15. Suppose we want to stored a pair (format:key value) (11,johnny wu) to one of peers in the system. Using out closest conventions ,since peer 12 is closest successor for key 11. We therefore store the pair into peer 12.<br><br><strong>Let’s see more detail about the example that we mentioned above.</strong><br></p>\n<p>If the peer 3 (in figure below) want to know “who is responsible for key 11”, it only send the messages to clockwise around the circle , namely pass the message to peer 4 , if peer 4 don’t responsible key 11, it just passes the message to peer 5 , This process continues until the message arrives at the peer 12 , peer 12 receive the message will send response back to peer 3.</p>\n<p><img src=\"Circle-DHT.png\" alt=\"circle\"><br></p>\n<p>This circular arrangement of the peers is a special case of an overlay network. In an overlay network, the peers form an abstract logical network which resides above the “underlay” computer network consisting of physical links, routers,and hosts. The links in an overlay network are not physical links, but are simply vir-tual liaisons between pairs of peers. In the overlay in Figure(a) above, there are eightpeers and eight overlay links; in the overlay in Figure (b) there are eight peersand 16 overlay links. A single overlay link typically uses many physical links and physical routers in the underlay network.<br></p>\n<p>The circular DHT provide a elegant way to build the database , but all N peer in the system , we have to forward the message around the circle , N/2 message are send average.<br></p>\n<p>Fortunately we can refine the circular DHT, we can add a number of <strong>shortcut</strong> to each peer in the system . So that the each peer not only keep track of successor and predecessor but also keep track of a small number of shortcut like figure(b) above.<br></p>\n<p>Thus,when the peer 4 receives message passes from peer 3 asking about key 11, it can determine the closer peer to key is its shortcut peer 10,then forward message directly to peer 10. Clearly the shortcut can significantly reduce the number of messages used to query<br></p>\n<p>The next native question is “How many shortcut should the peer have and which peer should be these neighboring shortcut. “<br><br>The answer doesn’t referred in the textbook (computer-network-a-top-down-approach),we can only search with network use google.<br></p>\n<h2 id=\"peer-churn\"><a href=\"#peer-churn\" class=\"headerlink\" title=\"peer churn\"></a>peer churn</h2><p>About peer churn we can learn in textbook page 155.</p>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>The questions is provided below,we can find the answer in the Computer Network A Top-down Approach</strong></p>\n<h1 id=\"HTTP\"><a href=\"#HTTP\" class=\"headerlink\" title=\"HTTP\"></a>HTTP</h1><ul>\n<li>HTTP is said to be a stateless protocol<h2 id=\"no-persistent-connections-and-persistent-connections\"><a href=\"#no-persistent-connections-and-persistent-connections\" class=\"headerlink\" title=\"no-persistent-connections and persistent-connections\"></a>no-persistent-connections and persistent-connections</h2>no-persistent-connections:Client obtains the 10 JPEGs over 10 serial TCP connections or whether JEPGs are obtained over parallel TCP connections?<br></li>\n</ul>\n<p>Advantage of persistent-connections(or disadvantage of no-persistent-connections):NO-persistent-connection has some shortcoming.First, a brand-new connection must be established and maintained for each requires objects. For earn TCP connections, TCP buffer must be allocated and TCP variable keeps between client and servers, This is a significant burden on the web servers. But persistent-connections don’t need to establish so many connections, just establish once connections can work.<br></p>\n<h2 id=\"HTTP-Require-and-Response\"><a href=\"#HTTP-Require-and-Response\" class=\"headerlink\" title=\"HTTP Require and Response\"></a>HTTP Require and Response</h2><p><strong>HTTP-Require</strong><br><img src=\"HTTP_requires.png\" alt=\"HTTP-Require\"></p>\n<p><strong>HTTP-Response</strong><br><img src=\"HTTP_respont.png\" alt=\"HTTP-Response\"></p>\n<h2 id=\"Cookie\"><a href=\"#Cookie\" class=\"headerlink\" title=\"Cookie\"></a>Cookie</h2><p>Cookie allow web site to keep track of users.<br><br>Cookie technology has four components: <br></p>\n<ul>\n<li>a cookie header line in the HTTP response message.</li>\n<li>a cookie header line in the HTTP require message.</li>\n<li>a cookie file kept on user’s end system and managed by user’s browser</li>\n<li>a cookie back-end database at the web site.</li>\n</ul>\n<p><img src=\"Cookie-process.png\" alt=\"HTTP-Cookie\"></p>\n<h2 id=\"Web-cache\"><a href=\"#Web-cache\" class=\"headerlink\" title=\"Web cache\"></a>Web cache</h2><p>Web cache also called proxy servers,Web cache can increasing response speed and reduce the cost of throughput.</p>\n<p><img src=\"Web-cache.png\" alt=\"HTTP-Web cache\"></p>\n<h2 id=\"The-condition-GET\"><a href=\"#The-condition-GET\" class=\"headerlink\" title=\"The condition GET\"></a>The condition GET</h2><p>At explore above ,We already have cache ,We now face a problem is that if the informations  of requirements have been modified but the cache still stored the old information ,How to solve this problem?<br><br>The answer is <strong>The condition GET</strong> ,. We can see details at the Computer network a Top-Down Approach<br></p>\n<h1 id=\"File-Transfer-Protocol-FTP\"><a href=\"#File-Transfer-Protocol-FTP\" class=\"headerlink\" title=\"File Transfer Protocol (FTP)\"></a>File Transfer Protocol (FTP)</h1><h2 id=\"control-connection-and-data-connection\"><a href=\"#control-connection-and-data-connection\" class=\"headerlink\" title=\"control connection and data connection\"></a>control connection and data connection<br></h2><p><strong>Control connection</strong> is used for sending control informations between two host, such as identification, password, commands<br><br><strong>Data connection</strong> is used for actually send a file .<br></p>\n<p>FTP use port 21 as Control connection and use port 20 as Data connection<br><br><img src=\"FTP-TCP-connections.png\" alt=\"FTP-TCP\"><br>As you see,FTP is established two TCP connections<br></p>\n<p>In the typically FTP sessions, Users initial access remote hosts, namely establish TCP control connection used port 21, then provide identifications and passwords through port 21. After providing this authorization information. Users can transfer files from localhost to remote host vice versa.</p>\n<p><img src=\"FTP-transfer-file.png\" alt=\"FTP-transfer-file\"><br>If user wanna to transfer another files during the same sessions,FTP will opens the another <strong>data connections</strong>(The data connections is no-persistent)<br><br>Throughout a sessions,the FTP servers must maintain state about the user. In particularly, The servers must be associate the <strong>control connections</strong> with a specific user and must keep track of user’s current directory as user’s wanders about the remote directory tree.<br></p>\n<h2 id=\"FTP-Commands-and-Replies\"><a href=\"#FTP-Commands-and-Replies\" class=\"headerlink\" title=\"FTP Commands and Replies\"></a>FTP Commands and Replies</h2><p>The FTP Commands and Replies sent across the control connection in 7-bits ASCLL format.<br><br>We can see details at computer-network-a-top-down-approach.</p>\n<h1 id=\"SMTP-Simple-Mail-Transfer-Protocol\"><a href=\"#SMTP-Simple-Mail-Transfer-Protocol\" class=\"headerlink\" title=\"SMTP(Simple Mail Transfer Protocol)\"></a>SMTP(Simple Mail Transfer Protocol)</h1><p>SMTP is a principal application layer protocol for electronic mail. As most application layer protocol, SMTP base on TCP provides reliable data transfer service and SMTP also has two side , client side which executes on the sender’s mail server, servers side which executes on recipient’s mail servers. When the mail server send mail to other mail servers , it act as a SMTP client, when the mail server receive mail from other mail server, it act as SMTP server.<br><img src=\"SMTP-transfer.png\" alt=\"SMTP-transfer\"></p>\n<ol>\n<li>Alice provides Bob’s email-address and composes a message then instruct Alice’s agent  send the message to Bob.<br></li>\n<li>Alice’s send the message to Alice’s mail servers,where it is placeing in message queue.<br></li>\n<li>Alice’s mail server established TCP connections to port 25 at Bob’s mail server. <br></li>\n<li>After initail SMTP handshaking, the SMTP client (Alice’s mail server) send the message to Bob’s server through TCP connection.<br></li>\n<li>The recipient side receives the message and places the message in Bob mailbox.<br></li>\n<li>Bob invoke his user agent to read the message at his convenience.<br></li>\n</ol>\n<p><em>In particular , if Bob’s mail server is down . The message can’t send to Bob’s mail server, the message will remain in Alice’s mail server and wait for a new attempt — the message do not get place in any other intermediate mail server, Reattempt done for every 30 minutes , if<br>resend  not success after several day , Alice’s mail server remove the message and notice Alice with e-mail message</em><br> <strong>More details of SMTP handshake or SMTP commands please see the Computer Network A Top-Down Approach</strong> <br></p>\n<h2 id=\"Comparison-with-HTTP\"><a href=\"#Comparison-with-HTTP\" class=\"headerlink\" title=\"Comparison with HTTP\"></a>Comparison with HTTP</h2><ol>\n<li>HTTP and SMTP both use persistent connections</li>\n<li>HTTP is mainly a pull protocol — Some one load information with browser on web servers or use HTTP to pull some information from the server at their convenience. SMTP is mainly a push protocol — The sending mail server push file to other receiving mail server . <br> </li>\n<li>SMTP requires each message include body of each message that must be encode be 7-bit-ASCLL , so that The SMTP is a bit of pain to send the large attachment ,video, image, audio. But HTTP data does not impose this restriction. <br></li>\n<li>HTTP encapsulate each object in it own HTTP response message , SMTP place all message’s object into one message. <h2 id=\"Mail-Access-Protocol\"><a href=\"#Mail-Access-Protocol\" class=\"headerlink\" title=\"Mail Access Protocol\"></a>Mail Access Protocol</h2>Bob can’t obtain the message through SMTP from the Bob’s mail server. Because SMTP is push protocol,obtain message is pull operation. To solve this problem by introducing a special mail access protocol that transfer messages from Bob’s mail server to Bob’s host .There are currently a number of mail access protocol including <strong>Post Office Protocol - version 3 (POP3),Internet Mail Access Protocol (IMAP) and HTTP</strong><br><img src=\"SMTP-access-mail.png\" alt=\"SMTP-access-mail\"></li>\n</ol>\n<h3 id=\"POP3-Post-Office-Protocol-Version-3\"><a href=\"#POP3-Post-Office-Protocol-Version-3\" class=\"headerlink\" title=\"POP3 (Post Office Protocol -Version 3)\"></a>POP3 (Post Office Protocol -Version 3)</h3><p>POP3 Bob’s agent use port 110 establish TCP connection with Bob’s mail servers , With the TCP connections established , POP3 through three phase: <strong>authorization</strong>, <strong>transaction</strong>, <strong>Update</strong>.<br></p>\n<ol>\n<li><strong>authorization</strong>: Bob’s agent send the username and password to authenticate the user 2. <strong>transaction</strong>: During this phase , user agent can mark retrieves the message also can mark message for deletion (or remove the mask) ,and obtain mail statistic .  3. <strong>Update</strong>: Update occurs after user agent issued the <em>quit</em> command ending this POP3 session ,at this time, mail server will delete messages that were marked for deletion.<br></li>\n</ol>\n<p><em>more details about POP3 commands or process can see in the textbook</em><br></p>\n<p><strong>During the POP3 sessions, the user agent and mail server maintain some state information. For example, maintain mark information for deletion during this POP3 session. However, POP3 doesn’t carry state information across POP3 sessions. (As I think, that’s mean POP3 maintain state information only occurs at POP3 sessions phase ,the state information will be deleted,if user agent ending the session)</strong></p>\n<h3 id=\"IMAP-Internet-Mail-Access-Protocol\"><a href=\"#IMAP-Internet-Mail-Access-Protocol\" class=\"headerlink\" title=\"IMAP (Internet Mail Access Protocol)\"></a>IMAP (Internet Mail Access Protocol)</h3><p>The IMAP is significantly complex than POP3,and more feature than POP3<br><br><strong>The most significantly difference is IMAP can carry the state informations across IMAP sessions, but POP3 can’t</strong><br></p>\n<h3 id=\"Web-base-Email-use-HTTP\"><a href=\"#Web-base-Email-use-HTTP\" class=\"headerlink\" title=\"Web-base Email (use HTTP)\"></a>Web-base Email (use HTTP)</h3><p>Web-base Email also famous today, for example gmail . Web browser and user communicates with its mailbox via HTTP.</p>\n<h1 id=\"DNS-domain-name-system\"><a href=\"#DNS-domain-name-system\" class=\"headerlink\" title=\"DNS (domain name system)\"></a>DNS (domain name system)</h1><p><strong>The DNS protocols run over UDP and uses port 53.</strong> <br></p>\n<p>The DNS is commonly employed by other application-layer protocol —including HTTP,SMTP, and FTP —to translate the user-supplied hostnames to IP address.<br></p>\n<p>We see example above the DNS adds an additional delay, but ,fortunately the DNS cache will help reduce this delay. <br></p>\n<p>DNS provide features: <strong>Host aliasing</strong> , <strong>Mail server aliasing</strong> , <strong>Load distribution</strong></p>\n<ul>\n<li>host aliasing and mail server aliasing make hostnames more mnemonic.<br></li>\n<li>load distribution : For replicated web server , a numbers set of IP address associated with one canonical hostname . It can make server easier to handle the large access .<br><h2 id=\"overview-of-how-DNS-work\"><a href=\"#overview-of-how-DNS-work\" class=\"headerlink\" title=\"overview of how DNS work\"></a>overview of how DNS work</h2><strong>Let’s take closer to look at these three classes of DNS servers</strong> <br></li>\n<li>Root DNS servers.</li>\n<li>Top-level domain(TLD) server.</li>\n<li>Authoritative DNS server.</li>\n</ul>\n<p>Take a look a simple example : <strong>www.amazon.com.</strong> (Don’t forget we have a . at the end) <br></p>\n<ul>\n<li>The <strong>.</strong> is Root DNS servers.</li>\n<li>The <strong>com.</strong> is Top-lever domain (TLD) server</li>\n<li>The <strong>amazon.com.</strong> is Authoritative DNS server.</li>\n<li>The <strong>www</strong> is hostname<br><img src=\"DNS-hierarchy.png\" alt=\"DNS-hierarchy\"><br>We also have a another critically important DNS servers is <strong>Local DNS server</strong> that does not strictly belong to the hierarchy of DNS server.<br><br>When the host make a DNS query, the query is send to Local DNS server which act as proxy forwarding the query into the DNS hierarchy server.<br><h2 id=\"Two-way-for-send-DNS-queries\"><a href=\"#Two-way-for-send-DNS-queries\" class=\"headerlink\" title=\"Two way for send DNS queries\"></a>Two way for send DNS queries</h2></li>\n<li><strong>iterative queries</strong><br><img src=\"DNS-server-iterative-queries.png\" alt=\"DNS-iterative-queries\"></li>\n<li><strong>recursive queries</strong><br><img src=\"DNS-server-recursive-queries.png\" alt=\"DNS-recursive-queries\"><h2 id=\"DNS-caching\"><a href=\"#DNS-caching\" class=\"headerlink\" title=\"DNS caching\"></a>DNS caching</h2>We reduce the delay of DNS server by DNS cache technology.<br></li>\n</ul>\n<p><strong>The DNS server receives a DNS reply (for example the mapping of IP address and hostname) it can cache the mapping into the local memory(also can cache the mapping of TLD servers). For example , the local DNS server can cache the mapping of each host queries,When the user’s host send a query to local DNS server frequently at the short period of time . The local DNS server can send the reply to user’s host instantly</strong>.<br></p>\n<p><em>The DNS servers discard the cache information after a period time (Often set to one or two day)</em><br></p>\n<h2 id=\"DNS-Records-and-Messages\"><a href=\"#DNS-Records-and-Messages\" class=\"headerlink\" title=\"DNS Records and Messages\"></a>DNS Records and Messages</h2><h3 id=\"DNS-Records\"><a href=\"#DNS-Records\" class=\"headerlink\" title=\"DNS Records\"></a>DNS Records</h3><p>The DNS distributed database store <strong>resource records (RRs)</strong><br><br>The RRs provide Hostname-to-IP address mappings.Each DNS reply carries one or more RRs .<br></p>\n<h4 id=\"DNS-Records-Format\"><a href=\"#DNS-Records-Format\" class=\"headerlink\" title=\"DNS Records Format\"></a>DNS Records Format</h4><p>The DNS Record have four fields that provide following below.<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">Name</th>\n<th style=\"text-align:left\">Value</th>\n<th style=\"text-align:left\">Type</th>\n<th style=\"text-align:left\">TTL</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\"></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>The TTL is live time of Records in the RRs . The meaning of Name and Value is depend on Type. <br></p>\n<p>In following example we will ignore the TTL filed.<br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Type</th>\n<th style=\"text-align:center\">Name</th>\n<th style=\"text-align:center\">Value</th>\n<th style=\"text-align:center\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">Hostname</td>\n<td style=\"text-align:center\">IP address</td>\n<td style=\"text-align:center\">Address record</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">NS</td>\n<td style=\"text-align:center\">Domain</td>\n<td style=\"text-align:center\">Hostname of authoritative</td>\n<td style=\"text-align:center\">Name server record</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">CNAME</td>\n<td style=\"text-align:center\">Alisa hostname</td>\n<td style=\"text-align:center\">Canonical name</td>\n<td style=\"text-align:center\">Canonical name record</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">MX</td>\n<td style=\"text-align:center\">Alisa hostname of mail server</td>\n<td style=\"text-align:center\">Canonical name of mail server</td>\n<td style=\"text-align:center\">Mail exchange record</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>If a DNS server is authoritative for particular hostname ,then the DNS server will contain type A record for the hostname.</strong><br></p>\n<p><strong>If a DNS server is not authoritative for a hostname ,then it will contain a type NS record for domain that include hostname, it also contain a type A record that provide IP address of DNS server in the value field of the NS record.</strong><br></p>\n<ul>\n<li>For example in the TLD server<br></li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Type</th>\n<th style=\"text-align:center\">Name</th>\n<th style=\"text-align:center\">Value</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">NS</td>\n<td style=\"text-align:center\">umass.edu</td>\n<td style=\"text-align:center\">dns.umass.edu</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">A</td>\n<td style=\"text-align:center\">dns.umass.edu</td>\n<td style=\"text-align:center\">128.119.40.111</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"DNS-Messages\"><a href=\"#DNS-Messages\" class=\"headerlink\" title=\"DNS Messages\"></a>DNS Messages</h2><p>The DNS query and DNS reply have same Messages format as shown in Figure below .<br></p>\n<ul>\n<li><p><strong>DNS-Messages-Format</strong><br><img src=\"DNS-Messages.png\" alt=\"DNS-Messages\"></p>\n</li>\n<li><p><strong>We can use dig command to see DNS reply messages</strong></p>\n</li>\n</ul>\n<p><img src=\"DNS-Messagas-dig.png\" alt=\"DNS-Messages-dig\"><br>ID:30379 is 16-bit number that identifies the query corresponding <strong>identification</strong> of figure above .This identifies is copied into the reply messages allowing the client match receive messages with sent queries. <br><br><strong>Let’s see more detail about header flags format</strong><br></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Flag field</th>\n<th style=\"text-align:center\">Description</th>\n<th style=\"text-align:center\">Length(bits)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">OR</td>\n<td style=\"text-align:center\">indicate message is reply(1) or query(0)</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">OPCODE</td>\n<td style=\"text-align:center\">The type can be QUERY(standard query ,0),IQUERY(inverse query,1) or STATUS(server status request,2)</td>\n<td style=\"text-align:center\">4</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">AA</td>\n<td style=\"text-align:center\">Authoritative Answer, in the response,indicates if the DNS server is authoritative for queried hostname</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">TC</td>\n<td style=\"text-align:center\">Truncation, indicates that this messages was truncated due excessive length</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RD</td>\n<td style=\"text-align:center\">Recursion desired indicate if client means a recursion query.</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RA</td>\n<td style=\"text-align:center\">Recursion Available indicate if reply messages supports recursion</td>\n<td style=\"text-align:center\">1</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">Z</td>\n<td style=\"text-align:center\">zero ,reserved for future use</td>\n<td style=\"text-align:center\">3</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">RCODE</td>\n<td style=\"text-align:center\">Response code, can be NOERROR(0),FORMERR(format error,1),SERVFAIL(2),NXDOMAIN(nonexistent domain 3),etc</td>\n<td style=\"text-align:center\">4</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h1 id=\"Peer-to-Peer-Applications\"><a href=\"#Peer-to-Peer-Applications\" class=\"headerlink\" title=\"Peer-to-Peer Applications\"></a>Peer-to-Peer Applications</h1><h2 id=\"BitTorrent\"><a href=\"#BitTorrent\" class=\"headerlink\" title=\"BitTorrent\"></a>BitTorrent</h2><p>BitTorrent is popular P2P protocol for file distribution.<br></p>\n<p>In BItTorrent lingo, the collection of all peer in the distribution is called torrent.<br></p>\n<p>Each torrent has a infrastructure called tracker.When a peer join in a torrent, it must register itself with tracker and periodically informs the tracker that it is still in the torrent. In this manner the tracker can keep the track of the peers that participating in the torrent. <br> </p>\n<p><strong>Let we see a example to know more detail about how does p2p work.</strong><br><br>When a new peer Alice  want to join in torrent,what does it need to do.</p>\n<ol>\n<li>Alice must register herself with tracker.</li>\n<li>The tracker will randomly select a subset of peers from a set of participating peers and send the all IP address of subset peers to Alice</li>\n<li>Alice attempts concurrent establish TCP connection with subset peers. The succeed establish TCP connection peer is called <strong>“neighboring peers”</strong>. The neighboring peer probably leave at any time .</li>\n<li>Periodically Alice will ask (over the TCP connection)neighboring peer for list of chucks they have. If Alice have L neighboring peers ,Alice will obtain L list of chuck that neighboring peers have, with this knowledge, Alice can issue(over the TCP connection) require for chucks she current doesn’t have .</li>\n<li>Along with time pass .Alice have a set of chuck and know which chuck her neighboring peers have . At this instant of time .<strong>Alice will issue require for chucks her doesn’t have and rarest among her neighboring peers</strong> and <strong>Use clever trading algorithm determine which require her need to response namely which neighboring peer she need send the chuck(about the clever trading algorithm we discuss below)</strong> <br><h3 id=\"Incentive-mechanism-Clever-trading-algorithm\"><a href=\"#Incentive-mechanism-Clever-trading-algorithm\" class=\"headerlink\" title=\"Incentive mechanism: Clever trading algorithm\"></a>Incentive mechanism: Clever trading algorithm</h3>To determine which require  need to response , BitTorrent use clever trading algorithm.<br></li>\n</ol>\n<p>Specifically. For each of her neighboring peers , Alice will continuity measures the rate at which she receive bits and determine the four peer that feed her bit at the highest rate. Alice will reciprocates by send the chucks to these same four peers.<br></p>\n<p>In the BitTorrent lingo , the four peers is said to be <strong>unchoked</strong>.<br>Every 10 seconds , Alice will recalculates the rate and possibly modifies the set of four peers.<br> </p>\n<p>In specially, every 30 seconds , Alice will select a addition neighboring peer at random and send it chuck, The peer is said to be <strong>optimistically unchocked</strong> , The optimistically unchocked may become one of Alice’s top four peer , if it rate which send chuck to Alice is high enough.<br><br>The optimistically unchocked allow new peer to get chuck so that they can have something to trade. All the other neighboring peers beside the five peers (one optimistically unchoked and four unchoked) can’t received any chucks from Alice.</p>\n<h1 id=\"distributed-Hash-Table-DHTs\"><a href=\"#distributed-Hash-Table-DHTs\" class=\"headerlink\" title=\"distributed Hash Table (DHTs)\"></a>distributed Hash Table (DHTs)</h1><p>Distributed Hash Table is referred to a distributed P2P version database.<br></p>\n<h2 id=\"Circular-DHT\"><a href=\"#Circular-DHT\" class=\"headerlink\" title=\"Circular DHT\"></a>Circular DHT</h2><p>Each peer only award two peers ,immediate successor and predecessor<br></p>\n<p>We use a hash function map each key to a integer in the ranger [0-2^n-1]. For example suppose n = 4 ,we get the ranger is [0-15]. Further suppose that these are eight peer in the system 1,3,4,5,8,10,12,15. Suppose we want to stored a pair (format:key value) (11,johnny wu) to one of peers in the system. Using out closest conventions ,since peer 12 is closest successor for key 11. We therefore store the pair into peer 12.<br><br><strong>Let’s see more detail about the example that we mentioned above.</strong><br></p>\n<p>If the peer 3 (in figure below) want to know “who is responsible for key 11”, it only send the messages to clockwise around the circle , namely pass the message to peer 4 , if peer 4 don’t responsible key 11, it just passes the message to peer 5 , This process continues until the message arrives at the peer 12 , peer 12 receive the message will send response back to peer 3.</p>\n<p><img src=\"Circle-DHT.png\" alt=\"circle\"><br></p>\n<p>This circular arrangement of the peers is a special case of an overlay network. In an overlay network, the peers form an abstract logical network which resides above the “underlay” computer network consisting of physical links, routers,and hosts. The links in an overlay network are not physical links, but are simply vir-tual liaisons between pairs of peers. In the overlay in Figure(a) above, there are eightpeers and eight overlay links; in the overlay in Figure (b) there are eight peersand 16 overlay links. A single overlay link typically uses many physical links and physical routers in the underlay network.<br></p>\n<p>The circular DHT provide a elegant way to build the database , but all N peer in the system , we have to forward the message around the circle , N/2 message are send average.<br></p>\n<p>Fortunately we can refine the circular DHT, we can add a number of <strong>shortcut</strong> to each peer in the system . So that the each peer not only keep track of successor and predecessor but also keep track of a small number of shortcut like figure(b) above.<br></p>\n<p>Thus,when the peer 4 receives message passes from peer 3 asking about key 11, it can determine the closer peer to key is its shortcut peer 10,then forward message directly to peer 10. Clearly the shortcut can significantly reduce the number of messages used to query<br></p>\n<p>The next native question is “How many shortcut should the peer have and which peer should be these neighboring shortcut. “<br><br>The answer doesn’t referred in the textbook (computer-network-a-top-down-approach),we can only search with network use google.<br></p>\n<h2 id=\"peer-churn\"><a href=\"#peer-churn\" class=\"headerlink\" title=\"peer churn\"></a>peer churn</h2><p>About peer churn we can learn in textbook page 155.</p>\n"},{"title":"process-switch-base-on-stack-switch","date":"2020-02-16T07:57:03.000Z","index_img":"/Picture/stack.png","_content":"\n# 基于内核栈切换的进程切换\n\n## 实验目的\n\n- 深入理解进程和进程切换的概念；\n- 综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题；\n- 开始建立系统认识。\n\n## 实验内容\n\n现在的 Linux 0.11 采用 TSS（后面会有详细论述）和一条指令就能完成任务切换，虽然简单，但这指令的执行时间却很长，在实现任务切换时大概需要 200 多个时钟周期。\n\n而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。\n\n本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 `switch_to` 实现去掉，写成一段基于堆栈切换的代码。\n\n本次实验包括如下内容：\n\n- 编写汇编程序 `switch_to`：\n- 完成主体框架；\n- 在主体框架下依次完成 PCB 切换、内核栈切换、LDT 切换等；\n- 修改 `fork()`，由于是基于内核栈的切换，所以进程需要创建出能完成内核栈切换的样子。\n- 修改 PCB，即 `task_struct` 结构，增加相应的内容域，同时处理由于修改了 task_struct 所造成的影响。\n- 用修改后的 Linux 0.11 仍然可以启动、可以正常使用。\n- （选做）分析实验 3 的日志体会修改前后系统运行的差别。\n\n## 实验报告\n\n回答下面三个题：\n\n#### 问题 1\n\n针对下面的代码片段：\n\n```\nmovl tss,%ecx\naddl $4096,%ebx\nmovl %ebx,ESP0(%ecx)\n```\n\n回答问题：\n\n- （1）为什么要加 4096；\n\n  答：因为一页内存低地址存进程PCB，高地址是堆栈，linux-0.11 一页内存大小为4Kb,所以+4096。\n\n- （2）为什么没有设置 tss 中的 ss0。\n\n  答\n\n#### 问题 2\n\n针对代码片段：\n\n```c\n*(--krnstack) = ebp;\n*(--krnstack) = ecx;\n*(--krnstack) = ebx;\n*(--krnstack) = 0;\n```\n\n回答问题：\n\n- （1）子进程第一次执行时，eax=？为什么要等于这个数？哪里的工作让 eax 等于这样一个数？\n\n  答：子进程第一次执行是eax =0;，为了让代码```if (!fork()) {....}```区分子进程和父进程。\n\n- （2）这段代码中的 ebx 和 ecx 来自哪里，是什么含义，为什么要通过这些代码将其写到子进程的内核栈中？\n\n  答：这段代码中的ebx和ecx是栈切换执行switch_to时压入的值，我觉得是为了切换进程时保护现场而压入的，在fork创建新进程（子进程）时添加这些代码进新进程内核栈是为了模拟父进程的内核栈。\n\n- （3）这段代码中的 ebp 来自哪里，是什么含义，为什么要做这样的设置？可以不设置吗？为什么？\n\n  答：ebp也是来自基于栈切换的switch_to（）时压入的，是当前进程在进行切换时保存当前进程现场的操作，为什么要这样设置呢？因为创建新的子进程当进程切换时需要pop所以这里是为了模拟父进程的内核栈.\n\n#### 问题 3\n\n为什么要在切换完 LDT 之后要重新设置 fs=0x17？而且为什么重设操作要出现在切换完 LDT 之后，出现在 LDT 之前又会怎么样？\n\n答：因为需要重新设置fs对应的隐藏寄存器的段基址和段限长，所以需要重设操作，出现在LDT之前则没有任何意义不会有任何改变。\n\n\n\n## TSS的切换\n\n### TSS (task state segment)\n\nThe **task state segment (TTS)** is a structure on x86-based computers which holds information about a task, it is used by the operating system kernel for task managenment. specifically, the following information is stored in the TSS:\n\n- processor register state\n- I/O port permissions\n- Inner-lever stack pointers (内部堆栈指针)\n- Previous TSS link\n\nAll this information should be stored at specific locations within the TSS as specified in the IA-32 manuals.\n\n### TR (task register).\n\nThe TR register is a 16-bit register which holds a segment selector for the TSS. It may be loaded through the LTR instruction. LTR is a privileged instruction and acts in a manner similar to other segment register loads. The task register has two parts: a portion visible and accessible by the programmer and an invisible one that is automatically loaded from the TSS descriptor.<br>\n\n\n\nIn the current Linux 0.11,the real completion of the  process switch is accomplished by the task state segment(Task State Segment,TSS for short).\n\nSpecifically, when designing the \"Intel architecture\"(that is the x86 system structure),\n\neach task(process or thread) corresponds to an independent TSS. TSS is a  corresponds\n\nto an independent TSS. TSS is a structure in memory that contains almost all CPU registers Image. There is a Task Register(TR for short) pointing to the TSS structure corresponding to the current process. \n\nThe so-called TSS switch is copies almost all the registers in the CPU(current) to the TSS \n\nstructure pointed  by TR.\n\nAt the same time a target TSS is found ,that is the TSS corresponding to the next process to be switched to, and the register image of TSS structure of next process  stored in CPU.\n\nIn here  the execution site switching  is completed.\n\nas shown in the figure  blow:\n\n![](process-switch-base-on-stack-switch/wm.png)\n\nInter architecture provides the command ljmp to achieve the process switch .\n\n\n\nThe specific working process is:\n\n- First, use the segment selector in TR to find the current TSS structure memory location in GDT table.\n- second,  the register image of current CPU  store to the TSS structure memory  of finding before.(store the current site !)\n- Now, we need to find the target process site and copy the register image of the target   process to the CPU. This just means we need to find TSS of the next process in  GDT table and copy the context of TSS structure memory to CPU.\n- when the register image of TSS structure of the target process store in CPU completely, that means achieve switch to target process site, now, the target process becomes the current process. \n- Finally , TR should be changed to point to the location of the target TSS segment in the GDT table.<br>\n\nall explain above  through one sentence execute  (ljmp segment selector : intra-segment offset).\n\nSo switch_to (a instruction) base on TSS for process and thread switching is actually a ljmp instruction：\n\n```assembly\n#define switch_to(n) {\\\nstruct {long a,b;} __tmp; \\\n__asm__(\"cmpl %%ecx,current\\n\\t\" \\\t \n\t\"je 1f\\n\\t\" \\\n\t\"movw %%dx,%1\\n\\t\" \\\n\t\"xchgl %%ecx,current\\n\\t\" \\\n\t\"ljmp *%0\\n\\t\" \\\n\t\"cmpl %%ecx,last_task_used_math\\n\\t\" \\\n\t\"jne 1f\\n\\t\" \\\n\t\"clts\\n\" \\\n\t\"1:\" \\\n\t::\"m\" (*&__tmp.a),\"m\" (*&__tmp.b), \\\n\t\"d\" (_TSS(n)),\"c\" ((long) task[n])); \\\n}\n\n#define FIRST_TSS_ENTRY 4\n\n#define TSS(n) (((unsigned long) n) << 4) + (FIRST_TSS_ENTRY << 3))\n```\n\nEach process is divided into two part which correspond to TSS and LDT, respectively. \n\nTSS and LDT are both 64-bit(8 bytes).\n\nso  _TSS(n) = n * 16 + 4 * 8 (bytes).\n\n**ljmp instruction can be used in two ways, which are \"ljmp $ segment selector, $ offset\" and \"ljmp * mem48\" respectively. In here \"ljmp *% 0\" used the second way, \"ljmp * mem48\" mean jump to Logical address (48 bits) of the mem48 contain (mem48 also is an address), the hight 16 bits of 48 bits correspond to segment_selector, the low 32 bits of 48 bits correspond to offset. So ,the core of switch_to is ljmp 0 , n\\*16+4\\*8  **\n\n**!! it is worth out attention:**\n\nThe '\\*' of the \"ljmp *mem48\" is different from '\\*' of C language . The '\\*' of the \"ljmp *mem48\"  is mean indirect jump.\n\n\n\n## 本次实验的内容\n\nAlthough ，the task switching can be completed with one instruction, the execution time of the instruction is very long . It take almost 200 time cycles to complete the task switch using the ljmp instruction. if we want to increase the switching speed ,we can use the heap_stack switch instead of ljmp instruction.\n\nMoreover. The use of heap_stack switching can also use the parallel optimization technology of instruction pipeline, while making design of the CPU simple.\n\nTherefore, both Windows and Linux use the heap_stack switching technology to handle process switching.\n\nTherefore rewriter the code of \"switch_to\" to  use the heap_stack switch instead of TSS is my task.\n\nTo achieve a process switch base on kernel , we need do three things :\n\n1. Rewrite \"switch_to\"\n2. Connect the rewritten \"switch_to\" and schedule() functions together.\n3. Modify the current fork().\n\n## schedule 与 switch_to\n\n### modify shcedule()\n\nThe task of schedule( ) is finding the position \"next\" of the next process in the array.  The \"next\" is equal to \"n\" of the GDT table(TSS[n]=n\\*16+4\\*8).  if we get the \"next\" in the schedule function, we can use \"switch_to (next)\" function move to another process.\n\nNow, we use heap_stack switching instead of TSS switching ,and so we need informations of  current process PCB 、target process PCB、current process kernel stack and target process kernel stack.\n\n The kernel stack of the Linux 0.11 process and the PCB of process are stored on the same page of memory (a 4kB size page of memory).The PCB is located at the low address of this page of memory ,and the stack is located at the high address of this page of memory.\n\nIn addition, since the PCB of the current process is pointed with a global variable \"current\", we  need to tell new switch_to () function a pointer to the target process PCB and we need to tell new switch_to function LDT(next) instead of TSS (next). Just mean ,we don't need TSS in each process now（we can delete code about TSS），but  also need LDT of  process.\n\n\n\nIn summary ,the current schedule() function (in kernel/sched.c) needs to be slightly modified, that is the following code:\n\n```C\nif ((*p)->state == TASK_RUNNING && (*p)->counter > c) \n    c = (*p)->counter, next = i; \n\n//......\n\nswitch_to(next);\n```\n\nmodify:\n\n```C\nif ((*p)->state == TASK_RUNNING && (*p)->counter > c) \n    c = (*p)->counter, next = i, pnext = *p;\n\n//.......\n\nswitch_to(pnext, _LDT(next)); \n```\n\n### Rewrite switch_to()\n\nRewrite switch_to() function is the most important step in this experiment.\n\nThis function, in turn, completes the following functions:\n\n- first, we need to handle the stack by the assembly language. just handle the ebp register.\n- second, we need to compare the parameter of stack about the next process's PCB with the current process.\n- third, we need in turn to complete PCB switch, rewrite kernel stack pointer of TSS, switch kernel stack, switch LDT and switch PC pointer (CS:EIP).\n\n```assembly\nswitch_to:\n    pushl %ebp\n    movl %esp,%ebp\n    pushl %ecx\n    pushl %ebx\n    pushl %eax\n    movl 8(%ebp),%ebx\n    cmpl %ebx,current\n    je 1f\n! 切换PCB\n    ! ...\n! TSS中的内核栈指针的重写\n    ! ...\n! 切换内核栈\n    ! ...\n! 切换LDT\n    ! ...\n    movl $0x17,%ecx\n    mov %cx,%fs\n! 和后面的 clts 配合来处理协处理器，由于和主题关系不大，此处不做论述\n    cmpl %eax,last_task_used_math \n    jne 1f\n    clts\n\n1:    popl %eax\n    popl %ebx\n    popl %ecx\n    popl %ebp\nret\n```\n\n**Switch PCB pointer**\n\nebx register is next process's PCB pointer.\n\nThe function of xchgl instruction  is to exchange contents between  two register.\n\n```assembly\nmovl %ebx,%eax\nxchgl %eax,current\t\n```\n\n**Rewrite pointer of kernel stack stored in  TSS**\n\nThe current TSS is different from TSS before. Before TSS is a global array but current TSS is a global variable. We need to redefine TSS pointer through two sentences.\n\n```\n#define ESP0 =4\nstruct tss_struct *tss = (init_task.task.tss);\n```\n\ncurrent TSS pointer ```tss``` similar current process pointer ```current```.\n\nThis has already discussed in detail before. In the system interrupt ,we need to find and determine the location of the kernel stack. and push the five register SS : ESP, CS: EIP and EFLAGS in user mode onto kernel stack. This is the key bridge between the user mode (user stack) and kernel mode (kernel stack). The key of find kernel stack position is use the TR register point to current TSS.\n\nAlthough we don't need to use TSS for switch process in now.  We still stay the intel interrupt system. So we still need it that is we define global variable ```tss```. All processes share that variable.\n\n```assembly\nmovl tss,%ecx\naddl $4096,%ebx\nmovl %ebx,ESP0(%ecx)\n```\n\nESP0 = 4 ,the ecx + ESP0 equal to position of kernel stack pointer in TSS (esp0).\n\n```C\nstruct tss_struct {\n\tlong\tback_link;\t/* 16 high bits zero */\n\tlong\tesp0;\n\tlong\tss0;\t\t/* 16 high bits zero */\n\tlong\tesp1;\n\tlong\tss1;\t\t/* 16 high bits zero */\n\tlong\tesp2;\n\tlong\tss2;\t\t/* 16 high bits zero */\n\tlong\tcr3;\n\tlong\teip;\n\tlong\teflags;\n\tlong\teax,ecx,edx,ebx;\n\tlong\tesp;\n\tlong\tebp;\n\tlong\tesi;\n\tlong\tedi;\n\tlong\tes;\t\t/* 16 high bits zero */\n\tlong\tcs;\t\t/* 16 high bits zero */\n\tlong\tss;\t\t/* 16 high bits zero */\n\tlong\tds;\t\t/* 16 high bits zero */\n\tlong\tfs;\t\t/* 16 high bits zero */\n\tlong\tgs;\t\t/* 16 high bits zero */\n\tlong\tldt;\t\t/* 16 high bits zero */\n\tlong\ttrace_bitmap;\t/* bits: trace 0, bitmap 16-31 */\n\tstruct i387_struct i387;\n};\n```\n\n**switch kernel stack :**\n\nIt's also simple to complete the kernel stack switch. we just need to store value of esp register of the current process  onto the current PCB , and take corresponding esp value of next PCB out and put it into esp register.\n\nsince Linux -0.11  didn't define the variable of kernel stack pointer in PCB(task_struct). so we need to add a variable ```kernelstack``` to Linux-0.11 PCB, we still need define another variable ``` KERNEL_STACK = 12```  for determine variable of  ```kernelstack``` position in PCB.\n\n**Why KERNEL_STACK equal to 12 ?**\n\nbecause the kernel code have many  assembly hardcodes about manipulating this structure, so,if we add the variable ```kernelstack``` in other position, we need to modify kernel code in many difference place. \n\n```C\nKERNEL_STACK = 12\nmovl %esp,KERNEL_STACK(%eax)\t! 保存上一个进程的栈顶指针\n! 再取一下 ebx，因为前面修改过 ebx 的值,此时eax的值等于上一个进程的PCB指针\nmovl 8(%ebp),%ebx\t\nmovl KERNEL_STACK(%ebx),%esp\t！取下个进程的栈顶指针放入esp\n```\n\ntask_struct:\n\n```C\n// 在 include/linux/sched.h 中\nstruct task_struct {\n    long state;\n    long counter;\n    long priority;\n    long kernelstack;\n//......\n```\n\nbecause we modify the PCB structure,  we also need to modify initialization code of 0 process PCB structure .Modify ```#define INIT_TASK { 0,15,15, 0,{ { },},0,...```  to ``` #define INIT_TASK { 0,15,15,PAGE_SIZE+(long)&init_task, 0,{ { },},0,...```\n\n**switch LDT**\n\n```assembly\nmovl 12(%ebp),%ecx\nlldt %cx\n!上面使改LDT代码\nmovl $0x17,%ecx\nmov %cx,%fs\n```\n\nWhy we have to add two code ```movl $0x17,%ecx``` ``` mov %cx,%fs``` behind that code of switch LDT.\n\nbecause we need to change the segment base address and segment length limit in the hidden register about fs.\n\nExamlpe with CS. The hidden register for increase CPU processing speed.\n\n![](process-switch-base-on-stack-switch/wm1.png)\n\n**switch PC （switch to next process）**\n\n```assembly\n1:    popl %eax\n    popl %ebx\n    popl %ecx\n    popl %ebp\nret\n```\n\n**kernel stack  now**\n\n![](https://img-blog.csdnimg.cn/20190819230403925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTc2MTQ3OA==,size_16,color_FFFFFF,t_70)\n\nExecute those codes to turn to the next process,if it isn't come here through code ```je 1f```. Because we have been changed the kernel stack before. we ```pop  (eax ,ebx,ecx,ebp) ``` is register of next process.   ret instruction equal to ```pop IP```.So we execute ```ret``` turn to schedule() function tail of next process. Now ! we completed the stack switch perfectly.\n\n## modify fork()\n\n**Why we need to modify fork() function ?**\n\n**Because, we need to simulate the parent process's kernel stack for the newly created child process. **\n\nNow, we need to modify the fork() function. it is to associate the process's user stack, user program to its kernel stack with SS: ESP, CS: IP, which is pushed in the kernel stack.\n\nIn addition, since fork() function-core is let the child process to use code, data, and stack of the parent process . the fork core has not changed, although we use the stack switching.\n\n![](process-switch-base-on-stack-switch/wm2.png)\n\nDon't hard to imagine. modify fork which  mean  initialize child process's kernel stack. In ```copy_process () ```as the core code of ```fork ()```, it used to apply a page of memory as process PCB. The kernel stack address position equal pointer p position add the one page of memory size.  so the code ```krnstack = (*long)(PAGE_SIZE + (long)p)``` can find the child process kernel stack position. next step is to initialize the content of krnstack pointer .\n\n```C\n/*modify in fork()*/\nlong *krnstack;\np = (struct task_struct *) get_free_page();\nkrnstack = (long)(PAGE_SIZE +(long)p);\n *(--krnstack) = ss & 0xffff;\n *(--krnstack) = esp;\n *(--krnstack) = eflags;\n *(--krnstack) = cs & 0xffff;\n *(--krnstack) = eip;\n *(--krnstack) = ds & 0xffff;\n *(--krnstack) = es & 0xffff;\n *(--krnstack) = fs & 0xffff;\n *(--krnstack) = gs & 0xffff;\n *(--krnstack) = esi;\n *(--krnstack) = edi;\n *(--krnstack) = edx;\n *(--krnstack) = (long)first_return_from_kernel;\n *(--krnstack) = ebp;\n *(--krnstack) = ecx;\n *(--krnstack) = ebx;\n *(--krnstack) = 0;\n p->kernelstack = krnstack;\n ......\n\n```\n\nThose code for simulate parent kernel stack for child process! \n\nMake a attention !\n\n```c\n*(--krnstack) = (long)first_return_from_kernel;\n*(--krnstack) = 0;\n```\n\nWe need to code a first_return_from_kernel as a mark! If we return to address first_return_from_kernel. We need to execute those code following.\n\n```assembly\n/*modify in system_call.s*/\n.align 2\nfirst_return_from_kernel:\npopl %edx\npopl %edi\npopl %esi\npop %gs\npop %fs\npop %es\npop %ds\niret\n```\n\ninstruction ```iret``` equal to \n\n```assembly\npop eip\npop cs\npop eflags\npop esp\npop ss\n```\n\n instruction ```*(--krnstack) = 0;```  Means eax =0 for distinguish parent process and child process.\n\n**In the end , don't forget add the two code following to corresponding .c file **\n\n```C\nextern void first_return_kernel(void); // in the fork()\nextern long switch_to(struct task_struct *p , unsigned long _ldt); // in the sched.c\n```\n\n## Modify step\n\n**Modify in system_call.s**\n\nWrite the switch_to、first_return_from_kernel、etc in the system_call.s**\n\n```assembly\n# Don't forget to change the hardcode.\n# Because I forget to change the hardcode , I stayed here so long time.\nstate\t= 0\t\t# these are offsets into the task-struct.\ncounter\t= 4\npriority = 8\nKERNEL_STACK = 12\nsignal\t= 16\nsigaction = 20\t\t# MUST be 16 (=len of sigaction)\nblocked = (33*16+4)\n\n# Define as a global variable，can be used in other file with the keyword extern declaration.\n.globl first_return_from_kernel, switch_to \n.align 2\nswitch_to:\n\tpushl %ebp\n\tmovl %esp, %ebp\n\tpushl %ecx\n\tpushl %ebx\n\tpushl %eax \n\tmovl 8(%ebp), %ebx \n\tcmpl %ebx, current \n\tje 1f\n\tmovl %ebx, %eax\n\txchgl %eax, current # eax=old_current, so current=pnext\n\tmovl tss, %ecx\t\t# ecx = tss of pnext, it also the new current\n\taddl $4096, %ebx\t# ebx=the top of current kernel stack(pnext)\n\tmovl %ebx, 4(%ecx)\n\tmovl %esp, KERNEL_STACK(%eax)\n\tmovl 8(%ebp), %ebx \n\tmovl KERNEL_STACK(%ebx), %esp\n\tmovl 12(%ebp), %ecx\n\tlldt %cx\n\tmovl $0x17, %ecx\n\tmov %cx, %fs\n\tcmpl %eax, last_task_used_math\t\n\tjne 1f\n\tclts\n1:  popl %eax\n\tpopl %ebx\n\tpopl %ecx\n\tpopl %ebp\n\tret\n.align 2\nfirst_return_from_kernel:\n\tpopl %edx\n\tpopl %edi\n\tpopl %esi\n\tpop %gs\n\tpop %fs\n\tpop %es\n\tpop %ds\n\tiret\n```\n\n**Modify sched.h **\n\n```C\nstruct task_struct {\n/* these are hardcoded - don't touch */\n\tlong state;\t/* -1 unrunnable, 0 runnable, >0 stopped */\n\tlong counter;\n\tlong priority;\n\tlong kernelstack;\n\tlong signal;\n\tstruct sigaction sigaction[32];\n\tlong blocked;\t/* bitmap of masked signals */\n    ......\n}\n#define INIT_TASK \\\n/* state etc */\t{ 0,15,15,PAGE_SIZE+(long)&init_task, \\\n/* signals */\t0,{{},},0, \\\n.................................\n\n /*注释掉\n#define switch_to(n) {\\\nstruct {long a,b;} __tmp; \\\n__asm__(\"cmpl %%ecx,current\\n\\t\" \\\n\t\"je 1f\\n\\t\" \\\n\t\"movw %%dx,%1\\n\\t\" \\\n\t\"xchgl %%ecx,current\\n\\t\" \\\n\t\"ljmp *%0\\n\\t\" \\\n\t\"cmpl %%ecx,last_task_used_math\\n\\t\" \\\n\t\"jne 1f\\n\\t\" \\\n\t\"clts\\n\" \\\n\t\"1:\" \\\n\t::\"m\" (*&__tmp.a),\"m\" (*&__tmp.b), \\\n\t\"d\" (_TSS(n)),\"c\" ((long) task[n])); \\\n}\n*/\n  \n```\n\n**Modify sched.c**\n\n```C\nextern long switch_to(struct task_struct *p , unsigned long _ldt);\nstruct tss_struct * tss = &(init_task.task.tss);\nvoid schedule(void)\n{\n\tint i,next,c;\n\tstruct task_struct ** p;\n\tstruct task_struct *pnext = &(init_task.task);\n\n/* check alarm, wake up any interruptible tasks that have got a signal */\n\n\tfor(p = &LAST_TASK ; p > &FIRST_TASK ; --p)\n\t\tif (*p) {\n\t\t\tif ((*p)->alarm && (*p)->alarm < jiffies) {\n\t\t\t\t\t(*p)->signal |= (1<<(SIGALRM-1));\n\t\t\t\t\t(*p)->alarm = 0;\n\t\t\t\t}\n\t\t\tif (((*p)->signal & ~(_BLOCKABLE & (*p)->blocked)) &&\n\t\t\t(*p)->state==TASK_INTERRUPTIBLE)\n\t\t\t\t(*p)->state=TASK_RUNNING;\n\t\t}\n\n/* this is the scheduler proper: */\n\n\twhile (1) {\n\t\tc = -1;\n\t\tnext = 0;\n\t\ti = NR_TASKS;\n\t\tp = &task[NR_TASKS];\n\t\twhile (--i) {\n\t\t\tif (!*--p)\n\t\t\t\tcontinue;\n\t\t\tif ((*p)->state == TASK_RUNNING && (*p)->counter > c){\n\t\t\t\tc = (*p)->counter, next = i;\n\t\t\t\tpnext = *p;\n\t\t\t}\n\t\t}\n\t\tif (c) break;\n\t\tfor(p = &LAST_TASK ; p > &FIRST_TASK ; --p)\n\t\t\tif (*p)\n\t\t\t\t(*p)->counter = ((*p)->counter >> 1) +\n\t\t\t\t\t\t(*p)->priority;\n\t}\n\tswitch_to(pnext,_LDT(next));\n}\n```\n\n**Modify fork()**\n\n```C\nextern void first_return_kernel(void);  \n\nint copy_process(int nr,long ebp,long edi,long esi,long gs,long none,\n\t\tlong ebx,long ecx,long edx,\n\t\tlong fs,long es,long ds,\n\t\tlong eip,long cs,long eflags,long esp,long ss)\n{\n\tstruct task_struct *p;\n\tint i;\n\tstruct file *f;\n\n\tp = (struct task_struct *) get_free_page();\n\tif (!p)\n\t\treturn -EAGAIN;\n\ttask[nr] = p;\n\t*p = *current;\t/* NOTE! this doesn't copy the supervisor stack */\n\tp->state = TASK_UNINTERRUPTIBLE;\n\tp->pid = last_pid;\n\tp->father = current->pid;\n\tp->counter = p->priority;\n\tlong * krnstack ;\n\tkrnstack = (long *) (PAGE_SIZE + (long) p);\n    *(--krnstack) = ss & 0xffff;\n    *(--krnstack) = esp;\n    *(--krnstack) = eflags;\n    *(--krnstack) = cs & 0xffff;\n    *(--krnstack) = eip;\n *(--krnstack) = ds & 0xffff; \n   *(--krnstack) = es & 0xffff; \n   *(--krnstack) = fs & 0xffff; \n *(--krnstack) = gs & 0xffff;\n  *(--krnstack) = esi; \n *(--krnstack) = edi; \n    *(--krnstack) = edx;\n\t*(--krnstack) =(long) first_return_kernel;\n    *(--krnstack) = ebp;\n    *(--krnstack) = ecx;\n    *(--krnstack) = ebx;\n    *(--krnstack) = 0;\n\tp->kernelstack = krnstack;\n\tp->signal = 0;\n\tp->alarm = 0;\n\tp->leader = 0;\t\t/* process leadership doesn't inherit */\n\tp->utime = p->stime = 0;\n\tp->cutime = p->cstime = 0;\n\tp->start_time = jiffies;\n\tp->tss.back_link = 0;\n\tp->tss.esp0 = PAGE_SIZE + (long) p;\n\tp->tss.ss0 = 0x10;\n\tp->tss.eip = eip;\n\tp->tss.eflags = eflags;\n\tp->tss.eax = 0;\n\tp->tss.ecx = ecx;\n\tp->tss.edx = edx;\n\tp->tss.ebx = ebx;\n\tp->tss.esp = esp;\n\tp->tss.ebp = ebp;\n\tp->tss.esi = esi;\n\tp->tss.edi = edi;\n\tp->tss.es = es & 0xffff;\n\tp->tss.cs = cs & 0xffff;\n\tp->tss.ss = ss & 0xffff;\n\tp->tss.ds = ds & 0xffff;\n\tp->tss.fs = fs & 0xffff;\n\tp->tss.gs = gs & 0xffff;\n\tp->tss.ldt = _LDT(nr);\n\tp->tss.trace_bitmap = 0x80000000;\n\tif (last_task_used_math == current)\n\t\t__asm__(\"clts ; fnsave %0\"::\"m\" (p->tss.i387));\n\tif (copy_mem(nr,p)) {\n\t\ttask[nr] = NULL;\n\t\tfree_page((long) p);\n\t\treturn -EAGAIN;\n\t}\n\tfor (i=0; i<NR_OPEN;i++)\n\t\tif ((f=p->filp[i]))\n\t\t\tf->f_count++;\n\tif (current->pwd)\n\t\tcurrent->pwd->i_count++;\n\tif (current->root)\n\t\tcurrent->root->i_count++;\n\tif (current->executable)\n\t\tcurrent->executable->i_count++;\n\tset_tss_desc(gdt+(nr<<1)+FIRST_TSS_ENTRY,&(p->tss));\n\tset_ldt_desc(gdt+(nr<<1)+FIRST_LDT_ENTRY,&(p->ldt));\n\tp->state = TASK_RUNNING;\t/* do this last, just in case */\n\treturn last_pid;\n}\n```\n\n","source":"_posts/process-switch-base-on-stack-switch.md","raw":"---\ntitle: process-switch-base-on-stack-switch\ndate: 2020-02-16 15:57:03\nindex_img: /Picture/stack.png\ntags: -操作系统\n\n---\n\n# 基于内核栈切换的进程切换\n\n## 实验目的\n\n- 深入理解进程和进程切换的概念；\n- 综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题；\n- 开始建立系统认识。\n\n## 实验内容\n\n现在的 Linux 0.11 采用 TSS（后面会有详细论述）和一条指令就能完成任务切换，虽然简单，但这指令的执行时间却很长，在实现任务切换时大概需要 200 多个时钟周期。\n\n而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。\n\n本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 `switch_to` 实现去掉，写成一段基于堆栈切换的代码。\n\n本次实验包括如下内容：\n\n- 编写汇编程序 `switch_to`：\n- 完成主体框架；\n- 在主体框架下依次完成 PCB 切换、内核栈切换、LDT 切换等；\n- 修改 `fork()`，由于是基于内核栈的切换，所以进程需要创建出能完成内核栈切换的样子。\n- 修改 PCB，即 `task_struct` 结构，增加相应的内容域，同时处理由于修改了 task_struct 所造成的影响。\n- 用修改后的 Linux 0.11 仍然可以启动、可以正常使用。\n- （选做）分析实验 3 的日志体会修改前后系统运行的差别。\n\n## 实验报告\n\n回答下面三个题：\n\n#### 问题 1\n\n针对下面的代码片段：\n\n```\nmovl tss,%ecx\naddl $4096,%ebx\nmovl %ebx,ESP0(%ecx)\n```\n\n回答问题：\n\n- （1）为什么要加 4096；\n\n  答：因为一页内存低地址存进程PCB，高地址是堆栈，linux-0.11 一页内存大小为4Kb,所以+4096。\n\n- （2）为什么没有设置 tss 中的 ss0。\n\n  答\n\n#### 问题 2\n\n针对代码片段：\n\n```c\n*(--krnstack) = ebp;\n*(--krnstack) = ecx;\n*(--krnstack) = ebx;\n*(--krnstack) = 0;\n```\n\n回答问题：\n\n- （1）子进程第一次执行时，eax=？为什么要等于这个数？哪里的工作让 eax 等于这样一个数？\n\n  答：子进程第一次执行是eax =0;，为了让代码```if (!fork()) {....}```区分子进程和父进程。\n\n- （2）这段代码中的 ebx 和 ecx 来自哪里，是什么含义，为什么要通过这些代码将其写到子进程的内核栈中？\n\n  答：这段代码中的ebx和ecx是栈切换执行switch_to时压入的值，我觉得是为了切换进程时保护现场而压入的，在fork创建新进程（子进程）时添加这些代码进新进程内核栈是为了模拟父进程的内核栈。\n\n- （3）这段代码中的 ebp 来自哪里，是什么含义，为什么要做这样的设置？可以不设置吗？为什么？\n\n  答：ebp也是来自基于栈切换的switch_to（）时压入的，是当前进程在进行切换时保存当前进程现场的操作，为什么要这样设置呢？因为创建新的子进程当进程切换时需要pop所以这里是为了模拟父进程的内核栈.\n\n#### 问题 3\n\n为什么要在切换完 LDT 之后要重新设置 fs=0x17？而且为什么重设操作要出现在切换完 LDT 之后，出现在 LDT 之前又会怎么样？\n\n答：因为需要重新设置fs对应的隐藏寄存器的段基址和段限长，所以需要重设操作，出现在LDT之前则没有任何意义不会有任何改变。\n\n\n\n## TSS的切换\n\n### TSS (task state segment)\n\nThe **task state segment (TTS)** is a structure on x86-based computers which holds information about a task, it is used by the operating system kernel for task managenment. specifically, the following information is stored in the TSS:\n\n- processor register state\n- I/O port permissions\n- Inner-lever stack pointers (内部堆栈指针)\n- Previous TSS link\n\nAll this information should be stored at specific locations within the TSS as specified in the IA-32 manuals.\n\n### TR (task register).\n\nThe TR register is a 16-bit register which holds a segment selector for the TSS. It may be loaded through the LTR instruction. LTR is a privileged instruction and acts in a manner similar to other segment register loads. The task register has two parts: a portion visible and accessible by the programmer and an invisible one that is automatically loaded from the TSS descriptor.<br>\n\n\n\nIn the current Linux 0.11,the real completion of the  process switch is accomplished by the task state segment(Task State Segment,TSS for short).\n\nSpecifically, when designing the \"Intel architecture\"(that is the x86 system structure),\n\neach task(process or thread) corresponds to an independent TSS. TSS is a  corresponds\n\nto an independent TSS. TSS is a structure in memory that contains almost all CPU registers Image. There is a Task Register(TR for short) pointing to the TSS structure corresponding to the current process. \n\nThe so-called TSS switch is copies almost all the registers in the CPU(current) to the TSS \n\nstructure pointed  by TR.\n\nAt the same time a target TSS is found ,that is the TSS corresponding to the next process to be switched to, and the register image of TSS structure of next process  stored in CPU.\n\nIn here  the execution site switching  is completed.\n\nas shown in the figure  blow:\n\n![](process-switch-base-on-stack-switch/wm.png)\n\nInter architecture provides the command ljmp to achieve the process switch .\n\n\n\nThe specific working process is:\n\n- First, use the segment selector in TR to find the current TSS structure memory location in GDT table.\n- second,  the register image of current CPU  store to the TSS structure memory  of finding before.(store the current site !)\n- Now, we need to find the target process site and copy the register image of the target   process to the CPU. This just means we need to find TSS of the next process in  GDT table and copy the context of TSS structure memory to CPU.\n- when the register image of TSS structure of the target process store in CPU completely, that means achieve switch to target process site, now, the target process becomes the current process. \n- Finally , TR should be changed to point to the location of the target TSS segment in the GDT table.<br>\n\nall explain above  through one sentence execute  (ljmp segment selector : intra-segment offset).\n\nSo switch_to (a instruction) base on TSS for process and thread switching is actually a ljmp instruction：\n\n```assembly\n#define switch_to(n) {\\\nstruct {long a,b;} __tmp; \\\n__asm__(\"cmpl %%ecx,current\\n\\t\" \\\t \n\t\"je 1f\\n\\t\" \\\n\t\"movw %%dx,%1\\n\\t\" \\\n\t\"xchgl %%ecx,current\\n\\t\" \\\n\t\"ljmp *%0\\n\\t\" \\\n\t\"cmpl %%ecx,last_task_used_math\\n\\t\" \\\n\t\"jne 1f\\n\\t\" \\\n\t\"clts\\n\" \\\n\t\"1:\" \\\n\t::\"m\" (*&__tmp.a),\"m\" (*&__tmp.b), \\\n\t\"d\" (_TSS(n)),\"c\" ((long) task[n])); \\\n}\n\n#define FIRST_TSS_ENTRY 4\n\n#define TSS(n) (((unsigned long) n) << 4) + (FIRST_TSS_ENTRY << 3))\n```\n\nEach process is divided into two part which correspond to TSS and LDT, respectively. \n\nTSS and LDT are both 64-bit(8 bytes).\n\nso  _TSS(n) = n * 16 + 4 * 8 (bytes).\n\n**ljmp instruction can be used in two ways, which are \"ljmp $ segment selector, $ offset\" and \"ljmp * mem48\" respectively. In here \"ljmp *% 0\" used the second way, \"ljmp * mem48\" mean jump to Logical address (48 bits) of the mem48 contain (mem48 also is an address), the hight 16 bits of 48 bits correspond to segment_selector, the low 32 bits of 48 bits correspond to offset. So ,the core of switch_to is ljmp 0 , n\\*16+4\\*8  **\n\n**!! it is worth out attention:**\n\nThe '\\*' of the \"ljmp *mem48\" is different from '\\*' of C language . The '\\*' of the \"ljmp *mem48\"  is mean indirect jump.\n\n\n\n## 本次实验的内容\n\nAlthough ，the task switching can be completed with one instruction, the execution time of the instruction is very long . It take almost 200 time cycles to complete the task switch using the ljmp instruction. if we want to increase the switching speed ,we can use the heap_stack switch instead of ljmp instruction.\n\nMoreover. The use of heap_stack switching can also use the parallel optimization technology of instruction pipeline, while making design of the CPU simple.\n\nTherefore, both Windows and Linux use the heap_stack switching technology to handle process switching.\n\nTherefore rewriter the code of \"switch_to\" to  use the heap_stack switch instead of TSS is my task.\n\nTo achieve a process switch base on kernel , we need do three things :\n\n1. Rewrite \"switch_to\"\n2. Connect the rewritten \"switch_to\" and schedule() functions together.\n3. Modify the current fork().\n\n## schedule 与 switch_to\n\n### modify shcedule()\n\nThe task of schedule( ) is finding the position \"next\" of the next process in the array.  The \"next\" is equal to \"n\" of the GDT table(TSS[n]=n\\*16+4\\*8).  if we get the \"next\" in the schedule function, we can use \"switch_to (next)\" function move to another process.\n\nNow, we use heap_stack switching instead of TSS switching ,and so we need informations of  current process PCB 、target process PCB、current process kernel stack and target process kernel stack.\n\n The kernel stack of the Linux 0.11 process and the PCB of process are stored on the same page of memory (a 4kB size page of memory).The PCB is located at the low address of this page of memory ,and the stack is located at the high address of this page of memory.\n\nIn addition, since the PCB of the current process is pointed with a global variable \"current\", we  need to tell new switch_to () function a pointer to the target process PCB and we need to tell new switch_to function LDT(next) instead of TSS (next). Just mean ,we don't need TSS in each process now（we can delete code about TSS），but  also need LDT of  process.\n\n\n\nIn summary ,the current schedule() function (in kernel/sched.c) needs to be slightly modified, that is the following code:\n\n```C\nif ((*p)->state == TASK_RUNNING && (*p)->counter > c) \n    c = (*p)->counter, next = i; \n\n//......\n\nswitch_to(next);\n```\n\nmodify:\n\n```C\nif ((*p)->state == TASK_RUNNING && (*p)->counter > c) \n    c = (*p)->counter, next = i, pnext = *p;\n\n//.......\n\nswitch_to(pnext, _LDT(next)); \n```\n\n### Rewrite switch_to()\n\nRewrite switch_to() function is the most important step in this experiment.\n\nThis function, in turn, completes the following functions:\n\n- first, we need to handle the stack by the assembly language. just handle the ebp register.\n- second, we need to compare the parameter of stack about the next process's PCB with the current process.\n- third, we need in turn to complete PCB switch, rewrite kernel stack pointer of TSS, switch kernel stack, switch LDT and switch PC pointer (CS:EIP).\n\n```assembly\nswitch_to:\n    pushl %ebp\n    movl %esp,%ebp\n    pushl %ecx\n    pushl %ebx\n    pushl %eax\n    movl 8(%ebp),%ebx\n    cmpl %ebx,current\n    je 1f\n! 切换PCB\n    ! ...\n! TSS中的内核栈指针的重写\n    ! ...\n! 切换内核栈\n    ! ...\n! 切换LDT\n    ! ...\n    movl $0x17,%ecx\n    mov %cx,%fs\n! 和后面的 clts 配合来处理协处理器，由于和主题关系不大，此处不做论述\n    cmpl %eax,last_task_used_math \n    jne 1f\n    clts\n\n1:    popl %eax\n    popl %ebx\n    popl %ecx\n    popl %ebp\nret\n```\n\n**Switch PCB pointer**\n\nebx register is next process's PCB pointer.\n\nThe function of xchgl instruction  is to exchange contents between  two register.\n\n```assembly\nmovl %ebx,%eax\nxchgl %eax,current\t\n```\n\n**Rewrite pointer of kernel stack stored in  TSS**\n\nThe current TSS is different from TSS before. Before TSS is a global array but current TSS is a global variable. We need to redefine TSS pointer through two sentences.\n\n```\n#define ESP0 =4\nstruct tss_struct *tss = (init_task.task.tss);\n```\n\ncurrent TSS pointer ```tss``` similar current process pointer ```current```.\n\nThis has already discussed in detail before. In the system interrupt ,we need to find and determine the location of the kernel stack. and push the five register SS : ESP, CS: EIP and EFLAGS in user mode onto kernel stack. This is the key bridge between the user mode (user stack) and kernel mode (kernel stack). The key of find kernel stack position is use the TR register point to current TSS.\n\nAlthough we don't need to use TSS for switch process in now.  We still stay the intel interrupt system. So we still need it that is we define global variable ```tss```. All processes share that variable.\n\n```assembly\nmovl tss,%ecx\naddl $4096,%ebx\nmovl %ebx,ESP0(%ecx)\n```\n\nESP0 = 4 ,the ecx + ESP0 equal to position of kernel stack pointer in TSS (esp0).\n\n```C\nstruct tss_struct {\n\tlong\tback_link;\t/* 16 high bits zero */\n\tlong\tesp0;\n\tlong\tss0;\t\t/* 16 high bits zero */\n\tlong\tesp1;\n\tlong\tss1;\t\t/* 16 high bits zero */\n\tlong\tesp2;\n\tlong\tss2;\t\t/* 16 high bits zero */\n\tlong\tcr3;\n\tlong\teip;\n\tlong\teflags;\n\tlong\teax,ecx,edx,ebx;\n\tlong\tesp;\n\tlong\tebp;\n\tlong\tesi;\n\tlong\tedi;\n\tlong\tes;\t\t/* 16 high bits zero */\n\tlong\tcs;\t\t/* 16 high bits zero */\n\tlong\tss;\t\t/* 16 high bits zero */\n\tlong\tds;\t\t/* 16 high bits zero */\n\tlong\tfs;\t\t/* 16 high bits zero */\n\tlong\tgs;\t\t/* 16 high bits zero */\n\tlong\tldt;\t\t/* 16 high bits zero */\n\tlong\ttrace_bitmap;\t/* bits: trace 0, bitmap 16-31 */\n\tstruct i387_struct i387;\n};\n```\n\n**switch kernel stack :**\n\nIt's also simple to complete the kernel stack switch. we just need to store value of esp register of the current process  onto the current PCB , and take corresponding esp value of next PCB out and put it into esp register.\n\nsince Linux -0.11  didn't define the variable of kernel stack pointer in PCB(task_struct). so we need to add a variable ```kernelstack``` to Linux-0.11 PCB, we still need define another variable ``` KERNEL_STACK = 12```  for determine variable of  ```kernelstack``` position in PCB.\n\n**Why KERNEL_STACK equal to 12 ?**\n\nbecause the kernel code have many  assembly hardcodes about manipulating this structure, so,if we add the variable ```kernelstack``` in other position, we need to modify kernel code in many difference place. \n\n```C\nKERNEL_STACK = 12\nmovl %esp,KERNEL_STACK(%eax)\t! 保存上一个进程的栈顶指针\n! 再取一下 ebx，因为前面修改过 ebx 的值,此时eax的值等于上一个进程的PCB指针\nmovl 8(%ebp),%ebx\t\nmovl KERNEL_STACK(%ebx),%esp\t！取下个进程的栈顶指针放入esp\n```\n\ntask_struct:\n\n```C\n// 在 include/linux/sched.h 中\nstruct task_struct {\n    long state;\n    long counter;\n    long priority;\n    long kernelstack;\n//......\n```\n\nbecause we modify the PCB structure,  we also need to modify initialization code of 0 process PCB structure .Modify ```#define INIT_TASK { 0,15,15, 0,{ { },},0,...```  to ``` #define INIT_TASK { 0,15,15,PAGE_SIZE+(long)&init_task, 0,{ { },},0,...```\n\n**switch LDT**\n\n```assembly\nmovl 12(%ebp),%ecx\nlldt %cx\n!上面使改LDT代码\nmovl $0x17,%ecx\nmov %cx,%fs\n```\n\nWhy we have to add two code ```movl $0x17,%ecx``` ``` mov %cx,%fs``` behind that code of switch LDT.\n\nbecause we need to change the segment base address and segment length limit in the hidden register about fs.\n\nExamlpe with CS. The hidden register for increase CPU processing speed.\n\n![](process-switch-base-on-stack-switch/wm1.png)\n\n**switch PC （switch to next process）**\n\n```assembly\n1:    popl %eax\n    popl %ebx\n    popl %ecx\n    popl %ebp\nret\n```\n\n**kernel stack  now**\n\n![](https://img-blog.csdnimg.cn/20190819230403925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTc2MTQ3OA==,size_16,color_FFFFFF,t_70)\n\nExecute those codes to turn to the next process,if it isn't come here through code ```je 1f```. Because we have been changed the kernel stack before. we ```pop  (eax ,ebx,ecx,ebp) ``` is register of next process.   ret instruction equal to ```pop IP```.So we execute ```ret``` turn to schedule() function tail of next process. Now ! we completed the stack switch perfectly.\n\n## modify fork()\n\n**Why we need to modify fork() function ?**\n\n**Because, we need to simulate the parent process's kernel stack for the newly created child process. **\n\nNow, we need to modify the fork() function. it is to associate the process's user stack, user program to its kernel stack with SS: ESP, CS: IP, which is pushed in the kernel stack.\n\nIn addition, since fork() function-core is let the child process to use code, data, and stack of the parent process . the fork core has not changed, although we use the stack switching.\n\n![](process-switch-base-on-stack-switch/wm2.png)\n\nDon't hard to imagine. modify fork which  mean  initialize child process's kernel stack. In ```copy_process () ```as the core code of ```fork ()```, it used to apply a page of memory as process PCB. The kernel stack address position equal pointer p position add the one page of memory size.  so the code ```krnstack = (*long)(PAGE_SIZE + (long)p)``` can find the child process kernel stack position. next step is to initialize the content of krnstack pointer .\n\n```C\n/*modify in fork()*/\nlong *krnstack;\np = (struct task_struct *) get_free_page();\nkrnstack = (long)(PAGE_SIZE +(long)p);\n *(--krnstack) = ss & 0xffff;\n *(--krnstack) = esp;\n *(--krnstack) = eflags;\n *(--krnstack) = cs & 0xffff;\n *(--krnstack) = eip;\n *(--krnstack) = ds & 0xffff;\n *(--krnstack) = es & 0xffff;\n *(--krnstack) = fs & 0xffff;\n *(--krnstack) = gs & 0xffff;\n *(--krnstack) = esi;\n *(--krnstack) = edi;\n *(--krnstack) = edx;\n *(--krnstack) = (long)first_return_from_kernel;\n *(--krnstack) = ebp;\n *(--krnstack) = ecx;\n *(--krnstack) = ebx;\n *(--krnstack) = 0;\n p->kernelstack = krnstack;\n ......\n\n```\n\nThose code for simulate parent kernel stack for child process! \n\nMake a attention !\n\n```c\n*(--krnstack) = (long)first_return_from_kernel;\n*(--krnstack) = 0;\n```\n\nWe need to code a first_return_from_kernel as a mark! If we return to address first_return_from_kernel. We need to execute those code following.\n\n```assembly\n/*modify in system_call.s*/\n.align 2\nfirst_return_from_kernel:\npopl %edx\npopl %edi\npopl %esi\npop %gs\npop %fs\npop %es\npop %ds\niret\n```\n\ninstruction ```iret``` equal to \n\n```assembly\npop eip\npop cs\npop eflags\npop esp\npop ss\n```\n\n instruction ```*(--krnstack) = 0;```  Means eax =0 for distinguish parent process and child process.\n\n**In the end , don't forget add the two code following to corresponding .c file **\n\n```C\nextern void first_return_kernel(void); // in the fork()\nextern long switch_to(struct task_struct *p , unsigned long _ldt); // in the sched.c\n```\n\n## Modify step\n\n**Modify in system_call.s**\n\nWrite the switch_to、first_return_from_kernel、etc in the system_call.s**\n\n```assembly\n# Don't forget to change the hardcode.\n# Because I forget to change the hardcode , I stayed here so long time.\nstate\t= 0\t\t# these are offsets into the task-struct.\ncounter\t= 4\npriority = 8\nKERNEL_STACK = 12\nsignal\t= 16\nsigaction = 20\t\t# MUST be 16 (=len of sigaction)\nblocked = (33*16+4)\n\n# Define as a global variable，can be used in other file with the keyword extern declaration.\n.globl first_return_from_kernel, switch_to \n.align 2\nswitch_to:\n\tpushl %ebp\n\tmovl %esp, %ebp\n\tpushl %ecx\n\tpushl %ebx\n\tpushl %eax \n\tmovl 8(%ebp), %ebx \n\tcmpl %ebx, current \n\tje 1f\n\tmovl %ebx, %eax\n\txchgl %eax, current # eax=old_current, so current=pnext\n\tmovl tss, %ecx\t\t# ecx = tss of pnext, it also the new current\n\taddl $4096, %ebx\t# ebx=the top of current kernel stack(pnext)\n\tmovl %ebx, 4(%ecx)\n\tmovl %esp, KERNEL_STACK(%eax)\n\tmovl 8(%ebp), %ebx \n\tmovl KERNEL_STACK(%ebx), %esp\n\tmovl 12(%ebp), %ecx\n\tlldt %cx\n\tmovl $0x17, %ecx\n\tmov %cx, %fs\n\tcmpl %eax, last_task_used_math\t\n\tjne 1f\n\tclts\n1:  popl %eax\n\tpopl %ebx\n\tpopl %ecx\n\tpopl %ebp\n\tret\n.align 2\nfirst_return_from_kernel:\n\tpopl %edx\n\tpopl %edi\n\tpopl %esi\n\tpop %gs\n\tpop %fs\n\tpop %es\n\tpop %ds\n\tiret\n```\n\n**Modify sched.h **\n\n```C\nstruct task_struct {\n/* these are hardcoded - don't touch */\n\tlong state;\t/* -1 unrunnable, 0 runnable, >0 stopped */\n\tlong counter;\n\tlong priority;\n\tlong kernelstack;\n\tlong signal;\n\tstruct sigaction sigaction[32];\n\tlong blocked;\t/* bitmap of masked signals */\n    ......\n}\n#define INIT_TASK \\\n/* state etc */\t{ 0,15,15,PAGE_SIZE+(long)&init_task, \\\n/* signals */\t0,{{},},0, \\\n.................................\n\n /*注释掉\n#define switch_to(n) {\\\nstruct {long a,b;} __tmp; \\\n__asm__(\"cmpl %%ecx,current\\n\\t\" \\\n\t\"je 1f\\n\\t\" \\\n\t\"movw %%dx,%1\\n\\t\" \\\n\t\"xchgl %%ecx,current\\n\\t\" \\\n\t\"ljmp *%0\\n\\t\" \\\n\t\"cmpl %%ecx,last_task_used_math\\n\\t\" \\\n\t\"jne 1f\\n\\t\" \\\n\t\"clts\\n\" \\\n\t\"1:\" \\\n\t::\"m\" (*&__tmp.a),\"m\" (*&__tmp.b), \\\n\t\"d\" (_TSS(n)),\"c\" ((long) task[n])); \\\n}\n*/\n  \n```\n\n**Modify sched.c**\n\n```C\nextern long switch_to(struct task_struct *p , unsigned long _ldt);\nstruct tss_struct * tss = &(init_task.task.tss);\nvoid schedule(void)\n{\n\tint i,next,c;\n\tstruct task_struct ** p;\n\tstruct task_struct *pnext = &(init_task.task);\n\n/* check alarm, wake up any interruptible tasks that have got a signal */\n\n\tfor(p = &LAST_TASK ; p > &FIRST_TASK ; --p)\n\t\tif (*p) {\n\t\t\tif ((*p)->alarm && (*p)->alarm < jiffies) {\n\t\t\t\t\t(*p)->signal |= (1<<(SIGALRM-1));\n\t\t\t\t\t(*p)->alarm = 0;\n\t\t\t\t}\n\t\t\tif (((*p)->signal & ~(_BLOCKABLE & (*p)->blocked)) &&\n\t\t\t(*p)->state==TASK_INTERRUPTIBLE)\n\t\t\t\t(*p)->state=TASK_RUNNING;\n\t\t}\n\n/* this is the scheduler proper: */\n\n\twhile (1) {\n\t\tc = -1;\n\t\tnext = 0;\n\t\ti = NR_TASKS;\n\t\tp = &task[NR_TASKS];\n\t\twhile (--i) {\n\t\t\tif (!*--p)\n\t\t\t\tcontinue;\n\t\t\tif ((*p)->state == TASK_RUNNING && (*p)->counter > c){\n\t\t\t\tc = (*p)->counter, next = i;\n\t\t\t\tpnext = *p;\n\t\t\t}\n\t\t}\n\t\tif (c) break;\n\t\tfor(p = &LAST_TASK ; p > &FIRST_TASK ; --p)\n\t\t\tif (*p)\n\t\t\t\t(*p)->counter = ((*p)->counter >> 1) +\n\t\t\t\t\t\t(*p)->priority;\n\t}\n\tswitch_to(pnext,_LDT(next));\n}\n```\n\n**Modify fork()**\n\n```C\nextern void first_return_kernel(void);  \n\nint copy_process(int nr,long ebp,long edi,long esi,long gs,long none,\n\t\tlong ebx,long ecx,long edx,\n\t\tlong fs,long es,long ds,\n\t\tlong eip,long cs,long eflags,long esp,long ss)\n{\n\tstruct task_struct *p;\n\tint i;\n\tstruct file *f;\n\n\tp = (struct task_struct *) get_free_page();\n\tif (!p)\n\t\treturn -EAGAIN;\n\ttask[nr] = p;\n\t*p = *current;\t/* NOTE! this doesn't copy the supervisor stack */\n\tp->state = TASK_UNINTERRUPTIBLE;\n\tp->pid = last_pid;\n\tp->father = current->pid;\n\tp->counter = p->priority;\n\tlong * krnstack ;\n\tkrnstack = (long *) (PAGE_SIZE + (long) p);\n    *(--krnstack) = ss & 0xffff;\n    *(--krnstack) = esp;\n    *(--krnstack) = eflags;\n    *(--krnstack) = cs & 0xffff;\n    *(--krnstack) = eip;\n *(--krnstack) = ds & 0xffff; \n   *(--krnstack) = es & 0xffff; \n   *(--krnstack) = fs & 0xffff; \n *(--krnstack) = gs & 0xffff;\n  *(--krnstack) = esi; \n *(--krnstack) = edi; \n    *(--krnstack) = edx;\n\t*(--krnstack) =(long) first_return_kernel;\n    *(--krnstack) = ebp;\n    *(--krnstack) = ecx;\n    *(--krnstack) = ebx;\n    *(--krnstack) = 0;\n\tp->kernelstack = krnstack;\n\tp->signal = 0;\n\tp->alarm = 0;\n\tp->leader = 0;\t\t/* process leadership doesn't inherit */\n\tp->utime = p->stime = 0;\n\tp->cutime = p->cstime = 0;\n\tp->start_time = jiffies;\n\tp->tss.back_link = 0;\n\tp->tss.esp0 = PAGE_SIZE + (long) p;\n\tp->tss.ss0 = 0x10;\n\tp->tss.eip = eip;\n\tp->tss.eflags = eflags;\n\tp->tss.eax = 0;\n\tp->tss.ecx = ecx;\n\tp->tss.edx = edx;\n\tp->tss.ebx = ebx;\n\tp->tss.esp = esp;\n\tp->tss.ebp = ebp;\n\tp->tss.esi = esi;\n\tp->tss.edi = edi;\n\tp->tss.es = es & 0xffff;\n\tp->tss.cs = cs & 0xffff;\n\tp->tss.ss = ss & 0xffff;\n\tp->tss.ds = ds & 0xffff;\n\tp->tss.fs = fs & 0xffff;\n\tp->tss.gs = gs & 0xffff;\n\tp->tss.ldt = _LDT(nr);\n\tp->tss.trace_bitmap = 0x80000000;\n\tif (last_task_used_math == current)\n\t\t__asm__(\"clts ; fnsave %0\"::\"m\" (p->tss.i387));\n\tif (copy_mem(nr,p)) {\n\t\ttask[nr] = NULL;\n\t\tfree_page((long) p);\n\t\treturn -EAGAIN;\n\t}\n\tfor (i=0; i<NR_OPEN;i++)\n\t\tif ((f=p->filp[i]))\n\t\t\tf->f_count++;\n\tif (current->pwd)\n\t\tcurrent->pwd->i_count++;\n\tif (current->root)\n\t\tcurrent->root->i_count++;\n\tif (current->executable)\n\t\tcurrent->executable->i_count++;\n\tset_tss_desc(gdt+(nr<<1)+FIRST_TSS_ENTRY,&(p->tss));\n\tset_ldt_desc(gdt+(nr<<1)+FIRST_LDT_ENTRY,&(p->ldt));\n\tp->state = TASK_RUNNING;\t/* do this last, just in case */\n\treturn last_pid;\n}\n```\n\n","slug":"process-switch-base-on-stack-switch","published":1,"updated":"2020-11-14T14:40:36.616Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4su002mr8s803omeyft","content":"<h1 id=\"基于内核栈切换的进程切换\"><a href=\"#基于内核栈切换的进程切换\" class=\"headerlink\" title=\"基于内核栈切换的进程切换\"></a>基于内核栈切换的进程切换</h1><h2 id=\"实验目的\"><a href=\"#实验目的\" class=\"headerlink\" title=\"实验目的\"></a>实验目的</h2><ul>\n<li>深入理解进程和进程切换的概念；</li>\n<li>综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题；</li>\n<li>开始建立系统认识。</li>\n</ul>\n<h2 id=\"实验内容\"><a href=\"#实验内容\" class=\"headerlink\" title=\"实验内容\"></a>实验内容</h2><p>现在的 Linux 0.11 采用 TSS（后面会有详细论述）和一条指令就能完成任务切换，虽然简单，但这指令的执行时间却很长，在实现任务切换时大概需要 200 多个时钟周期。</p>\n<p>而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。</p>\n<p>本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 <code>switch_to</code> 实现去掉，写成一段基于堆栈切换的代码。</p>\n<p>本次实验包括如下内容：</p>\n<ul>\n<li>编写汇编程序 <code>switch_to</code>：</li>\n<li>完成主体框架；</li>\n<li>在主体框架下依次完成 PCB 切换、内核栈切换、LDT 切换等；</li>\n<li>修改 <code>fork()</code>，由于是基于内核栈的切换，所以进程需要创建出能完成内核栈切换的样子。</li>\n<li>修改 PCB，即 <code>task_struct</code> 结构，增加相应的内容域，同时处理由于修改了 task_struct 所造成的影响。</li>\n<li>用修改后的 Linux 0.11 仍然可以启动、可以正常使用。</li>\n<li>（选做）分析实验 3 的日志体会修改前后系统运行的差别。</li>\n</ul>\n<h2 id=\"实验报告\"><a href=\"#实验报告\" class=\"headerlink\" title=\"实验报告\"></a>实验报告</h2><p>回答下面三个题：</p>\n<h4 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题 1\"></a>问题 1</h4><p>针对下面的代码片段：</p>\n<figure class=\"highlight mel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mel\">movl tss,%ecx<br>addl $4096,%ebx<br>movl %ebx,ESP0(%ecx)<br></code></pre></td></tr></table></figure>\n<p>回答问题：</p>\n<ul>\n<li><p>（1）为什么要加 4096；</p>\n<p>答：因为一页内存低地址存进程PCB，高地址是堆栈，linux-0.11 一页内存大小为4Kb,所以+4096。</p>\n</li>\n<li><p>（2）为什么没有设置 tss 中的 ss0。</p>\n<p>答</p>\n</li>\n</ul>\n<h4 id=\"问题-2\"><a href=\"#问题-2\" class=\"headerlink\" title=\"问题 2\"></a>问题 2</h4><p>针对代码片段：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">*(--krnstack) = ebp;<br>*(--krnstack) = ecx;<br>*(--krnstack) = ebx;<br>*(--krnstack) = <span class=\"hljs-number\">0</span>;<br></code></pre></td></tr></table></figure>\n<p>回答问题：</p>\n<ul>\n<li><p>（1）子进程第一次执行时，eax=？为什么要等于这个数？哪里的工作让 eax 等于这样一个数？</p>\n<p>答：子进程第一次执行是eax =0;，为了让代码<code>if (!fork()) &#123;....&#125;</code>区分子进程和父进程。</p>\n</li>\n<li><p>（2）这段代码中的 ebx 和 ecx 来自哪里，是什么含义，为什么要通过这些代码将其写到子进程的内核栈中？</p>\n<p>答：这段代码中的ebx和ecx是栈切换执行switch_to时压入的值，我觉得是为了切换进程时保护现场而压入的，在fork创建新进程（子进程）时添加这些代码进新进程内核栈是为了模拟父进程的内核栈。</p>\n</li>\n<li><p>（3）这段代码中的 ebp 来自哪里，是什么含义，为什么要做这样的设置？可以不设置吗？为什么？</p>\n<p>答：ebp也是来自基于栈切换的switch_to（）时压入的，是当前进程在进行切换时保存当前进程现场的操作，为什么要这样设置呢？因为创建新的子进程当进程切换时需要pop所以这里是为了模拟父进程的内核栈.</p>\n</li>\n</ul>\n<h4 id=\"问题-3\"><a href=\"#问题-3\" class=\"headerlink\" title=\"问题 3\"></a>问题 3</h4><p>为什么要在切换完 LDT 之后要重新设置 fs=0x17？而且为什么重设操作要出现在切换完 LDT 之后，出现在 LDT 之前又会怎么样？</p>\n<p>答：因为需要重新设置fs对应的隐藏寄存器的段基址和段限长，所以需要重设操作，出现在LDT之前则没有任何意义不会有任何改变。</p>\n<h2 id=\"TSS的切换\"><a href=\"#TSS的切换\" class=\"headerlink\" title=\"TSS的切换\"></a>TSS的切换</h2><h3 id=\"TSS-task-state-segment\"><a href=\"#TSS-task-state-segment\" class=\"headerlink\" title=\"TSS (task state segment)\"></a>TSS (task state segment)</h3><p>The <strong>task state segment (TTS)</strong> is a structure on x86-based computers which holds information about a task, it is used by the operating system kernel for task managenment. specifically, the following information is stored in the TSS:</p>\n<ul>\n<li>processor register state</li>\n<li>I/O port permissions</li>\n<li>Inner-lever stack pointers (内部堆栈指针)</li>\n<li>Previous TSS link</li>\n</ul>\n<p>All this information should be stored at specific locations within the TSS as specified in the IA-32 manuals.</p>\n<h3 id=\"TR-task-register\"><a href=\"#TR-task-register\" class=\"headerlink\" title=\"TR (task register).\"></a>TR (task register).</h3><p>The TR register is a 16-bit register which holds a segment selector for the TSS. It may be loaded through the LTR instruction. LTR is a privileged instruction and acts in a manner similar to other segment register loads. The task register has two parts: a portion visible and accessible by the programmer and an invisible one that is automatically loaded from the TSS descriptor.<br></p>\n<p>In the current Linux 0.11,the real completion of the  process switch is accomplished by the task state segment(Task State Segment,TSS for short).</p>\n<p>Specifically, when designing the “Intel architecture”(that is the x86 system structure),</p>\n<p>each task(process or thread) corresponds to an independent TSS. TSS is a  corresponds</p>\n<p>to an independent TSS. TSS is a structure in memory that contains almost all CPU registers Image. There is a Task Register(TR for short) pointing to the TSS structure corresponding to the current process. </p>\n<p>The so-called TSS switch is copies almost all the registers in the CPU(current) to the TSS </p>\n<p>structure pointed  by TR.</p>\n<p>At the same time a target TSS is found ,that is the TSS corresponding to the next process to be switched to, and the register image of TSS structure of next process  stored in CPU.</p>\n<p>In here  the execution site switching  is completed.</p>\n<p>as shown in the figure  blow:</p>\n<p><img src=\"process-switch-base-on-stack-switch/wm.png\" alt=\"\"></p>\n<p>Inter architecture provides the command ljmp to achieve the process switch .</p>\n<p>The specific working process is:</p>\n<ul>\n<li>First, use the segment selector in TR to find the current TSS structure memory location in GDT table.</li>\n<li>second,  the register image of current CPU  store to the TSS structure memory  of finding before.(store the current site !)</li>\n<li>Now, we need to find the target process site and copy the register image of the target   process to the CPU. This just means we need to find TSS of the next process in  GDT table and copy the context of TSS structure memory to CPU.</li>\n<li>when the register image of TSS structure of the target process store in CPU completely, that means achieve switch to target process site, now, the target process becomes the current process. </li>\n<li>Finally , TR should be changed to point to the location of the target TSS segment in the GDT table.<br></li>\n</ul>\n<p>all explain above  through one sentence execute  (ljmp segment selector : intra-segment offset).</p>\n<p>So switch_to (a instruction) base on TSS for process and thread switching is actually a ljmp instruction：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">#define switch_to(n) &#123;\\<br>struct &#123;long a,b;&#125; __tmp; \\<br>__asm__(&quot;cmpl %%ecx,current\\n\\t&quot; \\\t <br>\t&quot;je 1f\\n\\t&quot; \\<br>\t&quot;movw %%dx,%1\\n\\t&quot; \\<br>\t&quot;xchgl %%ecx,current\\n\\t&quot; \\<br>\t&quot;ljmp *%0\\n\\t&quot; \\<br>\t&quot;cmpl %%ecx,last_task_used_math\\n\\t&quot; \\<br>\t&quot;jne 1f\\n\\t&quot; \\<br>\t&quot;clts\\n&quot; \\<br>\t&quot;1:&quot; \\<br>\t::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \\<br>\t&quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \\<br>&#125;<br><br>#define FIRST_TSS_ENTRY 4<br><br>#define TSS(n) (((unsigned long) n) &lt;&lt; 4) + (FIRST_TSS_ENTRY &lt;&lt; 3))<br></code></pre></td></tr></table></figure>\n<p>Each process is divided into two part which correspond to TSS and LDT, respectively. </p>\n<p>TSS and LDT are both 64-bit(8 bytes).</p>\n<p>so  _TSS(n) = n <em> 16 + 4 </em> 8 (bytes).</p>\n<p><strong>ljmp instruction can be used in two ways, which are “ljmp $ segment selector, $ offset” and “ljmp <em> mem48” respectively. In here “ljmp </em>% 0” used the second way, “ljmp <em> mem48” mean jump to Logical address (48 bits) of the mem48 contain (mem48 also is an address), the hight 16 bits of 48 bits correspond to segment_selector, the low 32 bits of 48 bits correspond to offset. So ,the core of switch_to is ljmp 0 , n\\</em>16+4*8  </strong></p>\n<p><strong>!! it is worth out attention:</strong></p>\n<p>The ‘*‘ of the “ljmp <em>mem48” is different from ‘\\</em>‘ of C language . The ‘*‘ of the “ljmp *mem48”  is mean indirect jump.</p>\n<h2 id=\"本次实验的内容\"><a href=\"#本次实验的内容\" class=\"headerlink\" title=\"本次实验的内容\"></a>本次实验的内容</h2><p>Although ，the task switching can be completed with one instruction, the execution time of the instruction is very long . It take almost 200 time cycles to complete the task switch using the ljmp instruction. if we want to increase the switching speed ,we can use the heap_stack switch instead of ljmp instruction.</p>\n<p>Moreover. The use of heap_stack switching can also use the parallel optimization technology of instruction pipeline, while making design of the CPU simple.</p>\n<p>Therefore, both Windows and Linux use the heap_stack switching technology to handle process switching.</p>\n<p>Therefore rewriter the code of “switch_to” to  use the heap_stack switch instead of TSS is my task.</p>\n<p>To achieve a process switch base on kernel , we need do three things :</p>\n<ol>\n<li>Rewrite “switch_to”</li>\n<li>Connect the rewritten “switch_to” and schedule() functions together.</li>\n<li>Modify the current fork().</li>\n</ol>\n<h2 id=\"schedule-与-switch-to\"><a href=\"#schedule-与-switch-to\" class=\"headerlink\" title=\"schedule 与 switch_to\"></a>schedule 与 switch_to</h2><h3 id=\"modify-shcedule\"><a href=\"#modify-shcedule\" class=\"headerlink\" title=\"modify shcedule()\"></a>modify shcedule()</h3><p>The task of schedule( ) is finding the position “next” of the next process in the array.  The “next” is equal to “n” of the GDT table(TSS[n]=n*16+4*8).  if we get the “next” in the schedule function, we can use “switch_to (next)” function move to another process.</p>\n<p>Now, we use heap_stack switching instead of TSS switching ,and so we need informations of  current process PCB 、target process PCB、current process kernel stack and target process kernel stack.</p>\n<p> The kernel stack of the Linux 0.11 process and the PCB of process are stored on the same page of memory (a 4kB size page of memory).The PCB is located at the low address of this page of memory ,and the stack is located at the high address of this page of memory.</p>\n<p>In addition, since the PCB of the current process is pointed with a global variable “current”, we  need to tell new switch_to () function a pointer to the target process PCB and we need to tell new switch_to function LDT(next) instead of TSS (next). Just mean ,we don’t need TSS in each process now（we can delete code about TSS），but  also need LDT of  process.</p>\n<p>In summary ,the current schedule() function (in kernel/sched.c) needs to be slightly modified, that is the following code:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-keyword\">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) <br>    c = (*p)-&gt;counter, next = i; <br><br><span class=\"hljs-comment\">//......</span><br><br>switch_to(next);<br></code></pre></td></tr></table></figure>\n<p>modify:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-keyword\">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) <br>    c = (*p)-&gt;counter, next = i, pnext = *p;<br><br><span class=\"hljs-comment\">//.......</span><br><br>switch_to(pnext, _LDT(next)); <br></code></pre></td></tr></table></figure>\n<h3 id=\"Rewrite-switch-to\"><a href=\"#Rewrite-switch-to\" class=\"headerlink\" title=\"Rewrite switch_to()\"></a>Rewrite switch_to()</h3><p>Rewrite switch_to() function is the most important step in this experiment.</p>\n<p>This function, in turn, completes the following functions:</p>\n<ul>\n<li>first, we need to handle the stack by the assembly language. just handle the ebp register.</li>\n<li>second, we need to compare the parameter of stack about the next process’s PCB with the current process.</li>\n<li>third, we need in turn to complete PCB switch, rewrite kernel stack pointer of TSS, switch kernel stack, switch LDT and switch PC pointer (CS:EIP).</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">switch_to:<br>    pushl %ebp<br>    movl %esp,%ebp<br>    pushl %ecx<br>    pushl %ebx<br>    pushl %eax<br>    movl 8(%ebp),%ebx<br>    cmpl %ebx,current<br>    je 1f<br>! 切换PCB<br>    ! ...<br>! TSS中的内核栈指针的重写<br>    ! ...<br>! 切换内核栈<br>    ! ...<br>! 切换LDT<br>    ! ...<br>    movl $0x17,%ecx<br>    mov %cx,%fs<br>! 和后面的 clts 配合来处理协处理器，由于和主题关系不大，此处不做论述<br>    cmpl %eax,last_task_used_math <br>    jne 1f<br>    clts<br><br>1:    popl %eax<br>    popl %ebx<br>    popl %ecx<br>    popl %ebp<br>ret<br></code></pre></td></tr></table></figure>\n<p><strong>Switch PCB pointer</strong></p>\n<p>ebx register is next process’s PCB pointer.</p>\n<p>The function of xchgl instruction  is to exchange contents between  two register.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">movl %ebx,%eax<br>xchgl %eax,current\t<br></code></pre></td></tr></table></figure>\n<p><strong>Rewrite pointer of kernel stack stored in  TSS</strong></p>\n<p>The current TSS is different from TSS before. Before TSS is a global array but current TSS is a global variable. We need to redefine TSS pointer through two sentences.</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> ESP0 =4</span><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">tss_struct</span> *<span class=\"hljs-title\">tss</span> =</span> (init_task.task.tss);<br></code></pre></td></tr></table></figure>\n<p>current TSS pointer <code>tss</code> similar current process pointer <code>current</code>.</p>\n<p>This has already discussed in detail before. In the system interrupt ,we need to find and determine the location of the kernel stack. and push the five register SS : ESP, CS: EIP and EFLAGS in user mode onto kernel stack. This is the key bridge between the user mode (user stack) and kernel mode (kernel stack). The key of find kernel stack position is use the TR register point to current TSS.</p>\n<p>Although we don’t need to use TSS for switch process in now.  We still stay the intel interrupt system. So we still need it that is we define global variable <code>tss</code>. All processes share that variable.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">movl tss,%ecx<br>addl $4096,%ebx<br>movl %ebx,ESP0(%ecx)<br></code></pre></td></tr></table></figure>\n<p>ESP0 = 4 ,the ecx + ESP0 equal to position of kernel stack pointer in TSS (esp0).</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">tss_struct</span> &#123;</span><br>\t<span class=\"hljs-keyword\">long</span>\tback_link;\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tesp0;<br>\t<span class=\"hljs-keyword\">long</span>\tss0;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tesp1;<br>\t<span class=\"hljs-keyword\">long</span>\tss1;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tesp2;<br>\t<span class=\"hljs-keyword\">long</span>\tss2;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tcr3;<br>\t<span class=\"hljs-keyword\">long</span>\teip;<br>\t<span class=\"hljs-keyword\">long</span>\teflags;<br>\t<span class=\"hljs-keyword\">long</span>\teax,ecx,edx,ebx;<br>\t<span class=\"hljs-keyword\">long</span>\tesp;<br>\t<span class=\"hljs-keyword\">long</span>\tebp;<br>\t<span class=\"hljs-keyword\">long</span>\tesi;<br>\t<span class=\"hljs-keyword\">long</span>\tedi;<br>\t<span class=\"hljs-keyword\">long</span>\tes;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tcs;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tss;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tds;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tfs;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tgs;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tldt;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\ttrace_bitmap;\t<span class=\"hljs-comment\">/* bits: trace 0, bitmap 16-31 */</span><br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">i387_struct</span> <span class=\"hljs-title\">i387</span>;</span><br>&#125;;<br></code></pre></td></tr></table></figure>\n<p><strong>switch kernel stack :</strong></p>\n<p>It’s also simple to complete the kernel stack switch. we just need to store value of esp register of the current process  onto the current PCB , and take corresponding esp value of next PCB out and put it into esp register.</p>\n<p>since Linux -0.11  didn’t define the variable of kernel stack pointer in PCB(task_struct). so we need to add a variable <code>kernelstack</code> to Linux-0.11 PCB, we still need define another variable <code>KERNEL_STACK = 12</code>  for determine variable of  <code>kernelstack</code> position in PCB.</p>\n<p><strong>Why KERNEL_STACK equal to 12 ?</strong></p>\n<p>because the kernel code have many  assembly hardcodes about manipulating this structure, so,if we add the variable <code>kernelstack</code> in other position, we need to modify kernel code in many difference place. </p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\">KERNEL_STACK = <span class=\"hljs-number\">12</span><br>movl %esp,KERNEL_STACK(%eax)\t! 保存上一个进程的栈顶指针<br>! 再取一下 ebx，因为前面修改过 ebx 的值,此时eax的值等于上一个进程的PCB指针<br>movl <span class=\"hljs-number\">8</span>(%ebp),%ebx\t<br>movl KERNEL_STACK(%ebx),%esp\t！取下个进程的栈顶指针放入esp<br></code></pre></td></tr></table></figure>\n<p>task_struct:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-comment\">// 在 include/linux/sched.h 中</span><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> &#123;</span><br>    <span class=\"hljs-keyword\">long</span> state;<br>    <span class=\"hljs-keyword\">long</span> counter;<br>    <span class=\"hljs-keyword\">long</span> priority;<br>    <span class=\"hljs-keyword\">long</span> kernelstack;<br><span class=\"hljs-comment\">//......</span><br></code></pre></td></tr></table></figure>\n<p>because we modify the PCB structure,  we also need to modify initialization code of 0 process PCB structure .Modify <code>#define INIT_TASK &#123; 0,15,15, 0,&#123; &#123; &#125;,&#125;,0,...</code>  to <code>#define INIT_TASK &#123; 0,15,15,PAGE_SIZE+(long)&amp;init_task, 0,&#123; &#123; &#125;,&#125;,0,...</code></p>\n<p><strong>switch LDT</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">movl 12(%ebp),%ecx<br>lldt %cx<br>!上面使改LDT代码<br>movl $0x17,%ecx<br>mov %cx,%fs<br></code></pre></td></tr></table></figure>\n<p>Why we have to add two code <code>movl $0x17,%ecx</code> <code>mov %cx,%fs</code> behind that code of switch LDT.</p>\n<p>because we need to change the segment base address and segment length limit in the hidden register about fs.</p>\n<p>Examlpe with CS. The hidden register for increase CPU processing speed.</p>\n<p><img src=\"process-switch-base-on-stack-switch/wm1.png\" alt=\"\"></p>\n<p><strong>switch PC （switch to next process）</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">1:    popl %eax<br>    popl %ebx<br>    popl %ecx<br>    popl %ebp<br>ret<br></code></pre></td></tr></table></figure>\n<p><strong>kernel stack  now</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190819230403925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTc2MTQ3OA==,size_16,color_FFFFFF,t_70\" alt=\"\"></p>\n<p>Execute those codes to turn to the next process,if it isn’t come here through code <code>je 1f</code>. Because we have been changed the kernel stack before. we <code>pop  (eax ,ebx,ecx,ebp)</code> is register of next process.   ret instruction equal to <code>pop IP</code>.So we execute <code>ret</code> turn to schedule() function tail of next process. Now ! we completed the stack switch perfectly.</p>\n<h2 id=\"modify-fork\"><a href=\"#modify-fork\" class=\"headerlink\" title=\"modify fork()\"></a>modify fork()</h2><p><strong>Why we need to modify fork() function ?</strong></p>\n<p><strong>Because, we need to simulate the parent process’s kernel stack for the newly created child process. </strong></p>\n<p>Now, we need to modify the fork() function. it is to associate the process’s user stack, user program to its kernel stack with SS: ESP, CS: IP, which is pushed in the kernel stack.</p>\n<p>In addition, since fork() function-core is let the child process to use code, data, and stack of the parent process . the fork core has not changed, although we use the stack switching.</p>\n<p><img src=\"process-switch-base-on-stack-switch/wm2.png\" alt=\"\"></p>\n<p>Don’t hard to imagine. modify fork which  mean  initialize child process’s kernel stack. In <code>copy_process ()</code>as the core code of <code>fork ()</code>, it used to apply a page of memory as process PCB. The kernel stack address position equal pointer p position add the one page of memory size.  so the code <code>krnstack = (*long)(PAGE_SIZE + (long)p)</code> can find the child process kernel stack position. next step is to initialize the content of krnstack pointer .</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-comment\">/*modify in fork()*/</span><br><span class=\"hljs-keyword\">long</span> *krnstack;<br>p = (struct task_struct *) get_free_page();<br>krnstack = (<span class=\"hljs-keyword\">long</span>)(PAGE_SIZE +(<span class=\"hljs-keyword\">long</span>)p);<br> *(--krnstack) = ss &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = esp;<br> *(--krnstack) = eflags;<br> *(--krnstack) = cs &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = eip;<br> *(--krnstack) = ds &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = es &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = fs &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = gs &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = esi;<br> *(--krnstack) = edi;<br> *(--krnstack) = edx;<br> *(--krnstack) = (<span class=\"hljs-keyword\">long</span>)first_return_from_kernel;<br> *(--krnstack) = ebp;<br> *(--krnstack) = ecx;<br> *(--krnstack) = ebx;<br> *(--krnstack) = <span class=\"hljs-number\">0</span>;<br> p-&gt;kernelstack = krnstack;<br> ......<br><br></code></pre></td></tr></table></figure>\n<p>Those code for simulate parent kernel stack for child process! </p>\n<p>Make a attention !</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">*(--krnstack) = (<span class=\"hljs-keyword\">long</span>)first_return_from_kernel;<br>*(--krnstack) = <span class=\"hljs-number\">0</span>;<br></code></pre></td></tr></table></figure>\n<p>We need to code a first_return_from_kernel as a mark! If we return to address first_return_from_kernel. We need to execute those code following.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">&#x2F;*modify in system_call.s*&#x2F;<br>.align 2<br>first_return_from_kernel:<br>popl %edx<br>popl %edi<br>popl %esi<br>pop %gs<br>pop %fs<br>pop %es<br>pop %ds<br>iret<br></code></pre></td></tr></table></figure>\n<p>instruction <code>iret</code> equal to </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">pop eip<br>pop cs<br>pop eflags<br>pop esp<br>pop ss<br></code></pre></td></tr></table></figure>\n<p> instruction <code>*(--krnstack) = 0;</code>  Means eax =0 for distinguish parent process and child process.</p>\n<p><strong>In the end , don’t forget add the two code following to corresponding .c file </strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">first_return_kernel</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>; <span class=\"hljs-comment\">// in the fork()</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">long</span> <span class=\"hljs-title\">switch_to</span><span class=\"hljs-params\">(struct task_struct *p , <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> _ldt)</span></span>; <span class=\"hljs-comment\">// in the sched.c</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"Modify-step\"><a href=\"#Modify-step\" class=\"headerlink\" title=\"Modify step\"></a>Modify step</h2><p><strong>Modify in system_call.s</strong></p>\n<p>Write the switch_to、first_return_from_kernel、etc in the system_call.s**</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\"># Don&#39;t forget to change the hardcode.<br># Because I forget to change the hardcode , I stayed here so long time.<br>state\t&#x3D; 0\t\t# these are offsets into the task-struct.<br>counter\t&#x3D; 4<br>priority &#x3D; 8<br>KERNEL_STACK &#x3D; 12<br>signal\t&#x3D; 16<br>sigaction &#x3D; 20\t\t# MUST be 16 (&#x3D;len of sigaction)<br>blocked &#x3D; (33*16+4)<br><br># Define as a global variable，can be used in other file with the keyword extern declaration.<br>.globl first_return_from_kernel, switch_to <br>.align 2<br>switch_to:<br>\tpushl %ebp<br>\tmovl %esp, %ebp<br>\tpushl %ecx<br>\tpushl %ebx<br>\tpushl %eax <br>\tmovl 8(%ebp), %ebx <br>\tcmpl %ebx, current <br>\tje 1f<br>\tmovl %ebx, %eax<br>\txchgl %eax, current # eax&#x3D;old_current, so current&#x3D;pnext<br>\tmovl tss, %ecx\t\t# ecx &#x3D; tss of pnext, it also the new current<br>\taddl $4096, %ebx\t# ebx&#x3D;the top of current kernel stack(pnext)<br>\tmovl %ebx, 4(%ecx)<br>\tmovl %esp, KERNEL_STACK(%eax)<br>\tmovl 8(%ebp), %ebx <br>\tmovl KERNEL_STACK(%ebx), %esp<br>\tmovl 12(%ebp), %ecx<br>\tlldt %cx<br>\tmovl $0x17, %ecx<br>\tmov %cx, %fs<br>\tcmpl %eax, last_task_used_math\t<br>\tjne 1f<br>\tclts<br>1:  popl %eax<br>\tpopl %ebx<br>\tpopl %ecx<br>\tpopl %ebp<br>\tret<br>.align 2<br>first_return_from_kernel:<br>\tpopl %edx<br>\tpopl %edi<br>\tpopl %esi<br>\tpop %gs<br>\tpop %fs<br>\tpop %es<br>\tpop %ds<br>\tiret<br></code></pre></td></tr></table></figure>\n<p><strong>Modify sched.h </strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> &#123;</span><br><span class=\"hljs-comment\">/* these are hardcoded - don&#x27;t touch */</span><br>\t<span class=\"hljs-keyword\">long</span> state;\t<span class=\"hljs-comment\">/* -1 unrunnable, 0 runnable, &gt;0 stopped */</span><br>\t<span class=\"hljs-keyword\">long</span> counter;<br>\t<span class=\"hljs-keyword\">long</span> priority;<br>\t<span class=\"hljs-keyword\">long</span> kernelstack;<br>\t<span class=\"hljs-keyword\">long</span> signal;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">sigaction</span> <span class=\"hljs-title\">sigaction</span>[32];</span><br>\t<span class=\"hljs-keyword\">long</span> blocked;\t<span class=\"hljs-comment\">/* bitmap of masked signals */</span><br>    ......<br>&#125;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> INIT_TASK \\</span><br><span class=\"hljs-comment\">/* state etc */</span>\t&#123; <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">15</span>,<span class=\"hljs-number\">15</span>,PAGE_SIZE+(<span class=\"hljs-keyword\">long</span>)&amp;init_task, \\<br><span class=\"hljs-comment\">/* signals */</span>\t<span class=\"hljs-number\">0</span>,&#123;&#123;&#125;,&#125;,<span class=\"hljs-number\">0</span>, \\<br>.................................<br><br> <span class=\"hljs-comment\">/*注释掉</span><br><span class=\"hljs-comment\">#define switch_to(n) &#123;\\</span><br><span class=\"hljs-comment\">struct &#123;long a,b;&#125; __tmp; \\</span><br><span class=\"hljs-comment\">__asm__(&quot;cmpl %%ecx,current\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;je 1f\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;movw %%dx,%1\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;xchgl %%ecx,current\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;ljmp *%0\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;cmpl %%ecx,last_task_used_math\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;jne 1f\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;clts\\n&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;1:&quot; \\</span><br><span class=\"hljs-comment\">\t::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \\</span><br><span class=\"hljs-comment\">\t&quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \\</span><br><span class=\"hljs-comment\">&#125;</span><br><span class=\"hljs-comment\">*/</span><br>  <br></code></pre></td></tr></table></figure>\n<p><strong>Modify sched.c</strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">long</span> <span class=\"hljs-title\">switch_to</span><span class=\"hljs-params\">(struct task_struct *p , <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> _ldt)</span></span>;<br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">tss_struct</span> * <span class=\"hljs-title\">tss</span> =</span> &amp;(init_task.task.tss);<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">schedule</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> i,next,c;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> ** <span class=\"hljs-title\">p</span>;</span><br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> *<span class=\"hljs-title\">pnext</span> =</span> &amp;(init_task.task);<br><br><span class=\"hljs-comment\">/* check alarm, wake up any interruptible tasks that have got a signal */</span><br><br>\t<span class=\"hljs-keyword\">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)<br>\t\t<span class=\"hljs-keyword\">if</span> (*p) &#123;<br>\t\t\t<span class=\"hljs-keyword\">if</span> ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123;<br>\t\t\t\t\t(*p)-&gt;signal |= (<span class=\"hljs-number\">1</span>&lt;&lt;(SIGALRM<span class=\"hljs-number\">-1</span>));<br>\t\t\t\t\t(*p)-&gt;alarm = <span class=\"hljs-number\">0</span>;<br>\t\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp;<br>\t\t\t(*p)-&gt;state==TASK_INTERRUPTIBLE)<br>\t\t\t\t(*p)-&gt;state=TASK_RUNNING;<br>\t\t&#125;<br><br><span class=\"hljs-comment\">/* this is the scheduler proper: */</span><br><br>\t<span class=\"hljs-keyword\">while</span> (<span class=\"hljs-number\">1</span>) &#123;<br>\t\tc = <span class=\"hljs-number\">-1</span>;<br>\t\tnext = <span class=\"hljs-number\">0</span>;<br>\t\ti = NR_TASKS;<br>\t\tp = &amp;task[NR_TASKS];<br>\t\t<span class=\"hljs-keyword\">while</span> (--i) &#123;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (!*--p)<br>\t\t\t\t<span class=\"hljs-keyword\">continue</span>;<br>\t\t\t<span class=\"hljs-keyword\">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)&#123;<br>\t\t\t\tc = (*p)-&gt;counter, next = i;<br>\t\t\t\tpnext = *p;<br>\t\t\t&#125;<br>\t\t&#125;<br>\t\t<span class=\"hljs-keyword\">if</span> (c) <span class=\"hljs-keyword\">break</span>;<br>\t\t<span class=\"hljs-keyword\">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)<br>\t\t\t<span class=\"hljs-keyword\">if</span> (*p)<br>\t\t\t\t(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; <span class=\"hljs-number\">1</span>) +<br>\t\t\t\t\t\t(*p)-&gt;priority;<br>\t&#125;<br>\tswitch_to(pnext,_LDT(next));<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>Modify fork()</strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">first_return_kernel</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>;  <br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">copy_process</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> nr,<span class=\"hljs-keyword\">long</span> ebp,<span class=\"hljs-keyword\">long</span> edi,<span class=\"hljs-keyword\">long</span> esi,<span class=\"hljs-keyword\">long</span> gs,<span class=\"hljs-keyword\">long</span> none,</span></span><br><span class=\"hljs-function\"><span class=\"hljs-params\">\t\t<span class=\"hljs-keyword\">long</span> ebx,<span class=\"hljs-keyword\">long</span> ecx,<span class=\"hljs-keyword\">long</span> edx,</span></span><br><span class=\"hljs-function\"><span class=\"hljs-params\">\t\t<span class=\"hljs-keyword\">long</span> fs,<span class=\"hljs-keyword\">long</span> es,<span class=\"hljs-keyword\">long</span> ds,</span></span><br><span class=\"hljs-function\"><span class=\"hljs-params\">\t\t<span class=\"hljs-keyword\">long</span> eip,<span class=\"hljs-keyword\">long</span> cs,<span class=\"hljs-keyword\">long</span> eflags,<span class=\"hljs-keyword\">long</span> esp,<span class=\"hljs-keyword\">long</span> ss)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> *<span class=\"hljs-title\">p</span>;</span><br>\t<span class=\"hljs-keyword\">int</span> i;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">file</span> *<span class=\"hljs-title\">f</span>;</span><br><br>\tp = (struct task_struct *) get_free_page();<br>\t<span class=\"hljs-keyword\">if</span> (!p)<br>\t\t<span class=\"hljs-keyword\">return</span> -EAGAIN;<br>\ttask[nr] = p;<br>\t*p = *current;\t<span class=\"hljs-comment\">/* NOTE! this doesn&#x27;t copy the supervisor stack */</span><br>\tp-&gt;state = TASK_UNINTERRUPTIBLE;<br>\tp-&gt;pid = last_pid;<br>\tp-&gt;father = current-&gt;pid;<br>\tp-&gt;counter = p-&gt;priority;<br>\t<span class=\"hljs-keyword\">long</span> * krnstack ;<br>\tkrnstack = (<span class=\"hljs-keyword\">long</span> *) (PAGE_SIZE + (<span class=\"hljs-keyword\">long</span>) p);<br>    *(--krnstack) = ss &amp; <span class=\"hljs-number\">0xffff</span>;<br>    *(--krnstack) = esp;<br>    *(--krnstack) = eflags;<br>    *(--krnstack) = cs &amp; <span class=\"hljs-number\">0xffff</span>;<br>    *(--krnstack) = eip;<br> *(--krnstack) = ds &amp; <span class=\"hljs-number\">0xffff</span>; <br>   *(--krnstack) = es &amp; <span class=\"hljs-number\">0xffff</span>; <br>   *(--krnstack) = fs &amp; <span class=\"hljs-number\">0xffff</span>; <br> *(--krnstack) = gs &amp; <span class=\"hljs-number\">0xffff</span>;<br>  *(--krnstack) = esi; <br> *(--krnstack) = edi; <br>    *(--krnstack) = edx;<br>\t*(--krnstack) =(<span class=\"hljs-keyword\">long</span>) first_return_kernel;<br>    *(--krnstack) = ebp;<br>    *(--krnstack) = ecx;<br>    *(--krnstack) = ebx;<br>    *(--krnstack) = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;kernelstack = krnstack;<br>\tp-&gt;signal = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;alarm = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;leader = <span class=\"hljs-number\">0</span>;\t\t<span class=\"hljs-comment\">/* process leadership doesn&#x27;t inherit */</span><br>\tp-&gt;utime = p-&gt;stime = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;cutime = p-&gt;cstime = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;start_time = jiffies;<br>\tp-&gt;tss.back_link = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;tss.esp0 = PAGE_SIZE + (<span class=\"hljs-keyword\">long</span>) p;<br>\tp-&gt;tss.ss0 = <span class=\"hljs-number\">0x10</span>;<br>\tp-&gt;tss.eip = eip;<br>\tp-&gt;tss.eflags = eflags;<br>\tp-&gt;tss.eax = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;tss.ecx = ecx;<br>\tp-&gt;tss.edx = edx;<br>\tp-&gt;tss.ebx = ebx;<br>\tp-&gt;tss.esp = esp;<br>\tp-&gt;tss.ebp = ebp;<br>\tp-&gt;tss.esi = esi;<br>\tp-&gt;tss.edi = edi;<br>\tp-&gt;tss.es = es &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.cs = cs &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.ss = ss &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.ds = ds &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.fs = fs &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.gs = gs &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.ldt = _LDT(nr);<br>\tp-&gt;tss.trace_bitmap = <span class=\"hljs-number\">0x80000000</span>;<br>\t<span class=\"hljs-keyword\">if</span> (last_task_used_math == current)<br>\t\t__asm__(<span class=\"hljs-string\">&quot;clts ; fnsave %0&quot;</span>::<span class=\"hljs-string\">&quot;m&quot;</span> (p-&gt;tss.i387));<br>\t<span class=\"hljs-keyword\">if</span> (copy_mem(nr,p)) &#123;<br>\t\ttask[nr] = <span class=\"hljs-literal\">NULL</span>;<br>\t\tfree_page((<span class=\"hljs-keyword\">long</span>) p);<br>\t\t<span class=\"hljs-keyword\">return</span> -EAGAIN;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">for</span> (i=<span class=\"hljs-number\">0</span>; i&lt;NR_OPEN;i++)<br>\t\t<span class=\"hljs-keyword\">if</span> ((f=p-&gt;filp[i]))<br>\t\t\tf-&gt;f_count++;<br>\t<span class=\"hljs-keyword\">if</span> (current-&gt;pwd)<br>\t\tcurrent-&gt;pwd-&gt;i_count++;<br>\t<span class=\"hljs-keyword\">if</span> (current-&gt;root)<br>\t\tcurrent-&gt;root-&gt;i_count++;<br>\t<span class=\"hljs-keyword\">if</span> (current-&gt;executable)<br>\t\tcurrent-&gt;executable-&gt;i_count++;<br>\tset_tss_desc(gdt+(nr&lt;&lt;<span class=\"hljs-number\">1</span>)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss));<br>\tset_ldt_desc(gdt+(nr&lt;&lt;<span class=\"hljs-number\">1</span>)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt));<br>\tp-&gt;state = TASK_RUNNING;\t<span class=\"hljs-comment\">/* do this last, just in case */</span><br>\t<span class=\"hljs-keyword\">return</span> last_pid;<br>&#125;<br></code></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"基于内核栈切换的进程切换\"><a href=\"#基于内核栈切换的进程切换\" class=\"headerlink\" title=\"基于内核栈切换的进程切换\"></a>基于内核栈切换的进程切换</h1><h2 id=\"实验目的\"><a href=\"#实验目的\" class=\"headerlink\" title=\"实验目的\"></a>实验目的</h2><ul>\n<li>深入理解进程和进程切换的概念；</li>\n<li>综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题；</li>\n<li>开始建立系统认识。</li>\n</ul>\n<h2 id=\"实验内容\"><a href=\"#实验内容\" class=\"headerlink\" title=\"实验内容\"></a>实验内容</h2><p>现在的 Linux 0.11 采用 TSS（后面会有详细论述）和一条指令就能完成任务切换，虽然简单，但这指令的执行时间却很长，在实现任务切换时大概需要 200 多个时钟周期。</p>\n<p>而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。</p>\n<p>本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 <code>switch_to</code> 实现去掉，写成一段基于堆栈切换的代码。</p>\n<p>本次实验包括如下内容：</p>\n<ul>\n<li>编写汇编程序 <code>switch_to</code>：</li>\n<li>完成主体框架；</li>\n<li>在主体框架下依次完成 PCB 切换、内核栈切换、LDT 切换等；</li>\n<li>修改 <code>fork()</code>，由于是基于内核栈的切换，所以进程需要创建出能完成内核栈切换的样子。</li>\n<li>修改 PCB，即 <code>task_struct</code> 结构，增加相应的内容域，同时处理由于修改了 task_struct 所造成的影响。</li>\n<li>用修改后的 Linux 0.11 仍然可以启动、可以正常使用。</li>\n<li>（选做）分析实验 3 的日志体会修改前后系统运行的差别。</li>\n</ul>\n<h2 id=\"实验报告\"><a href=\"#实验报告\" class=\"headerlink\" title=\"实验报告\"></a>实验报告</h2><p>回答下面三个题：</p>\n<h4 id=\"问题-1\"><a href=\"#问题-1\" class=\"headerlink\" title=\"问题 1\"></a>问题 1</h4><p>针对下面的代码片段：</p>\n<figure class=\"highlight mel\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mel\">movl tss,%ecx<br>addl $4096,%ebx<br>movl %ebx,ESP0(%ecx)<br></code></pre></td></tr></table></figure>\n<p>回答问题：</p>\n<ul>\n<li><p>（1）为什么要加 4096；</p>\n<p>答：因为一页内存低地址存进程PCB，高地址是堆栈，linux-0.11 一页内存大小为4Kb,所以+4096。</p>\n</li>\n<li><p>（2）为什么没有设置 tss 中的 ss0。</p>\n<p>答</p>\n</li>\n</ul>\n<h4 id=\"问题-2\"><a href=\"#问题-2\" class=\"headerlink\" title=\"问题 2\"></a>问题 2</h4><p>针对代码片段：</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">*(--krnstack) = ebp;<br>*(--krnstack) = ecx;<br>*(--krnstack) = ebx;<br>*(--krnstack) = <span class=\"hljs-number\">0</span>;<br></code></pre></td></tr></table></figure>\n<p>回答问题：</p>\n<ul>\n<li><p>（1）子进程第一次执行时，eax=？为什么要等于这个数？哪里的工作让 eax 等于这样一个数？</p>\n<p>答：子进程第一次执行是eax =0;，为了让代码<code>if (!fork()) &#123;....&#125;</code>区分子进程和父进程。</p>\n</li>\n<li><p>（2）这段代码中的 ebx 和 ecx 来自哪里，是什么含义，为什么要通过这些代码将其写到子进程的内核栈中？</p>\n<p>答：这段代码中的ebx和ecx是栈切换执行switch_to时压入的值，我觉得是为了切换进程时保护现场而压入的，在fork创建新进程（子进程）时添加这些代码进新进程内核栈是为了模拟父进程的内核栈。</p>\n</li>\n<li><p>（3）这段代码中的 ebp 来自哪里，是什么含义，为什么要做这样的设置？可以不设置吗？为什么？</p>\n<p>答：ebp也是来自基于栈切换的switch_to（）时压入的，是当前进程在进行切换时保存当前进程现场的操作，为什么要这样设置呢？因为创建新的子进程当进程切换时需要pop所以这里是为了模拟父进程的内核栈.</p>\n</li>\n</ul>\n<h4 id=\"问题-3\"><a href=\"#问题-3\" class=\"headerlink\" title=\"问题 3\"></a>问题 3</h4><p>为什么要在切换完 LDT 之后要重新设置 fs=0x17？而且为什么重设操作要出现在切换完 LDT 之后，出现在 LDT 之前又会怎么样？</p>\n<p>答：因为需要重新设置fs对应的隐藏寄存器的段基址和段限长，所以需要重设操作，出现在LDT之前则没有任何意义不会有任何改变。</p>\n<h2 id=\"TSS的切换\"><a href=\"#TSS的切换\" class=\"headerlink\" title=\"TSS的切换\"></a>TSS的切换</h2><h3 id=\"TSS-task-state-segment\"><a href=\"#TSS-task-state-segment\" class=\"headerlink\" title=\"TSS (task state segment)\"></a>TSS (task state segment)</h3><p>The <strong>task state segment (TTS)</strong> is a structure on x86-based computers which holds information about a task, it is used by the operating system kernel for task managenment. specifically, the following information is stored in the TSS:</p>\n<ul>\n<li>processor register state</li>\n<li>I/O port permissions</li>\n<li>Inner-lever stack pointers (内部堆栈指针)</li>\n<li>Previous TSS link</li>\n</ul>\n<p>All this information should be stored at specific locations within the TSS as specified in the IA-32 manuals.</p>\n<h3 id=\"TR-task-register\"><a href=\"#TR-task-register\" class=\"headerlink\" title=\"TR (task register).\"></a>TR (task register).</h3><p>The TR register is a 16-bit register which holds a segment selector for the TSS. It may be loaded through the LTR instruction. LTR is a privileged instruction and acts in a manner similar to other segment register loads. The task register has two parts: a portion visible and accessible by the programmer and an invisible one that is automatically loaded from the TSS descriptor.<br></p>\n<p>In the current Linux 0.11,the real completion of the  process switch is accomplished by the task state segment(Task State Segment,TSS for short).</p>\n<p>Specifically, when designing the “Intel architecture”(that is the x86 system structure),</p>\n<p>each task(process or thread) corresponds to an independent TSS. TSS is a  corresponds</p>\n<p>to an independent TSS. TSS is a structure in memory that contains almost all CPU registers Image. There is a Task Register(TR for short) pointing to the TSS structure corresponding to the current process. </p>\n<p>The so-called TSS switch is copies almost all the registers in the CPU(current) to the TSS </p>\n<p>structure pointed  by TR.</p>\n<p>At the same time a target TSS is found ,that is the TSS corresponding to the next process to be switched to, and the register image of TSS structure of next process  stored in CPU.</p>\n<p>In here  the execution site switching  is completed.</p>\n<p>as shown in the figure  blow:</p>\n<p><img src=\"process-switch-base-on-stack-switch/wm.png\" alt=\"\"></p>\n<p>Inter architecture provides the command ljmp to achieve the process switch .</p>\n<p>The specific working process is:</p>\n<ul>\n<li>First, use the segment selector in TR to find the current TSS structure memory location in GDT table.</li>\n<li>second,  the register image of current CPU  store to the TSS structure memory  of finding before.(store the current site !)</li>\n<li>Now, we need to find the target process site and copy the register image of the target   process to the CPU. This just means we need to find TSS of the next process in  GDT table and copy the context of TSS structure memory to CPU.</li>\n<li>when the register image of TSS structure of the target process store in CPU completely, that means achieve switch to target process site, now, the target process becomes the current process. </li>\n<li>Finally , TR should be changed to point to the location of the target TSS segment in the GDT table.<br></li>\n</ul>\n<p>all explain above  through one sentence execute  (ljmp segment selector : intra-segment offset).</p>\n<p>So switch_to (a instruction) base on TSS for process and thread switching is actually a ljmp instruction：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">#define switch_to(n) &#123;\\<br>struct &#123;long a,b;&#125; __tmp; \\<br>__asm__(&quot;cmpl %%ecx,current\\n\\t&quot; \\\t <br>\t&quot;je 1f\\n\\t&quot; \\<br>\t&quot;movw %%dx,%1\\n\\t&quot; \\<br>\t&quot;xchgl %%ecx,current\\n\\t&quot; \\<br>\t&quot;ljmp *%0\\n\\t&quot; \\<br>\t&quot;cmpl %%ecx,last_task_used_math\\n\\t&quot; \\<br>\t&quot;jne 1f\\n\\t&quot; \\<br>\t&quot;clts\\n&quot; \\<br>\t&quot;1:&quot; \\<br>\t::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \\<br>\t&quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \\<br>&#125;<br><br>#define FIRST_TSS_ENTRY 4<br><br>#define TSS(n) (((unsigned long) n) &lt;&lt; 4) + (FIRST_TSS_ENTRY &lt;&lt; 3))<br></code></pre></td></tr></table></figure>\n<p>Each process is divided into two part which correspond to TSS and LDT, respectively. </p>\n<p>TSS and LDT are both 64-bit(8 bytes).</p>\n<p>so  _TSS(n) = n <em> 16 + 4 </em> 8 (bytes).</p>\n<p><strong>ljmp instruction can be used in two ways, which are “ljmp $ segment selector, $ offset” and “ljmp <em> mem48” respectively. In here “ljmp </em>% 0” used the second way, “ljmp <em> mem48” mean jump to Logical address (48 bits) of the mem48 contain (mem48 also is an address), the hight 16 bits of 48 bits correspond to segment_selector, the low 32 bits of 48 bits correspond to offset. So ,the core of switch_to is ljmp 0 , n\\</em>16+4*8  </strong></p>\n<p><strong>!! it is worth out attention:</strong></p>\n<p>The ‘*‘ of the “ljmp <em>mem48” is different from ‘\\</em>‘ of C language . The ‘*‘ of the “ljmp *mem48”  is mean indirect jump.</p>\n<h2 id=\"本次实验的内容\"><a href=\"#本次实验的内容\" class=\"headerlink\" title=\"本次实验的内容\"></a>本次实验的内容</h2><p>Although ，the task switching can be completed with one instruction, the execution time of the instruction is very long . It take almost 200 time cycles to complete the task switch using the ljmp instruction. if we want to increase the switching speed ,we can use the heap_stack switch instead of ljmp instruction.</p>\n<p>Moreover. The use of heap_stack switching can also use the parallel optimization technology of instruction pipeline, while making design of the CPU simple.</p>\n<p>Therefore, both Windows and Linux use the heap_stack switching technology to handle process switching.</p>\n<p>Therefore rewriter the code of “switch_to” to  use the heap_stack switch instead of TSS is my task.</p>\n<p>To achieve a process switch base on kernel , we need do three things :</p>\n<ol>\n<li>Rewrite “switch_to”</li>\n<li>Connect the rewritten “switch_to” and schedule() functions together.</li>\n<li>Modify the current fork().</li>\n</ol>\n<h2 id=\"schedule-与-switch-to\"><a href=\"#schedule-与-switch-to\" class=\"headerlink\" title=\"schedule 与 switch_to\"></a>schedule 与 switch_to</h2><h3 id=\"modify-shcedule\"><a href=\"#modify-shcedule\" class=\"headerlink\" title=\"modify shcedule()\"></a>modify shcedule()</h3><p>The task of schedule( ) is finding the position “next” of the next process in the array.  The “next” is equal to “n” of the GDT table(TSS[n]=n*16+4*8).  if we get the “next” in the schedule function, we can use “switch_to (next)” function move to another process.</p>\n<p>Now, we use heap_stack switching instead of TSS switching ,and so we need informations of  current process PCB 、target process PCB、current process kernel stack and target process kernel stack.</p>\n<p> The kernel stack of the Linux 0.11 process and the PCB of process are stored on the same page of memory (a 4kB size page of memory).The PCB is located at the low address of this page of memory ,and the stack is located at the high address of this page of memory.</p>\n<p>In addition, since the PCB of the current process is pointed with a global variable “current”, we  need to tell new switch_to () function a pointer to the target process PCB and we need to tell new switch_to function LDT(next) instead of TSS (next). Just mean ,we don’t need TSS in each process now（we can delete code about TSS），but  also need LDT of  process.</p>\n<p>In summary ,the current schedule() function (in kernel/sched.c) needs to be slightly modified, that is the following code:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-keyword\">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) <br>    c = (*p)-&gt;counter, next = i; <br><br><span class=\"hljs-comment\">//......</span><br><br>switch_to(next);<br></code></pre></td></tr></table></figure>\n<p>modify:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-keyword\">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c) <br>    c = (*p)-&gt;counter, next = i, pnext = *p;<br><br><span class=\"hljs-comment\">//.......</span><br><br>switch_to(pnext, _LDT(next)); <br></code></pre></td></tr></table></figure>\n<h3 id=\"Rewrite-switch-to\"><a href=\"#Rewrite-switch-to\" class=\"headerlink\" title=\"Rewrite switch_to()\"></a>Rewrite switch_to()</h3><p>Rewrite switch_to() function is the most important step in this experiment.</p>\n<p>This function, in turn, completes the following functions:</p>\n<ul>\n<li>first, we need to handle the stack by the assembly language. just handle the ebp register.</li>\n<li>second, we need to compare the parameter of stack about the next process’s PCB with the current process.</li>\n<li>third, we need in turn to complete PCB switch, rewrite kernel stack pointer of TSS, switch kernel stack, switch LDT and switch PC pointer (CS:EIP).</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">switch_to:<br>    pushl %ebp<br>    movl %esp,%ebp<br>    pushl %ecx<br>    pushl %ebx<br>    pushl %eax<br>    movl 8(%ebp),%ebx<br>    cmpl %ebx,current<br>    je 1f<br>! 切换PCB<br>    ! ...<br>! TSS中的内核栈指针的重写<br>    ! ...<br>! 切换内核栈<br>    ! ...<br>! 切换LDT<br>    ! ...<br>    movl $0x17,%ecx<br>    mov %cx,%fs<br>! 和后面的 clts 配合来处理协处理器，由于和主题关系不大，此处不做论述<br>    cmpl %eax,last_task_used_math <br>    jne 1f<br>    clts<br><br>1:    popl %eax<br>    popl %ebx<br>    popl %ecx<br>    popl %ebp<br>ret<br></code></pre></td></tr></table></figure>\n<p><strong>Switch PCB pointer</strong></p>\n<p>ebx register is next process’s PCB pointer.</p>\n<p>The function of xchgl instruction  is to exchange contents between  two register.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">movl %ebx,%eax<br>xchgl %eax,current\t<br></code></pre></td></tr></table></figure>\n<p><strong>Rewrite pointer of kernel stack stored in  TSS</strong></p>\n<p>The current TSS is different from TSS before. Before TSS is a global array but current TSS is a global variable. We need to redefine TSS pointer through two sentences.</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> ESP0 =4</span><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">tss_struct</span> *<span class=\"hljs-title\">tss</span> =</span> (init_task.task.tss);<br></code></pre></td></tr></table></figure>\n<p>current TSS pointer <code>tss</code> similar current process pointer <code>current</code>.</p>\n<p>This has already discussed in detail before. In the system interrupt ,we need to find and determine the location of the kernel stack. and push the five register SS : ESP, CS: EIP and EFLAGS in user mode onto kernel stack. This is the key bridge between the user mode (user stack) and kernel mode (kernel stack). The key of find kernel stack position is use the TR register point to current TSS.</p>\n<p>Although we don’t need to use TSS for switch process in now.  We still stay the intel interrupt system. So we still need it that is we define global variable <code>tss</code>. All processes share that variable.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">movl tss,%ecx<br>addl $4096,%ebx<br>movl %ebx,ESP0(%ecx)<br></code></pre></td></tr></table></figure>\n<p>ESP0 = 4 ,the ecx + ESP0 equal to position of kernel stack pointer in TSS (esp0).</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">tss_struct</span> &#123;</span><br>\t<span class=\"hljs-keyword\">long</span>\tback_link;\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tesp0;<br>\t<span class=\"hljs-keyword\">long</span>\tss0;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tesp1;<br>\t<span class=\"hljs-keyword\">long</span>\tss1;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tesp2;<br>\t<span class=\"hljs-keyword\">long</span>\tss2;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tcr3;<br>\t<span class=\"hljs-keyword\">long</span>\teip;<br>\t<span class=\"hljs-keyword\">long</span>\teflags;<br>\t<span class=\"hljs-keyword\">long</span>\teax,ecx,edx,ebx;<br>\t<span class=\"hljs-keyword\">long</span>\tesp;<br>\t<span class=\"hljs-keyword\">long</span>\tebp;<br>\t<span class=\"hljs-keyword\">long</span>\tesi;<br>\t<span class=\"hljs-keyword\">long</span>\tedi;<br>\t<span class=\"hljs-keyword\">long</span>\tes;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tcs;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tss;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tds;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tfs;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tgs;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\tldt;\t\t<span class=\"hljs-comment\">/* 16 high bits zero */</span><br>\t<span class=\"hljs-keyword\">long</span>\ttrace_bitmap;\t<span class=\"hljs-comment\">/* bits: trace 0, bitmap 16-31 */</span><br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">i387_struct</span> <span class=\"hljs-title\">i387</span>;</span><br>&#125;;<br></code></pre></td></tr></table></figure>\n<p><strong>switch kernel stack :</strong></p>\n<p>It’s also simple to complete the kernel stack switch. we just need to store value of esp register of the current process  onto the current PCB , and take corresponding esp value of next PCB out and put it into esp register.</p>\n<p>since Linux -0.11  didn’t define the variable of kernel stack pointer in PCB(task_struct). so we need to add a variable <code>kernelstack</code> to Linux-0.11 PCB, we still need define another variable <code>KERNEL_STACK = 12</code>  for determine variable of  <code>kernelstack</code> position in PCB.</p>\n<p><strong>Why KERNEL_STACK equal to 12 ?</strong></p>\n<p>because the kernel code have many  assembly hardcodes about manipulating this structure, so,if we add the variable <code>kernelstack</code> in other position, we need to modify kernel code in many difference place. </p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\">KERNEL_STACK = <span class=\"hljs-number\">12</span><br>movl %esp,KERNEL_STACK(%eax)\t! 保存上一个进程的栈顶指针<br>! 再取一下 ebx，因为前面修改过 ebx 的值,此时eax的值等于上一个进程的PCB指针<br>movl <span class=\"hljs-number\">8</span>(%ebp),%ebx\t<br>movl KERNEL_STACK(%ebx),%esp\t！取下个进程的栈顶指针放入esp<br></code></pre></td></tr></table></figure>\n<p>task_struct:</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-comment\">// 在 include/linux/sched.h 中</span><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> &#123;</span><br>    <span class=\"hljs-keyword\">long</span> state;<br>    <span class=\"hljs-keyword\">long</span> counter;<br>    <span class=\"hljs-keyword\">long</span> priority;<br>    <span class=\"hljs-keyword\">long</span> kernelstack;<br><span class=\"hljs-comment\">//......</span><br></code></pre></td></tr></table></figure>\n<p>because we modify the PCB structure,  we also need to modify initialization code of 0 process PCB structure .Modify <code>#define INIT_TASK &#123; 0,15,15, 0,&#123; &#123; &#125;,&#125;,0,...</code>  to <code>#define INIT_TASK &#123; 0,15,15,PAGE_SIZE+(long)&amp;init_task, 0,&#123; &#123; &#125;,&#125;,0,...</code></p>\n<p><strong>switch LDT</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">movl 12(%ebp),%ecx<br>lldt %cx<br>!上面使改LDT代码<br>movl $0x17,%ecx<br>mov %cx,%fs<br></code></pre></td></tr></table></figure>\n<p>Why we have to add two code <code>movl $0x17,%ecx</code> <code>mov %cx,%fs</code> behind that code of switch LDT.</p>\n<p>because we need to change the segment base address and segment length limit in the hidden register about fs.</p>\n<p>Examlpe with CS. The hidden register for increase CPU processing speed.</p>\n<p><img src=\"process-switch-base-on-stack-switch/wm1.png\" alt=\"\"></p>\n<p><strong>switch PC （switch to next process）</strong></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">1:    popl %eax<br>    popl %ebx<br>    popl %ecx<br>    popl %ebp<br>ret<br></code></pre></td></tr></table></figure>\n<p><strong>kernel stack  now</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/20190819230403925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTc2MTQ3OA==,size_16,color_FFFFFF,t_70\" alt=\"\"></p>\n<p>Execute those codes to turn to the next process,if it isn’t come here through code <code>je 1f</code>. Because we have been changed the kernel stack before. we <code>pop  (eax ,ebx,ecx,ebp)</code> is register of next process.   ret instruction equal to <code>pop IP</code>.So we execute <code>ret</code> turn to schedule() function tail of next process. Now ! we completed the stack switch perfectly.</p>\n<h2 id=\"modify-fork\"><a href=\"#modify-fork\" class=\"headerlink\" title=\"modify fork()\"></a>modify fork()</h2><p><strong>Why we need to modify fork() function ?</strong></p>\n<p><strong>Because, we need to simulate the parent process’s kernel stack for the newly created child process. </strong></p>\n<p>Now, we need to modify the fork() function. it is to associate the process’s user stack, user program to its kernel stack with SS: ESP, CS: IP, which is pushed in the kernel stack.</p>\n<p>In addition, since fork() function-core is let the child process to use code, data, and stack of the parent process . the fork core has not changed, although we use the stack switching.</p>\n<p><img src=\"process-switch-base-on-stack-switch/wm2.png\" alt=\"\"></p>\n<p>Don’t hard to imagine. modify fork which  mean  initialize child process’s kernel stack. In <code>copy_process ()</code>as the core code of <code>fork ()</code>, it used to apply a page of memory as process PCB. The kernel stack address position equal pointer p position add the one page of memory size.  so the code <code>krnstack = (*long)(PAGE_SIZE + (long)p)</code> can find the child process kernel stack position. next step is to initialize the content of krnstack pointer .</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-comment\">/*modify in fork()*/</span><br><span class=\"hljs-keyword\">long</span> *krnstack;<br>p = (struct task_struct *) get_free_page();<br>krnstack = (<span class=\"hljs-keyword\">long</span>)(PAGE_SIZE +(<span class=\"hljs-keyword\">long</span>)p);<br> *(--krnstack) = ss &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = esp;<br> *(--krnstack) = eflags;<br> *(--krnstack) = cs &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = eip;<br> *(--krnstack) = ds &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = es &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = fs &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = gs &amp; <span class=\"hljs-number\">0xffff</span>;<br> *(--krnstack) = esi;<br> *(--krnstack) = edi;<br> *(--krnstack) = edx;<br> *(--krnstack) = (<span class=\"hljs-keyword\">long</span>)first_return_from_kernel;<br> *(--krnstack) = ebp;<br> *(--krnstack) = ecx;<br> *(--krnstack) = ebx;<br> *(--krnstack) = <span class=\"hljs-number\">0</span>;<br> p-&gt;kernelstack = krnstack;<br> ......<br><br></code></pre></td></tr></table></figure>\n<p>Those code for simulate parent kernel stack for child process! </p>\n<p>Make a attention !</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c\">*(--krnstack) = (<span class=\"hljs-keyword\">long</span>)first_return_from_kernel;<br>*(--krnstack) = <span class=\"hljs-number\">0</span>;<br></code></pre></td></tr></table></figure>\n<p>We need to code a first_return_from_kernel as a mark! If we return to address first_return_from_kernel. We need to execute those code following.</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">&#x2F;*modify in system_call.s*&#x2F;<br>.align 2<br>first_return_from_kernel:<br>popl %edx<br>popl %edi<br>popl %esi<br>pop %gs<br>pop %fs<br>pop %es<br>pop %ds<br>iret<br></code></pre></td></tr></table></figure>\n<p>instruction <code>iret</code> equal to </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\">pop eip<br>pop cs<br>pop eflags<br>pop esp<br>pop ss<br></code></pre></td></tr></table></figure>\n<p> instruction <code>*(--krnstack) = 0;</code>  Means eax =0 for distinguish parent process and child process.</p>\n<p><strong>In the end , don’t forget add the two code following to corresponding .c file </strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">first_return_kernel</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>; <span class=\"hljs-comment\">// in the fork()</span><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">long</span> <span class=\"hljs-title\">switch_to</span><span class=\"hljs-params\">(struct task_struct *p , <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> _ldt)</span></span>; <span class=\"hljs-comment\">// in the sched.c</span><br></code></pre></td></tr></table></figure>\n<h2 id=\"Modify-step\"><a href=\"#Modify-step\" class=\"headerlink\" title=\"Modify step\"></a>Modify step</h2><p><strong>Modify in system_call.s</strong></p>\n<p>Write the switch_to、first_return_from_kernel、etc in the system_call.s**</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs assembly\"># Don&#39;t forget to change the hardcode.<br># Because I forget to change the hardcode , I stayed here so long time.<br>state\t&#x3D; 0\t\t# these are offsets into the task-struct.<br>counter\t&#x3D; 4<br>priority &#x3D; 8<br>KERNEL_STACK &#x3D; 12<br>signal\t&#x3D; 16<br>sigaction &#x3D; 20\t\t# MUST be 16 (&#x3D;len of sigaction)<br>blocked &#x3D; (33*16+4)<br><br># Define as a global variable，can be used in other file with the keyword extern declaration.<br>.globl first_return_from_kernel, switch_to <br>.align 2<br>switch_to:<br>\tpushl %ebp<br>\tmovl %esp, %ebp<br>\tpushl %ecx<br>\tpushl %ebx<br>\tpushl %eax <br>\tmovl 8(%ebp), %ebx <br>\tcmpl %ebx, current <br>\tje 1f<br>\tmovl %ebx, %eax<br>\txchgl %eax, current # eax&#x3D;old_current, so current&#x3D;pnext<br>\tmovl tss, %ecx\t\t# ecx &#x3D; tss of pnext, it also the new current<br>\taddl $4096, %ebx\t# ebx&#x3D;the top of current kernel stack(pnext)<br>\tmovl %ebx, 4(%ecx)<br>\tmovl %esp, KERNEL_STACK(%eax)<br>\tmovl 8(%ebp), %ebx <br>\tmovl KERNEL_STACK(%ebx), %esp<br>\tmovl 12(%ebp), %ecx<br>\tlldt %cx<br>\tmovl $0x17, %ecx<br>\tmov %cx, %fs<br>\tcmpl %eax, last_task_used_math\t<br>\tjne 1f<br>\tclts<br>1:  popl %eax<br>\tpopl %ebx<br>\tpopl %ecx<br>\tpopl %ebp<br>\tret<br>.align 2<br>first_return_from_kernel:<br>\tpopl %edx<br>\tpopl %edi<br>\tpopl %esi<br>\tpop %gs<br>\tpop %fs<br>\tpop %es<br>\tpop %ds<br>\tiret<br></code></pre></td></tr></table></figure>\n<p><strong>Modify sched.h </strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> &#123;</span><br><span class=\"hljs-comment\">/* these are hardcoded - don&#x27;t touch */</span><br>\t<span class=\"hljs-keyword\">long</span> state;\t<span class=\"hljs-comment\">/* -1 unrunnable, 0 runnable, &gt;0 stopped */</span><br>\t<span class=\"hljs-keyword\">long</span> counter;<br>\t<span class=\"hljs-keyword\">long</span> priority;<br>\t<span class=\"hljs-keyword\">long</span> kernelstack;<br>\t<span class=\"hljs-keyword\">long</span> signal;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">sigaction</span> <span class=\"hljs-title\">sigaction</span>[32];</span><br>\t<span class=\"hljs-keyword\">long</span> blocked;\t<span class=\"hljs-comment\">/* bitmap of masked signals */</span><br>    ......<br>&#125;<br><span class=\"hljs-meta\">#<span class=\"hljs-meta-keyword\">define</span> INIT_TASK \\</span><br><span class=\"hljs-comment\">/* state etc */</span>\t&#123; <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">15</span>,<span class=\"hljs-number\">15</span>,PAGE_SIZE+(<span class=\"hljs-keyword\">long</span>)&amp;init_task, \\<br><span class=\"hljs-comment\">/* signals */</span>\t<span class=\"hljs-number\">0</span>,&#123;&#123;&#125;,&#125;,<span class=\"hljs-number\">0</span>, \\<br>.................................<br><br> <span class=\"hljs-comment\">/*注释掉</span><br><span class=\"hljs-comment\">#define switch_to(n) &#123;\\</span><br><span class=\"hljs-comment\">struct &#123;long a,b;&#125; __tmp; \\</span><br><span class=\"hljs-comment\">__asm__(&quot;cmpl %%ecx,current\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;je 1f\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;movw %%dx,%1\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;xchgl %%ecx,current\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;ljmp *%0\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;cmpl %%ecx,last_task_used_math\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;jne 1f\\n\\t&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;clts\\n&quot; \\</span><br><span class=\"hljs-comment\">\t&quot;1:&quot; \\</span><br><span class=\"hljs-comment\">\t::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \\</span><br><span class=\"hljs-comment\">\t&quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \\</span><br><span class=\"hljs-comment\">&#125;</span><br><span class=\"hljs-comment\">*/</span><br>  <br></code></pre></td></tr></table></figure>\n<p><strong>Modify sched.c</strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">long</span> <span class=\"hljs-title\">switch_to</span><span class=\"hljs-params\">(struct task_struct *p , <span class=\"hljs-keyword\">unsigned</span> <span class=\"hljs-keyword\">long</span> _ldt)</span></span>;<br><span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">tss_struct</span> * <span class=\"hljs-title\">tss</span> =</span> &amp;(init_task.task.tss);<br><span class=\"hljs-function\"><span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">schedule</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-keyword\">int</span> i,next,c;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> ** <span class=\"hljs-title\">p</span>;</span><br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> *<span class=\"hljs-title\">pnext</span> =</span> &amp;(init_task.task);<br><br><span class=\"hljs-comment\">/* check alarm, wake up any interruptible tasks that have got a signal */</span><br><br>\t<span class=\"hljs-keyword\">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)<br>\t\t<span class=\"hljs-keyword\">if</span> (*p) &#123;<br>\t\t\t<span class=\"hljs-keyword\">if</span> ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123;<br>\t\t\t\t\t(*p)-&gt;signal |= (<span class=\"hljs-number\">1</span>&lt;&lt;(SIGALRM<span class=\"hljs-number\">-1</span>));<br>\t\t\t\t\t(*p)-&gt;alarm = <span class=\"hljs-number\">0</span>;<br>\t\t\t\t&#125;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp;<br>\t\t\t(*p)-&gt;state==TASK_INTERRUPTIBLE)<br>\t\t\t\t(*p)-&gt;state=TASK_RUNNING;<br>\t\t&#125;<br><br><span class=\"hljs-comment\">/* this is the scheduler proper: */</span><br><br>\t<span class=\"hljs-keyword\">while</span> (<span class=\"hljs-number\">1</span>) &#123;<br>\t\tc = <span class=\"hljs-number\">-1</span>;<br>\t\tnext = <span class=\"hljs-number\">0</span>;<br>\t\ti = NR_TASKS;<br>\t\tp = &amp;task[NR_TASKS];<br>\t\t<span class=\"hljs-keyword\">while</span> (--i) &#123;<br>\t\t\t<span class=\"hljs-keyword\">if</span> (!*--p)<br>\t\t\t\t<span class=\"hljs-keyword\">continue</span>;<br>\t\t\t<span class=\"hljs-keyword\">if</span> ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)&#123;<br>\t\t\t\tc = (*p)-&gt;counter, next = i;<br>\t\t\t\tpnext = *p;<br>\t\t\t&#125;<br>\t\t&#125;<br>\t\t<span class=\"hljs-keyword\">if</span> (c) <span class=\"hljs-keyword\">break</span>;<br>\t\t<span class=\"hljs-keyword\">for</span>(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)<br>\t\t\t<span class=\"hljs-keyword\">if</span> (*p)<br>\t\t\t\t(*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; <span class=\"hljs-number\">1</span>) +<br>\t\t\t\t\t\t(*p)-&gt;priority;<br>\t&#125;<br>\tswitch_to(pnext,_LDT(next));<br>&#125;<br></code></pre></td></tr></table></figure>\n<p><strong>Modify fork()</strong></p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs C\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-keyword\">void</span> <span class=\"hljs-title\">first_return_kernel</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">void</span>)</span></span>;  <br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">int</span> <span class=\"hljs-title\">copy_process</span><span class=\"hljs-params\">(<span class=\"hljs-keyword\">int</span> nr,<span class=\"hljs-keyword\">long</span> ebp,<span class=\"hljs-keyword\">long</span> edi,<span class=\"hljs-keyword\">long</span> esi,<span class=\"hljs-keyword\">long</span> gs,<span class=\"hljs-keyword\">long</span> none,</span></span><br><span class=\"hljs-function\"><span class=\"hljs-params\">\t\t<span class=\"hljs-keyword\">long</span> ebx,<span class=\"hljs-keyword\">long</span> ecx,<span class=\"hljs-keyword\">long</span> edx,</span></span><br><span class=\"hljs-function\"><span class=\"hljs-params\">\t\t<span class=\"hljs-keyword\">long</span> fs,<span class=\"hljs-keyword\">long</span> es,<span class=\"hljs-keyword\">long</span> ds,</span></span><br><span class=\"hljs-function\"><span class=\"hljs-params\">\t\t<span class=\"hljs-keyword\">long</span> eip,<span class=\"hljs-keyword\">long</span> cs,<span class=\"hljs-keyword\">long</span> eflags,<span class=\"hljs-keyword\">long</span> esp,<span class=\"hljs-keyword\">long</span> ss)</span></span><br><span class=\"hljs-function\"></span>&#123;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">task_struct</span> *<span class=\"hljs-title\">p</span>;</span><br>\t<span class=\"hljs-keyword\">int</span> i;<br>\t<span class=\"hljs-class\"><span class=\"hljs-keyword\">struct</span> <span class=\"hljs-title\">file</span> *<span class=\"hljs-title\">f</span>;</span><br><br>\tp = (struct task_struct *) get_free_page();<br>\t<span class=\"hljs-keyword\">if</span> (!p)<br>\t\t<span class=\"hljs-keyword\">return</span> -EAGAIN;<br>\ttask[nr] = p;<br>\t*p = *current;\t<span class=\"hljs-comment\">/* NOTE! this doesn&#x27;t copy the supervisor stack */</span><br>\tp-&gt;state = TASK_UNINTERRUPTIBLE;<br>\tp-&gt;pid = last_pid;<br>\tp-&gt;father = current-&gt;pid;<br>\tp-&gt;counter = p-&gt;priority;<br>\t<span class=\"hljs-keyword\">long</span> * krnstack ;<br>\tkrnstack = (<span class=\"hljs-keyword\">long</span> *) (PAGE_SIZE + (<span class=\"hljs-keyword\">long</span>) p);<br>    *(--krnstack) = ss &amp; <span class=\"hljs-number\">0xffff</span>;<br>    *(--krnstack) = esp;<br>    *(--krnstack) = eflags;<br>    *(--krnstack) = cs &amp; <span class=\"hljs-number\">0xffff</span>;<br>    *(--krnstack) = eip;<br> *(--krnstack) = ds &amp; <span class=\"hljs-number\">0xffff</span>; <br>   *(--krnstack) = es &amp; <span class=\"hljs-number\">0xffff</span>; <br>   *(--krnstack) = fs &amp; <span class=\"hljs-number\">0xffff</span>; <br> *(--krnstack) = gs &amp; <span class=\"hljs-number\">0xffff</span>;<br>  *(--krnstack) = esi; <br> *(--krnstack) = edi; <br>    *(--krnstack) = edx;<br>\t*(--krnstack) =(<span class=\"hljs-keyword\">long</span>) first_return_kernel;<br>    *(--krnstack) = ebp;<br>    *(--krnstack) = ecx;<br>    *(--krnstack) = ebx;<br>    *(--krnstack) = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;kernelstack = krnstack;<br>\tp-&gt;signal = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;alarm = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;leader = <span class=\"hljs-number\">0</span>;\t\t<span class=\"hljs-comment\">/* process leadership doesn&#x27;t inherit */</span><br>\tp-&gt;utime = p-&gt;stime = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;cutime = p-&gt;cstime = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;start_time = jiffies;<br>\tp-&gt;tss.back_link = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;tss.esp0 = PAGE_SIZE + (<span class=\"hljs-keyword\">long</span>) p;<br>\tp-&gt;tss.ss0 = <span class=\"hljs-number\">0x10</span>;<br>\tp-&gt;tss.eip = eip;<br>\tp-&gt;tss.eflags = eflags;<br>\tp-&gt;tss.eax = <span class=\"hljs-number\">0</span>;<br>\tp-&gt;tss.ecx = ecx;<br>\tp-&gt;tss.edx = edx;<br>\tp-&gt;tss.ebx = ebx;<br>\tp-&gt;tss.esp = esp;<br>\tp-&gt;tss.ebp = ebp;<br>\tp-&gt;tss.esi = esi;<br>\tp-&gt;tss.edi = edi;<br>\tp-&gt;tss.es = es &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.cs = cs &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.ss = ss &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.ds = ds &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.fs = fs &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.gs = gs &amp; <span class=\"hljs-number\">0xffff</span>;<br>\tp-&gt;tss.ldt = _LDT(nr);<br>\tp-&gt;tss.trace_bitmap = <span class=\"hljs-number\">0x80000000</span>;<br>\t<span class=\"hljs-keyword\">if</span> (last_task_used_math == current)<br>\t\t__asm__(<span class=\"hljs-string\">&quot;clts ; fnsave %0&quot;</span>::<span class=\"hljs-string\">&quot;m&quot;</span> (p-&gt;tss.i387));<br>\t<span class=\"hljs-keyword\">if</span> (copy_mem(nr,p)) &#123;<br>\t\ttask[nr] = <span class=\"hljs-literal\">NULL</span>;<br>\t\tfree_page((<span class=\"hljs-keyword\">long</span>) p);<br>\t\t<span class=\"hljs-keyword\">return</span> -EAGAIN;<br>\t&#125;<br>\t<span class=\"hljs-keyword\">for</span> (i=<span class=\"hljs-number\">0</span>; i&lt;NR_OPEN;i++)<br>\t\t<span class=\"hljs-keyword\">if</span> ((f=p-&gt;filp[i]))<br>\t\t\tf-&gt;f_count++;<br>\t<span class=\"hljs-keyword\">if</span> (current-&gt;pwd)<br>\t\tcurrent-&gt;pwd-&gt;i_count++;<br>\t<span class=\"hljs-keyword\">if</span> (current-&gt;root)<br>\t\tcurrent-&gt;root-&gt;i_count++;<br>\t<span class=\"hljs-keyword\">if</span> (current-&gt;executable)<br>\t\tcurrent-&gt;executable-&gt;i_count++;<br>\tset_tss_desc(gdt+(nr&lt;&lt;<span class=\"hljs-number\">1</span>)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss));<br>\tset_ldt_desc(gdt+(nr&lt;&lt;<span class=\"hljs-number\">1</span>)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt));<br>\tp-&gt;state = TASK_RUNNING;\t<span class=\"hljs-comment\">/* do this last, just in case */</span><br>\t<span class=\"hljs-keyword\">return</span> last_pid;<br>&#125;<br></code></pre></td></tr></table></figure>\n"},{"title":"Chapter 3: Transport Layer","date":"2020-04-17T11:08:48.000Z","index_img":"/Picture/TCP-UDP.png","_content":"**Most of content come from Computer-network-A-Top-Down-Approach.**\n\n# 3.4 Principles of Reliable Data Transfer\nit may be corrupt bits , lose packets, packets out of order during the data transfer from client to servers . So . For avoid the data lose or other situation happened When we receive the data at the **Application layer**,we need to build a reliable data transfer protocol.<br>\nIn fact , the layer that below the reliable data transfer protocol is unreliable . For example , TCP protocol is reliable data transfer protocol that is implemented top of unreliable (IP) end-to-end network layer.<br>\nwe will discuss \"build a reliable data transfer protocol above unreliable layer to reliable data transfer\" following section below.<br>\n\n![Reliable-data-tranfer](Reliable-data-tranfer.png)<br>\n\n# 3.4.1 Building a Reliable Data Transfer Protocol\nWe now step through a series of protocols , each one becoming more complex until arriving at a flawless reliable data transfer protocol.<br>\n## Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0\nWe first consider a simple case, in which the underlying channel is completely reliable. We call that protocol *rdt1.0*. The finite-state-machine (FSM) definitions for the sender and receiver are shown in Figure below.<br>\n![rdt1.0-finite-state-machine](rdt1.0-finite-state-machine.png)<br>\n\n**rdt1.0 data transferred actions:** <br>\n\n1. sending side<br>\n- The sending side simply accepts data from upper layer (application layer) via rdt_send(data) event.\n- Creates packets containing the data via the make_pkt(data) event.\n- Send the packets to the underlying channel (network layer) via the udt_send(packet) event.\n\n2. receiving side <br>\n- rdt receives packets from underlying channel (network layer) via the rdt_rcv(packet) event.\n- Remove the data from the packet via extract(packet,data) event.\n- Passes the data up to the upper layer(application layer) via the deliver_data(data).\n\n**In summary of rdt1.0**<br>\n\n*In this simple protocol , these is no difference between a unit of data or packet. Also all packet flow is send from sender to receiver over a reliable prefer channel, So receiver don't need send feedback to sender (tell the sender 'I have received the packet') since nothing can go wrong! Note that we have assume the receiver can receive data as fast as the sender happens to send data, Thus , there is no need for the receiver to ask the sender to slow down.*\n\n## Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0\nA more realistic model of the underlying channel is one in which bit in the packet may be corrupted , such bit errors typically occur in physical components of network as a packet is transmitted packets , propagated , or buffered.<br>  \n**we will continue assume for the moment that all transmitted packets are received in the order in which they we sent.**\n\n**Question:**<br>\n- The bit of packet may be corrupted , when the packet is transmitted ,propagated,or buffered .<br>\nFor example: yourself might dictate a long message over the phone and send to your friends. In typical scenario, the message receiver might say \"OK\"\nafter he has been heard , understood and recorded. But ! If the message receiver hears a garbled sentence . How to solve this problem?<br>\n\n**Solution:**<br>\nThe message receiver will ask the sender to repeat the garbled sentence.<br>\nThe rdt2.0 uses both positive acknowledgments (OK) and negative acknowledgments (\"Please repeat that\"). These control messages allow the receiver let sender know what have been received correctly , and what have been received error and thus requires repeating.<br>\nIn the computer network setting , reliable data transfer protocols base on such retransmission are known as ARQ (Automatic Repeat reQuest) protocols. \n\nFundamentally, three additional protocols capabilities are required in ARQ protocol to handle the presence of bit errors.<br>\n\n- **Error detection :** A mechanism is needed to allow the receiver to detect when bit error have occurred . We can use internet checksum field to achieve this function as UDP did.\n- **Receiver feedback :** The receiver needs to provide explicit feedback to the sender to let the sender know the receiver's view of the world. **Positive acknowledgment (ACK) and Negative acknowledgment (NAK)**\n- **Retransmission :** The sender need to repeat send the corrupted packet to receiver.<br>\n\n![rdt2.0-A-protocol](rdt2.0-A-protocol.png)<br>\n\n**rdt2.0 data transferred actions**\n1. sending side<br>\n- First of all the protocol state is \"Wait from call from above\" . The sender will pass data via *rdt_send(data)* event from upper layer to transfer layer, when the sender wanna to tranfer data.<br>\n- The sender will create packet(sndpkt) containing the data to be sent along with the checksum filed via *sndpkt=make_pkt(data,checksum) event*.<br>\n- Then send the packet(sndpkt）via udt_send(sndpkt) operation to receiver side.<br>\n- In the end change the protocol state to \"Wait for ACK or NAK\" for waiting response message from receiver **(In this state ,the sender cannot get more data from upper layer)**<br>\n- The sender will receive the response message and check it when the response message arrived. If the response is ACK (rdt_rcv(rcvpkt)&&isACK(rcvpkt)) , the sender will change the state back, otherwise the sender will resend the sndpkt to receiver via udt_send(sndpkt) event .<br>\n\n2. receiving side <br>\nThe receiving side still only has a state (wait call from below).<br>\n- The receiver will receive the packet and check it from below layer via **(rdt_rcv(rcvpkt)&&corrupt(rcvpkt)) and (rdt_rcv(rcvpkt)&7notcorrupt(rcvpkt))** event.\n- The receiver will make a packet along with NAK and send it back to sender side. If the packet suffer bit errors. \n- Otherwise the receiver gets the corrupt packet, it will extract the packet and deliver the data to upper layer via **extract(rcvpkt,data) and deliver_data(data)** event. In the end . The receiver will make a packet along with ACK and send it back to sender via **make_pkt(ACK) and udt_send(sndpkt)**<br>\n\n**fatal flaw of rdt2.0**<br>\nUnfortunately rdt2.0 has a fatal flaw. In particular , we haven't account for the possibility that the ACK and NAK could be corrupted !<br>\nAnd more difficulty question is how to recover from errors in ACK and NAK packets..\n\n\n**Solution for fatal flaw of rdt2.0**<br>\nSimply, we just need to retransmit the packet to the receiver when the sender got a corrupted ACK or NAK packets. <br>\n\n**This approach , however introduce the duplicates packets into the sender-receiver-channel. The difficulty is receiver can not know whether the arrived packet containing content is retransmitted packet or new packet ?**\n\nA simple solution to this new problem is to add a new filed and have sender number its data packets by putting sequence number into this filed. The receiver then need only check this sequence number to know whether or not the receiver packet is retransmission .<br>\nIn the sender side use 0 and 1 sequence numbers represent different  state of packets (new packet and old packet) . The packet containing sequence number 0 and sequence number 1 corresponding to the old packet and new packet, when the sender send packet containing sequence number 0 recent. In contrast ,the packet containing sequence number 0 and sequence number 1 corresponding to the new packet and old packet,when the sender send packet containing sequence number 1 recent. <br>\n\n\n## Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1\n\n*rdt2.0 added a sequence number filed called rdt2.1.*<br>\n\n**rdt2.1 data transfer action:**\n\n![rdt2.1-sender](rdt2.1-sender.png)<br>\n\n![rdt2.1-receiver](rdt2.1-receiver.png)<br>\n\n## Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2\n*We can accomplish the same effect as a NAK via only send ACK .<br>\nOut free NAK reliable data transfer protocol for a channel with bit errors known as rdt2.2.*<br>\n\nSuppose the sender sends a packet containing sequence number 0, the receiver receives this packet and sends ACK 0 response (containing sequence number 0) to the sender. Sender got this ACK 0 response message and send a new packet containing sequence number 1 to the receiver, at this moment, the receiver that receiver a corrupted new packet, then the receiver will send an ACK of last received correctly packet (ACK 0)to sender side. The sender that receiver the same ACK 0 response twice (that is, receiver duplicate ACK) know that the receiver did not receive the new packet.<br>\n\n**rdt2.2 data transfer action:**<br>\n1. sender side<br>\n![rdt2.2-sender](rdt2.2-sender.png)<br>\n2. receiver side<br>\n![rdt2.2-receiver](rdt2.2-receiver.png)<br>\n\n \n## Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0\n\n*suppose now that in additions to corrupting bit errors , the underlying channel can lose packet as well.* <br>\n\n**Questions:**<br> \n- How to detect packet loss and what to do when packet loss occurs.<br>\n\n**Solution:**<br>\n- The use of checksumming sequence numbers ACK packet and retransmissions - the techniques already developed in rdt2.2 allow us to solution the latter concern.<br>\n- To handling the first concern we require introduce a new protocol  mechanism. The protocol require the sender judiciously choose a time value. If an ACK is not received within this time , the packet is retransmitted .<br>\n\n**rdt3.0 data transfer action:**<br>\nBecause the packet sequence number alternate between 0 and 1, protocol rdt3.0 sometimes known as **alternating-bit-protocol**<br>\n*In the rdt3.0 , the sender will start a timer for packet via start_timer() event*\n\n**rdt3.0 sender side.<br>**\n\n![rdt3.0-sender](rdt3.0-sender.png)<br>\n\n![rdt3.0-operation-of-data-transfer-1](operation-of-rdt3.0-1.png)<br>\n\n![rdt3.0-operation-of-data-transfer-2](operation-of-rdt3.0-2.png)<br>\n\n**Question:**\n- How long must the sender wait to be certain that something has been lost ?<br>\n\n# 3.4.2 Pipelined Reliable Data Transfer Protocols \n**Question:**<br>\n- Although the rdt3.0 is a functionally correct protocol . But it's unlikely that anyone would happy with its performance . In fact , rdt3.0 has a dismal sender utilization. (more detail of calculation we can read the textbook)<br>\n\n**Solution:**<br>\nTo solution this performance problem is simple: Rather than operate in a stop-and-wait-protocol, the sender is allowed to send multiple packet without waiting for acknowledgment as illustrated figure below.<br>\n\n![Stop-and-wait-versus-pipelined-protocol](Stop-and-wait-versus-pipelined-protocol.png)\n\n*Since the many in-transit sender to receiver packets can be visualized as filling pipeline , the technique is known as pipelining*\n\n**pipelining has the following consequence for reliable data transfer protocols:**<br>\n- The range of sequence number must be increated . Since we require to send mutiple packet , each packet need a unquie sequence number.\n- The sender and receiver side of protocol must has to buffer more than one packet.\n- The range of sequence number and buffering requirements will depend on the manner in which data transfer protocol responds to lost, corrupt and overlay delayed packets. Two basic approaches toward pipelined errors recovery can be identified :**GO-Back-N and Selective repeat**.<br>\n\n## 3.4.3 Go-Back-N(GBN)\nIn the GBN protocol, the sender allowed to send mutiple packet without waiting for acknowledgment, but is constrained to have no more than some maximum allowable number N , the N often be referred as the window size, the Go-Back-N(GBN) protocol often be referred as sliding-window-protocol.<br>\n\n*We maybe have questions that why we limit the window size N instead of unlimited*<br>\nAbout this question we will discuss in the flow control and congestion control sections.<br>\n\n**Define**<br>\n![Sender's-view-of-sequence-numbers-in-the-Go-Back-N](Sender's-view-of-sequence-numbers-in-the-Go-Back-N.png)<br>\n- **Base:** The sequence number of the oldest unacknowledgment .\n- **nextseqnum :** The smallest unused sequence number.\n- **[0 ~ base-1]:** corresponds to have already been transmitted and acknowledged.\n- **[base ~ nextseqnum-1]:** corresponds to have already been sent but not yet acknowledge.\n- **[nextseqnum ~ base+N-1]:** can be used to send packet when the data arrived from upper layer.<br>\n **[base+N ~ ]:** can not be used until an unacknowledged packet has been acknowledged. \n\n*Note that the GBN protocol packet containing fixed-length-sequence-number-filed ,in TCP protocol ,the length of sequence-number-filed is 32 bits, the range of sequence number is [0 ~ $2^{32} -1$ ] different to rdt3.0 that ranger of sequence number is [0 ~ 1],and the length of sequence-number-filed is 1 bits.*<br>\n\n**GBN data transfer action:**<br>\n2. receiver side <br>\n\n![GBN's-FSM-description-receiver](GBN's-FSM-receiver.png)<br>\n\n**The GBN's sender must respond to three type of event.**<br>\n- **Invacation from above:** When rdt_send() be invoked from the upper layer. The sender requires to check the window whether the window has full. If the window is not full , the data from above can make be packet and sent . The sender will update appropriately some variables. If the window is full, the sender will refuse data and indication the upper layer that the window has full. The upper layer will resend it again before a period of time.<br>\n- **Receipt of an ACK:** Noting function `base = getacknum(rcvpkt)+1` because the receiver use **cumulative acknowledgment**(we will discuss in receiver side ), for example , we can know packet of sequence number low than n has received correctly in the receiver side. When the sender side got the packet of sequence number n. Then we can update `base = n+1` and (stop_timer()orstart_timer) according to corrusp<br>\n- **A timeout event:** If timeout occurs , the sender will resends all packets that previously sent but have not yet been acknowledgment . Namely`udt_send(sndpkt[base])....udt_send(sndpkt[nextseqnum-1])`<br>\n\n**The GBN's receiver must respond to event:**<br>\n*In the GBN protocol , the receiver will discard out-of-order packets , for example the receiver expected sequence number is n , but the receiver receive a packet containing sequence number n+1 or more larger than n , the receiver will discard this packet and resend the packet containing expected sequence number to sender via udt_send(sndpkt) event. So the receiver be called use **cumulative acknowledgment**.* <br>\n\n![GBN-in-operation](GBN-in-operation.png)<br>\n\n**Note that the GBN protocol sender must be maintain The upper and lower bound of its window and position of nextseqnum within this window. The receiver must be maintain the sequence number of next in-order-packet.(expectedseqnum)**<br>\n\nHow does GBN protocol work we can see this video: [GBN](https://www.youtube.com/watch?v=9BuaeEjIeQI)<br>\n\n## 3.4.4 Selective Repeat (SR)\n\n**Question:**\nAlthough GBN protocol avoiding the utilization problem of rdt3.0 , The GBN itself also has a performance problem . When the window size and bandwidth-delay both large, many packets can be in pipeline. If have a packet lost in the transmission will cause a large number of packets to retransmission.<br>\n\n**Solution:**\nAs the name suggests, **selective repeat protocol** avoid unnecessary retransmission by having the sender retransmit those packets that it suspects were received in error(that were lost or corrupted ) at the receiver.<br>\n\n![Selective-repeat(SR)-sender-and-receiver-views-of-sequence-number-space.png](Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png)<br>\n\n**Difference to GBN protocol, SR protocol has window in the receiver side like the figure above. <br>**\n*The receiver will acknowledgment a correctly received packet whether or not it is in-order. Out-of-order packet will be buffering until any missing packet (that is lower than sequence number has buffered) are received. When the packet of sequence number (rcv_base) is received , the receiver will deliver a batch of packet that **begin with sequence number (rcv_base) and end with smallest unreceived sequence number minus one** to upper layer. Then number rcv_base increase <br>*\n\n**SR protocol data transfer action:**<br>\n1. sender side <br>\n- **Data received from above:** The sender will check the next sequence number (nextseqnum) whether or not larger than window size `If(nextseqnum>base+N)`.If the nextseqnum is within the window, the sender will make data into packet and send it to receiver. Otherwise the sender will either buffered or returned to upper layer for later transmission as in GBN.<br>\n- **Timeout:**  Different to GBN protocol , in the SR protocol , each packet has its own logical timer since only a single packet will be transmitted on timeout.<br>\n- **ACK received:** If an ACK packet within the window is received , the SR sender will marks that packet as having been received. Until the packet containing sequence number (send_base) is received . Then the sender will move the send_base forward to the unackknowledgment packet with smallest sequence number.<br>\n\n2. receiver side <br>\n- Packet with sequence number in [rcv_base,rcv_base+N-1] is correctly received whatever whether or not in-order. Then the packet is buffered at the receiver . If the packet containing sequence number (rcv_base) is received. The receiver will deliver the packet that begins with rcv_base and end with the smallest unreceived sequence number minus one to the upper layer. Then move rcv_base forward to the smallest unreceived sequence number.<br>\n- Packet with sequence number in [rcv_base-N,rcv_base] is correctly received . Occur this situation cause is a ACK with sequence number in [rcv_base-N,rcv_base] maybe lost or corrupted or bandwidth-delay ,then timeout the sender retransmission the packet , In this case , an ACK must be generated and resend this ACK to sender, even though this is a packet that has previously acknowledgment.<br>\n- Otherwise : Ignore this packet.\n\n![SR-operation.png](SR-operation.png)<br>\n\n**Disadvantages of SR protocol**<br>\n*The two case could happen when the window size too-large and the range of sequence number too-small*<br>\nThe window size is 3 and the range of sequence number is 4 in the example <br>\n\n![SR-receiver-dilemma-a.png](SR-receiver-dilemma-a.png)<br>\n\n**In this case , the old packet 0 is recognized as new packet 0, packet confuse**\n\n![SR-receiver-dilemma-b.png](SR-receiver-dilemma-b.png)<br>\n\n**In this case , packet 3 is lost , the rcv_base = 3 , The packet 0 containing new data will be recognized as old packet 0 when the sender send the new packet 0. Because `0< [3,3+3-1]`. Packet confuse.**<br>\n\n*How small window size must be ?*<br>\n**Answer is window size must be less than or equal to a half of sequence number space for SR protocol.<br>**\n\nHow does SR protocol work we can see this video : [SR](https://www.youtube.com/watch?v=Cs8tR8A9jm8)\n\n# 3.5 Connection-Oriented Transport:TCP\n\n## 3.5.1　The TCP connection\nThe TCP \"connection\" is not an end-to-end TDM or FDM circuit as in a circuit switch network. Nor it's a virtual circuit , only as the connection state reside entirely in two end system.<br>\nThe TCP connection provide **full-duplex service**, namely , Application layer data of two end system  can sent to other side.\n\n**The TCP connection always point-of-point that is between a single sender and a single receiver.**<br>\nThe TCP connection established by **three-way-handshake** , the first two handshake by send the segment that can not carry payload, the third handshake by send the segment that can carry payload.<br>\n\nThe TCP connection also always point-to-point , that is a singer sender and a single receiver.<br>\n**The TCP connection has buffer in two end system. The data is passed through socket then the TCP directs this data to connection's sender buffer then the TCP will grab chuck of data from send's buffer and pass the data to network layer. As shown in figrue below.**<br>\n![TCP-sender-and-receiver-buffer](TCP-sender-and-receiver-buffer.png)<br>\n\n**Two terminology**<br>\n- MSS(Maximum segment size): The maximum amount of application data can place in segment.<br>\n- MTU(Maximum transmission unit): The largest frame size (application data plus TCP/IP header line)<br> \n\n**In Summary**<br>\n*The TCP connection consist of sender's buffer and sender's variables and socket connection to process in sender's host and socket connection to process in receiver's host and receiver's variables and receiver's buffer.*<br> *As mentioned early TCP connection only has two state reside in the sender host and receiver host , no buffer and variable allocated in network element between two end system host (router and switch and repeater)<br>*\n## 3.5.2 TCP Segment Structure \n![TCP-segment-structure](TCP-Segment-structure.png)<br>\n- **Source and destination port numbers**:corresponding to sender socket and receiver socket.<br>\n- **Checksum field**: for detecting the corrupt whether occurred during the traveling as like UDP checksum field.<br>\n- **The 32 bits sequence number field**: The sequence number is the byte number of first byte of data in the TCP packet sent (also called TCP segment)\n- **The 32 bits acknowledgment numbers**: The next packet that receiver expects to receive.\n- **The 16-bits receiver number**: Used for flow control , indicate the window size N that we discuss in the GBN and SR protocol.<br>\n- **The 4-bits header length field**: indicates how long the header is, in 32 bit “words”. The minimum value is “5” which would be 160 bits, or 20 bytes. The maximum length is 15, which would be 480 bits, or 60 bytes\n- **The optional and variable-length optional field**: Used  when  a  sender  andreceiver negotiate the maximum segment size (MSS) or as a window scaling fac-tor for use in high-speed networks. A time-stamping option is also defined. \n- **The flag field contain 6 bits**:\n  -  ACK bit : Used to indicate that value carried in the acknowledgment field is valid .\n  - RST,SYN,FIN bit: Used for connection setup and teardown .\n  - PSH bit: Used to indicate the receiver should pass the data to upper layer immediately.\n  - URG bit: I don't know what this means\n\n### Sequence number and acknowledgment number\nCause These two fields are critical part of TCP connection , We discuss more detail about these.<br>\n\n*All byte in TCP connection are numbered beginning at a **randomly choose** initial sequence number(ISN) , The SYN packets consume one sequence number , so actual data begin at ISN+1*<br>\n\n**For example The TCP connection establish as shown in figure below**<br>\n![TCP-connection-establish](TCP-connection.png)<br>\n- Step 1: The client want to establish connection with server , it will send a packet contain SYN bit and randomly choose initial sequence number (Client_isn) to sever.(no payload)<br>\n- Step 2: The server has received this packet then response a packet contain initial sequence number (server_isn) and SYN bit and acknowledgment number (Client_isn+1) to Client.(no payload)<br>\n- Step 3: The connection established success when the Client has received the response of packet, Client then change the SYN to 0 and send the packet contain sequence number client_isn+1 and acknowledgment number server_isn+1 and actual data (payload) to server.<br> \n\n## 3.5.3 Round-Trip Time Estimation and Timeout\nTCP like rdt3.0 use timeout/retransmission mechanism to recover from lost segment.<br>\nAlthough conceptually simple , many subtle issue arise when we implement timeout/retransmission mechanism in actual protocol such as TCP protocol.<br>\n**Questions:**\n- How larger time is timeout .<br> \n- How estimating the round-trip-time between the sender and receiver<br>\n- Should a timer be associated with each and every unacknowledgment packet?<br>\n\n### Estimating The Round-Trip-Time\n- **SampleRTT**: Represent the amount of time between when the packet sent from the sender (that is pass the packet to the network layer) and when the acknowledgment segment has received.<br>\n*The TCP does not estimate stampleRTT for every single packet(segment), Instead of TCP implementation take only one sampleRTT measurement at a time*\n- **EstimatedRTT**: Because different sampleRTT value will be fluctuate due to congestion in the routers and to varying load on the end systems. The sampleRTT is atypical , In order to estimate a typical RTT ,it is therefore natural to take some sort of avenger of sampleRTT . The TCP maintains an avenger called **EstimatedRTT**.<br>\n`EstimatedRTT = (1- a) * EstimatedRTT + a * SampleRTT`<br>\nThe value of `a` typically choose 0.125.<br>\n`EstimatedRTT = 0.875 * EstimatedRTT + 0.125 * sampleRTT`<br>\n![RTT-sample-and-RTT-estimates](RTT-sample-and-RTT-estimates.png)<br>\n- **DevRTT**: DevRTT as an estimate of how much sampleRTT typical deviates from EstimatedRTT.<br>\n`DevRTT = (1-b) * DevRTT + b * |sampleRTT - EstimatedRTT|`<br>\nThe value of `b` typical choose 0.25.<br>\n`DevRTT = 0.75 * DevRTT + 0.25 * |sampleRTT - EstimatedRTT|`<br>\n- **Timeout Interval**: Clearly The timeout interval should be greater than or equal to EstiamtedRTT or unnecessary retransmission will be sent. But the timeout should not be too larger than EstimatedRTT . Otherwise when the segment has lost , The TCP would not retransmission quickly , leading to large transfer delay.<br>\n`TimeoutInterval = EstimatedRTT + 4 * DevRTT`<br>\nAn **initial** Timeoutinterval value of 1 second is recommended \n\n## 3.5.4 Reliable Data Transfer\nTCP is best categorize as a hybrid of GBN and SR protocol.<br>\n\n**In the receiver(server) side:**<br>\nIn TCP protocol ,server use **cumulative ACK** as like GBN protocol does, server also buffer out-of-order packet as like SR protocol. <br>\n**In the sender(client)  side:**<br>\nSince TCP use cumulative ACK, If the client has received ACK with acknowledgment number 120, just mean the server has received all byte lower than 120<br>\n*For example: The server sends the ACK with acknowledgment number is 120, namely, server expect next sequence number is 120, the client got the ACK packet, then sent two packets with sequence number 120,130 to the server , unfortunately, the packet with sequence number 120 is lost, the server received the out-of-order packet with sequence number 130, then, the server buffers the out-of-order packet as like SR protocol does and sent ACK with acknowledgment number 120 back to the client , here is different to SR protocol, as like GBN protocol does.*\n### TCP Retransmission and Doubling the timeout interval\nDifferent from GBN and SR protocol, TCP only retransmits the not-yet-acknowledgment segment with the smallest sequence number when the timeout occurs, then restart timer with doubling timeout interval.<br>\n\n*For example : Suppose the timeoutinterval associated with oldest not-yet-acknowledgment segment is 0.75 sec when the timer expires, TCP will retransmit this segment and set new expiration time to 1.5 sec , If the timer expires again 1.5 sec later , TCP will retransmit this segment and set new expiration time to 3.0 sec, however whenever the timer is started after either of two other events (that is ACK received and data received from application above), the timeoutinterval is derived from the most recent value of EstimatedRTT and DevRTT*<br>\n\n**Qusetion: Why we need to doubling timeout interval.**<br>\nBecause, in times of congestion , the segment maybe dropped or suffer long queues delay, If we resent the packet persistently , the congestion may get worse . Instead TCP should acts more politely with earn sender retransmit after long and long interval.<br>\n\n**TCP Fast Retransmit**<br>\nOne of problem with timeout-triggered retransmissions is that the timeout period relatively long , when a segment is lost, this long timeout period will force sender to delay this segment retransmit thereby increasing the end-to-end delay. So we need to fast retransmits mechanism.<br>\n\nBefore discuss TCP Fast Retransmit , we should know how does ACK generate .<br>\n**TCP ACK Generation Recommendation**\n![TCP-ACK-Generation-Recommendation](TCP-ACK-Generation-Recommendation.png)<br>\nThe duplicate ACK is indicated that this segment has been lost, when the sender has received this same segment three time . TCP will perform fast retransmit , send this segment to receiver again.<br>\n*For example : The sender send a large number of segment back to back , if one segment is lost , there will likely be many back-to-back duplicate ACK, if the sender received same duplicate more than three time , The sender will be perform fast retransmit, As shown in figure below.*<br>\n\n![Fast-retransmit](Fast-retransmit.png)\n\n**Code snippet of Fast retransmit**<br>\n![Code snippet of Fast retransmit](Code-snippet-of-fast-retransmit.png)<br>\n\n## 3.5.5 Flow Control\n\nFlow control is speed-matching-service that be used to matching the sender sending speed and the receiver's application reading speed.<br>\nIf the application reading receiver's buffer at slow speed , the sender can very easily overflow the connection's receive buffer by sending too much data and too quickly.<br> \n\nTCP provide the flow control by having the sender maintain a variable called **receive window**, Because the TCP is full-duplex , the sender at each side of the connection maintain a distinct receive window.<br>\n\nSuppose the host A send segments to host B over TCP connection, host B allocate a buffer to this connection.<br>\nLet me define some variables for host B and host A.<br>\n**For Host B (server)**<br>\n- RcvBuffer : the size of receive window(buffer) size of host B.<br>\n- LastByteRead : the number of the last byte in the data stream read from receive buffer by application in B.<br>\n- LastByteRcv : the number of the last byte in the data stream has been received from network and has been placed in receive buffer.<br>\n- rwnd : the amount of space room in the buffer  `rwnd = Rcvbuffer - [LastByteRead - LastByteRcv]` <br>\n![RcvBuffer](TCP-RcvBuffer.png)<br>\n**For Host A (Client)** <br>\n- LastByteSent : the number of last byte in the data stream has sent at the sender side .<br>\n- LastByteAcked : the number of last byte in the data stream has ACKed at the sender side . <br>\n\nHost B and host A maintain those variables that we mention above.<br>\n\n**How to control the flow through these information.**<br>\nThe Host B tells Host A that how much space room it has in the connection buffer by place the value of rwnd in receive window field of ACK segment.<br>\nThe host A just need to keep the `LastByteSent - LastByteAcked` less than `rwnd` (,LastByteSent - LastByteAcked <= rwnd`), the sender can assure that it is not overflowing the receive buffer at the Host B.<br>\n\nIf the receive buffer has filled at the Host B, the Host A will stop sending data to Host B, instead, Host A will send one bit to Host B for keeping the connection until the Host B has space room again. <br>\n\n## 3.5.6 TCP-Connection-Manage\n**Establish TCP connection**<br>\n![TCP-Connection-Manage-1](TCP-connection-manage-1.png)<br>\n**Finish TCP connection**<br>\n![TCP-Connection-Manage-2](TCP-connection-manage-2.png)<br>\n**TCP states at the sender side**<br>\n![TCP-Connection-Manage-3](TCP-connection-manage-3.png)<br>\n**TCP states at the receiver side**<br>\n![TCP-Connection-Manage-4](TCP-connection-manage-4.png)<br>\n\n**The SYN flood attack**<br> \n*we can see detail in the textbook*<br>\n\n## 3.6 Principles of Congestion control \n\n### 3.6.1 The Causes and the costs of Congestion\n\n- **Scenario 1: Two sender , a Router with infinite buffer**<br>\nAssume the host A and host B have same sending original data rate $\\lambda _{in}$ ( application sending original data into socket  by $\\lambda _{in}$  ignore the cost of that be encapsulated by TCP/IP header line) and the router throughput capability is $R$\n![Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png](Congestion-scenario-1-two-connection.png)<br>\n\n\t*The throughput equal to R/2 is consequence of two sender Host A and Host B sharing outgoing link of the router.<br>*\n![Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png](Congestion-scenario-1-throughput-and-delay.png)<br>\n\n\t*We can see the sender sending rate more approaches $R/2$ , delay become more larger and larger. The delay become to infinite when the $\\lambda_{in}$ larger than $R/2$<br>*\n\n\t**Here , we found one cost of congestion -- large queue delay are experienced as the packet-arrived rate near the link throughput capability.<br>**\n\n- **Scenario 2: Two Senders and a Router with Finite Buffers**<br>\n\n\tThe $\\lambda_{in}$ is denoted application layer sending the original data into socket by $\\lambda_{in}$ bytes/sec.<br>\n\tThe $\\lambda'_{in}$ is denoted transfer layer sending segment into network by $\\lambda'_{in}$ bytes/sec (containing original data and retransmited data).<br>\n\tThe Router throughput capacity is $R$ bytes/sec.<br>\n![Chapter3-Transport-Layer/Scenario-2-two-hosts.png](Scenario-2-two-hosts.png)<br>\n**a.** The Host A and Host B is able to somehow (magically) determine whether or not the buffer is free in the router . sender only sends data only has free buffer . In this case  $\\lambda_{in}$ equal to $\\lambda'_{in}$, didn't occur packet loss. This case is shown as figure.a below <br>\n**b.** The Host A and Host B may set a larger enough timeout can determine the pakect has been lost , then sender only retransmit packet that is determinded has been lost. This case is shown as figure.b below, we can see the $0.5R$ units of data transmitted . $0.333R$ bytes is original data and $0.166R$ bytes is retransmitted data<br>\n**we can here see another cost of congestion is the sender must perform retransmit packet in order to compensate for dropped packet due to buffer overflow.**<br>\n**c.** The Host A and Host B may set a small timeout interval (or in face of large delay), the sender retransmit prematurely and retransmit packet that have been delay in queue but not yet lost. The original data and retransmited data both may reach the receiver , the receiver will discard the copy of original data . This case is shown as figure.c below <br>\n**we can here see the third cost of congestion -- unneeded retransmissions by sender in face of large delay may cause router to use it link bandwish to forward unneeded copies of packet**\n![Chapter3-Transport-Layer/Scenario-2-performance.png](Scenario-2-performance.png)<br>\n- **Scenario 3 Four sender and Router with Finite Buffer and Multihop Paths**\n\n![Chapter3-Transport-Layer/Scenario-3-Four-senders.png](Scenario-3-Four-senders.png)<br>\nIn this case the A-C connection share route R2 with B-D connection. Consider The host A send data to host C and host B send data to host D both at the same time . The data of host A arrive router R2 with R bytes/sec i , The data of Host B arrive router R2 with $\\lambda$ , the Host A and Host B need to compare for the free buffer of router R2, if the $\\lambda << R$ , nothing going happen , data will safely arrive in destination host, but if the $\\lambda >> R$ (the $\\lambda$ extremely large) , the router will be filled immediately by data of host B , the data of host A will lost because of buffer overflow and that work done by router A will be wasted.<br>\n\n![Chapter3-Transport-Layer/Scenario-3-performance.png](Scenario-3-performance.png)<br>\n**We can see the fourth cost of dropping the packet due to congestion -- when a packet is drop along a path, the transmission capacity that was used at each of upstream link to forward that packet to this point at which it is dropped end up having been wasted.**<br>\n\n### 3.6.2 Approach to Congestion Control \n\n**Two kind of Congestion control way**<br>\n- **End-to-End Congestion Control**\n- **Network-assisted Congestion Control:** The Network (router) provide the feedback to sender indicate the congestion state .**Two feedback way for congestion control.**<br>\n   - Direct feedback: The router direct inform the sender via send choke packet.<br>\n   - The router mark/updata in a packet flowing from sender to receiver to indicate the congestion. Upon recipt of a marked packet , the receiver notifies the sender congestion indication .<br>\n\n![Chapter3-Transport-Layer/Two-feedback-way.png](Two-feedback-way.png)\n\n### 3.6.3 Network Assisted ATM ABR Congestion Control\n**This section we can learn by textboot**<br>\n\n\n## 3.7 TCP Congestion Control (End-To-End Congestion Control)\nThis approach (The TCP Congestion Control Mechanism )taken by TCP is to have each sender limit the rate at which its sends traffic into its connection as a function of perceive network congestion. How to perceive the congestion ? we will discuss below. <br>\nThis approach requires senders keep track of an additional variable , **the congestion window** that is denoted **cwnd** [different to **receive window(rwnd)** at flow control]<br>\nThe congestion window imposes an constraint on the rate at which a TCP sender can send into the network.<br>\n`The unacknowledged data = LastByteSent - LastBystAck <= min{ cwnd , rwnd}`\n\n- **In order to focus to Congestion Control , we assume the receive window is large enough that we can ignore it.**<br>\n- **We also assume the sender always has data to send.**<br>\n- **We define the \"loss event\" at a TCP sender as the ocurrence of either a timeout or recipt of three duplicate ACK from the receiver.<br>**\n\n**How congestion is detected ?.**<br>\n*In the TCP congestion mechanism, The ACK is used to perceive the network congestion situation, The congestion window is used to constrain sent data rate. If ACK is received quickly, the TCP will increase the sender congestion window size quickly. If ACK is received slowly, the TCP will increase the sender congestion window size slowly. If \"loss event\" occurred (indicate Netwok congestion ),　the TCP will take some measures to reduce the congestion window size<br>*\n\n**Give a overview of TCP congestion control, Now ,let me see more detail about TCP congestion-control algorithm**<br>\n\nThe TCP congestion-control algorithm has three major components:\n- **Slow start**\n- **Congestion avoidance**\n- **Fast recovery**\n\n### Slow Start\n\nWhen a TCP connection begin . the value of cwnd typically initialized to a small value of 1 MSS (maximum segment size) resulting in an initial sending rate of roundly MSS/RTT. For example , The MSS equal to 500 bytes , the RTT equal to 200 msec , the resulting inital sending rate is only roundly 20 kbps.<br>\n**If each ACK that is sent within RTT can be received within the same RTT. The TCP is doubling the value of cwnd. Namely increase the value of cwnd by a single MSS every ACK within the same RTT**<br>\nFor example, the initial value of cwnd is 1 MSS, the sender is sending 1 segment into the network within an RTT . when ACK of this segment is received at the sender within the same RTT  , the TCP is doubling the value of cwnd that is to say cwnd become to 2 MSS, the sender can send two-segment within RTT right now. If these two ACK of segments is received at the sender within the same RTT  , the cwnd is doubling to 4 MSS.<br>\n**Thus the TCP send rate start slow , but grow exponentially during the slow phase.**<br>\n![Slow-Start](Slow-Start.png) <br>\n**When should this exponentail growth end?**\n- **The first way:** When timeout event ocurred , The TCP will set the value of cwnd back to 1 MSS begin slow start process anew, and *set a new state variable **ssthresh** (that is \"Slow Start Threashold\") to $cwnd/2$*\n- **The second way:** When the $cwnd \\geq ssthresh$ ocurred , the slow start end and turn into congestion aviodance mode.\n- **The third way:** When the thripe duplicate ACK is detected , the slow start end and turn into fast recovery mode, perform fast retransmit.\n\n### Congestion Avoidance \nOn entry to the Congestion-Avoidance state , the value of cwnd is approximately half its value when congestion was last encountered , that is to say , the congestion could be just around the corner.<br>\n**Thus , rather than doubling the value of cwnd every RTT. TCP adopt more conservative approach and increase the value of cwnd by just a single MSS every RTT**\n\n**The several events should do in the Congestion Avoidance state.**<br>\n- The TCP sender increases the value of cwnd by $MSS\\cdot(\\frac{MSS}{cwnd})$ bytes (here cwnd is constant) when ever a new Acknowledgment arrives. For example the cwnd equal to 500 bytes and the MSS equal to 50 bytes, the sender is sending 10 segment within an RTT . Thus the TCP sender is increasing the value of cwnd by $5$ bytes when ever a new Acknowledgment arrives.\n- When the timeout occurred , The TCP sender is set the value of cwnd back to $1$ MSS and the value of ssthresh is updated to half the value of cwnd , end up turn into slow start mode .<br>\n- When the thripe duplicate Acknowledgment is received . The sender is seting $ssthresh =\\frac{cwnd}{2}$ and $cwnd = ssthresh + 3 \\ast MSS$,then turn into fast recovery mode.\n\n### Fast Recovery \n**The several events should do in the Fast Recovery state**<br>\n- The value of cwnd increased by $1$ MSS for every duplicate ACK received for the missing segment that caused TCP enter the fast-recovery state.\n- When the ACK arrived for the missing segment , the sender set $cwnd = ssthresh$ and turn into congestion avoidance state .\n\n- If the timeout occurred , the sender  set the value of ssthresh to half the value of cwnd and set the value of cwnd to $1$ MSS, then turn into slow start state.<br>\n**The relationship between the three kinds of state**<br>\n![The-three-state-of-congestion-algorithm.png](The-three-state-of-congestion-algorithm.png)<br>\n**Congestion window size changes along with time Ignoring theinitial slow-start period when a connection begins and assuming that losses are indi-cated by triple duplicate ACKs rather than timeouts.<br>**\n![Congestion-window-size-changes-along-with-time.png](Congestion-window-size-changes-along-with-time.png)<br>\n","source":"_posts/Chapter3-Transport-Layer.md","raw":"---\ntitle: 'Chapter 3: Transport Layer'\ndate: 2020-04-17 19:08:48\nindex_img: /Picture/TCP-UDP.png\ncategories:\n- Computer Network A Top-Down Approach\ntags:\n- Computer Network A Top-Down Approach\n---\n**Most of content come from Computer-network-A-Top-Down-Approach.**\n\n# 3.4 Principles of Reliable Data Transfer\nit may be corrupt bits , lose packets, packets out of order during the data transfer from client to servers . So . For avoid the data lose or other situation happened When we receive the data at the **Application layer**,we need to build a reliable data transfer protocol.<br>\nIn fact , the layer that below the reliable data transfer protocol is unreliable . For example , TCP protocol is reliable data transfer protocol that is implemented top of unreliable (IP) end-to-end network layer.<br>\nwe will discuss \"build a reliable data transfer protocol above unreliable layer to reliable data transfer\" following section below.<br>\n\n![Reliable-data-tranfer](Reliable-data-tranfer.png)<br>\n\n# 3.4.1 Building a Reliable Data Transfer Protocol\nWe now step through a series of protocols , each one becoming more complex until arriving at a flawless reliable data transfer protocol.<br>\n## Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0\nWe first consider a simple case, in which the underlying channel is completely reliable. We call that protocol *rdt1.0*. The finite-state-machine (FSM) definitions for the sender and receiver are shown in Figure below.<br>\n![rdt1.0-finite-state-machine](rdt1.0-finite-state-machine.png)<br>\n\n**rdt1.0 data transferred actions:** <br>\n\n1. sending side<br>\n- The sending side simply accepts data from upper layer (application layer) via rdt_send(data) event.\n- Creates packets containing the data via the make_pkt(data) event.\n- Send the packets to the underlying channel (network layer) via the udt_send(packet) event.\n\n2. receiving side <br>\n- rdt receives packets from underlying channel (network layer) via the rdt_rcv(packet) event.\n- Remove the data from the packet via extract(packet,data) event.\n- Passes the data up to the upper layer(application layer) via the deliver_data(data).\n\n**In summary of rdt1.0**<br>\n\n*In this simple protocol , these is no difference between a unit of data or packet. Also all packet flow is send from sender to receiver over a reliable prefer channel, So receiver don't need send feedback to sender (tell the sender 'I have received the packet') since nothing can go wrong! Note that we have assume the receiver can receive data as fast as the sender happens to send data, Thus , there is no need for the receiver to ask the sender to slow down.*\n\n## Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0\nA more realistic model of the underlying channel is one in which bit in the packet may be corrupted , such bit errors typically occur in physical components of network as a packet is transmitted packets , propagated , or buffered.<br>  \n**we will continue assume for the moment that all transmitted packets are received in the order in which they we sent.**\n\n**Question:**<br>\n- The bit of packet may be corrupted , when the packet is transmitted ,propagated,or buffered .<br>\nFor example: yourself might dictate a long message over the phone and send to your friends. In typical scenario, the message receiver might say \"OK\"\nafter he has been heard , understood and recorded. But ! If the message receiver hears a garbled sentence . How to solve this problem?<br>\n\n**Solution:**<br>\nThe message receiver will ask the sender to repeat the garbled sentence.<br>\nThe rdt2.0 uses both positive acknowledgments (OK) and negative acknowledgments (\"Please repeat that\"). These control messages allow the receiver let sender know what have been received correctly , and what have been received error and thus requires repeating.<br>\nIn the computer network setting , reliable data transfer protocols base on such retransmission are known as ARQ (Automatic Repeat reQuest) protocols. \n\nFundamentally, three additional protocols capabilities are required in ARQ protocol to handle the presence of bit errors.<br>\n\n- **Error detection :** A mechanism is needed to allow the receiver to detect when bit error have occurred . We can use internet checksum field to achieve this function as UDP did.\n- **Receiver feedback :** The receiver needs to provide explicit feedback to the sender to let the sender know the receiver's view of the world. **Positive acknowledgment (ACK) and Negative acknowledgment (NAK)**\n- **Retransmission :** The sender need to repeat send the corrupted packet to receiver.<br>\n\n![rdt2.0-A-protocol](rdt2.0-A-protocol.png)<br>\n\n**rdt2.0 data transferred actions**\n1. sending side<br>\n- First of all the protocol state is \"Wait from call from above\" . The sender will pass data via *rdt_send(data)* event from upper layer to transfer layer, when the sender wanna to tranfer data.<br>\n- The sender will create packet(sndpkt) containing the data to be sent along with the checksum filed via *sndpkt=make_pkt(data,checksum) event*.<br>\n- Then send the packet(sndpkt）via udt_send(sndpkt) operation to receiver side.<br>\n- In the end change the protocol state to \"Wait for ACK or NAK\" for waiting response message from receiver **(In this state ,the sender cannot get more data from upper layer)**<br>\n- The sender will receive the response message and check it when the response message arrived. If the response is ACK (rdt_rcv(rcvpkt)&&isACK(rcvpkt)) , the sender will change the state back, otherwise the sender will resend the sndpkt to receiver via udt_send(sndpkt) event .<br>\n\n2. receiving side <br>\nThe receiving side still only has a state (wait call from below).<br>\n- The receiver will receive the packet and check it from below layer via **(rdt_rcv(rcvpkt)&&corrupt(rcvpkt)) and (rdt_rcv(rcvpkt)&7notcorrupt(rcvpkt))** event.\n- The receiver will make a packet along with NAK and send it back to sender side. If the packet suffer bit errors. \n- Otherwise the receiver gets the corrupt packet, it will extract the packet and deliver the data to upper layer via **extract(rcvpkt,data) and deliver_data(data)** event. In the end . The receiver will make a packet along with ACK and send it back to sender via **make_pkt(ACK) and udt_send(sndpkt)**<br>\n\n**fatal flaw of rdt2.0**<br>\nUnfortunately rdt2.0 has a fatal flaw. In particular , we haven't account for the possibility that the ACK and NAK could be corrupted !<br>\nAnd more difficulty question is how to recover from errors in ACK and NAK packets..\n\n\n**Solution for fatal flaw of rdt2.0**<br>\nSimply, we just need to retransmit the packet to the receiver when the sender got a corrupted ACK or NAK packets. <br>\n\n**This approach , however introduce the duplicates packets into the sender-receiver-channel. The difficulty is receiver can not know whether the arrived packet containing content is retransmitted packet or new packet ?**\n\nA simple solution to this new problem is to add a new filed and have sender number its data packets by putting sequence number into this filed. The receiver then need only check this sequence number to know whether or not the receiver packet is retransmission .<br>\nIn the sender side use 0 and 1 sequence numbers represent different  state of packets (new packet and old packet) . The packet containing sequence number 0 and sequence number 1 corresponding to the old packet and new packet, when the sender send packet containing sequence number 0 recent. In contrast ,the packet containing sequence number 0 and sequence number 1 corresponding to the new packet and old packet,when the sender send packet containing sequence number 1 recent. <br>\n\n\n## Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1\n\n*rdt2.0 added a sequence number filed called rdt2.1.*<br>\n\n**rdt2.1 data transfer action:**\n\n![rdt2.1-sender](rdt2.1-sender.png)<br>\n\n![rdt2.1-receiver](rdt2.1-receiver.png)<br>\n\n## Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2\n*We can accomplish the same effect as a NAK via only send ACK .<br>\nOut free NAK reliable data transfer protocol for a channel with bit errors known as rdt2.2.*<br>\n\nSuppose the sender sends a packet containing sequence number 0, the receiver receives this packet and sends ACK 0 response (containing sequence number 0) to the sender. Sender got this ACK 0 response message and send a new packet containing sequence number 1 to the receiver, at this moment, the receiver that receiver a corrupted new packet, then the receiver will send an ACK of last received correctly packet (ACK 0)to sender side. The sender that receiver the same ACK 0 response twice (that is, receiver duplicate ACK) know that the receiver did not receive the new packet.<br>\n\n**rdt2.2 data transfer action:**<br>\n1. sender side<br>\n![rdt2.2-sender](rdt2.2-sender.png)<br>\n2. receiver side<br>\n![rdt2.2-receiver](rdt2.2-receiver.png)<br>\n\n \n## Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0\n\n*suppose now that in additions to corrupting bit errors , the underlying channel can lose packet as well.* <br>\n\n**Questions:**<br> \n- How to detect packet loss and what to do when packet loss occurs.<br>\n\n**Solution:**<br>\n- The use of checksumming sequence numbers ACK packet and retransmissions - the techniques already developed in rdt2.2 allow us to solution the latter concern.<br>\n- To handling the first concern we require introduce a new protocol  mechanism. The protocol require the sender judiciously choose a time value. If an ACK is not received within this time , the packet is retransmitted .<br>\n\n**rdt3.0 data transfer action:**<br>\nBecause the packet sequence number alternate between 0 and 1, protocol rdt3.0 sometimes known as **alternating-bit-protocol**<br>\n*In the rdt3.0 , the sender will start a timer for packet via start_timer() event*\n\n**rdt3.0 sender side.<br>**\n\n![rdt3.0-sender](rdt3.0-sender.png)<br>\n\n![rdt3.0-operation-of-data-transfer-1](operation-of-rdt3.0-1.png)<br>\n\n![rdt3.0-operation-of-data-transfer-2](operation-of-rdt3.0-2.png)<br>\n\n**Question:**\n- How long must the sender wait to be certain that something has been lost ?<br>\n\n# 3.4.2 Pipelined Reliable Data Transfer Protocols \n**Question:**<br>\n- Although the rdt3.0 is a functionally correct protocol . But it's unlikely that anyone would happy with its performance . In fact , rdt3.0 has a dismal sender utilization. (more detail of calculation we can read the textbook)<br>\n\n**Solution:**<br>\nTo solution this performance problem is simple: Rather than operate in a stop-and-wait-protocol, the sender is allowed to send multiple packet without waiting for acknowledgment as illustrated figure below.<br>\n\n![Stop-and-wait-versus-pipelined-protocol](Stop-and-wait-versus-pipelined-protocol.png)\n\n*Since the many in-transit sender to receiver packets can be visualized as filling pipeline , the technique is known as pipelining*\n\n**pipelining has the following consequence for reliable data transfer protocols:**<br>\n- The range of sequence number must be increated . Since we require to send mutiple packet , each packet need a unquie sequence number.\n- The sender and receiver side of protocol must has to buffer more than one packet.\n- The range of sequence number and buffering requirements will depend on the manner in which data transfer protocol responds to lost, corrupt and overlay delayed packets. Two basic approaches toward pipelined errors recovery can be identified :**GO-Back-N and Selective repeat**.<br>\n\n## 3.4.3 Go-Back-N(GBN)\nIn the GBN protocol, the sender allowed to send mutiple packet without waiting for acknowledgment, but is constrained to have no more than some maximum allowable number N , the N often be referred as the window size, the Go-Back-N(GBN) protocol often be referred as sliding-window-protocol.<br>\n\n*We maybe have questions that why we limit the window size N instead of unlimited*<br>\nAbout this question we will discuss in the flow control and congestion control sections.<br>\n\n**Define**<br>\n![Sender's-view-of-sequence-numbers-in-the-Go-Back-N](Sender's-view-of-sequence-numbers-in-the-Go-Back-N.png)<br>\n- **Base:** The sequence number of the oldest unacknowledgment .\n- **nextseqnum :** The smallest unused sequence number.\n- **[0 ~ base-1]:** corresponds to have already been transmitted and acknowledged.\n- **[base ~ nextseqnum-1]:** corresponds to have already been sent but not yet acknowledge.\n- **[nextseqnum ~ base+N-1]:** can be used to send packet when the data arrived from upper layer.<br>\n **[base+N ~ ]:** can not be used until an unacknowledged packet has been acknowledged. \n\n*Note that the GBN protocol packet containing fixed-length-sequence-number-filed ,in TCP protocol ,the length of sequence-number-filed is 32 bits, the range of sequence number is [0 ~ $2^{32} -1$ ] different to rdt3.0 that ranger of sequence number is [0 ~ 1],and the length of sequence-number-filed is 1 bits.*<br>\n\n**GBN data transfer action:**<br>\n2. receiver side <br>\n\n![GBN's-FSM-description-receiver](GBN's-FSM-receiver.png)<br>\n\n**The GBN's sender must respond to three type of event.**<br>\n- **Invacation from above:** When rdt_send() be invoked from the upper layer. The sender requires to check the window whether the window has full. If the window is not full , the data from above can make be packet and sent . The sender will update appropriately some variables. If the window is full, the sender will refuse data and indication the upper layer that the window has full. The upper layer will resend it again before a period of time.<br>\n- **Receipt of an ACK:** Noting function `base = getacknum(rcvpkt)+1` because the receiver use **cumulative acknowledgment**(we will discuss in receiver side ), for example , we can know packet of sequence number low than n has received correctly in the receiver side. When the sender side got the packet of sequence number n. Then we can update `base = n+1` and (stop_timer()orstart_timer) according to corrusp<br>\n- **A timeout event:** If timeout occurs , the sender will resends all packets that previously sent but have not yet been acknowledgment . Namely`udt_send(sndpkt[base])....udt_send(sndpkt[nextseqnum-1])`<br>\n\n**The GBN's receiver must respond to event:**<br>\n*In the GBN protocol , the receiver will discard out-of-order packets , for example the receiver expected sequence number is n , but the receiver receive a packet containing sequence number n+1 or more larger than n , the receiver will discard this packet and resend the packet containing expected sequence number to sender via udt_send(sndpkt) event. So the receiver be called use **cumulative acknowledgment**.* <br>\n\n![GBN-in-operation](GBN-in-operation.png)<br>\n\n**Note that the GBN protocol sender must be maintain The upper and lower bound of its window and position of nextseqnum within this window. The receiver must be maintain the sequence number of next in-order-packet.(expectedseqnum)**<br>\n\nHow does GBN protocol work we can see this video: [GBN](https://www.youtube.com/watch?v=9BuaeEjIeQI)<br>\n\n## 3.4.4 Selective Repeat (SR)\n\n**Question:**\nAlthough GBN protocol avoiding the utilization problem of rdt3.0 , The GBN itself also has a performance problem . When the window size and bandwidth-delay both large, many packets can be in pipeline. If have a packet lost in the transmission will cause a large number of packets to retransmission.<br>\n\n**Solution:**\nAs the name suggests, **selective repeat protocol** avoid unnecessary retransmission by having the sender retransmit those packets that it suspects were received in error(that were lost or corrupted ) at the receiver.<br>\n\n![Selective-repeat(SR)-sender-and-receiver-views-of-sequence-number-space.png](Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png)<br>\n\n**Difference to GBN protocol, SR protocol has window in the receiver side like the figure above. <br>**\n*The receiver will acknowledgment a correctly received packet whether or not it is in-order. Out-of-order packet will be buffering until any missing packet (that is lower than sequence number has buffered) are received. When the packet of sequence number (rcv_base) is received , the receiver will deliver a batch of packet that **begin with sequence number (rcv_base) and end with smallest unreceived sequence number minus one** to upper layer. Then number rcv_base increase <br>*\n\n**SR protocol data transfer action:**<br>\n1. sender side <br>\n- **Data received from above:** The sender will check the next sequence number (nextseqnum) whether or not larger than window size `If(nextseqnum>base+N)`.If the nextseqnum is within the window, the sender will make data into packet and send it to receiver. Otherwise the sender will either buffered or returned to upper layer for later transmission as in GBN.<br>\n- **Timeout:**  Different to GBN protocol , in the SR protocol , each packet has its own logical timer since only a single packet will be transmitted on timeout.<br>\n- **ACK received:** If an ACK packet within the window is received , the SR sender will marks that packet as having been received. Until the packet containing sequence number (send_base) is received . Then the sender will move the send_base forward to the unackknowledgment packet with smallest sequence number.<br>\n\n2. receiver side <br>\n- Packet with sequence number in [rcv_base,rcv_base+N-1] is correctly received whatever whether or not in-order. Then the packet is buffered at the receiver . If the packet containing sequence number (rcv_base) is received. The receiver will deliver the packet that begins with rcv_base and end with the smallest unreceived sequence number minus one to the upper layer. Then move rcv_base forward to the smallest unreceived sequence number.<br>\n- Packet with sequence number in [rcv_base-N,rcv_base] is correctly received . Occur this situation cause is a ACK with sequence number in [rcv_base-N,rcv_base] maybe lost or corrupted or bandwidth-delay ,then timeout the sender retransmission the packet , In this case , an ACK must be generated and resend this ACK to sender, even though this is a packet that has previously acknowledgment.<br>\n- Otherwise : Ignore this packet.\n\n![SR-operation.png](SR-operation.png)<br>\n\n**Disadvantages of SR protocol**<br>\n*The two case could happen when the window size too-large and the range of sequence number too-small*<br>\nThe window size is 3 and the range of sequence number is 4 in the example <br>\n\n![SR-receiver-dilemma-a.png](SR-receiver-dilemma-a.png)<br>\n\n**In this case , the old packet 0 is recognized as new packet 0, packet confuse**\n\n![SR-receiver-dilemma-b.png](SR-receiver-dilemma-b.png)<br>\n\n**In this case , packet 3 is lost , the rcv_base = 3 , The packet 0 containing new data will be recognized as old packet 0 when the sender send the new packet 0. Because `0< [3,3+3-1]`. Packet confuse.**<br>\n\n*How small window size must be ?*<br>\n**Answer is window size must be less than or equal to a half of sequence number space for SR protocol.<br>**\n\nHow does SR protocol work we can see this video : [SR](https://www.youtube.com/watch?v=Cs8tR8A9jm8)\n\n# 3.5 Connection-Oriented Transport:TCP\n\n## 3.5.1　The TCP connection\nThe TCP \"connection\" is not an end-to-end TDM or FDM circuit as in a circuit switch network. Nor it's a virtual circuit , only as the connection state reside entirely in two end system.<br>\nThe TCP connection provide **full-duplex service**, namely , Application layer data of two end system  can sent to other side.\n\n**The TCP connection always point-of-point that is between a single sender and a single receiver.**<br>\nThe TCP connection established by **three-way-handshake** , the first two handshake by send the segment that can not carry payload, the third handshake by send the segment that can carry payload.<br>\n\nThe TCP connection also always point-to-point , that is a singer sender and a single receiver.<br>\n**The TCP connection has buffer in two end system. The data is passed through socket then the TCP directs this data to connection's sender buffer then the TCP will grab chuck of data from send's buffer and pass the data to network layer. As shown in figrue below.**<br>\n![TCP-sender-and-receiver-buffer](TCP-sender-and-receiver-buffer.png)<br>\n\n**Two terminology**<br>\n- MSS(Maximum segment size): The maximum amount of application data can place in segment.<br>\n- MTU(Maximum transmission unit): The largest frame size (application data plus TCP/IP header line)<br> \n\n**In Summary**<br>\n*The TCP connection consist of sender's buffer and sender's variables and socket connection to process in sender's host and socket connection to process in receiver's host and receiver's variables and receiver's buffer.*<br> *As mentioned early TCP connection only has two state reside in the sender host and receiver host , no buffer and variable allocated in network element between two end system host (router and switch and repeater)<br>*\n## 3.5.2 TCP Segment Structure \n![TCP-segment-structure](TCP-Segment-structure.png)<br>\n- **Source and destination port numbers**:corresponding to sender socket and receiver socket.<br>\n- **Checksum field**: for detecting the corrupt whether occurred during the traveling as like UDP checksum field.<br>\n- **The 32 bits sequence number field**: The sequence number is the byte number of first byte of data in the TCP packet sent (also called TCP segment)\n- **The 32 bits acknowledgment numbers**: The next packet that receiver expects to receive.\n- **The 16-bits receiver number**: Used for flow control , indicate the window size N that we discuss in the GBN and SR protocol.<br>\n- **The 4-bits header length field**: indicates how long the header is, in 32 bit “words”. The minimum value is “5” which would be 160 bits, or 20 bytes. The maximum length is 15, which would be 480 bits, or 60 bytes\n- **The optional and variable-length optional field**: Used  when  a  sender  andreceiver negotiate the maximum segment size (MSS) or as a window scaling fac-tor for use in high-speed networks. A time-stamping option is also defined. \n- **The flag field contain 6 bits**:\n  -  ACK bit : Used to indicate that value carried in the acknowledgment field is valid .\n  - RST,SYN,FIN bit: Used for connection setup and teardown .\n  - PSH bit: Used to indicate the receiver should pass the data to upper layer immediately.\n  - URG bit: I don't know what this means\n\n### Sequence number and acknowledgment number\nCause These two fields are critical part of TCP connection , We discuss more detail about these.<br>\n\n*All byte in TCP connection are numbered beginning at a **randomly choose** initial sequence number(ISN) , The SYN packets consume one sequence number , so actual data begin at ISN+1*<br>\n\n**For example The TCP connection establish as shown in figure below**<br>\n![TCP-connection-establish](TCP-connection.png)<br>\n- Step 1: The client want to establish connection with server , it will send a packet contain SYN bit and randomly choose initial sequence number (Client_isn) to sever.(no payload)<br>\n- Step 2: The server has received this packet then response a packet contain initial sequence number (server_isn) and SYN bit and acknowledgment number (Client_isn+1) to Client.(no payload)<br>\n- Step 3: The connection established success when the Client has received the response of packet, Client then change the SYN to 0 and send the packet contain sequence number client_isn+1 and acknowledgment number server_isn+1 and actual data (payload) to server.<br> \n\n## 3.5.3 Round-Trip Time Estimation and Timeout\nTCP like rdt3.0 use timeout/retransmission mechanism to recover from lost segment.<br>\nAlthough conceptually simple , many subtle issue arise when we implement timeout/retransmission mechanism in actual protocol such as TCP protocol.<br>\n**Questions:**\n- How larger time is timeout .<br> \n- How estimating the round-trip-time between the sender and receiver<br>\n- Should a timer be associated with each and every unacknowledgment packet?<br>\n\n### Estimating The Round-Trip-Time\n- **SampleRTT**: Represent the amount of time between when the packet sent from the sender (that is pass the packet to the network layer) and when the acknowledgment segment has received.<br>\n*The TCP does not estimate stampleRTT for every single packet(segment), Instead of TCP implementation take only one sampleRTT measurement at a time*\n- **EstimatedRTT**: Because different sampleRTT value will be fluctuate due to congestion in the routers and to varying load on the end systems. The sampleRTT is atypical , In order to estimate a typical RTT ,it is therefore natural to take some sort of avenger of sampleRTT . The TCP maintains an avenger called **EstimatedRTT**.<br>\n`EstimatedRTT = (1- a) * EstimatedRTT + a * SampleRTT`<br>\nThe value of `a` typically choose 0.125.<br>\n`EstimatedRTT = 0.875 * EstimatedRTT + 0.125 * sampleRTT`<br>\n![RTT-sample-and-RTT-estimates](RTT-sample-and-RTT-estimates.png)<br>\n- **DevRTT**: DevRTT as an estimate of how much sampleRTT typical deviates from EstimatedRTT.<br>\n`DevRTT = (1-b) * DevRTT + b * |sampleRTT - EstimatedRTT|`<br>\nThe value of `b` typical choose 0.25.<br>\n`DevRTT = 0.75 * DevRTT + 0.25 * |sampleRTT - EstimatedRTT|`<br>\n- **Timeout Interval**: Clearly The timeout interval should be greater than or equal to EstiamtedRTT or unnecessary retransmission will be sent. But the timeout should not be too larger than EstimatedRTT . Otherwise when the segment has lost , The TCP would not retransmission quickly , leading to large transfer delay.<br>\n`TimeoutInterval = EstimatedRTT + 4 * DevRTT`<br>\nAn **initial** Timeoutinterval value of 1 second is recommended \n\n## 3.5.4 Reliable Data Transfer\nTCP is best categorize as a hybrid of GBN and SR protocol.<br>\n\n**In the receiver(server) side:**<br>\nIn TCP protocol ,server use **cumulative ACK** as like GBN protocol does, server also buffer out-of-order packet as like SR protocol. <br>\n**In the sender(client)  side:**<br>\nSince TCP use cumulative ACK, If the client has received ACK with acknowledgment number 120, just mean the server has received all byte lower than 120<br>\n*For example: The server sends the ACK with acknowledgment number is 120, namely, server expect next sequence number is 120, the client got the ACK packet, then sent two packets with sequence number 120,130 to the server , unfortunately, the packet with sequence number 120 is lost, the server received the out-of-order packet with sequence number 130, then, the server buffers the out-of-order packet as like SR protocol does and sent ACK with acknowledgment number 120 back to the client , here is different to SR protocol, as like GBN protocol does.*\n### TCP Retransmission and Doubling the timeout interval\nDifferent from GBN and SR protocol, TCP only retransmits the not-yet-acknowledgment segment with the smallest sequence number when the timeout occurs, then restart timer with doubling timeout interval.<br>\n\n*For example : Suppose the timeoutinterval associated with oldest not-yet-acknowledgment segment is 0.75 sec when the timer expires, TCP will retransmit this segment and set new expiration time to 1.5 sec , If the timer expires again 1.5 sec later , TCP will retransmit this segment and set new expiration time to 3.0 sec, however whenever the timer is started after either of two other events (that is ACK received and data received from application above), the timeoutinterval is derived from the most recent value of EstimatedRTT and DevRTT*<br>\n\n**Qusetion: Why we need to doubling timeout interval.**<br>\nBecause, in times of congestion , the segment maybe dropped or suffer long queues delay, If we resent the packet persistently , the congestion may get worse . Instead TCP should acts more politely with earn sender retransmit after long and long interval.<br>\n\n**TCP Fast Retransmit**<br>\nOne of problem with timeout-triggered retransmissions is that the timeout period relatively long , when a segment is lost, this long timeout period will force sender to delay this segment retransmit thereby increasing the end-to-end delay. So we need to fast retransmits mechanism.<br>\n\nBefore discuss TCP Fast Retransmit , we should know how does ACK generate .<br>\n**TCP ACK Generation Recommendation**\n![TCP-ACK-Generation-Recommendation](TCP-ACK-Generation-Recommendation.png)<br>\nThe duplicate ACK is indicated that this segment has been lost, when the sender has received this same segment three time . TCP will perform fast retransmit , send this segment to receiver again.<br>\n*For example : The sender send a large number of segment back to back , if one segment is lost , there will likely be many back-to-back duplicate ACK, if the sender received same duplicate more than three time , The sender will be perform fast retransmit, As shown in figure below.*<br>\n\n![Fast-retransmit](Fast-retransmit.png)\n\n**Code snippet of Fast retransmit**<br>\n![Code snippet of Fast retransmit](Code-snippet-of-fast-retransmit.png)<br>\n\n## 3.5.5 Flow Control\n\nFlow control is speed-matching-service that be used to matching the sender sending speed and the receiver's application reading speed.<br>\nIf the application reading receiver's buffer at slow speed , the sender can very easily overflow the connection's receive buffer by sending too much data and too quickly.<br> \n\nTCP provide the flow control by having the sender maintain a variable called **receive window**, Because the TCP is full-duplex , the sender at each side of the connection maintain a distinct receive window.<br>\n\nSuppose the host A send segments to host B over TCP connection, host B allocate a buffer to this connection.<br>\nLet me define some variables for host B and host A.<br>\n**For Host B (server)**<br>\n- RcvBuffer : the size of receive window(buffer) size of host B.<br>\n- LastByteRead : the number of the last byte in the data stream read from receive buffer by application in B.<br>\n- LastByteRcv : the number of the last byte in the data stream has been received from network and has been placed in receive buffer.<br>\n- rwnd : the amount of space room in the buffer  `rwnd = Rcvbuffer - [LastByteRead - LastByteRcv]` <br>\n![RcvBuffer](TCP-RcvBuffer.png)<br>\n**For Host A (Client)** <br>\n- LastByteSent : the number of last byte in the data stream has sent at the sender side .<br>\n- LastByteAcked : the number of last byte in the data stream has ACKed at the sender side . <br>\n\nHost B and host A maintain those variables that we mention above.<br>\n\n**How to control the flow through these information.**<br>\nThe Host B tells Host A that how much space room it has in the connection buffer by place the value of rwnd in receive window field of ACK segment.<br>\nThe host A just need to keep the `LastByteSent - LastByteAcked` less than `rwnd` (,LastByteSent - LastByteAcked <= rwnd`), the sender can assure that it is not overflowing the receive buffer at the Host B.<br>\n\nIf the receive buffer has filled at the Host B, the Host A will stop sending data to Host B, instead, Host A will send one bit to Host B for keeping the connection until the Host B has space room again. <br>\n\n## 3.5.6 TCP-Connection-Manage\n**Establish TCP connection**<br>\n![TCP-Connection-Manage-1](TCP-connection-manage-1.png)<br>\n**Finish TCP connection**<br>\n![TCP-Connection-Manage-2](TCP-connection-manage-2.png)<br>\n**TCP states at the sender side**<br>\n![TCP-Connection-Manage-3](TCP-connection-manage-3.png)<br>\n**TCP states at the receiver side**<br>\n![TCP-Connection-Manage-4](TCP-connection-manage-4.png)<br>\n\n**The SYN flood attack**<br> \n*we can see detail in the textbook*<br>\n\n## 3.6 Principles of Congestion control \n\n### 3.6.1 The Causes and the costs of Congestion\n\n- **Scenario 1: Two sender , a Router with infinite buffer**<br>\nAssume the host A and host B have same sending original data rate $\\lambda _{in}$ ( application sending original data into socket  by $\\lambda _{in}$  ignore the cost of that be encapsulated by TCP/IP header line) and the router throughput capability is $R$\n![Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png](Congestion-scenario-1-two-connection.png)<br>\n\n\t*The throughput equal to R/2 is consequence of two sender Host A and Host B sharing outgoing link of the router.<br>*\n![Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png](Congestion-scenario-1-throughput-and-delay.png)<br>\n\n\t*We can see the sender sending rate more approaches $R/2$ , delay become more larger and larger. The delay become to infinite when the $\\lambda_{in}$ larger than $R/2$<br>*\n\n\t**Here , we found one cost of congestion -- large queue delay are experienced as the packet-arrived rate near the link throughput capability.<br>**\n\n- **Scenario 2: Two Senders and a Router with Finite Buffers**<br>\n\n\tThe $\\lambda_{in}$ is denoted application layer sending the original data into socket by $\\lambda_{in}$ bytes/sec.<br>\n\tThe $\\lambda'_{in}$ is denoted transfer layer sending segment into network by $\\lambda'_{in}$ bytes/sec (containing original data and retransmited data).<br>\n\tThe Router throughput capacity is $R$ bytes/sec.<br>\n![Chapter3-Transport-Layer/Scenario-2-two-hosts.png](Scenario-2-two-hosts.png)<br>\n**a.** The Host A and Host B is able to somehow (magically) determine whether or not the buffer is free in the router . sender only sends data only has free buffer . In this case  $\\lambda_{in}$ equal to $\\lambda'_{in}$, didn't occur packet loss. This case is shown as figure.a below <br>\n**b.** The Host A and Host B may set a larger enough timeout can determine the pakect has been lost , then sender only retransmit packet that is determinded has been lost. This case is shown as figure.b below, we can see the $0.5R$ units of data transmitted . $0.333R$ bytes is original data and $0.166R$ bytes is retransmitted data<br>\n**we can here see another cost of congestion is the sender must perform retransmit packet in order to compensate for dropped packet due to buffer overflow.**<br>\n**c.** The Host A and Host B may set a small timeout interval (or in face of large delay), the sender retransmit prematurely and retransmit packet that have been delay in queue but not yet lost. The original data and retransmited data both may reach the receiver , the receiver will discard the copy of original data . This case is shown as figure.c below <br>\n**we can here see the third cost of congestion -- unneeded retransmissions by sender in face of large delay may cause router to use it link bandwish to forward unneeded copies of packet**\n![Chapter3-Transport-Layer/Scenario-2-performance.png](Scenario-2-performance.png)<br>\n- **Scenario 3 Four sender and Router with Finite Buffer and Multihop Paths**\n\n![Chapter3-Transport-Layer/Scenario-3-Four-senders.png](Scenario-3-Four-senders.png)<br>\nIn this case the A-C connection share route R2 with B-D connection. Consider The host A send data to host C and host B send data to host D both at the same time . The data of host A arrive router R2 with R bytes/sec i , The data of Host B arrive router R2 with $\\lambda$ , the Host A and Host B need to compare for the free buffer of router R2, if the $\\lambda << R$ , nothing going happen , data will safely arrive in destination host, but if the $\\lambda >> R$ (the $\\lambda$ extremely large) , the router will be filled immediately by data of host B , the data of host A will lost because of buffer overflow and that work done by router A will be wasted.<br>\n\n![Chapter3-Transport-Layer/Scenario-3-performance.png](Scenario-3-performance.png)<br>\n**We can see the fourth cost of dropping the packet due to congestion -- when a packet is drop along a path, the transmission capacity that was used at each of upstream link to forward that packet to this point at which it is dropped end up having been wasted.**<br>\n\n### 3.6.2 Approach to Congestion Control \n\n**Two kind of Congestion control way**<br>\n- **End-to-End Congestion Control**\n- **Network-assisted Congestion Control:** The Network (router) provide the feedback to sender indicate the congestion state .**Two feedback way for congestion control.**<br>\n   - Direct feedback: The router direct inform the sender via send choke packet.<br>\n   - The router mark/updata in a packet flowing from sender to receiver to indicate the congestion. Upon recipt of a marked packet , the receiver notifies the sender congestion indication .<br>\n\n![Chapter3-Transport-Layer/Two-feedback-way.png](Two-feedback-way.png)\n\n### 3.6.3 Network Assisted ATM ABR Congestion Control\n**This section we can learn by textboot**<br>\n\n\n## 3.7 TCP Congestion Control (End-To-End Congestion Control)\nThis approach (The TCP Congestion Control Mechanism )taken by TCP is to have each sender limit the rate at which its sends traffic into its connection as a function of perceive network congestion. How to perceive the congestion ? we will discuss below. <br>\nThis approach requires senders keep track of an additional variable , **the congestion window** that is denoted **cwnd** [different to **receive window(rwnd)** at flow control]<br>\nThe congestion window imposes an constraint on the rate at which a TCP sender can send into the network.<br>\n`The unacknowledged data = LastByteSent - LastBystAck <= min{ cwnd , rwnd}`\n\n- **In order to focus to Congestion Control , we assume the receive window is large enough that we can ignore it.**<br>\n- **We also assume the sender always has data to send.**<br>\n- **We define the \"loss event\" at a TCP sender as the ocurrence of either a timeout or recipt of three duplicate ACK from the receiver.<br>**\n\n**How congestion is detected ?.**<br>\n*In the TCP congestion mechanism, The ACK is used to perceive the network congestion situation, The congestion window is used to constrain sent data rate. If ACK is received quickly, the TCP will increase the sender congestion window size quickly. If ACK is received slowly, the TCP will increase the sender congestion window size slowly. If \"loss event\" occurred (indicate Netwok congestion ),　the TCP will take some measures to reduce the congestion window size<br>*\n\n**Give a overview of TCP congestion control, Now ,let me see more detail about TCP congestion-control algorithm**<br>\n\nThe TCP congestion-control algorithm has three major components:\n- **Slow start**\n- **Congestion avoidance**\n- **Fast recovery**\n\n### Slow Start\n\nWhen a TCP connection begin . the value of cwnd typically initialized to a small value of 1 MSS (maximum segment size) resulting in an initial sending rate of roundly MSS/RTT. For example , The MSS equal to 500 bytes , the RTT equal to 200 msec , the resulting inital sending rate is only roundly 20 kbps.<br>\n**If each ACK that is sent within RTT can be received within the same RTT. The TCP is doubling the value of cwnd. Namely increase the value of cwnd by a single MSS every ACK within the same RTT**<br>\nFor example, the initial value of cwnd is 1 MSS, the sender is sending 1 segment into the network within an RTT . when ACK of this segment is received at the sender within the same RTT  , the TCP is doubling the value of cwnd that is to say cwnd become to 2 MSS, the sender can send two-segment within RTT right now. If these two ACK of segments is received at the sender within the same RTT  , the cwnd is doubling to 4 MSS.<br>\n**Thus the TCP send rate start slow , but grow exponentially during the slow phase.**<br>\n![Slow-Start](Slow-Start.png) <br>\n**When should this exponentail growth end?**\n- **The first way:** When timeout event ocurred , The TCP will set the value of cwnd back to 1 MSS begin slow start process anew, and *set a new state variable **ssthresh** (that is \"Slow Start Threashold\") to $cwnd/2$*\n- **The second way:** When the $cwnd \\geq ssthresh$ ocurred , the slow start end and turn into congestion aviodance mode.\n- **The third way:** When the thripe duplicate ACK is detected , the slow start end and turn into fast recovery mode, perform fast retransmit.\n\n### Congestion Avoidance \nOn entry to the Congestion-Avoidance state , the value of cwnd is approximately half its value when congestion was last encountered , that is to say , the congestion could be just around the corner.<br>\n**Thus , rather than doubling the value of cwnd every RTT. TCP adopt more conservative approach and increase the value of cwnd by just a single MSS every RTT**\n\n**The several events should do in the Congestion Avoidance state.**<br>\n- The TCP sender increases the value of cwnd by $MSS\\cdot(\\frac{MSS}{cwnd})$ bytes (here cwnd is constant) when ever a new Acknowledgment arrives. For example the cwnd equal to 500 bytes and the MSS equal to 50 bytes, the sender is sending 10 segment within an RTT . Thus the TCP sender is increasing the value of cwnd by $5$ bytes when ever a new Acknowledgment arrives.\n- When the timeout occurred , The TCP sender is set the value of cwnd back to $1$ MSS and the value of ssthresh is updated to half the value of cwnd , end up turn into slow start mode .<br>\n- When the thripe duplicate Acknowledgment is received . The sender is seting $ssthresh =\\frac{cwnd}{2}$ and $cwnd = ssthresh + 3 \\ast MSS$,then turn into fast recovery mode.\n\n### Fast Recovery \n**The several events should do in the Fast Recovery state**<br>\n- The value of cwnd increased by $1$ MSS for every duplicate ACK received for the missing segment that caused TCP enter the fast-recovery state.\n- When the ACK arrived for the missing segment , the sender set $cwnd = ssthresh$ and turn into congestion avoidance state .\n\n- If the timeout occurred , the sender  set the value of ssthresh to half the value of cwnd and set the value of cwnd to $1$ MSS, then turn into slow start state.<br>\n**The relationship between the three kinds of state**<br>\n![The-three-state-of-congestion-algorithm.png](The-three-state-of-congestion-algorithm.png)<br>\n**Congestion window size changes along with time Ignoring theinitial slow-start period when a connection begins and assuming that losses are indi-cated by triple duplicate ACKs rather than timeouts.<br>**\n![Congestion-window-size-changes-along-with-time.png](Congestion-window-size-changes-along-with-time.png)<br>\n","slug":"Chapter3-Transport-Layer","published":1,"updated":"2020-11-14T14:40:36.596Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4sx002sr8s8d3deb4b4","content":"<p><strong>Most of content come from Computer-network-A-Top-Down-Approach.</strong></p>\n<h1 id=\"3-4-Principles-of-Reliable-Data-Transfer\"><a href=\"#3-4-Principles-of-Reliable-Data-Transfer\" class=\"headerlink\" title=\"3.4 Principles of Reliable Data Transfer\"></a>3.4 Principles of Reliable Data Transfer</h1><p>it may be corrupt bits , lose packets, packets out of order during the data transfer from client to servers . So . For avoid the data lose or other situation happened When we receive the data at the <strong>Application layer</strong>,we need to build a reliable data transfer protocol.<br><br>In fact , the layer that below the reliable data transfer protocol is unreliable . For example , TCP protocol is reliable data transfer protocol that is implemented top of unreliable (IP) end-to-end network layer.<br><br>we will discuss “build a reliable data transfer protocol above unreliable layer to reliable data transfer” following section below.<br></p>\n<p><img src=\"Reliable-data-tranfer.png\" alt=\"Reliable-data-tranfer\"><br></p>\n<h1 id=\"3-4-1-Building-a-Reliable-Data-Transfer-Protocol\"><a href=\"#3-4-1-Building-a-Reliable-Data-Transfer-Protocol\" class=\"headerlink\" title=\"3.4.1 Building a Reliable Data Transfer Protocol\"></a>3.4.1 Building a Reliable Data Transfer Protocol</h1><p>We now step through a series of protocols , each one becoming more complex until arriving at a flawless reliable data transfer protocol.<br></p>\n<h2 id=\"Reliable-Data-Transfer-over-a-Perfectly-Reliable-Channel-rdt1-0\"><a href=\"#Reliable-Data-Transfer-over-a-Perfectly-Reliable-Channel-rdt1-0\" class=\"headerlink\" title=\"Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0\"></a>Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0</h2><p>We first consider a simple case, in which the underlying channel is completely reliable. We call that protocol <em>rdt1.0</em>. The finite-state-machine (FSM) definitions for the sender and receiver are shown in Figure below.<br><br><img src=\"rdt1.0-finite-state-machine.png\" alt=\"rdt1.0-finite-state-machine\"><br></p>\n<p><strong>rdt1.0 data transferred actions:</strong> <br></p>\n<ol>\n<li>sending side<br></li>\n</ol>\n<ul>\n<li>The sending side simply accepts data from upper layer (application layer) via rdt_send(data) event.</li>\n<li>Creates packets containing the data via the make_pkt(data) event.</li>\n<li>Send the packets to the underlying channel (network layer) via the udt_send(packet) event.</li>\n</ul>\n<ol>\n<li>receiving side <br></li>\n</ol>\n<ul>\n<li>rdt receives packets from underlying channel (network layer) via the rdt_rcv(packet) event.</li>\n<li>Remove the data from the packet via extract(packet,data) event.</li>\n<li>Passes the data up to the upper layer(application layer) via the deliver_data(data).</li>\n</ul>\n<p><strong>In summary of rdt1.0</strong><br></p>\n<p><em>In this simple protocol , these is no difference between a unit of data or packet. Also all packet flow is send from sender to receiver over a reliable prefer channel, So receiver don’t need send feedback to sender (tell the sender ‘I have received the packet’) since nothing can go wrong! Note that we have assume the receiver can receive data as fast as the sender happens to send data, Thus , there is no need for the receiver to ask the sender to slow down.</em></p>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-0\"><a href=\"#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-0\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0\"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0</h2><p>A more realistic model of the underlying channel is one in which bit in the packet may be corrupted , such bit errors typically occur in physical components of network as a packet is transmitted packets , propagated , or buffered.<br><br><strong>we will continue assume for the moment that all transmitted packets are received in the order in which they we sent.</strong></p>\n<p><strong>Question:</strong><br></p>\n<ul>\n<li>The bit of packet may be corrupted , when the packet is transmitted ,propagated,or buffered .<br><br>For example: yourself might dictate a long message over the phone and send to your friends. In typical scenario, the message receiver might say “OK”<br>after he has been heard , understood and recorded. But ! If the message receiver hears a garbled sentence . How to solve this problem?<br></li>\n</ul>\n<p><strong>Solution:</strong><br><br>The message receiver will ask the sender to repeat the garbled sentence.<br><br>The rdt2.0 uses both positive acknowledgments (OK) and negative acknowledgments (“Please repeat that”). These control messages allow the receiver let sender know what have been received correctly , and what have been received error and thus requires repeating.<br><br>In the computer network setting , reliable data transfer protocols base on such retransmission are known as ARQ (Automatic Repeat reQuest) protocols. </p>\n<p>Fundamentally, three additional protocols capabilities are required in ARQ protocol to handle the presence of bit errors.<br></p>\n<ul>\n<li><strong>Error detection :</strong> A mechanism is needed to allow the receiver to detect when bit error have occurred . We can use internet checksum field to achieve this function as UDP did.</li>\n<li><strong>Receiver feedback :</strong> The receiver needs to provide explicit feedback to the sender to let the sender know the receiver’s view of the world. <strong>Positive acknowledgment (ACK) and Negative acknowledgment (NAK)</strong></li>\n<li><strong>Retransmission :</strong> The sender need to repeat send the corrupted packet to receiver.<br></li>\n</ul>\n<p><img src=\"rdt2.0-A-protocol.png\" alt=\"rdt2.0-A-protocol\"><br></p>\n<p><strong>rdt2.0 data transferred actions</strong></p>\n<ol>\n<li>sending side<br></li>\n</ol>\n<ul>\n<li>First of all the protocol state is “Wait from call from above” . The sender will pass data via <em>rdt_send(data)</em> event from upper layer to transfer layer, when the sender wanna to tranfer data.<br></li>\n<li>The sender will create packet(sndpkt) containing the data to be sent along with the checksum filed via <em>sndpkt=make_pkt(data,checksum) event</em>.<br></li>\n<li>Then send the packet(sndpkt）via udt_send(sndpkt) operation to receiver side.<br></li>\n<li>In the end change the protocol state to “Wait for ACK or NAK” for waiting response message from receiver <strong>(In this state ,the sender cannot get more data from upper layer)</strong><br></li>\n<li>The sender will receive the response message and check it when the response message arrived. If the response is ACK (rdt_rcv(rcvpkt)&amp;&amp;isACK(rcvpkt)) , the sender will change the state back, otherwise the sender will resend the sndpkt to receiver via udt_send(sndpkt) event .<br></li>\n</ul>\n<ol>\n<li>receiving side <br><br>The receiving side still only has a state (wait call from below).<br></li>\n</ol>\n<ul>\n<li>The receiver will receive the packet and check it from below layer via <strong>(rdt_rcv(rcvpkt)&amp;&amp;corrupt(rcvpkt)) and (rdt_rcv(rcvpkt)&amp;7notcorrupt(rcvpkt))</strong> event.</li>\n<li>The receiver will make a packet along with NAK and send it back to sender side. If the packet suffer bit errors. </li>\n<li>Otherwise the receiver gets the corrupt packet, it will extract the packet and deliver the data to upper layer via <strong>extract(rcvpkt,data) and deliver_data(data)</strong> event. In the end . The receiver will make a packet along with ACK and send it back to sender via <strong>make_pkt(ACK) and udt_send(sndpkt)</strong><br></li>\n</ul>\n<p><strong>fatal flaw of rdt2.0</strong><br><br>Unfortunately rdt2.0 has a fatal flaw. In particular , we haven’t account for the possibility that the ACK and NAK could be corrupted !<br><br>And more difficulty question is how to recover from errors in ACK and NAK packets..</p>\n<p><strong>Solution for fatal flaw of rdt2.0</strong><br><br>Simply, we just need to retransmit the packet to the receiver when the sender got a corrupted ACK or NAK packets. <br></p>\n<p><strong>This approach , however introduce the duplicates packets into the sender-receiver-channel. The difficulty is receiver can not know whether the arrived packet containing content is retransmitted packet or new packet ?</strong></p>\n<p>A simple solution to this new problem is to add a new filed and have sender number its data packets by putting sequence number into this filed. The receiver then need only check this sequence number to know whether or not the receiver packet is retransmission .<br><br>In the sender side use 0 and 1 sequence numbers represent different  state of packets (new packet and old packet) . The packet containing sequence number 0 and sequence number 1 corresponding to the old packet and new packet, when the sender send packet containing sequence number 0 recent. In contrast ,the packet containing sequence number 0 and sequence number 1 corresponding to the new packet and old packet,when the sender send packet containing sequence number 1 recent. <br></p>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-1\"><a href=\"#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-1\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1\"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1</h2><p><em>rdt2.0 added a sequence number filed called rdt2.1.</em><br></p>\n<p><strong>rdt2.1 data transfer action:</strong></p>\n<p><img src=\"rdt2.1-sender.png\" alt=\"rdt2.1-sender\"><br></p>\n<p><img src=\"rdt2.1-receiver.png\" alt=\"rdt2.1-receiver\"><br></p>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-2\"><a href=\"#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-2\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2\"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2</h2><p><em>We can accomplish the same effect as a NAK via only send ACK .<br><br>Out free NAK reliable data transfer protocol for a channel with bit errors known as rdt2.2.</em><br></p>\n<p>Suppose the sender sends a packet containing sequence number 0, the receiver receives this packet and sends ACK 0 response (containing sequence number 0) to the sender. Sender got this ACK 0 response message and send a new packet containing sequence number 1 to the receiver, at this moment, the receiver that receiver a corrupted new packet, then the receiver will send an ACK of last received correctly packet (ACK 0)to sender side. The sender that receiver the same ACK 0 response twice (that is, receiver duplicate ACK) know that the receiver did not receive the new packet.<br></p>\n<p><strong>rdt2.2 data transfer action:</strong><br></p>\n<ol>\n<li>sender side<br><br><img src=\"rdt2.2-sender.png\" alt=\"rdt2.2-sender\"><br></li>\n<li>receiver side<br><br><img src=\"rdt2.2-receiver.png\" alt=\"rdt2.2-receiver\"><br></li>\n</ol>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Lossy-Channel-With-Bit-Errors-rdt3-0\"><a href=\"#Reliable-Data-Transfer-Over-a-Lossy-Channel-With-Bit-Errors-rdt3-0\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0\"></a>Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0</h2><p><em>suppose now that in additions to corrupting bit errors , the underlying channel can lose packet as well.</em> <br></p>\n<p><strong>Questions:</strong><br> </p>\n<ul>\n<li>How to detect packet loss and what to do when packet loss occurs.<br></li>\n</ul>\n<p><strong>Solution:</strong><br></p>\n<ul>\n<li>The use of checksumming sequence numbers ACK packet and retransmissions - the techniques already developed in rdt2.2 allow us to solution the latter concern.<br></li>\n<li>To handling the first concern we require introduce a new protocol  mechanism. The protocol require the sender judiciously choose a time value. If an ACK is not received within this time , the packet is retransmitted .<br></li>\n</ul>\n<p><strong>rdt3.0 data transfer action:</strong><br><br>Because the packet sequence number alternate between 0 and 1, protocol rdt3.0 sometimes known as <strong>alternating-bit-protocol</strong><br><br><em>In the rdt3.0 , the sender will start a timer for packet via start_timer() event</em></p>\n<p><strong>rdt3.0 sender side.<br></strong></p>\n<p><img src=\"rdt3.0-sender.png\" alt=\"rdt3.0-sender\"><br></p>\n<p><img src=\"operation-of-rdt3.0-1.png\" alt=\"rdt3.0-operation-of-data-transfer-1\"><br></p>\n<p><img src=\"operation-of-rdt3.0-2.png\" alt=\"rdt3.0-operation-of-data-transfer-2\"><br></p>\n<p><strong>Question:</strong></p>\n<ul>\n<li>How long must the sender wait to be certain that something has been lost ?<br></li>\n</ul>\n<h1 id=\"3-4-2-Pipelined-Reliable-Data-Transfer-Protocols\"><a href=\"#3-4-2-Pipelined-Reliable-Data-Transfer-Protocols\" class=\"headerlink\" title=\"3.4.2 Pipelined Reliable Data Transfer Protocols\"></a>3.4.2 Pipelined Reliable Data Transfer Protocols</h1><p><strong>Question:</strong><br></p>\n<ul>\n<li>Although the rdt3.0 is a functionally correct protocol . But it’s unlikely that anyone would happy with its performance . In fact , rdt3.0 has a dismal sender utilization. (more detail of calculation we can read the textbook)<br></li>\n</ul>\n<p><strong>Solution:</strong><br><br>To solution this performance problem is simple: Rather than operate in a stop-and-wait-protocol, the sender is allowed to send multiple packet without waiting for acknowledgment as illustrated figure below.<br></p>\n<p><img src=\"Stop-and-wait-versus-pipelined-protocol.png\" alt=\"Stop-and-wait-versus-pipelined-protocol\"></p>\n<p><em>Since the many in-transit sender to receiver packets can be visualized as filling pipeline , the technique is known as pipelining</em></p>\n<p><strong>pipelining has the following consequence for reliable data transfer protocols:</strong><br></p>\n<ul>\n<li>The range of sequence number must be increated . Since we require to send mutiple packet , each packet need a unquie sequence number.</li>\n<li>The sender and receiver side of protocol must has to buffer more than one packet.</li>\n<li>The range of sequence number and buffering requirements will depend on the manner in which data transfer protocol responds to lost, corrupt and overlay delayed packets. Two basic approaches toward pipelined errors recovery can be identified :<strong>GO-Back-N and Selective repeat</strong>.<br></li>\n</ul>\n<h2 id=\"3-4-3-Go-Back-N-GBN\"><a href=\"#3-4-3-Go-Back-N-GBN\" class=\"headerlink\" title=\"3.4.3 Go-Back-N(GBN)\"></a>3.4.3 Go-Back-N(GBN)</h2><p>In the GBN protocol, the sender allowed to send mutiple packet without waiting for acknowledgment, but is constrained to have no more than some maximum allowable number N , the N often be referred as the window size, the Go-Back-N(GBN) protocol often be referred as sliding-window-protocol.<br></p>\n<p><em>We maybe have questions that why we limit the window size N instead of unlimited</em><br><br>About this question we will discuss in the flow control and congestion control sections.<br></p>\n<p><strong>Define</strong><br><br><img src=\"Sender&#39;s-view-of-sequence-numbers-in-the-Go-Back-N.png\" alt=\"Sender&#39;s-view-of-sequence-numbers-in-the-Go-Back-N\"><br></p>\n<ul>\n<li><strong>Base:</strong> The sequence number of the oldest unacknowledgment .</li>\n<li><strong>nextseqnum :</strong> The smallest unused sequence number.</li>\n<li><strong>[0 ~ base-1]:</strong> corresponds to have already been transmitted and acknowledged.</li>\n<li><strong>[base ~ nextseqnum-1]:</strong> corresponds to have already been sent but not yet acknowledge.</li>\n<li><strong>[nextseqnum ~ base+N-1]:</strong> can be used to send packet when the data arrived from upper layer.<br><br><strong>[base+N ~ ]:</strong> can not be used until an unacknowledged packet has been acknowledged. </li>\n</ul>\n<p><em>Note that the GBN protocol packet containing fixed-length-sequence-number-filed ,in TCP protocol ,the length of sequence-number-filed is 32 bits, the range of sequence number is [0 ~ $2^{32} -1$ ] different to rdt3.0 that ranger of sequence number is [0 ~ 1],and the length of sequence-number-filed is 1 bits.</em><br></p>\n<p><strong>GBN data transfer action:</strong><br></p>\n<ol>\n<li>receiver side <br></li>\n</ol>\n<p><img src=\"GBN&#39;s-FSM-receiver.png\" alt=\"GBN&#39;s-FSM-description-receiver\"><br></p>\n<p><strong>The GBN’s sender must respond to three type of event.</strong><br></p>\n<ul>\n<li><strong>Invacation from above:</strong> When rdt_send() be invoked from the upper layer. The sender requires to check the window whether the window has full. If the window is not full , the data from above can make be packet and sent . The sender will update appropriately some variables. If the window is full, the sender will refuse data and indication the upper layer that the window has full. The upper layer will resend it again before a period of time.<br></li>\n<li><strong>Receipt of an ACK:</strong> Noting function <code>base = getacknum(rcvpkt)+1</code> because the receiver use <strong>cumulative acknowledgment</strong>(we will discuss in receiver side ), for example , we can know packet of sequence number low than n has received correctly in the receiver side. When the sender side got the packet of sequence number n. Then we can update <code>base = n+1</code> and (stop_timer()orstart_timer) according to corrusp<br></li>\n<li><strong>A timeout event:</strong> If timeout occurs , the sender will resends all packets that previously sent but have not yet been acknowledgment . Namely<code>udt_send(sndpkt[base])....udt_send(sndpkt[nextseqnum-1])</code><br></li>\n</ul>\n<p><strong>The GBN’s receiver must respond to event:</strong><br><br><em>In the GBN protocol , the receiver will discard out-of-order packets , for example the receiver expected sequence number is n , but the receiver receive a packet containing sequence number n+1 or more larger than n , the receiver will discard this packet and resend the packet containing expected sequence number to sender via udt_send(sndpkt) event. So the receiver be called use <strong>cumulative acknowledgment</strong>.</em> <br></p>\n<p><img src=\"GBN-in-operation.png\" alt=\"GBN-in-operation\"><br></p>\n<p><strong>Note that the GBN protocol sender must be maintain The upper and lower bound of its window and position of nextseqnum within this window. The receiver must be maintain the sequence number of next in-order-packet.(expectedseqnum)</strong><br></p>\n<p>How does GBN protocol work we can see this video: <a href=\"https://www.youtube.com/watch?v=9BuaeEjIeQI\">GBN</a><br></p>\n<h2 id=\"3-4-4-Selective-Repeat-SR\"><a href=\"#3-4-4-Selective-Repeat-SR\" class=\"headerlink\" title=\"3.4.4 Selective Repeat (SR)\"></a>3.4.4 Selective Repeat (SR)</h2><p><strong>Question:</strong><br>Although GBN protocol avoiding the utilization problem of rdt3.0 , The GBN itself also has a performance problem . When the window size and bandwidth-delay both large, many packets can be in pipeline. If have a packet lost in the transmission will cause a large number of packets to retransmission.<br></p>\n<p><strong>Solution:</strong><br>As the name suggests, <strong>selective repeat protocol</strong> avoid unnecessary retransmission by having the sender retransmit those packets that it suspects were received in error(that were lost or corrupted ) at the receiver.<br></p>\n<p><img src=\"Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png\" alt=\"Selective-repeat(SR)-sender-and-receiver-views-of-sequence-number-space.png\"><br></p>\n<p><strong>Difference to GBN protocol, SR protocol has window in the receiver side like the figure above. <br></strong><br><em>The receiver will acknowledgment a correctly received packet whether or not it is in-order. Out-of-order packet will be buffering until any missing packet (that is lower than sequence number has buffered) are received. When the packet of sequence number (rcv_base) is received , the receiver will deliver a batch of packet that <strong>begin with sequence number (rcv_base) and end with smallest unreceived sequence number minus one</strong> to upper layer. Then number rcv_base increase <br></em></p>\n<p><strong>SR protocol data transfer action:</strong><br></p>\n<ol>\n<li>sender side <br></li>\n</ol>\n<ul>\n<li><strong>Data received from above:</strong> The sender will check the next sequence number (nextseqnum) whether or not larger than window size <code>If(nextseqnum&gt;base+N)</code>.If the nextseqnum is within the window, the sender will make data into packet and send it to receiver. Otherwise the sender will either buffered or returned to upper layer for later transmission as in GBN.<br></li>\n<li><strong>Timeout:</strong>  Different to GBN protocol , in the SR protocol , each packet has its own logical timer since only a single packet will be transmitted on timeout.<br></li>\n<li><strong>ACK received:</strong> If an ACK packet within the window is received , the SR sender will marks that packet as having been received. Until the packet containing sequence number (send_base) is received . Then the sender will move the send_base forward to the unackknowledgment packet with smallest sequence number.<br></li>\n</ul>\n<ol>\n<li>receiver side <br></li>\n</ol>\n<ul>\n<li>Packet with sequence number in [rcv_base,rcv_base+N-1] is correctly received whatever whether or not in-order. Then the packet is buffered at the receiver . If the packet containing sequence number (rcv_base) is received. The receiver will deliver the packet that begins with rcv_base and end with the smallest unreceived sequence number minus one to the upper layer. Then move rcv_base forward to the smallest unreceived sequence number.<br></li>\n<li>Packet with sequence number in [rcv_base-N,rcv_base] is correctly received . Occur this situation cause is a ACK with sequence number in [rcv_base-N,rcv_base] maybe lost or corrupted or bandwidth-delay ,then timeout the sender retransmission the packet , In this case , an ACK must be generated and resend this ACK to sender, even though this is a packet that has previously acknowledgment.<br></li>\n<li>Otherwise : Ignore this packet.</li>\n</ul>\n<p><img src=\"SR-operation.png\" alt=\"SR-operation.png\"><br></p>\n<p><strong>Disadvantages of SR protocol</strong><br><br><em>The two case could happen when the window size too-large and the range of sequence number too-small</em><br><br>The window size is 3 and the range of sequence number is 4 in the example <br></p>\n<p><img src=\"SR-receiver-dilemma-a.png\" alt=\"SR-receiver-dilemma-a.png\"><br></p>\n<p><strong>In this case , the old packet 0 is recognized as new packet 0, packet confuse</strong></p>\n<p><img src=\"SR-receiver-dilemma-b.png\" alt=\"SR-receiver-dilemma-b.png\"><br></p>\n<p><strong>In this case , packet 3 is lost , the rcv_base = 3 , The packet 0 containing new data will be recognized as old packet 0 when the sender send the new packet 0. Because <code>0&lt; [3,3+3-1]</code>. Packet confuse.</strong><br></p>\n<p><em>How small window size must be ?</em><br><br><strong>Answer is window size must be less than or equal to a half of sequence number space for SR protocol.<br></strong></p>\n<p>How does SR protocol work we can see this video : <a href=\"https://www.youtube.com/watch?v=Cs8tR8A9jm8\">SR</a></p>\n<h1 id=\"3-5-Connection-Oriented-Transport-TCP\"><a href=\"#3-5-Connection-Oriented-Transport-TCP\" class=\"headerlink\" title=\"3.5 Connection-Oriented Transport:TCP\"></a>3.5 Connection-Oriented Transport:TCP</h1><h2 id=\"3-5-1-The-TCP-connection\"><a href=\"#3-5-1-The-TCP-connection\" class=\"headerlink\" title=\"3.5.1　The TCP connection\"></a>3.5.1　The TCP connection</h2><p>The TCP “connection” is not an end-to-end TDM or FDM circuit as in a circuit switch network. Nor it’s a virtual circuit , only as the connection state reside entirely in two end system.<br><br>The TCP connection provide <strong>full-duplex service</strong>, namely , Application layer data of two end system  can sent to other side.</p>\n<p><strong>The TCP connection always point-of-point that is between a single sender and a single receiver.</strong><br><br>The TCP connection established by <strong>three-way-handshake</strong> , the first two handshake by send the segment that can not carry payload, the third handshake by send the segment that can carry payload.<br></p>\n<p>The TCP connection also always point-to-point , that is a singer sender and a single receiver.<br><br><strong>The TCP connection has buffer in two end system. The data is passed through socket then the TCP directs this data to connection’s sender buffer then the TCP will grab chuck of data from send’s buffer and pass the data to network layer. As shown in figrue below.</strong><br><br><img src=\"TCP-sender-and-receiver-buffer.png\" alt=\"TCP-sender-and-receiver-buffer\"><br></p>\n<p><strong>Two terminology</strong><br></p>\n<ul>\n<li>MSS(Maximum segment size): The maximum amount of application data can place in segment.<br></li>\n<li>MTU(Maximum transmission unit): The largest frame size (application data plus TCP/IP header line)<br> </li>\n</ul>\n<p><strong>In Summary</strong><br><br><em>The TCP connection consist of sender’s buffer and sender’s variables and socket connection to process in sender’s host and socket connection to process in receiver’s host and receiver’s variables and receiver’s buffer.</em><br> <em>As mentioned early TCP connection only has two state reside in the sender host and receiver host , no buffer and variable allocated in network element between two end system host (router and switch and repeater)<br></em></p>\n<h2 id=\"3-5-2-TCP-Segment-Structure\"><a href=\"#3-5-2-TCP-Segment-Structure\" class=\"headerlink\" title=\"3.5.2 TCP Segment Structure\"></a>3.5.2 TCP Segment Structure</h2><p><img src=\"TCP-Segment-structure.png\" alt=\"TCP-segment-structure\"><br></p>\n<ul>\n<li><strong>Source and destination port numbers</strong>:corresponding to sender socket and receiver socket.<br></li>\n<li><strong>Checksum field</strong>: for detecting the corrupt whether occurred during the traveling as like UDP checksum field.<br></li>\n<li><strong>The 32 bits sequence number field</strong>: The sequence number is the byte number of first byte of data in the TCP packet sent (also called TCP segment)</li>\n<li><strong>The 32 bits acknowledgment numbers</strong>: The next packet that receiver expects to receive.</li>\n<li><strong>The 16-bits receiver number</strong>: Used for flow control , indicate the window size N that we discuss in the GBN and SR protocol.<br></li>\n<li><strong>The 4-bits header length field</strong>: indicates how long the header is, in 32 bit “words”. The minimum value is “5” which would be 160 bits, or 20 bytes. The maximum length is 15, which would be 480 bits, or 60 bytes</li>\n<li><strong>The optional and variable-length optional field</strong>: Used  when  a  sender  andreceiver negotiate the maximum segment size (MSS) or as a window scaling fac-tor for use in high-speed networks. A time-stamping option is also defined. </li>\n<li><strong>The flag field contain 6 bits</strong>:<ul>\n<li>ACK bit : Used to indicate that value carried in the acknowledgment field is valid .</li>\n<li>RST,SYN,FIN bit: Used for connection setup and teardown .</li>\n<li>PSH bit: Used to indicate the receiver should pass the data to upper layer immediately.</li>\n<li>URG bit: I don’t know what this means</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Sequence-number-and-acknowledgment-number\"><a href=\"#Sequence-number-and-acknowledgment-number\" class=\"headerlink\" title=\"Sequence number and acknowledgment number\"></a>Sequence number and acknowledgment number</h3><p>Cause These two fields are critical part of TCP connection , We discuss more detail about these.<br></p>\n<p><em>All byte in TCP connection are numbered beginning at a <strong>randomly choose</strong> initial sequence number(ISN) , The SYN packets consume one sequence number , so actual data begin at ISN+1</em><br></p>\n<p><strong>For example The TCP connection establish as shown in figure below</strong><br><br><img src=\"TCP-connection.png\" alt=\"TCP-connection-establish\"><br></p>\n<ul>\n<li>Step 1: The client want to establish connection with server , it will send a packet contain SYN bit and randomly choose initial sequence number (Client_isn) to sever.(no payload)<br></li>\n<li>Step 2: The server has received this packet then response a packet contain initial sequence number (server_isn) and SYN bit and acknowledgment number (Client_isn+1) to Client.(no payload)<br></li>\n<li>Step 3: The connection established success when the Client has received the response of packet, Client then change the SYN to 0 and send the packet contain sequence number client_isn+1 and acknowledgment number server_isn+1 and actual data (payload) to server.<br> </li>\n</ul>\n<h2 id=\"3-5-3-Round-Trip-Time-Estimation-and-Timeout\"><a href=\"#3-5-3-Round-Trip-Time-Estimation-and-Timeout\" class=\"headerlink\" title=\"3.5.3 Round-Trip Time Estimation and Timeout\"></a>3.5.3 Round-Trip Time Estimation and Timeout</h2><p>TCP like rdt3.0 use timeout/retransmission mechanism to recover from lost segment.<br><br>Although conceptually simple , many subtle issue arise when we implement timeout/retransmission mechanism in actual protocol such as TCP protocol.<br><br><strong>Questions:</strong></p>\n<ul>\n<li>How larger time is timeout .<br> </li>\n<li>How estimating the round-trip-time between the sender and receiver<br></li>\n<li>Should a timer be associated with each and every unacknowledgment packet?<br></li>\n</ul>\n<h3 id=\"Estimating-The-Round-Trip-Time\"><a href=\"#Estimating-The-Round-Trip-Time\" class=\"headerlink\" title=\"Estimating The Round-Trip-Time\"></a>Estimating The Round-Trip-Time</h3><ul>\n<li><strong>SampleRTT</strong>: Represent the amount of time between when the packet sent from the sender (that is pass the packet to the network layer) and when the acknowledgment segment has received.<br><br><em>The TCP does not estimate stampleRTT for every single packet(segment), Instead of TCP implementation take only one sampleRTT measurement at a time</em></li>\n<li><strong>EstimatedRTT</strong>: Because different sampleRTT value will be fluctuate due to congestion in the routers and to varying load on the end systems. The sampleRTT is atypical , In order to estimate a typical RTT ,it is therefore natural to take some sort of avenger of sampleRTT . The TCP maintains an avenger called <strong>EstimatedRTT</strong>.<br><br><code>EstimatedRTT = (1- a) * EstimatedRTT + a * SampleRTT</code><br><br>The value of <code>a</code> typically choose 0.125.<br><br><code>EstimatedRTT = 0.875 * EstimatedRTT + 0.125 * sampleRTT</code><br><br><img src=\"RTT-sample-and-RTT-estimates.png\" alt=\"RTT-sample-and-RTT-estimates\"><br></li>\n<li><strong>DevRTT</strong>: DevRTT as an estimate of how much sampleRTT typical deviates from EstimatedRTT.<br><br><code>DevRTT = (1-b) * DevRTT + b * |sampleRTT - EstimatedRTT|</code><br><br>The value of <code>b</code> typical choose 0.25.<br><br><code>DevRTT = 0.75 * DevRTT + 0.25 * |sampleRTT - EstimatedRTT|</code><br></li>\n<li><strong>Timeout Interval</strong>: Clearly The timeout interval should be greater than or equal to EstiamtedRTT or unnecessary retransmission will be sent. But the timeout should not be too larger than EstimatedRTT . Otherwise when the segment has lost , The TCP would not retransmission quickly , leading to large transfer delay.<br><br><code>TimeoutInterval = EstimatedRTT + 4 * DevRTT</code><br><br>An <strong>initial</strong> Timeoutinterval value of 1 second is recommended </li>\n</ul>\n<h2 id=\"3-5-4-Reliable-Data-Transfer\"><a href=\"#3-5-4-Reliable-Data-Transfer\" class=\"headerlink\" title=\"3.5.4 Reliable Data Transfer\"></a>3.5.4 Reliable Data Transfer</h2><p>TCP is best categorize as a hybrid of GBN and SR protocol.<br></p>\n<p><strong>In the receiver(server) side:</strong><br><br>In TCP protocol ,server use <strong>cumulative ACK</strong> as like GBN protocol does, server also buffer out-of-order packet as like SR protocol. <br><br><strong>In the sender(client)  side:</strong><br><br>Since TCP use cumulative ACK, If the client has received ACK with acknowledgment number 120, just mean the server has received all byte lower than 120<br><br><em>For example: The server sends the ACK with acknowledgment number is 120, namely, server expect next sequence number is 120, the client got the ACK packet, then sent two packets with sequence number 120,130 to the server , unfortunately, the packet with sequence number 120 is lost, the server received the out-of-order packet with sequence number 130, then, the server buffers the out-of-order packet as like SR protocol does and sent ACK with acknowledgment number 120 back to the client , here is different to SR protocol, as like GBN protocol does.</em></p>\n<h3 id=\"TCP-Retransmission-and-Doubling-the-timeout-interval\"><a href=\"#TCP-Retransmission-and-Doubling-the-timeout-interval\" class=\"headerlink\" title=\"TCP Retransmission and Doubling the timeout interval\"></a>TCP Retransmission and Doubling the timeout interval</h3><p>Different from GBN and SR protocol, TCP only retransmits the not-yet-acknowledgment segment with the smallest sequence number when the timeout occurs, then restart timer with doubling timeout interval.<br></p>\n<p><em>For example : Suppose the timeoutinterval associated with oldest not-yet-acknowledgment segment is 0.75 sec when the timer expires, TCP will retransmit this segment and set new expiration time to 1.5 sec , If the timer expires again 1.5 sec later , TCP will retransmit this segment and set new expiration time to 3.0 sec, however whenever the timer is started after either of two other events (that is ACK received and data received from application above), the timeoutinterval is derived from the most recent value of EstimatedRTT and DevRTT</em><br></p>\n<p><strong>Qusetion: Why we need to doubling timeout interval.</strong><br><br>Because, in times of congestion , the segment maybe dropped or suffer long queues delay, If we resent the packet persistently , the congestion may get worse . Instead TCP should acts more politely with earn sender retransmit after long and long interval.<br></p>\n<p><strong>TCP Fast Retransmit</strong><br><br>One of problem with timeout-triggered retransmissions is that the timeout period relatively long , when a segment is lost, this long timeout period will force sender to delay this segment retransmit thereby increasing the end-to-end delay. So we need to fast retransmits mechanism.<br></p>\n<p>Before discuss TCP Fast Retransmit , we should know how does ACK generate .<br><br><strong>TCP ACK Generation Recommendation</strong><br><img src=\"TCP-ACK-Generation-Recommendation.png\" alt=\"TCP-ACK-Generation-Recommendation\"><br><br>The duplicate ACK is indicated that this segment has been lost, when the sender has received this same segment three time . TCP will perform fast retransmit , send this segment to receiver again.<br><br><em>For example : The sender send a large number of segment back to back , if one segment is lost , there will likely be many back-to-back duplicate ACK, if the sender received same duplicate more than three time , The sender will be perform fast retransmit, As shown in figure below.</em><br></p>\n<p><img src=\"Fast-retransmit.png\" alt=\"Fast-retransmit\"></p>\n<p><strong>Code snippet of Fast retransmit</strong><br><br><img src=\"Code-snippet-of-fast-retransmit.png\" alt=\"Code snippet of Fast retransmit\"><br></p>\n<h2 id=\"3-5-5-Flow-Control\"><a href=\"#3-5-5-Flow-Control\" class=\"headerlink\" title=\"3.5.5 Flow Control\"></a>3.5.5 Flow Control</h2><p>Flow control is speed-matching-service that be used to matching the sender sending speed and the receiver’s application reading speed.<br><br>If the application reading receiver’s buffer at slow speed , the sender can very easily overflow the connection’s receive buffer by sending too much data and too quickly.<br> </p>\n<p>TCP provide the flow control by having the sender maintain a variable called <strong>receive window</strong>, Because the TCP is full-duplex , the sender at each side of the connection maintain a distinct receive window.<br></p>\n<p>Suppose the host A send segments to host B over TCP connection, host B allocate a buffer to this connection.<br><br>Let me define some variables for host B and host A.<br><br><strong>For Host B (server)</strong><br></p>\n<ul>\n<li>RcvBuffer : the size of receive window(buffer) size of host B.<br></li>\n<li>LastByteRead : the number of the last byte in the data stream read from receive buffer by application in B.<br></li>\n<li>LastByteRcv : the number of the last byte in the data stream has been received from network and has been placed in receive buffer.<br></li>\n<li>rwnd : the amount of space room in the buffer  <code>rwnd = Rcvbuffer - [LastByteRead - LastByteRcv]</code> <br><br><img src=\"TCP-RcvBuffer.png\" alt=\"RcvBuffer\"><br><br><strong>For Host A (Client)</strong> <br></li>\n<li>LastByteSent : the number of last byte in the data stream has sent at the sender side .<br></li>\n<li>LastByteAcked : the number of last byte in the data stream has ACKed at the sender side . <br></li>\n</ul>\n<p>Host B and host A maintain those variables that we mention above.<br></p>\n<p><strong>How to control the flow through these information.</strong><br><br>The Host B tells Host A that how much space room it has in the connection buffer by place the value of rwnd in receive window field of ACK segment.<br><br>The host A just need to keep the <code>LastByteSent - LastByteAcked</code> less than <code>rwnd</code> (,LastByteSent - LastByteAcked &lt;= rwnd`), the sender can assure that it is not overflowing the receive buffer at the Host B.<br></p>\n<p>If the receive buffer has filled at the Host B, the Host A will stop sending data to Host B, instead, Host A will send one bit to Host B for keeping the connection until the Host B has space room again. <br></p>\n<h2 id=\"3-5-6-TCP-Connection-Manage\"><a href=\"#3-5-6-TCP-Connection-Manage\" class=\"headerlink\" title=\"3.5.6 TCP-Connection-Manage\"></a>3.5.6 TCP-Connection-Manage</h2><p><strong>Establish TCP connection</strong><br><br><img src=\"TCP-connection-manage-1.png\" alt=\"TCP-Connection-Manage-1\"><br><br><strong>Finish TCP connection</strong><br><br><img src=\"TCP-connection-manage-2.png\" alt=\"TCP-Connection-Manage-2\"><br><br><strong>TCP states at the sender side</strong><br><br><img src=\"TCP-connection-manage-3.png\" alt=\"TCP-Connection-Manage-3\"><br><br><strong>TCP states at the receiver side</strong><br><br><img src=\"TCP-connection-manage-4.png\" alt=\"TCP-Connection-Manage-4\"><br></p>\n<p><strong>The SYN flood attack</strong><br><br><em>we can see detail in the textbook</em><br></p>\n<h2 id=\"3-6-Principles-of-Congestion-control\"><a href=\"#3-6-Principles-of-Congestion-control\" class=\"headerlink\" title=\"3.6 Principles of Congestion control\"></a>3.6 Principles of Congestion control</h2><h3 id=\"3-6-1-The-Causes-and-the-costs-of-Congestion\"><a href=\"#3-6-1-The-Causes-and-the-costs-of-Congestion\" class=\"headerlink\" title=\"3.6.1 The Causes and the costs of Congestion\"></a>3.6.1 The Causes and the costs of Congestion</h3><ul>\n<li><p><strong>Scenario 1: Two sender , a Router with infinite buffer</strong><br><br>Assume the host A and host B have same sending original data rate $\\lambda <em>{in}$ ( application sending original data into socket  by $\\lambda </em>{in}$  ignore the cost of that be encapsulated by TCP/IP header line) and the router throughput capability is $R$<br><img src=\"Congestion-scenario-1-two-connection.png\" alt=\"Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png\"><br></p>\n<p>  <em>The throughput equal to R/2 is consequence of two sender Host A and Host B sharing outgoing link of the router.<br></em><br><img src=\"Congestion-scenario-1-throughput-and-delay.png\" alt=\"Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png\"><br></p>\n<p>  <em>We can see the sender sending rate more approaches $R/2$ , delay become more larger and larger. The delay become to infinite when the $\\lambda_{in}$ larger than $R/2$<br></em></p>\n<p>  <strong>Here , we found one cost of congestion — large queue delay are experienced as the packet-arrived rate near the link throughput capability.<br></strong></p>\n</li>\n<li><p><strong>Scenario 2: Two Senders and a Router with Finite Buffers</strong><br></p>\n<p>  The $\\lambda<em>{in}$ is denoted application layer sending the original data into socket by $\\lambda</em>{in}$ bytes/sec.<br><br>  The $\\lambda’<em>{in}$ is denoted transfer layer sending segment into network by $\\lambda’</em>{in}$ bytes/sec (containing original data and retransmited data).<br><br>  The Router throughput capacity is $R$ bytes/sec.<br><br><img src=\"Scenario-2-two-hosts.png\" alt=\"Chapter3-Transport-Layer/Scenario-2-two-hosts.png\"><br><br><strong>a.</strong> The Host A and Host B is able to somehow (magically) determine whether or not the buffer is free in the router . sender only sends data only has free buffer . In this case  $\\lambda<em>{in}$ equal to $\\lambda’</em>{in}$, didn’t occur packet loss. This case is shown as figure.a below <br><br><strong>b.</strong> The Host A and Host B may set a larger enough timeout can determine the pakect has been lost , then sender only retransmit packet that is determinded has been lost. This case is shown as figure.b below, we can see the $0.5R$ units of data transmitted . $0.333R$ bytes is original data and $0.166R$ bytes is retransmitted data<br><br><strong>we can here see another cost of congestion is the sender must perform retransmit packet in order to compensate for dropped packet due to buffer overflow.</strong><br><br><strong>c.</strong> The Host A and Host B may set a small timeout interval (or in face of large delay), the sender retransmit prematurely and retransmit packet that have been delay in queue but not yet lost. The original data and retransmited data both may reach the receiver , the receiver will discard the copy of original data . This case is shown as figure.c below <br><br><strong>we can here see the third cost of congestion — unneeded retransmissions by sender in face of large delay may cause router to use it link bandwish to forward unneeded copies of packet</strong><br><img src=\"Scenario-2-performance.png\" alt=\"Chapter3-Transport-Layer/Scenario-2-performance.png\"><br></p>\n</li>\n<li><strong>Scenario 3 Four sender and Router with Finite Buffer and Multihop Paths</strong></li>\n</ul>\n<p><img src=\"Scenario-3-Four-senders.png\" alt=\"Chapter3-Transport-Layer/Scenario-3-Four-senders.png\"><br><br>In this case the A-C connection share route R2 with B-D connection. Consider The host A send data to host C and host B send data to host D both at the same time . The data of host A arrive router R2 with R bytes/sec i , The data of Host B arrive router R2 with $\\lambda$ , the Host A and Host B need to compare for the free buffer of router R2, if the $\\lambda &lt;&lt; R$ , nothing going happen , data will safely arrive in destination host, but if the $\\lambda &gt;&gt; R$ (the $\\lambda$ extremely large) , the router will be filled immediately by data of host B , the data of host A will lost because of buffer overflow and that work done by router A will be wasted.<br></p>\n<p><img src=\"Scenario-3-performance.png\" alt=\"Chapter3-Transport-Layer/Scenario-3-performance.png\"><br><br><strong>We can see the fourth cost of dropping the packet due to congestion — when a packet is drop along a path, the transmission capacity that was used at each of upstream link to forward that packet to this point at which it is dropped end up having been wasted.</strong><br></p>\n<h3 id=\"3-6-2-Approach-to-Congestion-Control\"><a href=\"#3-6-2-Approach-to-Congestion-Control\" class=\"headerlink\" title=\"3.6.2 Approach to Congestion Control\"></a>3.6.2 Approach to Congestion Control</h3><p><strong>Two kind of Congestion control way</strong><br></p>\n<ul>\n<li><strong>End-to-End Congestion Control</strong></li>\n<li><strong>Network-assisted Congestion Control:</strong> The Network (router) provide the feedback to sender indicate the congestion state .<strong>Two feedback way for congestion control.</strong><br><ul>\n<li>Direct feedback: The router direct inform the sender via send choke packet.<br></li>\n<li>The router mark/updata in a packet flowing from sender to receiver to indicate the congestion. Upon recipt of a marked packet , the receiver notifies the sender congestion indication .<br></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"Two-feedback-way.png\" alt=\"Chapter3-Transport-Layer/Two-feedback-way.png\"></p>\n<h3 id=\"3-6-3-Network-Assisted-ATM-ABR-Congestion-Control\"><a href=\"#3-6-3-Network-Assisted-ATM-ABR-Congestion-Control\" class=\"headerlink\" title=\"3.6.3 Network Assisted ATM ABR Congestion Control\"></a>3.6.3 Network Assisted ATM ABR Congestion Control</h3><p><strong>This section we can learn by textboot</strong><br></p>\n<h2 id=\"3-7-TCP-Congestion-Control-End-To-End-Congestion-Control\"><a href=\"#3-7-TCP-Congestion-Control-End-To-End-Congestion-Control\" class=\"headerlink\" title=\"3.7 TCP Congestion Control (End-To-End Congestion Control)\"></a>3.7 TCP Congestion Control (End-To-End Congestion Control)</h2><p>This approach (The TCP Congestion Control Mechanism )taken by TCP is to have each sender limit the rate at which its sends traffic into its connection as a function of perceive network congestion. How to perceive the congestion ? we will discuss below. <br><br>This approach requires senders keep track of an additional variable , <strong>the congestion window</strong> that is denoted <strong>cwnd</strong> [different to <strong>receive window(rwnd)</strong> at flow control]<br><br>The congestion window imposes an constraint on the rate at which a TCP sender can send into the network.<br><br><code>The unacknowledged data = LastByteSent - LastBystAck &lt;= min&#123; cwnd , rwnd&#125;</code></p>\n<ul>\n<li><strong>In order to focus to Congestion Control , we assume the receive window is large enough that we can ignore it.</strong><br></li>\n<li><strong>We also assume the sender always has data to send.</strong><br></li>\n<li><strong>We define the “loss event” at a TCP sender as the ocurrence of either a timeout or recipt of three duplicate ACK from the receiver.<br></strong></li>\n</ul>\n<p><strong>How congestion is detected ?.</strong><br><br><em>In the TCP congestion mechanism, The ACK is used to perceive the network congestion situation, The congestion window is used to constrain sent data rate. If ACK is received quickly, the TCP will increase the sender congestion window size quickly. If ACK is received slowly, the TCP will increase the sender congestion window size slowly. If “loss event” occurred (indicate Netwok congestion ),　the TCP will take some measures to reduce the congestion window size<br></em></p>\n<p><strong>Give a overview of TCP congestion control, Now ,let me see more detail about TCP congestion-control algorithm</strong><br></p>\n<p>The TCP congestion-control algorithm has three major components:</p>\n<ul>\n<li><strong>Slow start</strong></li>\n<li><strong>Congestion avoidance</strong></li>\n<li><strong>Fast recovery</strong></li>\n</ul>\n<h3 id=\"Slow-Start\"><a href=\"#Slow-Start\" class=\"headerlink\" title=\"Slow Start\"></a>Slow Start</h3><p>When a TCP connection begin . the value of cwnd typically initialized to a small value of 1 MSS (maximum segment size) resulting in an initial sending rate of roundly MSS/RTT. For example , The MSS equal to 500 bytes , the RTT equal to 200 msec , the resulting inital sending rate is only roundly 20 kbps.<br><br><strong>If each ACK that is sent within RTT can be received within the same RTT. The TCP is doubling the value of cwnd. Namely increase the value of cwnd by a single MSS every ACK within the same RTT</strong><br><br>For example, the initial value of cwnd is 1 MSS, the sender is sending 1 segment into the network within an RTT . when ACK of this segment is received at the sender within the same RTT  , the TCP is doubling the value of cwnd that is to say cwnd become to 2 MSS, the sender can send two-segment within RTT right now. If these two ACK of segments is received at the sender within the same RTT  , the cwnd is doubling to 4 MSS.<br><br><strong>Thus the TCP send rate start slow , but grow exponentially during the slow phase.</strong><br><br><img src=\"Slow-Start.png\" alt=\"Slow-Start\"> <br><br><strong>When should this exponentail growth end?</strong></p>\n<ul>\n<li><strong>The first way:</strong> When timeout event ocurred , The TCP will set the value of cwnd back to 1 MSS begin slow start process anew, and <em>set a new state variable <strong>ssthresh</strong> (that is “Slow Start Threashold”) to $cwnd/2$</em></li>\n<li><strong>The second way:</strong> When the $cwnd \\geq ssthresh$ ocurred , the slow start end and turn into congestion aviodance mode.</li>\n<li><strong>The third way:</strong> When the thripe duplicate ACK is detected , the slow start end and turn into fast recovery mode, perform fast retransmit.</li>\n</ul>\n<h3 id=\"Congestion-Avoidance\"><a href=\"#Congestion-Avoidance\" class=\"headerlink\" title=\"Congestion Avoidance\"></a>Congestion Avoidance</h3><p>On entry to the Congestion-Avoidance state , the value of cwnd is approximately half its value when congestion was last encountered , that is to say , the congestion could be just around the corner.<br><br><strong>Thus , rather than doubling the value of cwnd every RTT. TCP adopt more conservative approach and increase the value of cwnd by just a single MSS every RTT</strong></p>\n<p><strong>The several events should do in the Congestion Avoidance state.</strong><br></p>\n<ul>\n<li>The TCP sender increases the value of cwnd by $MSS\\cdot(\\frac{MSS}{cwnd})$ bytes (here cwnd is constant) when ever a new Acknowledgment arrives. For example the cwnd equal to 500 bytes and the MSS equal to 50 bytes, the sender is sending 10 segment within an RTT . Thus the TCP sender is increasing the value of cwnd by $5$ bytes when ever a new Acknowledgment arrives.</li>\n<li>When the timeout occurred , The TCP sender is set the value of cwnd back to $1$ MSS and the value of ssthresh is updated to half the value of cwnd , end up turn into slow start mode .<br></li>\n<li>When the thripe duplicate Acknowledgment is received . The sender is seting $ssthresh =\\frac{cwnd}{2}$ and $cwnd = ssthresh + 3 \\ast MSS$,then turn into fast recovery mode.</li>\n</ul>\n<h3 id=\"Fast-Recovery\"><a href=\"#Fast-Recovery\" class=\"headerlink\" title=\"Fast Recovery\"></a>Fast Recovery</h3><p><strong>The several events should do in the Fast Recovery state</strong><br></p>\n<ul>\n<li>The value of cwnd increased by $1$ MSS for every duplicate ACK received for the missing segment that caused TCP enter the fast-recovery state.</li>\n<li><p>When the ACK arrived for the missing segment , the sender set $cwnd = ssthresh$ and turn into congestion avoidance state .</p>\n</li>\n<li><p>If the timeout occurred , the sender  set the value of ssthresh to half the value of cwnd and set the value of cwnd to $1$ MSS, then turn into slow start state.<br><br><strong>The relationship between the three kinds of state</strong><br><br><img src=\"The-three-state-of-congestion-algorithm.png\" alt=\"The-three-state-of-congestion-algorithm.png\"><br><br><strong>Congestion window size changes along with time Ignoring theinitial slow-start period when a connection begins and assuming that losses are indi-cated by triple duplicate ACKs rather than timeouts.<br></strong><br><img src=\"Congestion-window-size-changes-along-with-time.png\" alt=\"Congestion-window-size-changes-along-with-time.png\"><br></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>Most of content come from Computer-network-A-Top-Down-Approach.</strong></p>\n<h1 id=\"3-4-Principles-of-Reliable-Data-Transfer\"><a href=\"#3-4-Principles-of-Reliable-Data-Transfer\" class=\"headerlink\" title=\"3.4 Principles of Reliable Data Transfer\"></a>3.4 Principles of Reliable Data Transfer</h1><p>it may be corrupt bits , lose packets, packets out of order during the data transfer from client to servers . So . For avoid the data lose or other situation happened When we receive the data at the <strong>Application layer</strong>,we need to build a reliable data transfer protocol.<br><br>In fact , the layer that below the reliable data transfer protocol is unreliable . For example , TCP protocol is reliable data transfer protocol that is implemented top of unreliable (IP) end-to-end network layer.<br><br>we will discuss “build a reliable data transfer protocol above unreliable layer to reliable data transfer” following section below.<br></p>\n<p><img src=\"Reliable-data-tranfer.png\" alt=\"Reliable-data-tranfer\"><br></p>\n<h1 id=\"3-4-1-Building-a-Reliable-Data-Transfer-Protocol\"><a href=\"#3-4-1-Building-a-Reliable-Data-Transfer-Protocol\" class=\"headerlink\" title=\"3.4.1 Building a Reliable Data Transfer Protocol\"></a>3.4.1 Building a Reliable Data Transfer Protocol</h1><p>We now step through a series of protocols , each one becoming more complex until arriving at a flawless reliable data transfer protocol.<br></p>\n<h2 id=\"Reliable-Data-Transfer-over-a-Perfectly-Reliable-Channel-rdt1-0\"><a href=\"#Reliable-Data-Transfer-over-a-Perfectly-Reliable-Channel-rdt1-0\" class=\"headerlink\" title=\"Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0\"></a>Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0</h2><p>We first consider a simple case, in which the underlying channel is completely reliable. We call that protocol <em>rdt1.0</em>. The finite-state-machine (FSM) definitions for the sender and receiver are shown in Figure below.<br><br><img src=\"rdt1.0-finite-state-machine.png\" alt=\"rdt1.0-finite-state-machine\"><br></p>\n<p><strong>rdt1.0 data transferred actions:</strong> <br></p>\n<ol>\n<li>sending side<br></li>\n</ol>\n<ul>\n<li>The sending side simply accepts data from upper layer (application layer) via rdt_send(data) event.</li>\n<li>Creates packets containing the data via the make_pkt(data) event.</li>\n<li>Send the packets to the underlying channel (network layer) via the udt_send(packet) event.</li>\n</ul>\n<ol>\n<li>receiving side <br></li>\n</ol>\n<ul>\n<li>rdt receives packets from underlying channel (network layer) via the rdt_rcv(packet) event.</li>\n<li>Remove the data from the packet via extract(packet,data) event.</li>\n<li>Passes the data up to the upper layer(application layer) via the deliver_data(data).</li>\n</ul>\n<p><strong>In summary of rdt1.0</strong><br></p>\n<p><em>In this simple protocol , these is no difference between a unit of data or packet. Also all packet flow is send from sender to receiver over a reliable prefer channel, So receiver don’t need send feedback to sender (tell the sender ‘I have received the packet’) since nothing can go wrong! Note that we have assume the receiver can receive data as fast as the sender happens to send data, Thus , there is no need for the receiver to ask the sender to slow down.</em></p>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-0\"><a href=\"#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-0\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0\"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0</h2><p>A more realistic model of the underlying channel is one in which bit in the packet may be corrupted , such bit errors typically occur in physical components of network as a packet is transmitted packets , propagated , or buffered.<br><br><strong>we will continue assume for the moment that all transmitted packets are received in the order in which they we sent.</strong></p>\n<p><strong>Question:</strong><br></p>\n<ul>\n<li>The bit of packet may be corrupted , when the packet is transmitted ,propagated,or buffered .<br><br>For example: yourself might dictate a long message over the phone and send to your friends. In typical scenario, the message receiver might say “OK”<br>after he has been heard , understood and recorded. But ! If the message receiver hears a garbled sentence . How to solve this problem?<br></li>\n</ul>\n<p><strong>Solution:</strong><br><br>The message receiver will ask the sender to repeat the garbled sentence.<br><br>The rdt2.0 uses both positive acknowledgments (OK) and negative acknowledgments (“Please repeat that”). These control messages allow the receiver let sender know what have been received correctly , and what have been received error and thus requires repeating.<br><br>In the computer network setting , reliable data transfer protocols base on such retransmission are known as ARQ (Automatic Repeat reQuest) protocols. </p>\n<p>Fundamentally, three additional protocols capabilities are required in ARQ protocol to handle the presence of bit errors.<br></p>\n<ul>\n<li><strong>Error detection :</strong> A mechanism is needed to allow the receiver to detect when bit error have occurred . We can use internet checksum field to achieve this function as UDP did.</li>\n<li><strong>Receiver feedback :</strong> The receiver needs to provide explicit feedback to the sender to let the sender know the receiver’s view of the world. <strong>Positive acknowledgment (ACK) and Negative acknowledgment (NAK)</strong></li>\n<li><strong>Retransmission :</strong> The sender need to repeat send the corrupted packet to receiver.<br></li>\n</ul>\n<p><img src=\"rdt2.0-A-protocol.png\" alt=\"rdt2.0-A-protocol\"><br></p>\n<p><strong>rdt2.0 data transferred actions</strong></p>\n<ol>\n<li>sending side<br></li>\n</ol>\n<ul>\n<li>First of all the protocol state is “Wait from call from above” . The sender will pass data via <em>rdt_send(data)</em> event from upper layer to transfer layer, when the sender wanna to tranfer data.<br></li>\n<li>The sender will create packet(sndpkt) containing the data to be sent along with the checksum filed via <em>sndpkt=make_pkt(data,checksum) event</em>.<br></li>\n<li>Then send the packet(sndpkt）via udt_send(sndpkt) operation to receiver side.<br></li>\n<li>In the end change the protocol state to “Wait for ACK or NAK” for waiting response message from receiver <strong>(In this state ,the sender cannot get more data from upper layer)</strong><br></li>\n<li>The sender will receive the response message and check it when the response message arrived. If the response is ACK (rdt_rcv(rcvpkt)&amp;&amp;isACK(rcvpkt)) , the sender will change the state back, otherwise the sender will resend the sndpkt to receiver via udt_send(sndpkt) event .<br></li>\n</ul>\n<ol>\n<li>receiving side <br><br>The receiving side still only has a state (wait call from below).<br></li>\n</ol>\n<ul>\n<li>The receiver will receive the packet and check it from below layer via <strong>(rdt_rcv(rcvpkt)&amp;&amp;corrupt(rcvpkt)) and (rdt_rcv(rcvpkt)&amp;7notcorrupt(rcvpkt))</strong> event.</li>\n<li>The receiver will make a packet along with NAK and send it back to sender side. If the packet suffer bit errors. </li>\n<li>Otherwise the receiver gets the corrupt packet, it will extract the packet and deliver the data to upper layer via <strong>extract(rcvpkt,data) and deliver_data(data)</strong> event. In the end . The receiver will make a packet along with ACK and send it back to sender via <strong>make_pkt(ACK) and udt_send(sndpkt)</strong><br></li>\n</ul>\n<p><strong>fatal flaw of rdt2.0</strong><br><br>Unfortunately rdt2.0 has a fatal flaw. In particular , we haven’t account for the possibility that the ACK and NAK could be corrupted !<br><br>And more difficulty question is how to recover from errors in ACK and NAK packets..</p>\n<p><strong>Solution for fatal flaw of rdt2.0</strong><br><br>Simply, we just need to retransmit the packet to the receiver when the sender got a corrupted ACK or NAK packets. <br></p>\n<p><strong>This approach , however introduce the duplicates packets into the sender-receiver-channel. The difficulty is receiver can not know whether the arrived packet containing content is retransmitted packet or new packet ?</strong></p>\n<p>A simple solution to this new problem is to add a new filed and have sender number its data packets by putting sequence number into this filed. The receiver then need only check this sequence number to know whether or not the receiver packet is retransmission .<br><br>In the sender side use 0 and 1 sequence numbers represent different  state of packets (new packet and old packet) . The packet containing sequence number 0 and sequence number 1 corresponding to the old packet and new packet, when the sender send packet containing sequence number 0 recent. In contrast ,the packet containing sequence number 0 and sequence number 1 corresponding to the new packet and old packet,when the sender send packet containing sequence number 1 recent. <br></p>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-1\"><a href=\"#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-1\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1\"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1</h2><p><em>rdt2.0 added a sequence number filed called rdt2.1.</em><br></p>\n<p><strong>rdt2.1 data transfer action:</strong></p>\n<p><img src=\"rdt2.1-sender.png\" alt=\"rdt2.1-sender\"><br></p>\n<p><img src=\"rdt2.1-receiver.png\" alt=\"rdt2.1-receiver\"><br></p>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-2\"><a href=\"#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-2\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2\"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2</h2><p><em>We can accomplish the same effect as a NAK via only send ACK .<br><br>Out free NAK reliable data transfer protocol for a channel with bit errors known as rdt2.2.</em><br></p>\n<p>Suppose the sender sends a packet containing sequence number 0, the receiver receives this packet and sends ACK 0 response (containing sequence number 0) to the sender. Sender got this ACK 0 response message and send a new packet containing sequence number 1 to the receiver, at this moment, the receiver that receiver a corrupted new packet, then the receiver will send an ACK of last received correctly packet (ACK 0)to sender side. The sender that receiver the same ACK 0 response twice (that is, receiver duplicate ACK) know that the receiver did not receive the new packet.<br></p>\n<p><strong>rdt2.2 data transfer action:</strong><br></p>\n<ol>\n<li>sender side<br><br><img src=\"rdt2.2-sender.png\" alt=\"rdt2.2-sender\"><br></li>\n<li>receiver side<br><br><img src=\"rdt2.2-receiver.png\" alt=\"rdt2.2-receiver\"><br></li>\n</ol>\n<h2 id=\"Reliable-Data-Transfer-Over-a-Lossy-Channel-With-Bit-Errors-rdt3-0\"><a href=\"#Reliable-Data-Transfer-Over-a-Lossy-Channel-With-Bit-Errors-rdt3-0\" class=\"headerlink\" title=\"Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0\"></a>Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0</h2><p><em>suppose now that in additions to corrupting bit errors , the underlying channel can lose packet as well.</em> <br></p>\n<p><strong>Questions:</strong><br> </p>\n<ul>\n<li>How to detect packet loss and what to do when packet loss occurs.<br></li>\n</ul>\n<p><strong>Solution:</strong><br></p>\n<ul>\n<li>The use of checksumming sequence numbers ACK packet and retransmissions - the techniques already developed in rdt2.2 allow us to solution the latter concern.<br></li>\n<li>To handling the first concern we require introduce a new protocol  mechanism. The protocol require the sender judiciously choose a time value. If an ACK is not received within this time , the packet is retransmitted .<br></li>\n</ul>\n<p><strong>rdt3.0 data transfer action:</strong><br><br>Because the packet sequence number alternate between 0 and 1, protocol rdt3.0 sometimes known as <strong>alternating-bit-protocol</strong><br><br><em>In the rdt3.0 , the sender will start a timer for packet via start_timer() event</em></p>\n<p><strong>rdt3.0 sender side.<br></strong></p>\n<p><img src=\"rdt3.0-sender.png\" alt=\"rdt3.0-sender\"><br></p>\n<p><img src=\"operation-of-rdt3.0-1.png\" alt=\"rdt3.0-operation-of-data-transfer-1\"><br></p>\n<p><img src=\"operation-of-rdt3.0-2.png\" alt=\"rdt3.0-operation-of-data-transfer-2\"><br></p>\n<p><strong>Question:</strong></p>\n<ul>\n<li>How long must the sender wait to be certain that something has been lost ?<br></li>\n</ul>\n<h1 id=\"3-4-2-Pipelined-Reliable-Data-Transfer-Protocols\"><a href=\"#3-4-2-Pipelined-Reliable-Data-Transfer-Protocols\" class=\"headerlink\" title=\"3.4.2 Pipelined Reliable Data Transfer Protocols\"></a>3.4.2 Pipelined Reliable Data Transfer Protocols</h1><p><strong>Question:</strong><br></p>\n<ul>\n<li>Although the rdt3.0 is a functionally correct protocol . But it’s unlikely that anyone would happy with its performance . In fact , rdt3.0 has a dismal sender utilization. (more detail of calculation we can read the textbook)<br></li>\n</ul>\n<p><strong>Solution:</strong><br><br>To solution this performance problem is simple: Rather than operate in a stop-and-wait-protocol, the sender is allowed to send multiple packet without waiting for acknowledgment as illustrated figure below.<br></p>\n<p><img src=\"Stop-and-wait-versus-pipelined-protocol.png\" alt=\"Stop-and-wait-versus-pipelined-protocol\"></p>\n<p><em>Since the many in-transit sender to receiver packets can be visualized as filling pipeline , the technique is known as pipelining</em></p>\n<p><strong>pipelining has the following consequence for reliable data transfer protocols:</strong><br></p>\n<ul>\n<li>The range of sequence number must be increated . Since we require to send mutiple packet , each packet need a unquie sequence number.</li>\n<li>The sender and receiver side of protocol must has to buffer more than one packet.</li>\n<li>The range of sequence number and buffering requirements will depend on the manner in which data transfer protocol responds to lost, corrupt and overlay delayed packets. Two basic approaches toward pipelined errors recovery can be identified :<strong>GO-Back-N and Selective repeat</strong>.<br></li>\n</ul>\n<h2 id=\"3-4-3-Go-Back-N-GBN\"><a href=\"#3-4-3-Go-Back-N-GBN\" class=\"headerlink\" title=\"3.4.3 Go-Back-N(GBN)\"></a>3.4.3 Go-Back-N(GBN)</h2><p>In the GBN protocol, the sender allowed to send mutiple packet without waiting for acknowledgment, but is constrained to have no more than some maximum allowable number N , the N often be referred as the window size, the Go-Back-N(GBN) protocol often be referred as sliding-window-protocol.<br></p>\n<p><em>We maybe have questions that why we limit the window size N instead of unlimited</em><br><br>About this question we will discuss in the flow control and congestion control sections.<br></p>\n<p><strong>Define</strong><br><br><img src=\"Sender&#39;s-view-of-sequence-numbers-in-the-Go-Back-N.png\" alt=\"Sender&#39;s-view-of-sequence-numbers-in-the-Go-Back-N\"><br></p>\n<ul>\n<li><strong>Base:</strong> The sequence number of the oldest unacknowledgment .</li>\n<li><strong>nextseqnum :</strong> The smallest unused sequence number.</li>\n<li><strong>[0 ~ base-1]:</strong> corresponds to have already been transmitted and acknowledged.</li>\n<li><strong>[base ~ nextseqnum-1]:</strong> corresponds to have already been sent but not yet acknowledge.</li>\n<li><strong>[nextseqnum ~ base+N-1]:</strong> can be used to send packet when the data arrived from upper layer.<br><br><strong>[base+N ~ ]:</strong> can not be used until an unacknowledged packet has been acknowledged. </li>\n</ul>\n<p><em>Note that the GBN protocol packet containing fixed-length-sequence-number-filed ,in TCP protocol ,the length of sequence-number-filed is 32 bits, the range of sequence number is [0 ~ $2^{32} -1$ ] different to rdt3.0 that ranger of sequence number is [0 ~ 1],and the length of sequence-number-filed is 1 bits.</em><br></p>\n<p><strong>GBN data transfer action:</strong><br></p>\n<ol>\n<li>receiver side <br></li>\n</ol>\n<p><img src=\"GBN&#39;s-FSM-receiver.png\" alt=\"GBN&#39;s-FSM-description-receiver\"><br></p>\n<p><strong>The GBN’s sender must respond to three type of event.</strong><br></p>\n<ul>\n<li><strong>Invacation from above:</strong> When rdt_send() be invoked from the upper layer. The sender requires to check the window whether the window has full. If the window is not full , the data from above can make be packet and sent . The sender will update appropriately some variables. If the window is full, the sender will refuse data and indication the upper layer that the window has full. The upper layer will resend it again before a period of time.<br></li>\n<li><strong>Receipt of an ACK:</strong> Noting function <code>base = getacknum(rcvpkt)+1</code> because the receiver use <strong>cumulative acknowledgment</strong>(we will discuss in receiver side ), for example , we can know packet of sequence number low than n has received correctly in the receiver side. When the sender side got the packet of sequence number n. Then we can update <code>base = n+1</code> and (stop_timer()orstart_timer) according to corrusp<br></li>\n<li><strong>A timeout event:</strong> If timeout occurs , the sender will resends all packets that previously sent but have not yet been acknowledgment . Namely<code>udt_send(sndpkt[base])....udt_send(sndpkt[nextseqnum-1])</code><br></li>\n</ul>\n<p><strong>The GBN’s receiver must respond to event:</strong><br><br><em>In the GBN protocol , the receiver will discard out-of-order packets , for example the receiver expected sequence number is n , but the receiver receive a packet containing sequence number n+1 or more larger than n , the receiver will discard this packet and resend the packet containing expected sequence number to sender via udt_send(sndpkt) event. So the receiver be called use <strong>cumulative acknowledgment</strong>.</em> <br></p>\n<p><img src=\"GBN-in-operation.png\" alt=\"GBN-in-operation\"><br></p>\n<p><strong>Note that the GBN protocol sender must be maintain The upper and lower bound of its window and position of nextseqnum within this window. The receiver must be maintain the sequence number of next in-order-packet.(expectedseqnum)</strong><br></p>\n<p>How does GBN protocol work we can see this video: <a href=\"https://www.youtube.com/watch?v=9BuaeEjIeQI\">GBN</a><br></p>\n<h2 id=\"3-4-4-Selective-Repeat-SR\"><a href=\"#3-4-4-Selective-Repeat-SR\" class=\"headerlink\" title=\"3.4.4 Selective Repeat (SR)\"></a>3.4.4 Selective Repeat (SR)</h2><p><strong>Question:</strong><br>Although GBN protocol avoiding the utilization problem of rdt3.0 , The GBN itself also has a performance problem . When the window size and bandwidth-delay both large, many packets can be in pipeline. If have a packet lost in the transmission will cause a large number of packets to retransmission.<br></p>\n<p><strong>Solution:</strong><br>As the name suggests, <strong>selective repeat protocol</strong> avoid unnecessary retransmission by having the sender retransmit those packets that it suspects were received in error(that were lost or corrupted ) at the receiver.<br></p>\n<p><img src=\"Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png\" alt=\"Selective-repeat(SR)-sender-and-receiver-views-of-sequence-number-space.png\"><br></p>\n<p><strong>Difference to GBN protocol, SR protocol has window in the receiver side like the figure above. <br></strong><br><em>The receiver will acknowledgment a correctly received packet whether or not it is in-order. Out-of-order packet will be buffering until any missing packet (that is lower than sequence number has buffered) are received. When the packet of sequence number (rcv_base) is received , the receiver will deliver a batch of packet that <strong>begin with sequence number (rcv_base) and end with smallest unreceived sequence number minus one</strong> to upper layer. Then number rcv_base increase <br></em></p>\n<p><strong>SR protocol data transfer action:</strong><br></p>\n<ol>\n<li>sender side <br></li>\n</ol>\n<ul>\n<li><strong>Data received from above:</strong> The sender will check the next sequence number (nextseqnum) whether or not larger than window size <code>If(nextseqnum&gt;base+N)</code>.If the nextseqnum is within the window, the sender will make data into packet and send it to receiver. Otherwise the sender will either buffered or returned to upper layer for later transmission as in GBN.<br></li>\n<li><strong>Timeout:</strong>  Different to GBN protocol , in the SR protocol , each packet has its own logical timer since only a single packet will be transmitted on timeout.<br></li>\n<li><strong>ACK received:</strong> If an ACK packet within the window is received , the SR sender will marks that packet as having been received. Until the packet containing sequence number (send_base) is received . Then the sender will move the send_base forward to the unackknowledgment packet with smallest sequence number.<br></li>\n</ul>\n<ol>\n<li>receiver side <br></li>\n</ol>\n<ul>\n<li>Packet with sequence number in [rcv_base,rcv_base+N-1] is correctly received whatever whether or not in-order. Then the packet is buffered at the receiver . If the packet containing sequence number (rcv_base) is received. The receiver will deliver the packet that begins with rcv_base and end with the smallest unreceived sequence number minus one to the upper layer. Then move rcv_base forward to the smallest unreceived sequence number.<br></li>\n<li>Packet with sequence number in [rcv_base-N,rcv_base] is correctly received . Occur this situation cause is a ACK with sequence number in [rcv_base-N,rcv_base] maybe lost or corrupted or bandwidth-delay ,then timeout the sender retransmission the packet , In this case , an ACK must be generated and resend this ACK to sender, even though this is a packet that has previously acknowledgment.<br></li>\n<li>Otherwise : Ignore this packet.</li>\n</ul>\n<p><img src=\"SR-operation.png\" alt=\"SR-operation.png\"><br></p>\n<p><strong>Disadvantages of SR protocol</strong><br><br><em>The two case could happen when the window size too-large and the range of sequence number too-small</em><br><br>The window size is 3 and the range of sequence number is 4 in the example <br></p>\n<p><img src=\"SR-receiver-dilemma-a.png\" alt=\"SR-receiver-dilemma-a.png\"><br></p>\n<p><strong>In this case , the old packet 0 is recognized as new packet 0, packet confuse</strong></p>\n<p><img src=\"SR-receiver-dilemma-b.png\" alt=\"SR-receiver-dilemma-b.png\"><br></p>\n<p><strong>In this case , packet 3 is lost , the rcv_base = 3 , The packet 0 containing new data will be recognized as old packet 0 when the sender send the new packet 0. Because <code>0&lt; [3,3+3-1]</code>. Packet confuse.</strong><br></p>\n<p><em>How small window size must be ?</em><br><br><strong>Answer is window size must be less than or equal to a half of sequence number space for SR protocol.<br></strong></p>\n<p>How does SR protocol work we can see this video : <a href=\"https://www.youtube.com/watch?v=Cs8tR8A9jm8\">SR</a></p>\n<h1 id=\"3-5-Connection-Oriented-Transport-TCP\"><a href=\"#3-5-Connection-Oriented-Transport-TCP\" class=\"headerlink\" title=\"3.5 Connection-Oriented Transport:TCP\"></a>3.5 Connection-Oriented Transport:TCP</h1><h2 id=\"3-5-1-The-TCP-connection\"><a href=\"#3-5-1-The-TCP-connection\" class=\"headerlink\" title=\"3.5.1　The TCP connection\"></a>3.5.1　The TCP connection</h2><p>The TCP “connection” is not an end-to-end TDM or FDM circuit as in a circuit switch network. Nor it’s a virtual circuit , only as the connection state reside entirely in two end system.<br><br>The TCP connection provide <strong>full-duplex service</strong>, namely , Application layer data of two end system  can sent to other side.</p>\n<p><strong>The TCP connection always point-of-point that is between a single sender and a single receiver.</strong><br><br>The TCP connection established by <strong>three-way-handshake</strong> , the first two handshake by send the segment that can not carry payload, the third handshake by send the segment that can carry payload.<br></p>\n<p>The TCP connection also always point-to-point , that is a singer sender and a single receiver.<br><br><strong>The TCP connection has buffer in two end system. The data is passed through socket then the TCP directs this data to connection’s sender buffer then the TCP will grab chuck of data from send’s buffer and pass the data to network layer. As shown in figrue below.</strong><br><br><img src=\"TCP-sender-and-receiver-buffer.png\" alt=\"TCP-sender-and-receiver-buffer\"><br></p>\n<p><strong>Two terminology</strong><br></p>\n<ul>\n<li>MSS(Maximum segment size): The maximum amount of application data can place in segment.<br></li>\n<li>MTU(Maximum transmission unit): The largest frame size (application data plus TCP/IP header line)<br> </li>\n</ul>\n<p><strong>In Summary</strong><br><br><em>The TCP connection consist of sender’s buffer and sender’s variables and socket connection to process in sender’s host and socket connection to process in receiver’s host and receiver’s variables and receiver’s buffer.</em><br> <em>As mentioned early TCP connection only has two state reside in the sender host and receiver host , no buffer and variable allocated in network element between two end system host (router and switch and repeater)<br></em></p>\n<h2 id=\"3-5-2-TCP-Segment-Structure\"><a href=\"#3-5-2-TCP-Segment-Structure\" class=\"headerlink\" title=\"3.5.2 TCP Segment Structure\"></a>3.5.2 TCP Segment Structure</h2><p><img src=\"TCP-Segment-structure.png\" alt=\"TCP-segment-structure\"><br></p>\n<ul>\n<li><strong>Source and destination port numbers</strong>:corresponding to sender socket and receiver socket.<br></li>\n<li><strong>Checksum field</strong>: for detecting the corrupt whether occurred during the traveling as like UDP checksum field.<br></li>\n<li><strong>The 32 bits sequence number field</strong>: The sequence number is the byte number of first byte of data in the TCP packet sent (also called TCP segment)</li>\n<li><strong>The 32 bits acknowledgment numbers</strong>: The next packet that receiver expects to receive.</li>\n<li><strong>The 16-bits receiver number</strong>: Used for flow control , indicate the window size N that we discuss in the GBN and SR protocol.<br></li>\n<li><strong>The 4-bits header length field</strong>: indicates how long the header is, in 32 bit “words”. The minimum value is “5” which would be 160 bits, or 20 bytes. The maximum length is 15, which would be 480 bits, or 60 bytes</li>\n<li><strong>The optional and variable-length optional field</strong>: Used  when  a  sender  andreceiver negotiate the maximum segment size (MSS) or as a window scaling fac-tor for use in high-speed networks. A time-stamping option is also defined. </li>\n<li><strong>The flag field contain 6 bits</strong>:<ul>\n<li>ACK bit : Used to indicate that value carried in the acknowledgment field is valid .</li>\n<li>RST,SYN,FIN bit: Used for connection setup and teardown .</li>\n<li>PSH bit: Used to indicate the receiver should pass the data to upper layer immediately.</li>\n<li>URG bit: I don’t know what this means</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Sequence-number-and-acknowledgment-number\"><a href=\"#Sequence-number-and-acknowledgment-number\" class=\"headerlink\" title=\"Sequence number and acknowledgment number\"></a>Sequence number and acknowledgment number</h3><p>Cause These two fields are critical part of TCP connection , We discuss more detail about these.<br></p>\n<p><em>All byte in TCP connection are numbered beginning at a <strong>randomly choose</strong> initial sequence number(ISN) , The SYN packets consume one sequence number , so actual data begin at ISN+1</em><br></p>\n<p><strong>For example The TCP connection establish as shown in figure below</strong><br><br><img src=\"TCP-connection.png\" alt=\"TCP-connection-establish\"><br></p>\n<ul>\n<li>Step 1: The client want to establish connection with server , it will send a packet contain SYN bit and randomly choose initial sequence number (Client_isn) to sever.(no payload)<br></li>\n<li>Step 2: The server has received this packet then response a packet contain initial sequence number (server_isn) and SYN bit and acknowledgment number (Client_isn+1) to Client.(no payload)<br></li>\n<li>Step 3: The connection established success when the Client has received the response of packet, Client then change the SYN to 0 and send the packet contain sequence number client_isn+1 and acknowledgment number server_isn+1 and actual data (payload) to server.<br> </li>\n</ul>\n<h2 id=\"3-5-3-Round-Trip-Time-Estimation-and-Timeout\"><a href=\"#3-5-3-Round-Trip-Time-Estimation-and-Timeout\" class=\"headerlink\" title=\"3.5.3 Round-Trip Time Estimation and Timeout\"></a>3.5.3 Round-Trip Time Estimation and Timeout</h2><p>TCP like rdt3.0 use timeout/retransmission mechanism to recover from lost segment.<br><br>Although conceptually simple , many subtle issue arise when we implement timeout/retransmission mechanism in actual protocol such as TCP protocol.<br><br><strong>Questions:</strong></p>\n<ul>\n<li>How larger time is timeout .<br> </li>\n<li>How estimating the round-trip-time between the sender and receiver<br></li>\n<li>Should a timer be associated with each and every unacknowledgment packet?<br></li>\n</ul>\n<h3 id=\"Estimating-The-Round-Trip-Time\"><a href=\"#Estimating-The-Round-Trip-Time\" class=\"headerlink\" title=\"Estimating The Round-Trip-Time\"></a>Estimating The Round-Trip-Time</h3><ul>\n<li><strong>SampleRTT</strong>: Represent the amount of time between when the packet sent from the sender (that is pass the packet to the network layer) and when the acknowledgment segment has received.<br><br><em>The TCP does not estimate stampleRTT for every single packet(segment), Instead of TCP implementation take only one sampleRTT measurement at a time</em></li>\n<li><strong>EstimatedRTT</strong>: Because different sampleRTT value will be fluctuate due to congestion in the routers and to varying load on the end systems. The sampleRTT is atypical , In order to estimate a typical RTT ,it is therefore natural to take some sort of avenger of sampleRTT . The TCP maintains an avenger called <strong>EstimatedRTT</strong>.<br><br><code>EstimatedRTT = (1- a) * EstimatedRTT + a * SampleRTT</code><br><br>The value of <code>a</code> typically choose 0.125.<br><br><code>EstimatedRTT = 0.875 * EstimatedRTT + 0.125 * sampleRTT</code><br><br><img src=\"RTT-sample-and-RTT-estimates.png\" alt=\"RTT-sample-and-RTT-estimates\"><br></li>\n<li><strong>DevRTT</strong>: DevRTT as an estimate of how much sampleRTT typical deviates from EstimatedRTT.<br><br><code>DevRTT = (1-b) * DevRTT + b * |sampleRTT - EstimatedRTT|</code><br><br>The value of <code>b</code> typical choose 0.25.<br><br><code>DevRTT = 0.75 * DevRTT + 0.25 * |sampleRTT - EstimatedRTT|</code><br></li>\n<li><strong>Timeout Interval</strong>: Clearly The timeout interval should be greater than or equal to EstiamtedRTT or unnecessary retransmission will be sent. But the timeout should not be too larger than EstimatedRTT . Otherwise when the segment has lost , The TCP would not retransmission quickly , leading to large transfer delay.<br><br><code>TimeoutInterval = EstimatedRTT + 4 * DevRTT</code><br><br>An <strong>initial</strong> Timeoutinterval value of 1 second is recommended </li>\n</ul>\n<h2 id=\"3-5-4-Reliable-Data-Transfer\"><a href=\"#3-5-4-Reliable-Data-Transfer\" class=\"headerlink\" title=\"3.5.4 Reliable Data Transfer\"></a>3.5.4 Reliable Data Transfer</h2><p>TCP is best categorize as a hybrid of GBN and SR protocol.<br></p>\n<p><strong>In the receiver(server) side:</strong><br><br>In TCP protocol ,server use <strong>cumulative ACK</strong> as like GBN protocol does, server also buffer out-of-order packet as like SR protocol. <br><br><strong>In the sender(client)  side:</strong><br><br>Since TCP use cumulative ACK, If the client has received ACK with acknowledgment number 120, just mean the server has received all byte lower than 120<br><br><em>For example: The server sends the ACK with acknowledgment number is 120, namely, server expect next sequence number is 120, the client got the ACK packet, then sent two packets with sequence number 120,130 to the server , unfortunately, the packet with sequence number 120 is lost, the server received the out-of-order packet with sequence number 130, then, the server buffers the out-of-order packet as like SR protocol does and sent ACK with acknowledgment number 120 back to the client , here is different to SR protocol, as like GBN protocol does.</em></p>\n<h3 id=\"TCP-Retransmission-and-Doubling-the-timeout-interval\"><a href=\"#TCP-Retransmission-and-Doubling-the-timeout-interval\" class=\"headerlink\" title=\"TCP Retransmission and Doubling the timeout interval\"></a>TCP Retransmission and Doubling the timeout interval</h3><p>Different from GBN and SR protocol, TCP only retransmits the not-yet-acknowledgment segment with the smallest sequence number when the timeout occurs, then restart timer with doubling timeout interval.<br></p>\n<p><em>For example : Suppose the timeoutinterval associated with oldest not-yet-acknowledgment segment is 0.75 sec when the timer expires, TCP will retransmit this segment and set new expiration time to 1.5 sec , If the timer expires again 1.5 sec later , TCP will retransmit this segment and set new expiration time to 3.0 sec, however whenever the timer is started after either of two other events (that is ACK received and data received from application above), the timeoutinterval is derived from the most recent value of EstimatedRTT and DevRTT</em><br></p>\n<p><strong>Qusetion: Why we need to doubling timeout interval.</strong><br><br>Because, in times of congestion , the segment maybe dropped or suffer long queues delay, If we resent the packet persistently , the congestion may get worse . Instead TCP should acts more politely with earn sender retransmit after long and long interval.<br></p>\n<p><strong>TCP Fast Retransmit</strong><br><br>One of problem with timeout-triggered retransmissions is that the timeout period relatively long , when a segment is lost, this long timeout period will force sender to delay this segment retransmit thereby increasing the end-to-end delay. So we need to fast retransmits mechanism.<br></p>\n<p>Before discuss TCP Fast Retransmit , we should know how does ACK generate .<br><br><strong>TCP ACK Generation Recommendation</strong><br><img src=\"TCP-ACK-Generation-Recommendation.png\" alt=\"TCP-ACK-Generation-Recommendation\"><br><br>The duplicate ACK is indicated that this segment has been lost, when the sender has received this same segment three time . TCP will perform fast retransmit , send this segment to receiver again.<br><br><em>For example : The sender send a large number of segment back to back , if one segment is lost , there will likely be many back-to-back duplicate ACK, if the sender received same duplicate more than three time , The sender will be perform fast retransmit, As shown in figure below.</em><br></p>\n<p><img src=\"Fast-retransmit.png\" alt=\"Fast-retransmit\"></p>\n<p><strong>Code snippet of Fast retransmit</strong><br><br><img src=\"Code-snippet-of-fast-retransmit.png\" alt=\"Code snippet of Fast retransmit\"><br></p>\n<h2 id=\"3-5-5-Flow-Control\"><a href=\"#3-5-5-Flow-Control\" class=\"headerlink\" title=\"3.5.5 Flow Control\"></a>3.5.5 Flow Control</h2><p>Flow control is speed-matching-service that be used to matching the sender sending speed and the receiver’s application reading speed.<br><br>If the application reading receiver’s buffer at slow speed , the sender can very easily overflow the connection’s receive buffer by sending too much data and too quickly.<br> </p>\n<p>TCP provide the flow control by having the sender maintain a variable called <strong>receive window</strong>, Because the TCP is full-duplex , the sender at each side of the connection maintain a distinct receive window.<br></p>\n<p>Suppose the host A send segments to host B over TCP connection, host B allocate a buffer to this connection.<br><br>Let me define some variables for host B and host A.<br><br><strong>For Host B (server)</strong><br></p>\n<ul>\n<li>RcvBuffer : the size of receive window(buffer) size of host B.<br></li>\n<li>LastByteRead : the number of the last byte in the data stream read from receive buffer by application in B.<br></li>\n<li>LastByteRcv : the number of the last byte in the data stream has been received from network and has been placed in receive buffer.<br></li>\n<li>rwnd : the amount of space room in the buffer  <code>rwnd = Rcvbuffer - [LastByteRead - LastByteRcv]</code> <br><br><img src=\"TCP-RcvBuffer.png\" alt=\"RcvBuffer\"><br><br><strong>For Host A (Client)</strong> <br></li>\n<li>LastByteSent : the number of last byte in the data stream has sent at the sender side .<br></li>\n<li>LastByteAcked : the number of last byte in the data stream has ACKed at the sender side . <br></li>\n</ul>\n<p>Host B and host A maintain those variables that we mention above.<br></p>\n<p><strong>How to control the flow through these information.</strong><br><br>The Host B tells Host A that how much space room it has in the connection buffer by place the value of rwnd in receive window field of ACK segment.<br><br>The host A just need to keep the <code>LastByteSent - LastByteAcked</code> less than <code>rwnd</code> (,LastByteSent - LastByteAcked &lt;= rwnd`), the sender can assure that it is not overflowing the receive buffer at the Host B.<br></p>\n<p>If the receive buffer has filled at the Host B, the Host A will stop sending data to Host B, instead, Host A will send one bit to Host B for keeping the connection until the Host B has space room again. <br></p>\n<h2 id=\"3-5-6-TCP-Connection-Manage\"><a href=\"#3-5-6-TCP-Connection-Manage\" class=\"headerlink\" title=\"3.5.6 TCP-Connection-Manage\"></a>3.5.6 TCP-Connection-Manage</h2><p><strong>Establish TCP connection</strong><br><br><img src=\"TCP-connection-manage-1.png\" alt=\"TCP-Connection-Manage-1\"><br><br><strong>Finish TCP connection</strong><br><br><img src=\"TCP-connection-manage-2.png\" alt=\"TCP-Connection-Manage-2\"><br><br><strong>TCP states at the sender side</strong><br><br><img src=\"TCP-connection-manage-3.png\" alt=\"TCP-Connection-Manage-3\"><br><br><strong>TCP states at the receiver side</strong><br><br><img src=\"TCP-connection-manage-4.png\" alt=\"TCP-Connection-Manage-4\"><br></p>\n<p><strong>The SYN flood attack</strong><br><br><em>we can see detail in the textbook</em><br></p>\n<h2 id=\"3-6-Principles-of-Congestion-control\"><a href=\"#3-6-Principles-of-Congestion-control\" class=\"headerlink\" title=\"3.6 Principles of Congestion control\"></a>3.6 Principles of Congestion control</h2><h3 id=\"3-6-1-The-Causes-and-the-costs-of-Congestion\"><a href=\"#3-6-1-The-Causes-and-the-costs-of-Congestion\" class=\"headerlink\" title=\"3.6.1 The Causes and the costs of Congestion\"></a>3.6.1 The Causes and the costs of Congestion</h3><ul>\n<li><p><strong>Scenario 1: Two sender , a Router with infinite buffer</strong><br><br>Assume the host A and host B have same sending original data rate $\\lambda <em>{in}$ ( application sending original data into socket  by $\\lambda </em>{in}$  ignore the cost of that be encapsulated by TCP/IP header line) and the router throughput capability is $R$<br><img src=\"Congestion-scenario-1-two-connection.png\" alt=\"Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png\"><br></p>\n<p>  <em>The throughput equal to R/2 is consequence of two sender Host A and Host B sharing outgoing link of the router.<br></em><br><img src=\"Congestion-scenario-1-throughput-and-delay.png\" alt=\"Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png\"><br></p>\n<p>  <em>We can see the sender sending rate more approaches $R/2$ , delay become more larger and larger. The delay become to infinite when the $\\lambda_{in}$ larger than $R/2$<br></em></p>\n<p>  <strong>Here , we found one cost of congestion — large queue delay are experienced as the packet-arrived rate near the link throughput capability.<br></strong></p>\n</li>\n<li><p><strong>Scenario 2: Two Senders and a Router with Finite Buffers</strong><br></p>\n<p>  The $\\lambda<em>{in}$ is denoted application layer sending the original data into socket by $\\lambda</em>{in}$ bytes/sec.<br><br>  The $\\lambda’<em>{in}$ is denoted transfer layer sending segment into network by $\\lambda’</em>{in}$ bytes/sec (containing original data and retransmited data).<br><br>  The Router throughput capacity is $R$ bytes/sec.<br><br><img src=\"Scenario-2-two-hosts.png\" alt=\"Chapter3-Transport-Layer/Scenario-2-two-hosts.png\"><br><br><strong>a.</strong> The Host A and Host B is able to somehow (magically) determine whether or not the buffer is free in the router . sender only sends data only has free buffer . In this case  $\\lambda<em>{in}$ equal to $\\lambda’</em>{in}$, didn’t occur packet loss. This case is shown as figure.a below <br><br><strong>b.</strong> The Host A and Host B may set a larger enough timeout can determine the pakect has been lost , then sender only retransmit packet that is determinded has been lost. This case is shown as figure.b below, we can see the $0.5R$ units of data transmitted . $0.333R$ bytes is original data and $0.166R$ bytes is retransmitted data<br><br><strong>we can here see another cost of congestion is the sender must perform retransmit packet in order to compensate for dropped packet due to buffer overflow.</strong><br><br><strong>c.</strong> The Host A and Host B may set a small timeout interval (or in face of large delay), the sender retransmit prematurely and retransmit packet that have been delay in queue but not yet lost. The original data and retransmited data both may reach the receiver , the receiver will discard the copy of original data . This case is shown as figure.c below <br><br><strong>we can here see the third cost of congestion — unneeded retransmissions by sender in face of large delay may cause router to use it link bandwish to forward unneeded copies of packet</strong><br><img src=\"Scenario-2-performance.png\" alt=\"Chapter3-Transport-Layer/Scenario-2-performance.png\"><br></p>\n</li>\n<li><strong>Scenario 3 Four sender and Router with Finite Buffer and Multihop Paths</strong></li>\n</ul>\n<p><img src=\"Scenario-3-Four-senders.png\" alt=\"Chapter3-Transport-Layer/Scenario-3-Four-senders.png\"><br><br>In this case the A-C connection share route R2 with B-D connection. Consider The host A send data to host C and host B send data to host D both at the same time . The data of host A arrive router R2 with R bytes/sec i , The data of Host B arrive router R2 with $\\lambda$ , the Host A and Host B need to compare for the free buffer of router R2, if the $\\lambda &lt;&lt; R$ , nothing going happen , data will safely arrive in destination host, but if the $\\lambda &gt;&gt; R$ (the $\\lambda$ extremely large) , the router will be filled immediately by data of host B , the data of host A will lost because of buffer overflow and that work done by router A will be wasted.<br></p>\n<p><img src=\"Scenario-3-performance.png\" alt=\"Chapter3-Transport-Layer/Scenario-3-performance.png\"><br><br><strong>We can see the fourth cost of dropping the packet due to congestion — when a packet is drop along a path, the transmission capacity that was used at each of upstream link to forward that packet to this point at which it is dropped end up having been wasted.</strong><br></p>\n<h3 id=\"3-6-2-Approach-to-Congestion-Control\"><a href=\"#3-6-2-Approach-to-Congestion-Control\" class=\"headerlink\" title=\"3.6.2 Approach to Congestion Control\"></a>3.6.2 Approach to Congestion Control</h3><p><strong>Two kind of Congestion control way</strong><br></p>\n<ul>\n<li><strong>End-to-End Congestion Control</strong></li>\n<li><strong>Network-assisted Congestion Control:</strong> The Network (router) provide the feedback to sender indicate the congestion state .<strong>Two feedback way for congestion control.</strong><br><ul>\n<li>Direct feedback: The router direct inform the sender via send choke packet.<br></li>\n<li>The router mark/updata in a packet flowing from sender to receiver to indicate the congestion. Upon recipt of a marked packet , the receiver notifies the sender congestion indication .<br></li>\n</ul>\n</li>\n</ul>\n<p><img src=\"Two-feedback-way.png\" alt=\"Chapter3-Transport-Layer/Two-feedback-way.png\"></p>\n<h3 id=\"3-6-3-Network-Assisted-ATM-ABR-Congestion-Control\"><a href=\"#3-6-3-Network-Assisted-ATM-ABR-Congestion-Control\" class=\"headerlink\" title=\"3.6.3 Network Assisted ATM ABR Congestion Control\"></a>3.6.3 Network Assisted ATM ABR Congestion Control</h3><p><strong>This section we can learn by textboot</strong><br></p>\n<h2 id=\"3-7-TCP-Congestion-Control-End-To-End-Congestion-Control\"><a href=\"#3-7-TCP-Congestion-Control-End-To-End-Congestion-Control\" class=\"headerlink\" title=\"3.7 TCP Congestion Control (End-To-End Congestion Control)\"></a>3.7 TCP Congestion Control (End-To-End Congestion Control)</h2><p>This approach (The TCP Congestion Control Mechanism )taken by TCP is to have each sender limit the rate at which its sends traffic into its connection as a function of perceive network congestion. How to perceive the congestion ? we will discuss below. <br><br>This approach requires senders keep track of an additional variable , <strong>the congestion window</strong> that is denoted <strong>cwnd</strong> [different to <strong>receive window(rwnd)</strong> at flow control]<br><br>The congestion window imposes an constraint on the rate at which a TCP sender can send into the network.<br><br><code>The unacknowledged data = LastByteSent - LastBystAck &lt;= min&#123; cwnd , rwnd&#125;</code></p>\n<ul>\n<li><strong>In order to focus to Congestion Control , we assume the receive window is large enough that we can ignore it.</strong><br></li>\n<li><strong>We also assume the sender always has data to send.</strong><br></li>\n<li><strong>We define the “loss event” at a TCP sender as the ocurrence of either a timeout or recipt of three duplicate ACK from the receiver.<br></strong></li>\n</ul>\n<p><strong>How congestion is detected ?.</strong><br><br><em>In the TCP congestion mechanism, The ACK is used to perceive the network congestion situation, The congestion window is used to constrain sent data rate. If ACK is received quickly, the TCP will increase the sender congestion window size quickly. If ACK is received slowly, the TCP will increase the sender congestion window size slowly. If “loss event” occurred (indicate Netwok congestion ),　the TCP will take some measures to reduce the congestion window size<br></em></p>\n<p><strong>Give a overview of TCP congestion control, Now ,let me see more detail about TCP congestion-control algorithm</strong><br></p>\n<p>The TCP congestion-control algorithm has three major components:</p>\n<ul>\n<li><strong>Slow start</strong></li>\n<li><strong>Congestion avoidance</strong></li>\n<li><strong>Fast recovery</strong></li>\n</ul>\n<h3 id=\"Slow-Start\"><a href=\"#Slow-Start\" class=\"headerlink\" title=\"Slow Start\"></a>Slow Start</h3><p>When a TCP connection begin . the value of cwnd typically initialized to a small value of 1 MSS (maximum segment size) resulting in an initial sending rate of roundly MSS/RTT. For example , The MSS equal to 500 bytes , the RTT equal to 200 msec , the resulting inital sending rate is only roundly 20 kbps.<br><br><strong>If each ACK that is sent within RTT can be received within the same RTT. The TCP is doubling the value of cwnd. Namely increase the value of cwnd by a single MSS every ACK within the same RTT</strong><br><br>For example, the initial value of cwnd is 1 MSS, the sender is sending 1 segment into the network within an RTT . when ACK of this segment is received at the sender within the same RTT  , the TCP is doubling the value of cwnd that is to say cwnd become to 2 MSS, the sender can send two-segment within RTT right now. If these two ACK of segments is received at the sender within the same RTT  , the cwnd is doubling to 4 MSS.<br><br><strong>Thus the TCP send rate start slow , but grow exponentially during the slow phase.</strong><br><br><img src=\"Slow-Start.png\" alt=\"Slow-Start\"> <br><br><strong>When should this exponentail growth end?</strong></p>\n<ul>\n<li><strong>The first way:</strong> When timeout event ocurred , The TCP will set the value of cwnd back to 1 MSS begin slow start process anew, and <em>set a new state variable <strong>ssthresh</strong> (that is “Slow Start Threashold”) to $cwnd/2$</em></li>\n<li><strong>The second way:</strong> When the $cwnd \\geq ssthresh$ ocurred , the slow start end and turn into congestion aviodance mode.</li>\n<li><strong>The third way:</strong> When the thripe duplicate ACK is detected , the slow start end and turn into fast recovery mode, perform fast retransmit.</li>\n</ul>\n<h3 id=\"Congestion-Avoidance\"><a href=\"#Congestion-Avoidance\" class=\"headerlink\" title=\"Congestion Avoidance\"></a>Congestion Avoidance</h3><p>On entry to the Congestion-Avoidance state , the value of cwnd is approximately half its value when congestion was last encountered , that is to say , the congestion could be just around the corner.<br><br><strong>Thus , rather than doubling the value of cwnd every RTT. TCP adopt more conservative approach and increase the value of cwnd by just a single MSS every RTT</strong></p>\n<p><strong>The several events should do in the Congestion Avoidance state.</strong><br></p>\n<ul>\n<li>The TCP sender increases the value of cwnd by $MSS\\cdot(\\frac{MSS}{cwnd})$ bytes (here cwnd is constant) when ever a new Acknowledgment arrives. For example the cwnd equal to 500 bytes and the MSS equal to 50 bytes, the sender is sending 10 segment within an RTT . Thus the TCP sender is increasing the value of cwnd by $5$ bytes when ever a new Acknowledgment arrives.</li>\n<li>When the timeout occurred , The TCP sender is set the value of cwnd back to $1$ MSS and the value of ssthresh is updated to half the value of cwnd , end up turn into slow start mode .<br></li>\n<li>When the thripe duplicate Acknowledgment is received . The sender is seting $ssthresh =\\frac{cwnd}{2}$ and $cwnd = ssthresh + 3 \\ast MSS$,then turn into fast recovery mode.</li>\n</ul>\n<h3 id=\"Fast-Recovery\"><a href=\"#Fast-Recovery\" class=\"headerlink\" title=\"Fast Recovery\"></a>Fast Recovery</h3><p><strong>The several events should do in the Fast Recovery state</strong><br></p>\n<ul>\n<li>The value of cwnd increased by $1$ MSS for every duplicate ACK received for the missing segment that caused TCP enter the fast-recovery state.</li>\n<li><p>When the ACK arrived for the missing segment , the sender set $cwnd = ssthresh$ and turn into congestion avoidance state .</p>\n</li>\n<li><p>If the timeout occurred , the sender  set the value of ssthresh to half the value of cwnd and set the value of cwnd to $1$ MSS, then turn into slow start state.<br><br><strong>The relationship between the three kinds of state</strong><br><br><img src=\"The-three-state-of-congestion-algorithm.png\" alt=\"The-three-state-of-congestion-algorithm.png\"><br><br><strong>Congestion window size changes along with time Ignoring theinitial slow-start period when a connection begins and assuming that losses are indi-cated by triple duplicate ACKs rather than timeouts.<br></strong><br><img src=\"Congestion-window-size-changes-along-with-time.png\" alt=\"Congestion-window-size-changes-along-with-time.png\"><br></p>\n</li>\n</ul>\n"},{"title":"Chapter4-The-Network-Layer","index_img":"/Picture/ipv4-ipv6.jpg","date":"2020-05-18T07:01:46.000Z","banner_img":null,"_content":"**In summary , this chapter has three major parts , The first past , section 4.1 and 4.2 cover the network layer function and services. The second part , section 4.3 and 4.4 covers forwarding , finally , the third past ,  section 4.5 through 4.7 covers routing.<br>**\n\n\n# 4.1 Introduction \nThe first past is used to introduce network layer function and services.<br>\n## 4.1.1 Forwarding and Routing\n- **Forwarding :** When the packet arrives at router's input link , the router must move the packet to the appropriate output link. Section 4.3 we will look inside router and examine how a packet is actually forwarded from an input link to output link within a router.<br>\n\n- **Routing :** The network layer must determine the route or path taken by packets as they flow from sender to receiver. The algorithm that calculated these paths are referred to as routing algorithm . We will discuss routing algorithm inside at section 4.5<br>\n\n**Forwarding table :** A router forwards a packet by examining the value of a field in the arrived packet's header and use the header value to index into the router's forwarding table. The value stored in forwarding table entry for indicate the router's outgoing link interface to which that packet is to be forwarded .<br>\n![Routing-algorithm-determine-value-in-forwarding-table](Routing-algorithm-determine-value-in-forwarding-tables.png)<br>\n\n**How to configure the forwarding table of all router at the network.**<br>\nThe answer is though the routing algorithm. The router receive the routing protocol message which are used to configure its forwarding table.<br>\n\n**Routing algorithm:** The routing algorithm has two kinds , one is centralized , another is decentralized.<br>\n- *centralized :*  Every router has complete information about all other router in the network and the traffic status of the network. These algorithm is known as LS (link state) algorithm.<br>\n- *decentralized :* Earn router have information about the routers it is directly connected to -- it doesn't know every router in the network. (These algorithm also known as DV (distance vector) algorithm.)\n\n## Connection Setup \nAddition to the two importance function (forward and routing) , the third importance function is **connection setup.**<br>\nWe will examine connection setup in Section 4.2.<br>\n\n## 4.1.2 Network Service Models\n\n|**Questions:**|\n|:-----:|\n|*When the transport layer at a sending host transmits a packet into the network layer , can transport layer rely on the network layer to deliver the packet to destination ?*|\n|*When multiple packets is sent , will they be delivered to the transport layer in the receiver's host in order in which they were sent ?*|\n|*will the amount of time between the send of two sequential packet transmission be same as the amount of time between their reception?*|\n|*will the network provide the feedback about the congestion in the network?*|\n|*what is the abstract view(properties) of the channel connecting the transport layer in the sending and receiving hosts?*|\n**The answer depend on provided network service model.<br>\nThe specific services that could be provide by network layer include :<br>**\n\n\n|Network Service Models| Description| \n|:-----:|:-----:|\n| *Guaranteed delivery*| This service guaranteed that packet will eventually arrive at destination. |\n| *Guaranteed delivery with bounded delay*| This service not only guaranteed delivery of packets , but also delivery within a specified host-to-host delay bounded. |\n| *In-order packet delivery*| This service guaranteed that packet arrived at the destination in the order that they were sent.|\n| *Guaranteed minimal bandwidth*|The network layer service emulates the behavior of transmission a specified bit rate (for example 1Mbps) between sending and receiving host. As long as sending host transmits bits at a rate below the specified bit rate , then no packet lost and packet arrived within a prespecified host-to-host delay.(for example 40 msc).|\n| *Guaranteed maximum jitter*| The service guaranteed that the amount of time between the transmission of two successive packets at the sender is equal to the amount of time between their receipt at destination.(or that this spacing changes by no more than some specified value).|\n| *Security service*|Using a secret session key known by a source and destination host , the network layer in the source host could encrypt the payloads of all datagrams being sent to the destination , the network layer in the destination host would then be responsible for decrypting the payloads. In addition to confidentiality, the network layer could provide data integrity and source authentication services.|\n\n### Internet , ATM CBR and ATM ABR service models.\n- **Internet-Best-effort-service**\n- **Constant bit rate (CBR) ATM network service**\n- **Available bit rate (ABR) ATM network service**\n![Internet-ATM](Internet-ATM.png)<br>\n\n# 4.2 Virtual Circuit and Datagram Networks\nSimilar to UDP and TCP , the network layer also provide the connectionless service and connection-oriented service.<br>\n\nIn all computer network architectures to data (Internet , ATM , frame relay , and so on ) the network layer provides either a host-to-host connectionless service or a host-to-host connection service , but not both . Computer networks that provide only a connection service at network layer are called **Virtual-circuit(VC) networks** , computer network that provide only connectionless service at the network layer are called **datagram networks**.\n\n## 4.2.1 Virtual-Circuit Networks\n**A VC consists of :**<br>\n(1). A path (that is , a series of links and routers) between the source and the destination hosts <br>\n(2). VC number one number for each link along the path .<br>\n(3). Entries in the forwarding table in each router along the path. A packet belonging to a virtual circuit will carry a VC number in its header. Because a virtual circuit may have a different VC number on each link. Each intervening router must replace the VC number of each traversing packet with a new VC number . The new VC number is obtained from forwarding table.<br>\n\n**For example:**<br>\nsuppose The host A request to establish VC connection between itself and host B , We choose the path is A-R1-R2-B , suppose we set 12 , 22 and 32 to these three link. Hence , the value of VC number field is 12 when the packet leave  host A , the value of VC number field is 22 when the packet leave  R1 , the value of VC number field is 32 when the packet leave  R2 .\n![Simple-Virtual-Circult-Network.png](Simple-Virtual-Circult-Network.png)<br>\n![Simple-VC-Path.png](Simple-VC-Path.png)<br>\n\nWhenever a new VC is established across a router , an entry is added to the forwarding table . Similarly , whenever a VC terminates , the appropriate entry in each table along its path are removed. -- **In a VC network , the network router must maintain connection state information for each ongoing connection**<br>\n\n**Three identifiable phases in a virtual-circuit network.**<br>\n- **VC setup:** The network layer determines the path between sender and receiver , that is the series of link and routers through which all packets of VC will travel. The network layer also determines the VC number for each link along the path. Finally , the network layer add the entry to forwarding table in each router along the path. During the VC setup , the network layer may also reserve resource (for example : bandwidth) along the path of VC.\n- **Data transfer :** The VC connection have been established , packets can being flow along the VC.\n- **VC teardown:** This is initiated when the sender (or receiver) informs the network layer of its desire to terminate the VC connection , The network layer will typically inform the end system on the other side of the network of call termination and update the forwarding tables in each of packet routers on the path to indicate that the VC no long exist.<br>\n\n**Signaling Message and Signaling Protocol**<br>\n- **Signaling Message:** The message that the end systems send into the network to initiate or terminate a VC , the message passed between the routers to setup the VC (that is to modify connection state in router table ).\n- **Signaling Protocol :** The protocol used to exchange signaling message are often referred to as signaling protocol.\n![Virtual-Circuit-Setup.png](Virtual-Circuit-Setup.png)<br>\n\n*More detail about the signaling protocol and signaling message see [Black 1997] for a general discussion of signaling in connection-oriented networksand [ITU-T Q.2931 1995] for the specification of ATM’s Q.2931 signaling protocol.*<br>\n\n## 4.2.2 Datagram Networks\nIn the datagram networks , each time and end system want to send a packet , it stamps the packet with the address of the destination end system and then pop the packet into the network . As shown in figure follow , **these is no VC setup and routers do not maintain any VC state information (because there are no VCs)**\n![Datagram-Network.png](Datagram-Network.png)<br>\n\nAs a packet is transmitted from source to destination , it passes through a series of routers , Each of these router use the packet's destination address to forward the packet , Specifically , each router these of router has a forwarding table map the destination address to link interfaces , When a packet arrived at the router , the router use the packet's destination address to look up appropriate link interface in the forwarding table , the router then intentionally forwards the packet to the output link interface. <br>\n\n![Datagram-Forwarding-Table.png](Datagram-Forwarding-Table.png)<br>\nWhen these are multiple matches , the router uses the **longest prefix matching rule** that is finding the longest matching entry in the forwarding table , and then forwards the packet to link interface associated with the longest prefix match.<br>\n\n*The time scale at which this forward state information (forward table entry) change is relatively slow. Indeed in a datagram network the forwarding table are modified by routing algorithm. which typically update a forwarding table every one-to-five minutes or so.* \n\n# 4.3 What's Inside a Router?\n\nA high-level view of a generic router architecture is shown in figure follow . Four router components can be identified :<br>\n- **Input port :** An input port perform several key functions .\n\t- It performs the physical layer function of terminating an incoming physical link at router. (Occurring in leftmost box of input port\nand rightmost box of output port.)<br>\n\t- It performs the link-layer functions needed to interoperate\nwith the link layer at other side of incoming link . (Occurring in middle box in the input and output ports)<br>\n\t- It perform the lookup functions that is the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. (Occurring in the rightmost box of input port)\n- **Switching Fabric :** The switching fabric connects the router's input port to its output port.<br>\n- **Output port:** An output port store the packet from switching fabric and transmits these packets on outgoing link by performing the necessary link-layer and physical-layer functions.<br>\n- **Routing Processor :** The routing processor executes the routing protocol (study in section 4.6) maintain routing table and attached link state information and computer the forwarding table for the router .It also perform the network management (study in chapter 9).\n![Router-Architecture.png](Router-Architecture.png)<br>\n\nA router input port , output port and switch fabric together implement the forwarding function and almost always implemented in the hardware.<br>\n\n## 4.3.1 Input Processing\nThe lookup performed in the input port is central to the router's operation -- it is here that the router uses the forwarding table to lookup the output port to which an arrived packet will be forwarded via switching fabric , the forwarding table is computed and updated by the router processor. The forwarding table is copied from the routing processor to the line cards over separate bus (eg: PCI bus). With the forwarding table copies , forwarding decision can be made locally , at each input port , without invoking the centralized routing processor. Once a packet's output port have been determined via the lookup , the packet can be sent into the switching fabric.<br>\n![Input-Port-Processing.png](Input-Port-Processing.png)<br>\n\n**Although lookup is arguably the most importance action in input port processing many other action must be taken :** <br>\n- Physical and link layer processing must be occur as discussed above;\n- The packet's version number , checksum and time-to-live-field (We will study in section 4.4.1)<br>\n- counter used to network management (such as the number of IP datagram received) must be updated.\n\n## 4.3.2 Switching \n![Three-Switching-Techniques.png](Three-Switching-Techniques.png)<br>\n**Switching can be accomplished in a number of way , as shown in figure above.<br>**\n- **Switching via memory :** The simplest , earliest routers were traditional computers with switching between the input ports and output ports being done direct control of the CPU (routing process). Input port and output ports functioned as traditional I/O devices in traditional operating system. An input ports with an arriving packet signaled the routing process via an interrupt , The packet was then copied from input port to processor memory. The routing process was then extracted the destination address from the header , look up the appropriate outpost in the forwarding table , and copied the packet to the output post's buffer.\n**Note that two packet can not be forwarded at the same time even if they has different destination ports. So that packets transferring speed is very slow.** Many modern routers switch via memory. A major difference from early routers,however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards.\n\n- **Switching via bus:** In this approach , an input port transfers packet directly to output port without intervention by the routing process. This is typically done by having the input port pre-pend a switching internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. The packet is received by all output posts , but only the port that matches the label will keep this packet. The label is then removed at the outpost port. **If multiple packets arrive to the router at the same , each at a different input ports , all but one must wait since only one packet can cross the bus at a time .(The roundabout could only contain one car at a time)**\n\n- **Switching via an interconnection network:** A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports and N output ports . Each vertical bus intersects intersects each horizontal bus at a crosspoint , which can opened and closed at any time by switching fabric controller. When a packet arrives from post A and need to be forwarded to post B , the switch controller closes the crosspoint at intersection of buses A and Y and port A sends the packet onto its bus , which is picked up (only) by bus Y. Note that the packet from B need to be forwarded to post X at the same time , **crossbar network are capable of forwarding multiple packet in parallel, However if two different input post destined to same output post , the one have to wait at the input port.**\n\n## 4.3.3 Output processing\nOutput post processing take packets that have been stored in the output port's memory and then transmit them over the output link. This include selecting and de-queueing packet for transmission and performing the needed link-layer and physical-layer transmission functions.<br>\n![Output-Port-Processing.png](Output-Port-Processing.png)<br>\n\n## 4.3.4 Where Does Queueing Occur ?\nIt's clear that packet queue may form at both the input port and the output port.<br>\n![Output-Port-Queueing.png](Output-Port-Queueing.png)<br>\nIn this scenario (*$R_{switch}$ fast enough $R_{link}$* ), packets arriving at each of N input ports and destined to same the output port. Since the output port can transmit only a single packet in a unit of time(a packet transmission time) . The N arriving packets will have to queue(wait) for transmission over to outgoing link. Eventually if the number of queued packets grow large enough to exhaust available memory at the output port , in which case packet are dropped.<br>\nA consequence of output port queueing is that **packet scheduler** at the output port must choose a packet among those queued for transmission. The selection may be first-come-fist-served (FCFS) , weighted fair queueing (WFQ) which shares the outgoing link fairy among the different end-to-end connections that have packets queued for transmission.<br>\nSimilarly , if there is not enough memory to buffer an incoming packet , a decision must be made to either drop arriving packet or remove one or more already-queued packets to make room for newly arriving packet.\nFor example : *Active Queue Management (AQM) algorithm* and *Random Early Detection (RED) algorithm*<br>\nIf *$R_{switch}$ not fast enough $R_{link}$* The switch fabric to transfer all arriving packets though the fabric without delay , then packet queueing can also occur at the input ports that is packets must join input port to wait turn to be transferred though the switching fabric to output port.<br>\n![HOL-Block-At-An-Input-Queued-Switch.png](HOL-Block-At-An-Input-Queued-Switch.png)<br>\nFigure above shown an example , and suppose that<br>\n**(1)**.the switching fabric is crossbar switching fabric.<br>\n**(2)**.Packets are moved from a given input queue to their desired output queue in an FCFS manner. Two packets (*darkly shaded, port 1,3*) at the front of their input port queues are destined for the same upper-right output port. Suppose that the switching fabric choose to transfer the packet from the front of the upper-left queue. In this case the packet in lower-left queue must wait , not only darkly shaded must be wait , but also the lightly shaded packet that behind the darkly shaded in the lower-left queue even though it destined for middle-right output port . This phenomenon is knowns as **head-of-the-line (HOL) blocking.**\n\n# 4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.\n**Inside of the Internet's Network Layer:**<br>\n![A-Look-Inside-The-Internet-Network-Layer.png](A-Look-Inside-The-Internet-Network-Layer.png)<br>\n**The three major component inside the internet network:**\n- **IP Protocol**\n- **Routing Component (Routing protocol study in section 4.6)**\n- **Report error and in datagram and respond to request for certain network-layer information. Internet Contorl Message Protocol (ICMP) studied in section 4.4.3**\n\n## 4.4.1 Datagram Format\nThe network-layer packet is referred to as a datagram.<br>\n**Ipv4-Datagram-Format:**<br>\n![Ipv4-Datagram-Format.png](Ipv4-Datagram-Format.png)<br>\n**The key field of Datagram format are following:**<br>\n- **Version number :** These 4 bits specify the IP protocol version of the datagram , by look at the version number , the router can determine how to interpret the remainder of IP datagram . Different Version of IP use different datagram format.<br>\n- **Header length:** Because the IPv4 datagram contain a variable number of options (which are included in the IPv4 datagram header) This 4 bits is needed to determine where the data actually being in the datagram . Most Ipv4 datagram don't contain option , so the typical IP datagram has a 20 bytes header.\n- **Type of service:** The type of service bits were included in ipv4 header to allow different types of datagram (for example : requiring low delay , hight throughput or reliability).\n- **Datagram length:** This is a total length of the IP datagram (Header Plus Data) , since this field is 16 bits , so that the maximum size of the IP datagram is 65535 bytes, however datagram rarely larger than 1500 bytes.\n- **Identifier , flags , fragmentation offset:** These three field we will consider depth in shortly.\n- **Time-to-live:** The field used to ensure that datagram don't circulate forever in the network.\n- **Protocol :** The value of this field is used to indicates the specific transport-layer-protocol to which the data portion of this datagram should be passed , for example the value 6 represent TCP and the value 17 represent UDP.\n- **Header Checksum :** The header checksum aids a router detecting bit error in a received IP datagram.<br>\n**Why does TCP/IP perform error checking at both the transport and network layer.**<br>\n\t- *only the IP header is checksummed at the IP layer while the TCP/UDP checksum is computed over the entire TCP/UDP segment.*\n\t- *TCP/UDP and IP do not necessarily both have to belong to the same protocol stack. IP also can service other protocol (different to TCP/UDP).*\n- **Source and Destination IP Addresses**\n- **Options :** The options flied allow an IP header to be extended.\n- **Data field (payload):** In most circumstance , the data field of the IP datagram contains the transport-layer segment (for example UDP/TCP) . However , the data field can carry other types of data such as ICMP message .\n\n### IP datagram fragmentation \nSince not all link-layer protocol can carry network-layer protocol of the same size . Some protocol can carry big datagrams , whereas other protocols can only a little packets. (for example : Ethernet frames carry 1500 bytes of data, the wide-area links can no more than 576 bytes.)<br>\n\n*Because each IP datagram is encapsulated within the link-layer frame for transport from one router to next router. The problem is that each of link along the router between sender and destination can use different link-layer protocols and each of those protocol can have different MTUs(maximum transmission unit).<br>*\n\nSuppose the router have MTU that is smaller than the length of the IP datagram . How to squeeze this oversize IP datagram into the payload field of the link-layer frame?<br>\nThe solution is to fragment the data in the IP datagram into two or more smaller IP datagrams , encapsulate each of these smaller IP datagram in a separate link-layer frame and send these frames over the outgoing link . Each of these smaller datagram is referred to as a fragment.<br>\nFragment need to reassembled before they reached the transport layer at the destination . Indeed both TCP and UDP expecting to complete, unfragmented segment from the network layer.<br>\n\n**How to determine a packet whether or not a fragment , how to reassemble these fragment and when the destination host have received the last fragment of some original larger datagram.**<br>\nThe answer is three field in the ipv4 datagram header.<br>\n- **16-bits-identifier field:** When a datagram is created , the sending host stamps the datagram with an identification number as well as source and destination address. Typically , the sending host increments the identification number of each datagram it sends.<br>\n- **13-bits Fragmentation offset:** When a router need to fragment a datagram , each resulting fragment is stamped with the source and destination address , and identification number of original datagram , and then the Fragmentation offset field is used to specify where the fragment fit within the original IP datagram.*(unit is bit)*\n\n- **Flags field:** This field is used to identify the last fragment of Original Ipv4 datagram . The last fragment has a flags bit set to 0 , and other fragment has a flags bit set to 1.<br>\n![IP-fragmentation-and-reassembly.png](IP-fragmentation-and-reassembly.png)<br>\n![Ip-fragments.png](Ip-fragments.png)<br>\nIf one or more fragment does not arrive , the incomplete fragments is discarded and not passed to transport layer , and The transport layer protocol is TCP , TCP will recover this loss by retransmission.<br>\n\n## 4.4.2 IPv4 Addressing\n- **Interface :** The boundary between the host and physical link is called an interface.\n\n**A router has multiple interfaces and each of these interfaces have its own unique IP address.**\n![Interface-Address-And-Subnets.png](Interface-Address-And-Subnets.png)<br>\n- **Subnet:** To determine the subnet detach each interface from its host and router , creating islands of isolated networks with interfaces terminating the end points of isolated networks , Each of these isolated networks is called a subnet.<br>\n\nShown as figure above , In the upper-left , this network interconnecting three host interfaces and one router interface forms a **subnet**. IP addressing assigns an address to this subnet : 223.1.1.0/24 , where the /24 notation , sometime known as **subnet mask**, Indicate that the leftmost 24-bits of 32-bits quantity define the subnet address.\n\nThe internet's addressing assignment strategy is known as **Classless Interdomain Routing (CIDR)** As with subnet addressing , the 32-bits IP address is divided into two parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the number of bits in the first past of the address (**network prefix**) . When we cover the internet BGP routing protocol in the section 4.6 , we will see that only these leading x prefix bits are considered by routers the organization's network. That is when a router outside the organization forwards a datagram whose destination address is inside the organization only these leading x bits of the address need be considered . The remaining $32-x$ bits of an address can be though of as distinguishing among the devices within the organization. These bits will be considered when forwarding packets at routers within the organization.<br>\n\n*The special IP address : 255.255.255.255 (IP broadcast address), when a host send a datagram with destination address 255.255.255.255, this message is delivered to all host on the same subnet.*\n\n### Obtaining a Block of Address\n*Internet corporation  for Assigned Name and Number (ICANN) has responsibility for managing the IP address space and allocating address blocks to ISPs and other organizations.<br>*\n\nIn order to obtain a block of IP addresses for use within an organization's subnet , a network administrator might first contract its ISP , while would provide addresses from a larger block of addresses that had already been allocated to the ISP. For example , the ISP may itself have been allocated the address block 200.23.16.0/20 ,the ISP divide its address block into eight equal-sized contiguous address block and give one of these address block out to each of up to eight organizations.<br>\n![Organization-Address.png](Organization-Address.png)<br>\n\n### Obtaining a host Address : The Dynamic Host Configuration Protocol\nOnce an organization obtained a block of addresses it can assign individual IP address to host and router interface in its organization.\nThe router IP address typically manually configure by a system administrator. The host IP address typically configure by using **Dynamic Host Configuration Protocol (DHCP)** DHCP allows a host obtain an IP address automatically. As the host join and leave , the DHCP server need to update its list of available IP addresses.<br>\n\nDHCP is a client-service protocol . A client is typically a newly arriving host wanting to obtain network configuration informations. Each subnet have a DHCP service . If no server is present on the subnet , a DHCP relay agent (typically a router) that knows the address of a DHCP service for that network is needed , for example show as figure below , DHCP service attached to subnet 223.1.2/24 , with the router serving as relay agent for arriving clients attached to subnet 223.1.1/24 and 223.1.3/24 .<br>\n![DHCP-Client-Server-Scenario.png](DHCP-Client-Server-Scenario.png)<br>\n\n**When a newly arriving host income to subnet , The DHCP has four steps for assign a IP address to new host.<br>**\n- **DHCP server discovery:**  This is done using **DHCP discovery message** The new host send a DHCP discovery message with a UDP packet , port 67 source IP address : 0.0.0.0 (since , new host hasn't IP address) and destination IP address : 255.255.255.255 (broadcast address). The UDP packet is encapsulated in a IP datagram and then passed to the link-layer. (We will cover the detail of broadcast in section 5.4)<br>\n\n- **DHCP server offer(s) :** A DHCP server receiving a DHCP discovery message responds to the client with the **DHCP offset message** that is broadcast to all notes on the subnet using the broadcast IP address : 255.255.255.255. Each server offer message contain the transaction ID of the receiver discovery message , the proposed IP address for the client , the network mask , and an IP address lease time . \n\n- **DHCP request :** The newly arriving client will choose from among one or more server offers and respond to its selected offer with **DHCP request message** echoing back the configuration parameters.\n\n- **DHCP ACK:** The server responds to the DHCP request message with a **DHCP ACK message** confirming the requested parameters.<br>\n\n*yiaddr(as in “your Internet address”)*\n![DHCP-Client-Server-Interaction.png](DHCP-Client-Server-Interaction.png)<br>\nOnce the clients receives the DHCP ACK , the interaction is compelte and client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease's expiration , DHCP also provide a mechanism that allow a client to renew its lease on an IP address.<br>\n\n### Network Address Translation (NAT)\nWith proliferation of small office , home office (for example , the kid at home not only their computer but have one or more smartphone and networked game ..etc) , the ISP have not enough IP address to handle this scenarios , what should we do in this scenarios.<br>\n\nThe answer is NAT (Network Address Translation)<br>\n**Figure follow is show the operation of NAT-enabled router.<br>**\n![Network-Address-Translation.png](Network-Address-Translation.png)<br>\nIn figure above all traffic leaving the home router for for the larger internet has a source IP address of 138.76.29.7 and all traffic entering the home router must have a destination IP address 138.76.29.7. In essence the NAT-enabled router is hiding the detail of the home network from the outside world.<br>\n\n- **Question: How the home network computer (or other network device) get their home IP address (for example 10.0.0.0/24)?**<br>\nThe answer is DHCP , The router get its IP address from the ISP's DHCP server and the router runs a DHCP server to provide addresses to computer (or other device ) within the NAT-DHCP-router-controlled-home-network's-address-space.<br>\n\n- **Question : If all datagram arriving at the NAT-Router from the WAN have the same destination IP address , how does the router know the internal host which it should forward a given datagram.** <br>\nThe trick is use a **NAT translation table** at the NAT router , and to include port number as well as IP addresses in table entries. For example shown as figure above , the host computer 10.0.0.1 request a web page on some web server (port 80) with IP address 128.119.40.186 . The host 10.0.0.1 assigns the (arbitrary) source port number 3345 and send the datagram into the LAN , The NAT-Router receives the datagram , genarates a new source port number 5001 , replace the source IP address with it WAN-side IP address 138.76.29.7 and replace the original source number 3345 with its new source port number 5001. NAT-Router adds an new entry to its NAT translation table and send a new datagram to WAN , when a datagram arriving at the NAT-Router , the NAT-Router use the destination IP address and destination port to obtain appropriate IP address (10.0.0.1) and destination port (3345) , then send a datagram to home network.\n\n### UPnP \nThe detail we can see the textbook page 352.\n\n## 4.4.3 Internet Control Message Protocol (ICMP)\nICMP protocol is used by hosts and router communicate network-layer informations to each other. The most typical use of ICMP is error reporting.<br>\nThe ICMP message is carried inside the IP datagrams , that is ICMP messages are carried as IP payload.<br>\n\nICMP message have a type field and a code field and checksum field.<br>\n![General-en.svg.png](General-en.svg.png)<br>\n\n**The ICMP control message :**<br>\n![ICMP-Message-Types.png](ICMP-Message-Types.png)<br>\n\n## 4.4.4 IPv6\n\n### IPv6 Datagram Format \n**Most importance changes introduced in IPv6 :<br>**\n\n-  **Expanded addressing capabilities :** IPv6 increases the size of the IP address from 32 bits to 128 bits . This ensure that the world won't run out of IP address. In addition to unicast and multicast address , IPv6 introduced a new type of address called **anycast address**<br>\n\n- **A streamlined 40-byte header :** A number of IPv4 fields have been dropped or made optional , The resulting 40-bytes-fixed-length header allows for faster processing of the IP datagram . A new encoding of option allow for more flexible option processing.\n\n- **Flow labeling and priority :** The IPv6 header also has an 8-bits traffic class field. This field can be used to give priority to certain datagram within a flow or it can be used to give priority to datagram from certain application (for example ICMP) over datagram from other applications (for example : network new).\n\n![IPv6-Datagram-Format.png](IPv6-Datagram-Format.png)<br>\n\n**The following fields defined in IPv6:**\n- **Version :** This 4-bits field identifies the IP version number.<br>\n- **Traffic class :** This 8-bits field is similar in spirit to the TOS (Type of service) field we saw in IPv4.\n- **Flow label :** This 20-bits is used to identify a flow of datagrams.<br>\n- **Payload length :** This 16-bits is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fix-length 40-byte datagram header.\n- **Next header :** This field is used identifies the protocol to which the content of this datagram will be delivered. This field uses the same values as the protocol field in the IPv4 field.\n- **Hop limit :** The content of this field are decremented by one by each router that forward the datagram . If the hop limit count reaches zero , the datagram is discarded.\n- **Source and destination address :** 128-bits IP address.\n- **Data :** This is the payload portion of the IPv6 datagram.\n\n**The several fields appearing in the IPv4 datagram are no longer present in the IPv6 datagram.**<br>\n\n- **Fragmentation/Reassembly :** IPv6 do not allow for fragmentation and reassembly at intermediate . These operations performed only by the source and destination . If an IPv6 datagram received by a router is too large to be forwarded over the outgoing link , the router simply drops the datagram and sends \"a packet too big\" ICMP error message back to the sender , the sender can then resend the packet using a smaller IP datagram size. Fragmentation and reassembly is a time-consuming operation ; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up IP forwarding within the network.\n- **Header checksum :** Because the transport-layer and link-layer protocols in the internet layers perform checksumming , the designers of IP protocol felt that this functionality was sufficiently redundant in the network layer could be removed. The IPv4 header checksum needed to recomputed at every router , As with fragmentation and reassembly , this too was a costly operation in IPv4.\n- **Options :** An options field is no longer a part of the standard IP header. However , it has not gone away . Instead the option field is one of possible next header pointed to from within the IPv6 header . Just as TCP or UDP protocol headers can be the next header within an IP packet .\n\n*A new version of ICMP protocol is known as ICMPv6 , that is used to service for IPv6*\n\n\n### Transitioning from IPv4 to IPv6\nWe have two approaches for gradually integrating IPv6 hosts and routers into an IPv4 world (with the long-term goal, of course, of having all Ipv4 node eventually translation to IPv4).<br>\n\n**Dual-Stack Approach :**<br>\nThat is IPv6 nodes also have complete IPv4 implementation. That has the ability to send and receive an both IPv4 and IPv6 datagram ; when interoprating with an IPv4 node an IPv6/IPv4 node can use IPv4 datagram , when interopratig with an IPv6 node it can speak IPv6. IPv6 and IPv4 nodes must have both IPv6 and Ipv4 address.<br> \n![A-Dual-Stack-Approachs.png](A-Dual-Stack-Approachs.png)<br>\n\n**Problem :** <br>\nAs figure above , The node A communicate with node F , and node A send a datagram to node F , when a datagram is sent from node B (IPv6) to node C (IPv4) , The node B must create a new datagram to send to node C , the data field of the IPv6 can be copied into the data field of the IPv4 datagram and appropriate address mapping can be done . However , in performing the conversion from IPv6 to IPv4 , there will be IPv6-specific fields in the datagram (for example the flow identifier field) that have no counterpart in IPv4 , The information in these fields will be lost.<br>\n\n**Tunneling (An alternative to the dual-stack approach):**<br> \n*Tunneling can solve the problem note above.*<br>\n![Tunneling.png](Tunneling.png)<br>\nSuppose two IPv6 nodes (for example : B and E in the figure above) want to interoperate using IPv6 datagram but are connected to each other by intervening IPv4 routers. We refer to the intervening set of IPv4 router between two IPv6 router as a **tunnel**. With tunneling , the IPv6 node on the send side of the tunnel (node B) **takes the entire IPv6 datagram and put it into the data field (payload) of IPv4 datagram.\nThis IPv4 datagram is then addressed to the IPv6 node on the receiving side of the tunnel (node E) and sent to the first node in the tunnel (node C). The IPv6 node on the receiving side of the tunnel eventually receives the IPv4 datagram (it is a destination of IPv4 datagram!) determine that IPv4 datagram contain an IPv6 datagram , extract the IPv6 datagram and then routes the IPv6 datagram exactly as it would if it had received the IPv6 datagram from a directly connected IPv6 neighbor.<br>\n\n## 4.4.5 A Brief Foray into IP Security\nUsing IPsec protocol provide security service . (more detail see the chapter 8).\n\n# 4.5 Routing Algorithm \n**Routing Algorithm operating in network routers , exchange and compute the information that is used to configure these forwarding table .**<br>\nWhether network layer provide datagram service (packet between the source and destination may takes many different routes)or VC service (packet between the source and destination take the same path) , the network layer must determine the path that packets take from sender to receiver.<br>\n\n*We will see the job of routing is determine the good paths **(least-cost-path)** from senders to receivers through the network of routers.*\n\n**Classify routing algorithm according to whether they are global or decentralized.**<br>\n- **A global routing algorithm :** Computes the least-cost path between a source and destination using complete global knowledge about the network.(complete global knowledge is mean all node connectively relationship and link cost in the network). In practice algorithm with global state information are often referred to as **Link-state(LS) algorithm**.<br>\n- **A decentralized routing algorithm :** The calculation of least-cost path is carried out in an iterative , distributed manner. No node have complete information about the cost of all network link , instead each node begins with only the knowledge of the cost of its own directly attached links. Then through an iterative process of the calculation and exchange of information with its neighboring nodes , a node gradually calculates the least-cost path to destination or set of destinations. The decentralized routing algorithm is called distance-vector (DV) algorithm .\n\n## 4.5.1 The Link-State (LS) Routing Algorithm \nIn practice , The Link-State Routing Algorithm is accomplished by having each node broadcast link-state packets to all other nodes in the network , with each link-state packet containing the identifies and cost of it attached links. The result of the note's broadcast is that all node have an identical and complete view of the network.  Each node can then run the LS algorithm and compute the same set of least-cost paths as every other node.\n\nThe LS algorithm is known as **Dijkstra's Algorithm** name after its inventor. A closely related algorithm is Prim's Algorithm .\n\n**Let us define the following notation:**<br>\n- **D(v) :** Cost of the least-cost path from the source to destination v as of this iteration of the algorithm.\n- **P(v) :** Previous node (neighbor of node v) along the current least-cost path from source to node v.\n- **N':** subset of nodes , if v in **N'** represent the least-cost path from source to v have been definitely known.\n\n![Graph-Of-Link-State-Algorithm.png](Graph-Of-Link-State-Algorithm.png)<br>\n\n*Link-State Algorithm For Source Node u*<br>\n\n```c++\nInitialization :\n\tN' = {u};\n\tfor all nodes v \n\t\tif v is a neighbor of u \n\t\t\tthen D(v) = c(u,v)\n\t\telse D(v) = ∞\nLoop :\n\tFind w not in N' simultaneously D(w) is a minimum\n\tAdd w to N'\n\tUpdate D(v) for each neighbor v of w and not in N' : \n\tD(v) = min ( D(v) , D(w)+c(w,v) );\nUntil : N' = N ( N is set of all node )\n```\n![Result-Of-LS-Algorithm.png](Result-Of-LS-Algorithm.png)<br>\n \n**The detail of step can watch the video follow:**<br> \n\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/ud7qWRBirsk\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n**Problem of LS algorithm :**<br>\n\n**Figure follow shown a simple network topology where link costs are equal to the load carried on the link.**\nIn this example , link cost are not symmetric that is the C(u,v) equal to C(v,u) only if the load carried on the both directions on the link(u,v) is same . <br>\n\n**In this example , node z originates a unit of traffic destined for node w , node x also originates a unit of traffic destined for node w and node y injects an amount of traffic equal to e also destined for node w .**<br>\n\n**The order of looking at figure is a->b->c->d**<br>\n\n![Oscillations-With-Congestion-Sensitive-Routing.png](Oscillations-With-Congestion-Sensitive-Routing.png)<br>\n\nWe can see the **Oscillation** with congestion sensitive routing.<br>\n\nWhat can be done to prevent such oscillation ?<br>\nOne solution would be to mandate that link costs not depend on the amount of traffic carried -- an unacceptable solution since one goal of routing is to avoid highly congested links, Another solution is to ensure that not all routers run the LS algorithm at the same time.\n\n## 4.5.2 The Distance-Vector (DV) Routing Algorithm\nWhereas the LS algorithm is an algorithm using global information , the **distance-vector algorithm** is *iterative , asynchronous , and distributed. <br>*\n- It is distributed in that each node receive some information from its directly attached neighbors , perform a calculation and distributed the result of its calculation back to its neighbors.<br>\n\n- It is iterative in that , this process continue on until no more information is exchanged between the neighbors.<br>\n\n- It is asynchronous in that is does not require all of the nodes to operate in lockstep with each other.<br>\n\n**The Distance-Vector Routing Algorithm also known as Bellman-Ford Algorithm**<br>\n\nFor get the least-cost paths , we need to using the celebrated **Bellman-Ford equations:**<br> **$d_{v}(y)$ is distance from $v$ to $y$**\n$$d_{x}(y)=min_v{c(x,y)+d_v(y)}$$\nWhere the $min_{v}$ in the equation is taken over all of x's neighbors.After traveling from x to v , if we then take the least-cost path from v to y , the path cost will be $c(x,y)+d_{v}(y)$ . Since we must begin by traveling to some neighbor $v$ , the least cost from $x$ to $y$ is the minimum of $c(x,y)+d_{v}(y)$ taken over all neighbor $v$.\n\n**Distance-Vector (DV) Algorithm:** <br>\nat each node ,x:<br>\n\n**Initialization :** <br>\n&nbsp; &nbsp;  &nbsp; &nbsp; for all destinations $y$ in $N$ : <br>\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp;$D_{x}(y)$ = $c(x,y)$  &nbsp; /\\* if y is not a neighbor then $c(x,y)$ = $\\infty$ \\*/ <br>\n&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br> \n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; $D_{w}(y)$ = $?$ &nbsp; /\\* for all destinations $y$ in $N$ \\*/<br>\n&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br>\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; send distance vector $D_{x} = [ D_{x}(y) : y$ in $N ]$ to $w$<br>\n**Loop**<br>\n&nbsp; &nbsp; **wait** (until i see a link cost change to some neighbor $w$ <br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t&nbsp;&nbsp;or until i receive a distance vector from some neighbor $w$) <br>\n&nbsp;&nbsp;&nbsp; for each $y$ in $N$ :<br>\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t$D_{x}(y)$ = $min_{v} \\{c(x,y) + D_{v}(y)\\}$<br>\n&nbsp;&nbsp;&nbsp;if $D_{x}(y)$ changed for any destination $y$ <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; send the distance vector $D_{x}$ = $[D_{x}(y) : y$ in $N]$ to all neighbors<br>\n**Forever** <br>\n\n**A simple three node illustrates the operation of DV algorithm**<br>\n![DV-Simple-Example.png](DV-Simple-Example.png)\n\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/dmS1t2twFrI\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n### Distance-Vector Algorithm : Link-Cost Changes and Link failure\n![Changes-in-link-cost.png](Changes-in-link-cost.png)<br>\n\nFigure (a) above illustrates a scenario where link cost from y to x distance vector change from 4 to 1. We force here only on y' and z' distance table entires to destination x. The Dv algorithm causes the following sequence of events to occur :<br>\n- At time $t_{0}$ , $y$ detects the link-cost change (the cost has change from 4 to 1 ) updates its distance vector and inform the neighbors of this change since its distance has changed.\n- At time $t_{1}$ , $z$ receives the update from $y$ and update its table . It computer a new least cost of $x$ (it has decreased from a cost of 5 to cost of 2 ) and send its new distance vector to its neighbors.\n- At time $t_{2}$ , $y$ receive $z's$ update and updates its distance table . $y's$ least cost do not change hence $y$ does not send any message to $z$. The algorithm come to a quiescent state.\n\nThus only two iterations are requited for the DV algorithm to reach a quiescent state. <br>\n\nLet now consider what happen when a link cost increases , support that support the link cost between $x$ and $y$ increases from 4 to 60 as shown in figure (b) above.<br>\n\n- Before the link cost changes , $D_{x}(y) = 4$ , $D_{y}(z) =1$ , $D_{z}(y) = 1$ and $D_{z}(x) = 5$ , $y$ detect the link cost change (the cost change from 4 to 60) , $y$ computes its new minimum-cost path to x have a cost of  \n\t$$D_{y}(x) = min \\{C(y,x) + D_{x}(x) , C(y,z)+ D_{z}(x)\\}= min \\{ 60+0,1+5\\} = 6$$ \n\tof course , with out global view of the network , we can see that this new cost via $z$ is wrong . But the only information node $y$ has is that its direct cost to $x$ is 60 and that $z$ has last told $y$ that $z$ could get $x$ with a cost of 5 . So in order to get to $x$, $y$ would now route through $z$ , fully expecting that $z$ will be able to get to $x$ with cost of 5.\n- Since node $y$ has computed a new minimum cost to $x$ , it inform $z$ of new distance vector at time $t_{1}$.\n- Sometime after $t_{1}$ , $z$ receive the $y's$ new distance vector ,which indicates that $y's$ minimum cost to $x$ is 6 . $z$ know get to $y$ with a cost of 1 and computes a new least cost to x of \n\t$$D_{z}(x) = min \\{50+0, 1+6\\}=7$$\n\tSince $z's$ least-cost to $x$ is increased , and then it inform $y$ of its new distance vector at $t_{2}$ at $t_{2}$.\n- In a similar manner , after receiving $z's$ a new distance vector , $y$ determines $D_{y}(x)=8$ and send $z$ its distance vector . $z$ then determine $D_{z}(x) = 9$ and sends $y$ its new distance vector over and over again until $D_{z}(x)= min\\{C_{z}(y)+D_{y}(x) , C_{z}(x)+D_{x}(x)\\}= min\\{50+1 ,50+0 \\}=50$ , at this point , $z$ finally ! determine that its lease-cost path to $x$ is via its direct connection to $x$.\n\n**What way could solve the problem noted above ?**<br>\nThe answer is *Poisoned Reverse.*<br>\n\n### Distance-Vector Algorithm : Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known as *poisoned reverse.* The idea is simple **if $z$ routers through $y$ to get to destination $x$ , then $z$ will advertise to $y$ that its distance to $x$ is infinity**, $z$ will advertise to $y$ that $D_{z}(x) = \\infty$ ( even though $z$ known $D_{x}(z) = 5$ in truth) $z$ will continue telling this little white lie to $y$ as long as it route $x$ via $y$ . Since $y$ believes that $z$ had no path to $x$ ,$y$ will never attempt to route to $x$ via $z$ , as long as $z$ continues to route to $x$ via $y$\nLet now see how *Poisoned Reverse* solved the particular looping problem :  When the link-cost $(x,y)$ change from 4 to 60 , $y's$ distance table indicate $D_{z}(x) = \\infty$ .\n- At the time $t_{0}$ ,$y$ update its table and continues to route directly to $x$ , albeit at the higher cost of 60 and then inform $z$ of the new distance vector to $x$ , that is $D_{y}(x) =60$ .\n- After receiving the update at $t_{1}$ , $z$ immediately shits the its route to $x$ to be via the direct $(z,x)$ link at the cost of 50, and then $z$ inform $y$ of new cost of $D_{z}(x) = 50$ .\n- After receiving the update from $z$ , $y$ update its distance table at $D_{y}(x)=51$, also , since $z$ is now on $y$'s lease-cost path to $x$ , $y$ poisoned the reverse from $z$ to $x$ by informing $z$ at time $t_{3}$ that $D_{y}(x) = \\infty$ (even though $y$ know $D_{y}(x)=51$ in trush)\n\n**Does poisoned reverse solve the general count-to-infinity problem ? It dose not , when looping involving three or more nodes will not be detected by poisoned reverse.**<br>\n\n\n### A comparison of LS and DV Algorithm\n\n- **Message complexity :** **In LS algorithm** requires each node know all cost of link in the network . The require O(|E|\\*|N|) to be sent. Also , whenever a link cost changes , the new link cost must be sent to all node in the internet. **In the DV algorithm** The node only need to exchange the information between directly connection neighbors. When a link cost change , the DV algorithm will propagate the results of the changed link cost only if the new cost results in a changed lease-cost path for one of nodes attached to that link.\n\n- **Speed of convergence :** LS is O($|N|^2$) algorithm require O(|N||E|) messages to be sent. DV algorithm can converge slowly and can have routing loops while the algorithm is converging . DV algorithm also suffers from the count-to-infinity problem. \n\n- **Robustness:** What can happen if route fails misbehaves or is sabotage? Because LS algorithm only compute own forwarding table of each node in the network , This mean route calculation are somewhat separated under LS . Providing a degree of robustness. Under DV algorithm , a node must advertise incorrect least-cost path to any all destination , so that a malfunctioning router may be cause other router flood the malfunctioning router with traffic and cause a large portions of the internet to become disconnected for up to several hours.<br>\n\n## 4.5.3 Hierarchical Routing\nIn our study of LS and DV algorithm , In practice , this model and its view of homogeneous set of routers all executing the same routing algorithm is a bit simplistic for at least two important reasons:<br>\n\n- **Scale** :Because , today's public internet consist of hundreds of millions hosts , LS algorithm updates among all of the router in public internet world would leave no bandwidth left for sending data packets, and under DV algorithm that iterated among such a large number of routers would surely never converge.\n\n- **Administrative autonomy:** The corporation / organization / individual want to run and administer its network as it wishes.<br>\n\n**Both of these problems can be solve by organizing routers into autonomous systems (ASs)**<br>\n\nEach AS consisting of a group of routers that are typically under the same administrative control ( eg : operated by the same ISP or belonging to the same company network).\n\nThe routing algorithm running within a autonomous system is called an **Intra-autonomous-system routing protocol**\nOne or more router in the AS being responsible for forwarding packets to destinations outside other AS : there routers are called **gateway router**, Obtaining reachability information from neighboring AS and propagating the reachability information to all router internal to AS are handled by the **inter-AS-routing-protocol**<br>\n![autonomous-system-graph.png](autonomous-system-graph.png)<br>\nIf a destination router of outside AS can be reached by more than one gateway router , the router inside AS can using **Hot-Potato-Algorithm** to choose which gateway router should be select. The hot-potato-algorithm is using information from Intra-AS-Routing-Protocol to choose the lease-cost path of gateway routers.\n![hot-potato-algorithm.png](hot-potato-algorithm.png)<br>\n\n\n# 4.6 Routing in the internet\n\n## 4.6.1 Intra-AS Routing in the Internet : RIP\nRIP is a distance-vector algorithm that operates in a manner very close to idealized DV protocol . Each router maintains a RIP table is known as a routing table. RIP is implemented as an application-layer process can send and receive the (require/response) message over a standard socket (port 520) and using UDP protocol.<br>\n![RIP-UDP-Application.png](RIP-UDP-Application.png)<br>\nIn RIP , routing updates are exchanged between neighbors approximately every 30 seconds using a **RIP response message**(RIP response message also known as **RIP advertisements**) . If a router does not hear from its neighbor at least once every 180 seconds , that neighbor is considered to be no longer reachable ; that is , either neighbor is died or the connecting link has gone down , when this happen , RIP modifies the local routing table and then propagates this information by sending advertisement to still alive neighbors.<br>\n\n**Let us see a simple example:**<br>\nDotted lines indicate that still has other AS connect on  ; thus this autonomous systems have many more routers and link than figure shown follow.\n![ASs-connection-graph-RIP.png](ASs-connection-graph-RIP.png)<br>\n**Routing table of Router-D before receiving advertisement from Router-A:**<br>\n![Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png](Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png)<br>\n\n**Advertisement from router A:**<br>\n![Advertisement-From-RouterA.png](Advertisement-From-RouterA.png)<br>\n**Routing table of Router-D after receiving advertisement from Router-A:**<br>\n![Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png](Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png)<br>\n\n## 4.6.2 Intra-AS Routing in the Internet : OSPF\nOSPF is a link-state algorithm that uses flooding of link-state information and dijkstra least-cost path algorithm . With OSPF protocol , a router constructs a complete topological map of the entire autonomous system , The router then locally run dijkstra algorithm to determine the shortest-path tree to all subnet. Individual link cost can be configured by the network administrator .<br>\n\nUnder OSPF protocol , A router broadcast link-state information whenever there is change in a link's state , It also broadcast information periodically (at least once every 30 minutes) even if the link's state has not changed. OSPF protocol advertisements are contains in OSPF message that carried directly by IP protocol , with a upper-layer protocol 89 for OSPF.<br>\n\nThe OSPF protocol also checks that link are operational and allows an OPSF router to obtain a neighboring router's database of network-wide link state.\n\nOPSF is conceived as the successor to RIP and as has a number of advanced feature. The advanced feature is include the following:<br>\n\n- **Security:** Exchanged between OPSF router can be authenticated , with authentication ,only trusted router can participate in OPSF protocol within an AS. Two type of authentication is can be configured -- **simple and MD5**( discuss in chapter 8).\n\n- **Multiple same-cost path:** OPSF allow multiple same-cost path to be used , don't need to select a path to carry all traffic.\n\n- **Integrated support to unicast and multicast routing:** Multicast OSPF (MOSPF).<br>\n- **Support a hierarchy within a single routing domain:** An OPSF autonomous system can be configured hierarchically into areas , Each area run its own OSPF link-state-algorithm , with each router in an area broadcasting its link-state to all other in that area. Within each area of a autonomous system has one or more **area border router** are responsible for routing packets to outside the area . And exactly one OPSF area in the AS is configured to be the **backbone** area. The primary role of the backbone area is to route traffic between the other area in the AS. *Inter-area routing* within the AS requires that the packet be first route to a area border router , and routed through the backbone to the area border router that is in the destination area , and then routed to the final destination.\n\n## 4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)\nLet's us examine how path are determined for source-destination pair span multiple ASs.<br>\nUnder BGP protocol , pair of router exchange information through semi-permanent TCP connection using port 179.<br>\nThe BGP protocol TCP connection has two type of connection : <br>\n- BGP TCP connection between router within a same AS.\n- BGP TCP connection between routers in two different ASs.\n\nTwo interconnecting router corresponding source and destination router that using TCP are called **BGP peers** . The TCP connection along with all BGP message sent over the connection is called **BGP session**.<br>\n**Two type of BGP session:**<br>\n- External BGP session (eBGP session) : The BGP message is sent span two routers.\n- Internal BGP session (iBGP session) : The BGP message is sent within an AS.\n![BGP-sessions.png](BGP-sessions.png)<br>\nIn the BGP , destinations are not a host but instead are CIDRized prefixes with each prefixes is representing a subnet or a collection of subnet.<br>\n\nIn the BGP , some ASs has a globally unique **autonomous system numbers(ASN)** , the ASs hasn't ASN is called stub AS. ASN similar to IP address are assigned by ICANN regional register.<br>\n\nWhen a router advertise prefix to outside ASs , it include with a number of **BGP attributes :** , in BGP jargon , a prefix along with its attributes is called a route. The BGP  attributes is following: <br>\n- **AS-PATH :** The attributes contain the ASN that the prefix have been passed.\n- **NEXT-HOP:** The NEXT-HOP is router interface that begins the AS-PATH. \n\n### BGP Route selection\nUnder BGP protocol , a router may be receive more than one route to the same prefix . Then BGP must be sequentially invokes the following elimination rules until one possible remain , The elimination rules is following:<br>\n\n- Routes are assigned a local preference values as one of their attributes , the routes with the highest local preference value are selected.\n- From the remaining routes ( all routes has same preference value ) with the shortest AS-PATH are selected.\n- From the remaining routes ( all routes has same preference value and same AS-PATH length) with closest NEXT-HOP are selected, here closest mean the least-cost path of a router itself interface and its corresponding eBGP session interface.\n- If more than one route still remains , the router use the BGP identifiers to select the route.\n\n### Putting all together : How does an entry get into a router's forwarding table ? \n**How does the packet is forwarded within a router ?<br>**\nWhen a packet arrive to the router , the packet's destination IP address compared with the prefixes in the forwarding table and find a longest prefix match . Then the packet is forwarded to router's port that associated with that matched prefix.<br>\n**How does an entry get into a router's forwarding table ?**<br>\n*In order to get an entry into a router's forwarding table , first , the router must be aware of the prefix. The router become aware of the prefix via a BGP route advertisement , such a route advertisement may be sent over a eBGP session or over a iBGP session. After the router become aware of prefix , it need to determine appropriate output port to which datagram destined to that prefix will be forwarded. Before it can enter that entry (prefix + port) into its forwarding table . If router receive more than one route advertisement for this prefix , it is uses the BGP selection process to select to best route for the prefix , suppose the route have been selected , the selected route include NEXT-HOP attribute , which is IP address of first router outside the router's AS along this best route. Then the router uses its Intra-AS routing protocol (typically OSPF) , to determine the shortest path to the NEXT-HOP router. The router finally determines the port number to associate with the prefix by identifying the first link along the shortest path . The router finally can enter the prefix-port pair into the forwarding table.*\n\n# 4.7 Broadcast and Multicast Routing\n\n## 4.7.1 Broadcast Routing Algorithm\n**Two type of Broadcast routing algorithm: <br>**\n- **Source-Duplication:** A packet is created and duplicated by a source router , and source router broadcast to all router in the network by unicast. This approach has several drawback is following:\n\t- inefficiency : The source router is required to copy a large amount of same packet and send these via a single link.\n\t- Additional protocol mechanisms to obtain the address of the broadcast recipient ,would add more overhead and make the system more complex .\n- **In-network duplication:** The source router broadcast by sending only one packet to attached routers , and then the attached routers copy the packet and send it to next attached routers .\n![Source-duplication-In-network-duplication.png](Source-duplication-In-network-duplication.png)<br>\n\n### Uncontrolled Flooding \nThe most obvious technique for broadcast is **Flooding** approach in which the source node send its copy of packet to its neighbor.<br>\nAlthough this approach is simple and elegant , it has a fatal flaw , that is , if the graph has a cycles , then one or more broadcast packet will cycle indefinitely .<br>\nThis broadcast storm along with broadcast packet increasingly would cause the network crash (network useless).\n\n### Controlled Flooding\nIn practice , we have several way to solve the problem of uncontrolled flooding .<br>\n- **Sequence-number-controlled-flooding:** A source node put its address or other unique identifies as well as broadcast sequence number into broadcast packet , then send it to all neighbors. Each node maintain a list of the source address and sequence number of broadcast packet , it first checks whether the packet is in this list , if so , the packet is dropped , if not , the packet is duplicated and forwarded to all node's neighbors.<br>\n\n- **Reverse path forwarding (RPF):** Reverse path forwarding is also known as Reverse path broadcast (RPB) , When a node receives a broadcast packet with the source node address , **the node transmits the packet on all of its outgoing link (expect one that outgoing link of its receive that packet)only if the packet arrived on the link that is on its own shortest unicast path back to the source. Otherwise , this packet is discarded simply.**\nAs likely the figure following , the router E transmits only the packet that arrived from router C to all neighbors(because it is the shortest path from router D to source router A), Otherwise , the packet is discarded simply.\n![RPF.png](RPF.png)<br>\n\n### Spanning-Tree Broadcast  \nAlthough The sequence-number-controlled-flooding algorithm and RPF algorithm avoid the broadcast storm , these don't completely avoid the transmission of redundant broadcast packet.<br>\nActually , every node receive only one broadcast packet is enough. The Spanning-Tree Broadcast algorithm can solve this problem .<br>\n\nThus , a node first have to construct a spanning-tree , when it wants to provide broadcast for all network node.<br>\n\nWe consider only one simple algorithm here , that is **Center-based approach** to build a spanning-tree.<br>\n- First determine a center node (also known as **core** and **rendezvous point**)\n- The network node then unicast **tree-join message** addressed to center node. A tree-join message is forwarded using unicast routing toward the center until either arrives at a node that has already belong to the spanning tree or arrives at the center node.\n\n*If each link associated cost , then a spanning-tree whose cost is the minimum of all of graph's spanning-tree is called a **minimum spanning-tree** .* <br>\n\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/Uj47dxYPow8\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n## 4.7.2 Multicast\nIn multicast communication , we are immediately faced with two problem .<br>\n- How to identify the receiver of multicast packet.\n- How to address a packet send to these receivers.\nNetwork layer multicast in the internet consist of two complementary components : **IGMP (Internet Group Management Protocol) and Multicast routing protocol**. The IGMP is used to solve first problem. The Multicast routing protocol is used to solve second problem.<br>\n\n### Internet Group Management Protocol\nThe IGMP protocol version 3 operates between a host and its directly attached router. The figure following , shows three fist-hop multicast protocol each connected to its attached hosts via one outgoing local interface.<br>\n![IGMP-component.png](IGMP-component.png)<br>\nIGMP provide the mean for a host to inform its attached router that an application running on the host want to join a specific multicast group.<br>\n\n**IGMP has three message types.**<br>\n- **Membership_query message:** That is sent by router to all host on an attached interface to determine which hosts on attached network are member of which multicast group.\n- **Membership_report message :** This message is used to respond to Membership_query message for inform the attached router that it still in multicast group and also be used to first joins a multicast group.\n- **Leave_group message :** This message is used to inform the router stops forwarding the multicast message to it. Interesting this message is optional , but it is optional , how to detect when a host leave the multicast group , The answer is the router infer this host have been leaved a multicast if this host no longer respond to Membership_query message. This example is called **soft state** in the internet protocol.<br>\n\n### Multicast Routing Algorithm \nThe goal of multicast routing , then is find a tree of links that connects all of routers that have attached hosts belonging to the multicast group . Multicast packet will be routed along with this tree from the multicast sender to all of the host belong to this multicast tree , of course , the tree also can contain some router that haven't hosts belong to Multicast group.<br>\n\nTwo approach have been adopted for determining the multicast router tree.<br>\n- **A group shared tree :** As in the case of Spanning-tree broadcast , multicast routing over a group-shared tree is base on building a tree that include all edge router with attached host belonging to multicast group. In practice , a center-based approach is used to construct the multicast routing tree with edge router with attached hosts belonging to multicast group send (via unicast) join-message addressed to center router.<br>\n- **A source base tree :** The group shared tree constructs a single, shared routing tree to route packet from all senders . This approach is constructs a multicast routing tree for each source in the multicast group . In practice , an RPF algorithm is used to construct a multicast forwarding tree for multicast datagram originating at source x. The RPF broadcast algorithm require a bits of tweaking when it is used to multicast. To see why consider router D in Figure following. Under broadcast RPF , it forward packets to router G , even though router has no attached hosts that are joined to multicast group . While this is not so bad for this case , where router D has only one downstream router G , imagine what would happen if router D has thousand of downstream router ? Each of these downstream router would receive unwanted multicast packets. The solution of this problem is known as **pruning**.\n![RPF-Multicast.png](RPF-Multicast.png)<br>\n","source":"_posts/Chapter4-The-Network-Layer.md","raw":"---\ntitle: Chapter4-The-Network-Layer\nindex_img: /Picture/ipv4-ipv6.jpg\ndate: 2020-05-18 15:01:46\ntags:\n- Computer Network A Top-Down Approach\ncategories:\n- Computer Network A Top-Down Approach\nbanner_img:\n---\n**In summary , this chapter has three major parts , The first past , section 4.1 and 4.2 cover the network layer function and services. The second part , section 4.3 and 4.4 covers forwarding , finally , the third past ,  section 4.5 through 4.7 covers routing.<br>**\n\n\n# 4.1 Introduction \nThe first past is used to introduce network layer function and services.<br>\n## 4.1.1 Forwarding and Routing\n- **Forwarding :** When the packet arrives at router's input link , the router must move the packet to the appropriate output link. Section 4.3 we will look inside router and examine how a packet is actually forwarded from an input link to output link within a router.<br>\n\n- **Routing :** The network layer must determine the route or path taken by packets as they flow from sender to receiver. The algorithm that calculated these paths are referred to as routing algorithm . We will discuss routing algorithm inside at section 4.5<br>\n\n**Forwarding table :** A router forwards a packet by examining the value of a field in the arrived packet's header and use the header value to index into the router's forwarding table. The value stored in forwarding table entry for indicate the router's outgoing link interface to which that packet is to be forwarded .<br>\n![Routing-algorithm-determine-value-in-forwarding-table](Routing-algorithm-determine-value-in-forwarding-tables.png)<br>\n\n**How to configure the forwarding table of all router at the network.**<br>\nThe answer is though the routing algorithm. The router receive the routing protocol message which are used to configure its forwarding table.<br>\n\n**Routing algorithm:** The routing algorithm has two kinds , one is centralized , another is decentralized.<br>\n- *centralized :*  Every router has complete information about all other router in the network and the traffic status of the network. These algorithm is known as LS (link state) algorithm.<br>\n- *decentralized :* Earn router have information about the routers it is directly connected to -- it doesn't know every router in the network. (These algorithm also known as DV (distance vector) algorithm.)\n\n## Connection Setup \nAddition to the two importance function (forward and routing) , the third importance function is **connection setup.**<br>\nWe will examine connection setup in Section 4.2.<br>\n\n## 4.1.2 Network Service Models\n\n|**Questions:**|\n|:-----:|\n|*When the transport layer at a sending host transmits a packet into the network layer , can transport layer rely on the network layer to deliver the packet to destination ?*|\n|*When multiple packets is sent , will they be delivered to the transport layer in the receiver's host in order in which they were sent ?*|\n|*will the amount of time between the send of two sequential packet transmission be same as the amount of time between their reception?*|\n|*will the network provide the feedback about the congestion in the network?*|\n|*what is the abstract view(properties) of the channel connecting the transport layer in the sending and receiving hosts?*|\n**The answer depend on provided network service model.<br>\nThe specific services that could be provide by network layer include :<br>**\n\n\n|Network Service Models| Description| \n|:-----:|:-----:|\n| *Guaranteed delivery*| This service guaranteed that packet will eventually arrive at destination. |\n| *Guaranteed delivery with bounded delay*| This service not only guaranteed delivery of packets , but also delivery within a specified host-to-host delay bounded. |\n| *In-order packet delivery*| This service guaranteed that packet arrived at the destination in the order that they were sent.|\n| *Guaranteed minimal bandwidth*|The network layer service emulates the behavior of transmission a specified bit rate (for example 1Mbps) between sending and receiving host. As long as sending host transmits bits at a rate below the specified bit rate , then no packet lost and packet arrived within a prespecified host-to-host delay.(for example 40 msc).|\n| *Guaranteed maximum jitter*| The service guaranteed that the amount of time between the transmission of two successive packets at the sender is equal to the amount of time between their receipt at destination.(or that this spacing changes by no more than some specified value).|\n| *Security service*|Using a secret session key known by a source and destination host , the network layer in the source host could encrypt the payloads of all datagrams being sent to the destination , the network layer in the destination host would then be responsible for decrypting the payloads. In addition to confidentiality, the network layer could provide data integrity and source authentication services.|\n\n### Internet , ATM CBR and ATM ABR service models.\n- **Internet-Best-effort-service**\n- **Constant bit rate (CBR) ATM network service**\n- **Available bit rate (ABR) ATM network service**\n![Internet-ATM](Internet-ATM.png)<br>\n\n# 4.2 Virtual Circuit and Datagram Networks\nSimilar to UDP and TCP , the network layer also provide the connectionless service and connection-oriented service.<br>\n\nIn all computer network architectures to data (Internet , ATM , frame relay , and so on ) the network layer provides either a host-to-host connectionless service or a host-to-host connection service , but not both . Computer networks that provide only a connection service at network layer are called **Virtual-circuit(VC) networks** , computer network that provide only connectionless service at the network layer are called **datagram networks**.\n\n## 4.2.1 Virtual-Circuit Networks\n**A VC consists of :**<br>\n(1). A path (that is , a series of links and routers) between the source and the destination hosts <br>\n(2). VC number one number for each link along the path .<br>\n(3). Entries in the forwarding table in each router along the path. A packet belonging to a virtual circuit will carry a VC number in its header. Because a virtual circuit may have a different VC number on each link. Each intervening router must replace the VC number of each traversing packet with a new VC number . The new VC number is obtained from forwarding table.<br>\n\n**For example:**<br>\nsuppose The host A request to establish VC connection between itself and host B , We choose the path is A-R1-R2-B , suppose we set 12 , 22 and 32 to these three link. Hence , the value of VC number field is 12 when the packet leave  host A , the value of VC number field is 22 when the packet leave  R1 , the value of VC number field is 32 when the packet leave  R2 .\n![Simple-Virtual-Circult-Network.png](Simple-Virtual-Circult-Network.png)<br>\n![Simple-VC-Path.png](Simple-VC-Path.png)<br>\n\nWhenever a new VC is established across a router , an entry is added to the forwarding table . Similarly , whenever a VC terminates , the appropriate entry in each table along its path are removed. -- **In a VC network , the network router must maintain connection state information for each ongoing connection**<br>\n\n**Three identifiable phases in a virtual-circuit network.**<br>\n- **VC setup:** The network layer determines the path between sender and receiver , that is the series of link and routers through which all packets of VC will travel. The network layer also determines the VC number for each link along the path. Finally , the network layer add the entry to forwarding table in each router along the path. During the VC setup , the network layer may also reserve resource (for example : bandwidth) along the path of VC.\n- **Data transfer :** The VC connection have been established , packets can being flow along the VC.\n- **VC teardown:** This is initiated when the sender (or receiver) informs the network layer of its desire to terminate the VC connection , The network layer will typically inform the end system on the other side of the network of call termination and update the forwarding tables in each of packet routers on the path to indicate that the VC no long exist.<br>\n\n**Signaling Message and Signaling Protocol**<br>\n- **Signaling Message:** The message that the end systems send into the network to initiate or terminate a VC , the message passed between the routers to setup the VC (that is to modify connection state in router table ).\n- **Signaling Protocol :** The protocol used to exchange signaling message are often referred to as signaling protocol.\n![Virtual-Circuit-Setup.png](Virtual-Circuit-Setup.png)<br>\n\n*More detail about the signaling protocol and signaling message see [Black 1997] for a general discussion of signaling in connection-oriented networksand [ITU-T Q.2931 1995] for the specification of ATM’s Q.2931 signaling protocol.*<br>\n\n## 4.2.2 Datagram Networks\nIn the datagram networks , each time and end system want to send a packet , it stamps the packet with the address of the destination end system and then pop the packet into the network . As shown in figure follow , **these is no VC setup and routers do not maintain any VC state information (because there are no VCs)**\n![Datagram-Network.png](Datagram-Network.png)<br>\n\nAs a packet is transmitted from source to destination , it passes through a series of routers , Each of these router use the packet's destination address to forward the packet , Specifically , each router these of router has a forwarding table map the destination address to link interfaces , When a packet arrived at the router , the router use the packet's destination address to look up appropriate link interface in the forwarding table , the router then intentionally forwards the packet to the output link interface. <br>\n\n![Datagram-Forwarding-Table.png](Datagram-Forwarding-Table.png)<br>\nWhen these are multiple matches , the router uses the **longest prefix matching rule** that is finding the longest matching entry in the forwarding table , and then forwards the packet to link interface associated with the longest prefix match.<br>\n\n*The time scale at which this forward state information (forward table entry) change is relatively slow. Indeed in a datagram network the forwarding table are modified by routing algorithm. which typically update a forwarding table every one-to-five minutes or so.* \n\n# 4.3 What's Inside a Router?\n\nA high-level view of a generic router architecture is shown in figure follow . Four router components can be identified :<br>\n- **Input port :** An input port perform several key functions .\n\t- It performs the physical layer function of terminating an incoming physical link at router. (Occurring in leftmost box of input port\nand rightmost box of output port.)<br>\n\t- It performs the link-layer functions needed to interoperate\nwith the link layer at other side of incoming link . (Occurring in middle box in the input and output ports)<br>\n\t- It perform the lookup functions that is the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. (Occurring in the rightmost box of input port)\n- **Switching Fabric :** The switching fabric connects the router's input port to its output port.<br>\n- **Output port:** An output port store the packet from switching fabric and transmits these packets on outgoing link by performing the necessary link-layer and physical-layer functions.<br>\n- **Routing Processor :** The routing processor executes the routing protocol (study in section 4.6) maintain routing table and attached link state information and computer the forwarding table for the router .It also perform the network management (study in chapter 9).\n![Router-Architecture.png](Router-Architecture.png)<br>\n\nA router input port , output port and switch fabric together implement the forwarding function and almost always implemented in the hardware.<br>\n\n## 4.3.1 Input Processing\nThe lookup performed in the input port is central to the router's operation -- it is here that the router uses the forwarding table to lookup the output port to which an arrived packet will be forwarded via switching fabric , the forwarding table is computed and updated by the router processor. The forwarding table is copied from the routing processor to the line cards over separate bus (eg: PCI bus). With the forwarding table copies , forwarding decision can be made locally , at each input port , without invoking the centralized routing processor. Once a packet's output port have been determined via the lookup , the packet can be sent into the switching fabric.<br>\n![Input-Port-Processing.png](Input-Port-Processing.png)<br>\n\n**Although lookup is arguably the most importance action in input port processing many other action must be taken :** <br>\n- Physical and link layer processing must be occur as discussed above;\n- The packet's version number , checksum and time-to-live-field (We will study in section 4.4.1)<br>\n- counter used to network management (such as the number of IP datagram received) must be updated.\n\n## 4.3.2 Switching \n![Three-Switching-Techniques.png](Three-Switching-Techniques.png)<br>\n**Switching can be accomplished in a number of way , as shown in figure above.<br>**\n- **Switching via memory :** The simplest , earliest routers were traditional computers with switching between the input ports and output ports being done direct control of the CPU (routing process). Input port and output ports functioned as traditional I/O devices in traditional operating system. An input ports with an arriving packet signaled the routing process via an interrupt , The packet was then copied from input port to processor memory. The routing process was then extracted the destination address from the header , look up the appropriate outpost in the forwarding table , and copied the packet to the output post's buffer.\n**Note that two packet can not be forwarded at the same time even if they has different destination ports. So that packets transferring speed is very slow.** Many modern routers switch via memory. A major difference from early routers,however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards.\n\n- **Switching via bus:** In this approach , an input port transfers packet directly to output port without intervention by the routing process. This is typically done by having the input port pre-pend a switching internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. The packet is received by all output posts , but only the port that matches the label will keep this packet. The label is then removed at the outpost port. **If multiple packets arrive to the router at the same , each at a different input ports , all but one must wait since only one packet can cross the bus at a time .(The roundabout could only contain one car at a time)**\n\n- **Switching via an interconnection network:** A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports and N output ports . Each vertical bus intersects intersects each horizontal bus at a crosspoint , which can opened and closed at any time by switching fabric controller. When a packet arrives from post A and need to be forwarded to post B , the switch controller closes the crosspoint at intersection of buses A and Y and port A sends the packet onto its bus , which is picked up (only) by bus Y. Note that the packet from B need to be forwarded to post X at the same time , **crossbar network are capable of forwarding multiple packet in parallel, However if two different input post destined to same output post , the one have to wait at the input port.**\n\n## 4.3.3 Output processing\nOutput post processing take packets that have been stored in the output port's memory and then transmit them over the output link. This include selecting and de-queueing packet for transmission and performing the needed link-layer and physical-layer transmission functions.<br>\n![Output-Port-Processing.png](Output-Port-Processing.png)<br>\n\n## 4.3.4 Where Does Queueing Occur ?\nIt's clear that packet queue may form at both the input port and the output port.<br>\n![Output-Port-Queueing.png](Output-Port-Queueing.png)<br>\nIn this scenario (*$R_{switch}$ fast enough $R_{link}$* ), packets arriving at each of N input ports and destined to same the output port. Since the output port can transmit only a single packet in a unit of time(a packet transmission time) . The N arriving packets will have to queue(wait) for transmission over to outgoing link. Eventually if the number of queued packets grow large enough to exhaust available memory at the output port , in which case packet are dropped.<br>\nA consequence of output port queueing is that **packet scheduler** at the output port must choose a packet among those queued for transmission. The selection may be first-come-fist-served (FCFS) , weighted fair queueing (WFQ) which shares the outgoing link fairy among the different end-to-end connections that have packets queued for transmission.<br>\nSimilarly , if there is not enough memory to buffer an incoming packet , a decision must be made to either drop arriving packet or remove one or more already-queued packets to make room for newly arriving packet.\nFor example : *Active Queue Management (AQM) algorithm* and *Random Early Detection (RED) algorithm*<br>\nIf *$R_{switch}$ not fast enough $R_{link}$* The switch fabric to transfer all arriving packets though the fabric without delay , then packet queueing can also occur at the input ports that is packets must join input port to wait turn to be transferred though the switching fabric to output port.<br>\n![HOL-Block-At-An-Input-Queued-Switch.png](HOL-Block-At-An-Input-Queued-Switch.png)<br>\nFigure above shown an example , and suppose that<br>\n**(1)**.the switching fabric is crossbar switching fabric.<br>\n**(2)**.Packets are moved from a given input queue to their desired output queue in an FCFS manner. Two packets (*darkly shaded, port 1,3*) at the front of their input port queues are destined for the same upper-right output port. Suppose that the switching fabric choose to transfer the packet from the front of the upper-left queue. In this case the packet in lower-left queue must wait , not only darkly shaded must be wait , but also the lightly shaded packet that behind the darkly shaded in the lower-left queue even though it destined for middle-right output port . This phenomenon is knowns as **head-of-the-line (HOL) blocking.**\n\n# 4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.\n**Inside of the Internet's Network Layer:**<br>\n![A-Look-Inside-The-Internet-Network-Layer.png](A-Look-Inside-The-Internet-Network-Layer.png)<br>\n**The three major component inside the internet network:**\n- **IP Protocol**\n- **Routing Component (Routing protocol study in section 4.6)**\n- **Report error and in datagram and respond to request for certain network-layer information. Internet Contorl Message Protocol (ICMP) studied in section 4.4.3**\n\n## 4.4.1 Datagram Format\nThe network-layer packet is referred to as a datagram.<br>\n**Ipv4-Datagram-Format:**<br>\n![Ipv4-Datagram-Format.png](Ipv4-Datagram-Format.png)<br>\n**The key field of Datagram format are following:**<br>\n- **Version number :** These 4 bits specify the IP protocol version of the datagram , by look at the version number , the router can determine how to interpret the remainder of IP datagram . Different Version of IP use different datagram format.<br>\n- **Header length:** Because the IPv4 datagram contain a variable number of options (which are included in the IPv4 datagram header) This 4 bits is needed to determine where the data actually being in the datagram . Most Ipv4 datagram don't contain option , so the typical IP datagram has a 20 bytes header.\n- **Type of service:** The type of service bits were included in ipv4 header to allow different types of datagram (for example : requiring low delay , hight throughput or reliability).\n- **Datagram length:** This is a total length of the IP datagram (Header Plus Data) , since this field is 16 bits , so that the maximum size of the IP datagram is 65535 bytes, however datagram rarely larger than 1500 bytes.\n- **Identifier , flags , fragmentation offset:** These three field we will consider depth in shortly.\n- **Time-to-live:** The field used to ensure that datagram don't circulate forever in the network.\n- **Protocol :** The value of this field is used to indicates the specific transport-layer-protocol to which the data portion of this datagram should be passed , for example the value 6 represent TCP and the value 17 represent UDP.\n- **Header Checksum :** The header checksum aids a router detecting bit error in a received IP datagram.<br>\n**Why does TCP/IP perform error checking at both the transport and network layer.**<br>\n\t- *only the IP header is checksummed at the IP layer while the TCP/UDP checksum is computed over the entire TCP/UDP segment.*\n\t- *TCP/UDP and IP do not necessarily both have to belong to the same protocol stack. IP also can service other protocol (different to TCP/UDP).*\n- **Source and Destination IP Addresses**\n- **Options :** The options flied allow an IP header to be extended.\n- **Data field (payload):** In most circumstance , the data field of the IP datagram contains the transport-layer segment (for example UDP/TCP) . However , the data field can carry other types of data such as ICMP message .\n\n### IP datagram fragmentation \nSince not all link-layer protocol can carry network-layer protocol of the same size . Some protocol can carry big datagrams , whereas other protocols can only a little packets. (for example : Ethernet frames carry 1500 bytes of data, the wide-area links can no more than 576 bytes.)<br>\n\n*Because each IP datagram is encapsulated within the link-layer frame for transport from one router to next router. The problem is that each of link along the router between sender and destination can use different link-layer protocols and each of those protocol can have different MTUs(maximum transmission unit).<br>*\n\nSuppose the router have MTU that is smaller than the length of the IP datagram . How to squeeze this oversize IP datagram into the payload field of the link-layer frame?<br>\nThe solution is to fragment the data in the IP datagram into two or more smaller IP datagrams , encapsulate each of these smaller IP datagram in a separate link-layer frame and send these frames over the outgoing link . Each of these smaller datagram is referred to as a fragment.<br>\nFragment need to reassembled before they reached the transport layer at the destination . Indeed both TCP and UDP expecting to complete, unfragmented segment from the network layer.<br>\n\n**How to determine a packet whether or not a fragment , how to reassemble these fragment and when the destination host have received the last fragment of some original larger datagram.**<br>\nThe answer is three field in the ipv4 datagram header.<br>\n- **16-bits-identifier field:** When a datagram is created , the sending host stamps the datagram with an identification number as well as source and destination address. Typically , the sending host increments the identification number of each datagram it sends.<br>\n- **13-bits Fragmentation offset:** When a router need to fragment a datagram , each resulting fragment is stamped with the source and destination address , and identification number of original datagram , and then the Fragmentation offset field is used to specify where the fragment fit within the original IP datagram.*(unit is bit)*\n\n- **Flags field:** This field is used to identify the last fragment of Original Ipv4 datagram . The last fragment has a flags bit set to 0 , and other fragment has a flags bit set to 1.<br>\n![IP-fragmentation-and-reassembly.png](IP-fragmentation-and-reassembly.png)<br>\n![Ip-fragments.png](Ip-fragments.png)<br>\nIf one or more fragment does not arrive , the incomplete fragments is discarded and not passed to transport layer , and The transport layer protocol is TCP , TCP will recover this loss by retransmission.<br>\n\n## 4.4.2 IPv4 Addressing\n- **Interface :** The boundary between the host and physical link is called an interface.\n\n**A router has multiple interfaces and each of these interfaces have its own unique IP address.**\n![Interface-Address-And-Subnets.png](Interface-Address-And-Subnets.png)<br>\n- **Subnet:** To determine the subnet detach each interface from its host and router , creating islands of isolated networks with interfaces terminating the end points of isolated networks , Each of these isolated networks is called a subnet.<br>\n\nShown as figure above , In the upper-left , this network interconnecting three host interfaces and one router interface forms a **subnet**. IP addressing assigns an address to this subnet : 223.1.1.0/24 , where the /24 notation , sometime known as **subnet mask**, Indicate that the leftmost 24-bits of 32-bits quantity define the subnet address.\n\nThe internet's addressing assignment strategy is known as **Classless Interdomain Routing (CIDR)** As with subnet addressing , the 32-bits IP address is divided into two parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the number of bits in the first past of the address (**network prefix**) . When we cover the internet BGP routing protocol in the section 4.6 , we will see that only these leading x prefix bits are considered by routers the organization's network. That is when a router outside the organization forwards a datagram whose destination address is inside the organization only these leading x bits of the address need be considered . The remaining $32-x$ bits of an address can be though of as distinguishing among the devices within the organization. These bits will be considered when forwarding packets at routers within the organization.<br>\n\n*The special IP address : 255.255.255.255 (IP broadcast address), when a host send a datagram with destination address 255.255.255.255, this message is delivered to all host on the same subnet.*\n\n### Obtaining a Block of Address\n*Internet corporation  for Assigned Name and Number (ICANN) has responsibility for managing the IP address space and allocating address blocks to ISPs and other organizations.<br>*\n\nIn order to obtain a block of IP addresses for use within an organization's subnet , a network administrator might first contract its ISP , while would provide addresses from a larger block of addresses that had already been allocated to the ISP. For example , the ISP may itself have been allocated the address block 200.23.16.0/20 ,the ISP divide its address block into eight equal-sized contiguous address block and give one of these address block out to each of up to eight organizations.<br>\n![Organization-Address.png](Organization-Address.png)<br>\n\n### Obtaining a host Address : The Dynamic Host Configuration Protocol\nOnce an organization obtained a block of addresses it can assign individual IP address to host and router interface in its organization.\nThe router IP address typically manually configure by a system administrator. The host IP address typically configure by using **Dynamic Host Configuration Protocol (DHCP)** DHCP allows a host obtain an IP address automatically. As the host join and leave , the DHCP server need to update its list of available IP addresses.<br>\n\nDHCP is a client-service protocol . A client is typically a newly arriving host wanting to obtain network configuration informations. Each subnet have a DHCP service . If no server is present on the subnet , a DHCP relay agent (typically a router) that knows the address of a DHCP service for that network is needed , for example show as figure below , DHCP service attached to subnet 223.1.2/24 , with the router serving as relay agent for arriving clients attached to subnet 223.1.1/24 and 223.1.3/24 .<br>\n![DHCP-Client-Server-Scenario.png](DHCP-Client-Server-Scenario.png)<br>\n\n**When a newly arriving host income to subnet , The DHCP has four steps for assign a IP address to new host.<br>**\n- **DHCP server discovery:**  This is done using **DHCP discovery message** The new host send a DHCP discovery message with a UDP packet , port 67 source IP address : 0.0.0.0 (since , new host hasn't IP address) and destination IP address : 255.255.255.255 (broadcast address). The UDP packet is encapsulated in a IP datagram and then passed to the link-layer. (We will cover the detail of broadcast in section 5.4)<br>\n\n- **DHCP server offer(s) :** A DHCP server receiving a DHCP discovery message responds to the client with the **DHCP offset message** that is broadcast to all notes on the subnet using the broadcast IP address : 255.255.255.255. Each server offer message contain the transaction ID of the receiver discovery message , the proposed IP address for the client , the network mask , and an IP address lease time . \n\n- **DHCP request :** The newly arriving client will choose from among one or more server offers and respond to its selected offer with **DHCP request message** echoing back the configuration parameters.\n\n- **DHCP ACK:** The server responds to the DHCP request message with a **DHCP ACK message** confirming the requested parameters.<br>\n\n*yiaddr(as in “your Internet address”)*\n![DHCP-Client-Server-Interaction.png](DHCP-Client-Server-Interaction.png)<br>\nOnce the clients receives the DHCP ACK , the interaction is compelte and client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease's expiration , DHCP also provide a mechanism that allow a client to renew its lease on an IP address.<br>\n\n### Network Address Translation (NAT)\nWith proliferation of small office , home office (for example , the kid at home not only their computer but have one or more smartphone and networked game ..etc) , the ISP have not enough IP address to handle this scenarios , what should we do in this scenarios.<br>\n\nThe answer is NAT (Network Address Translation)<br>\n**Figure follow is show the operation of NAT-enabled router.<br>**\n![Network-Address-Translation.png](Network-Address-Translation.png)<br>\nIn figure above all traffic leaving the home router for for the larger internet has a source IP address of 138.76.29.7 and all traffic entering the home router must have a destination IP address 138.76.29.7. In essence the NAT-enabled router is hiding the detail of the home network from the outside world.<br>\n\n- **Question: How the home network computer (or other network device) get their home IP address (for example 10.0.0.0/24)?**<br>\nThe answer is DHCP , The router get its IP address from the ISP's DHCP server and the router runs a DHCP server to provide addresses to computer (or other device ) within the NAT-DHCP-router-controlled-home-network's-address-space.<br>\n\n- **Question : If all datagram arriving at the NAT-Router from the WAN have the same destination IP address , how does the router know the internal host which it should forward a given datagram.** <br>\nThe trick is use a **NAT translation table** at the NAT router , and to include port number as well as IP addresses in table entries. For example shown as figure above , the host computer 10.0.0.1 request a web page on some web server (port 80) with IP address 128.119.40.186 . The host 10.0.0.1 assigns the (arbitrary) source port number 3345 and send the datagram into the LAN , The NAT-Router receives the datagram , genarates a new source port number 5001 , replace the source IP address with it WAN-side IP address 138.76.29.7 and replace the original source number 3345 with its new source port number 5001. NAT-Router adds an new entry to its NAT translation table and send a new datagram to WAN , when a datagram arriving at the NAT-Router , the NAT-Router use the destination IP address and destination port to obtain appropriate IP address (10.0.0.1) and destination port (3345) , then send a datagram to home network.\n\n### UPnP \nThe detail we can see the textbook page 352.\n\n## 4.4.3 Internet Control Message Protocol (ICMP)\nICMP protocol is used by hosts and router communicate network-layer informations to each other. The most typical use of ICMP is error reporting.<br>\nThe ICMP message is carried inside the IP datagrams , that is ICMP messages are carried as IP payload.<br>\n\nICMP message have a type field and a code field and checksum field.<br>\n![General-en.svg.png](General-en.svg.png)<br>\n\n**The ICMP control message :**<br>\n![ICMP-Message-Types.png](ICMP-Message-Types.png)<br>\n\n## 4.4.4 IPv6\n\n### IPv6 Datagram Format \n**Most importance changes introduced in IPv6 :<br>**\n\n-  **Expanded addressing capabilities :** IPv6 increases the size of the IP address from 32 bits to 128 bits . This ensure that the world won't run out of IP address. In addition to unicast and multicast address , IPv6 introduced a new type of address called **anycast address**<br>\n\n- **A streamlined 40-byte header :** A number of IPv4 fields have been dropped or made optional , The resulting 40-bytes-fixed-length header allows for faster processing of the IP datagram . A new encoding of option allow for more flexible option processing.\n\n- **Flow labeling and priority :** The IPv6 header also has an 8-bits traffic class field. This field can be used to give priority to certain datagram within a flow or it can be used to give priority to datagram from certain application (for example ICMP) over datagram from other applications (for example : network new).\n\n![IPv6-Datagram-Format.png](IPv6-Datagram-Format.png)<br>\n\n**The following fields defined in IPv6:**\n- **Version :** This 4-bits field identifies the IP version number.<br>\n- **Traffic class :** This 8-bits field is similar in spirit to the TOS (Type of service) field we saw in IPv4.\n- **Flow label :** This 20-bits is used to identify a flow of datagrams.<br>\n- **Payload length :** This 16-bits is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fix-length 40-byte datagram header.\n- **Next header :** This field is used identifies the protocol to which the content of this datagram will be delivered. This field uses the same values as the protocol field in the IPv4 field.\n- **Hop limit :** The content of this field are decremented by one by each router that forward the datagram . If the hop limit count reaches zero , the datagram is discarded.\n- **Source and destination address :** 128-bits IP address.\n- **Data :** This is the payload portion of the IPv6 datagram.\n\n**The several fields appearing in the IPv4 datagram are no longer present in the IPv6 datagram.**<br>\n\n- **Fragmentation/Reassembly :** IPv6 do not allow for fragmentation and reassembly at intermediate . These operations performed only by the source and destination . If an IPv6 datagram received by a router is too large to be forwarded over the outgoing link , the router simply drops the datagram and sends \"a packet too big\" ICMP error message back to the sender , the sender can then resend the packet using a smaller IP datagram size. Fragmentation and reassembly is a time-consuming operation ; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up IP forwarding within the network.\n- **Header checksum :** Because the transport-layer and link-layer protocols in the internet layers perform checksumming , the designers of IP protocol felt that this functionality was sufficiently redundant in the network layer could be removed. The IPv4 header checksum needed to recomputed at every router , As with fragmentation and reassembly , this too was a costly operation in IPv4.\n- **Options :** An options field is no longer a part of the standard IP header. However , it has not gone away . Instead the option field is one of possible next header pointed to from within the IPv6 header . Just as TCP or UDP protocol headers can be the next header within an IP packet .\n\n*A new version of ICMP protocol is known as ICMPv6 , that is used to service for IPv6*\n\n\n### Transitioning from IPv4 to IPv6\nWe have two approaches for gradually integrating IPv6 hosts and routers into an IPv4 world (with the long-term goal, of course, of having all Ipv4 node eventually translation to IPv4).<br>\n\n**Dual-Stack Approach :**<br>\nThat is IPv6 nodes also have complete IPv4 implementation. That has the ability to send and receive an both IPv4 and IPv6 datagram ; when interoprating with an IPv4 node an IPv6/IPv4 node can use IPv4 datagram , when interopratig with an IPv6 node it can speak IPv6. IPv6 and IPv4 nodes must have both IPv6 and Ipv4 address.<br> \n![A-Dual-Stack-Approachs.png](A-Dual-Stack-Approachs.png)<br>\n\n**Problem :** <br>\nAs figure above , The node A communicate with node F , and node A send a datagram to node F , when a datagram is sent from node B (IPv6) to node C (IPv4) , The node B must create a new datagram to send to node C , the data field of the IPv6 can be copied into the data field of the IPv4 datagram and appropriate address mapping can be done . However , in performing the conversion from IPv6 to IPv4 , there will be IPv6-specific fields in the datagram (for example the flow identifier field) that have no counterpart in IPv4 , The information in these fields will be lost.<br>\n\n**Tunneling (An alternative to the dual-stack approach):**<br> \n*Tunneling can solve the problem note above.*<br>\n![Tunneling.png](Tunneling.png)<br>\nSuppose two IPv6 nodes (for example : B and E in the figure above) want to interoperate using IPv6 datagram but are connected to each other by intervening IPv4 routers. We refer to the intervening set of IPv4 router between two IPv6 router as a **tunnel**. With tunneling , the IPv6 node on the send side of the tunnel (node B) **takes the entire IPv6 datagram and put it into the data field (payload) of IPv4 datagram.\nThis IPv4 datagram is then addressed to the IPv6 node on the receiving side of the tunnel (node E) and sent to the first node in the tunnel (node C). The IPv6 node on the receiving side of the tunnel eventually receives the IPv4 datagram (it is a destination of IPv4 datagram!) determine that IPv4 datagram contain an IPv6 datagram , extract the IPv6 datagram and then routes the IPv6 datagram exactly as it would if it had received the IPv6 datagram from a directly connected IPv6 neighbor.<br>\n\n## 4.4.5 A Brief Foray into IP Security\nUsing IPsec protocol provide security service . (more detail see the chapter 8).\n\n# 4.5 Routing Algorithm \n**Routing Algorithm operating in network routers , exchange and compute the information that is used to configure these forwarding table .**<br>\nWhether network layer provide datagram service (packet between the source and destination may takes many different routes)or VC service (packet between the source and destination take the same path) , the network layer must determine the path that packets take from sender to receiver.<br>\n\n*We will see the job of routing is determine the good paths **(least-cost-path)** from senders to receivers through the network of routers.*\n\n**Classify routing algorithm according to whether they are global or decentralized.**<br>\n- **A global routing algorithm :** Computes the least-cost path between a source and destination using complete global knowledge about the network.(complete global knowledge is mean all node connectively relationship and link cost in the network). In practice algorithm with global state information are often referred to as **Link-state(LS) algorithm**.<br>\n- **A decentralized routing algorithm :** The calculation of least-cost path is carried out in an iterative , distributed manner. No node have complete information about the cost of all network link , instead each node begins with only the knowledge of the cost of its own directly attached links. Then through an iterative process of the calculation and exchange of information with its neighboring nodes , a node gradually calculates the least-cost path to destination or set of destinations. The decentralized routing algorithm is called distance-vector (DV) algorithm .\n\n## 4.5.1 The Link-State (LS) Routing Algorithm \nIn practice , The Link-State Routing Algorithm is accomplished by having each node broadcast link-state packets to all other nodes in the network , with each link-state packet containing the identifies and cost of it attached links. The result of the note's broadcast is that all node have an identical and complete view of the network.  Each node can then run the LS algorithm and compute the same set of least-cost paths as every other node.\n\nThe LS algorithm is known as **Dijkstra's Algorithm** name after its inventor. A closely related algorithm is Prim's Algorithm .\n\n**Let us define the following notation:**<br>\n- **D(v) :** Cost of the least-cost path from the source to destination v as of this iteration of the algorithm.\n- **P(v) :** Previous node (neighbor of node v) along the current least-cost path from source to node v.\n- **N':** subset of nodes , if v in **N'** represent the least-cost path from source to v have been definitely known.\n\n![Graph-Of-Link-State-Algorithm.png](Graph-Of-Link-State-Algorithm.png)<br>\n\n*Link-State Algorithm For Source Node u*<br>\n\n```c++\nInitialization :\n\tN' = {u};\n\tfor all nodes v \n\t\tif v is a neighbor of u \n\t\t\tthen D(v) = c(u,v)\n\t\telse D(v) = ∞\nLoop :\n\tFind w not in N' simultaneously D(w) is a minimum\n\tAdd w to N'\n\tUpdate D(v) for each neighbor v of w and not in N' : \n\tD(v) = min ( D(v) , D(w)+c(w,v) );\nUntil : N' = N ( N is set of all node )\n```\n![Result-Of-LS-Algorithm.png](Result-Of-LS-Algorithm.png)<br>\n \n**The detail of step can watch the video follow:**<br> \n\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/ud7qWRBirsk\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n**Problem of LS algorithm :**<br>\n\n**Figure follow shown a simple network topology where link costs are equal to the load carried on the link.**\nIn this example , link cost are not symmetric that is the C(u,v) equal to C(v,u) only if the load carried on the both directions on the link(u,v) is same . <br>\n\n**In this example , node z originates a unit of traffic destined for node w , node x also originates a unit of traffic destined for node w and node y injects an amount of traffic equal to e also destined for node w .**<br>\n\n**The order of looking at figure is a->b->c->d**<br>\n\n![Oscillations-With-Congestion-Sensitive-Routing.png](Oscillations-With-Congestion-Sensitive-Routing.png)<br>\n\nWe can see the **Oscillation** with congestion sensitive routing.<br>\n\nWhat can be done to prevent such oscillation ?<br>\nOne solution would be to mandate that link costs not depend on the amount of traffic carried -- an unacceptable solution since one goal of routing is to avoid highly congested links, Another solution is to ensure that not all routers run the LS algorithm at the same time.\n\n## 4.5.2 The Distance-Vector (DV) Routing Algorithm\nWhereas the LS algorithm is an algorithm using global information , the **distance-vector algorithm** is *iterative , asynchronous , and distributed. <br>*\n- It is distributed in that each node receive some information from its directly attached neighbors , perform a calculation and distributed the result of its calculation back to its neighbors.<br>\n\n- It is iterative in that , this process continue on until no more information is exchanged between the neighbors.<br>\n\n- It is asynchronous in that is does not require all of the nodes to operate in lockstep with each other.<br>\n\n**The Distance-Vector Routing Algorithm also known as Bellman-Ford Algorithm**<br>\n\nFor get the least-cost paths , we need to using the celebrated **Bellman-Ford equations:**<br> **$d_{v}(y)$ is distance from $v$ to $y$**\n$$d_{x}(y)=min_v{c(x,y)+d_v(y)}$$\nWhere the $min_{v}$ in the equation is taken over all of x's neighbors.After traveling from x to v , if we then take the least-cost path from v to y , the path cost will be $c(x,y)+d_{v}(y)$ . Since we must begin by traveling to some neighbor $v$ , the least cost from $x$ to $y$ is the minimum of $c(x,y)+d_{v}(y)$ taken over all neighbor $v$.\n\n**Distance-Vector (DV) Algorithm:** <br>\nat each node ,x:<br>\n\n**Initialization :** <br>\n&nbsp; &nbsp;  &nbsp; &nbsp; for all destinations $y$ in $N$ : <br>\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp;$D_{x}(y)$ = $c(x,y)$  &nbsp; /\\* if y is not a neighbor then $c(x,y)$ = $\\infty$ \\*/ <br>\n&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br> \n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; $D_{w}(y)$ = $?$ &nbsp; /\\* for all destinations $y$ in $N$ \\*/<br>\n&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br>\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; send distance vector $D_{x} = [ D_{x}(y) : y$ in $N ]$ to $w$<br>\n**Loop**<br>\n&nbsp; &nbsp; **wait** (until i see a link cost change to some neighbor $w$ <br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t&nbsp;&nbsp;or until i receive a distance vector from some neighbor $w$) <br>\n&nbsp;&nbsp;&nbsp; for each $y$ in $N$ :<br>\n&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\t$D_{x}(y)$ = $min_{v} \\{c(x,y) + D_{v}(y)\\}$<br>\n&nbsp;&nbsp;&nbsp;if $D_{x}(y)$ changed for any destination $y$ <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; send the distance vector $D_{x}$ = $[D_{x}(y) : y$ in $N]$ to all neighbors<br>\n**Forever** <br>\n\n**A simple three node illustrates the operation of DV algorithm**<br>\n![DV-Simple-Example.png](DV-Simple-Example.png)\n\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/dmS1t2twFrI\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n### Distance-Vector Algorithm : Link-Cost Changes and Link failure\n![Changes-in-link-cost.png](Changes-in-link-cost.png)<br>\n\nFigure (a) above illustrates a scenario where link cost from y to x distance vector change from 4 to 1. We force here only on y' and z' distance table entires to destination x. The Dv algorithm causes the following sequence of events to occur :<br>\n- At time $t_{0}$ , $y$ detects the link-cost change (the cost has change from 4 to 1 ) updates its distance vector and inform the neighbors of this change since its distance has changed.\n- At time $t_{1}$ , $z$ receives the update from $y$ and update its table . It computer a new least cost of $x$ (it has decreased from a cost of 5 to cost of 2 ) and send its new distance vector to its neighbors.\n- At time $t_{2}$ , $y$ receive $z's$ update and updates its distance table . $y's$ least cost do not change hence $y$ does not send any message to $z$. The algorithm come to a quiescent state.\n\nThus only two iterations are requited for the DV algorithm to reach a quiescent state. <br>\n\nLet now consider what happen when a link cost increases , support that support the link cost between $x$ and $y$ increases from 4 to 60 as shown in figure (b) above.<br>\n\n- Before the link cost changes , $D_{x}(y) = 4$ , $D_{y}(z) =1$ , $D_{z}(y) = 1$ and $D_{z}(x) = 5$ , $y$ detect the link cost change (the cost change from 4 to 60) , $y$ computes its new minimum-cost path to x have a cost of  \n\t$$D_{y}(x) = min \\{C(y,x) + D_{x}(x) , C(y,z)+ D_{z}(x)\\}= min \\{ 60+0,1+5\\} = 6$$ \n\tof course , with out global view of the network , we can see that this new cost via $z$ is wrong . But the only information node $y$ has is that its direct cost to $x$ is 60 and that $z$ has last told $y$ that $z$ could get $x$ with a cost of 5 . So in order to get to $x$, $y$ would now route through $z$ , fully expecting that $z$ will be able to get to $x$ with cost of 5.\n- Since node $y$ has computed a new minimum cost to $x$ , it inform $z$ of new distance vector at time $t_{1}$.\n- Sometime after $t_{1}$ , $z$ receive the $y's$ new distance vector ,which indicates that $y's$ minimum cost to $x$ is 6 . $z$ know get to $y$ with a cost of 1 and computes a new least cost to x of \n\t$$D_{z}(x) = min \\{50+0, 1+6\\}=7$$\n\tSince $z's$ least-cost to $x$ is increased , and then it inform $y$ of its new distance vector at $t_{2}$ at $t_{2}$.\n- In a similar manner , after receiving $z's$ a new distance vector , $y$ determines $D_{y}(x)=8$ and send $z$ its distance vector . $z$ then determine $D_{z}(x) = 9$ and sends $y$ its new distance vector over and over again until $D_{z}(x)= min\\{C_{z}(y)+D_{y}(x) , C_{z}(x)+D_{x}(x)\\}= min\\{50+1 ,50+0 \\}=50$ , at this point , $z$ finally ! determine that its lease-cost path to $x$ is via its direct connection to $x$.\n\n**What way could solve the problem noted above ?**<br>\nThe answer is *Poisoned Reverse.*<br>\n\n### Distance-Vector Algorithm : Adding Poisoned Reverse\nThe specific looping scenario just described can be avoided using a technique known as *poisoned reverse.* The idea is simple **if $z$ routers through $y$ to get to destination $x$ , then $z$ will advertise to $y$ that its distance to $x$ is infinity**, $z$ will advertise to $y$ that $D_{z}(x) = \\infty$ ( even though $z$ known $D_{x}(z) = 5$ in truth) $z$ will continue telling this little white lie to $y$ as long as it route $x$ via $y$ . Since $y$ believes that $z$ had no path to $x$ ,$y$ will never attempt to route to $x$ via $z$ , as long as $z$ continues to route to $x$ via $y$\nLet now see how *Poisoned Reverse* solved the particular looping problem :  When the link-cost $(x,y)$ change from 4 to 60 , $y's$ distance table indicate $D_{z}(x) = \\infty$ .\n- At the time $t_{0}$ ,$y$ update its table and continues to route directly to $x$ , albeit at the higher cost of 60 and then inform $z$ of the new distance vector to $x$ , that is $D_{y}(x) =60$ .\n- After receiving the update at $t_{1}$ , $z$ immediately shits the its route to $x$ to be via the direct $(z,x)$ link at the cost of 50, and then $z$ inform $y$ of new cost of $D_{z}(x) = 50$ .\n- After receiving the update from $z$ , $y$ update its distance table at $D_{y}(x)=51$, also , since $z$ is now on $y$'s lease-cost path to $x$ , $y$ poisoned the reverse from $z$ to $x$ by informing $z$ at time $t_{3}$ that $D_{y}(x) = \\infty$ (even though $y$ know $D_{y}(x)=51$ in trush)\n\n**Does poisoned reverse solve the general count-to-infinity problem ? It dose not , when looping involving three or more nodes will not be detected by poisoned reverse.**<br>\n\n\n### A comparison of LS and DV Algorithm\n\n- **Message complexity :** **In LS algorithm** requires each node know all cost of link in the network . The require O(|E|\\*|N|) to be sent. Also , whenever a link cost changes , the new link cost must be sent to all node in the internet. **In the DV algorithm** The node only need to exchange the information between directly connection neighbors. When a link cost change , the DV algorithm will propagate the results of the changed link cost only if the new cost results in a changed lease-cost path for one of nodes attached to that link.\n\n- **Speed of convergence :** LS is O($|N|^2$) algorithm require O(|N||E|) messages to be sent. DV algorithm can converge slowly and can have routing loops while the algorithm is converging . DV algorithm also suffers from the count-to-infinity problem. \n\n- **Robustness:** What can happen if route fails misbehaves or is sabotage? Because LS algorithm only compute own forwarding table of each node in the network , This mean route calculation are somewhat separated under LS . Providing a degree of robustness. Under DV algorithm , a node must advertise incorrect least-cost path to any all destination , so that a malfunctioning router may be cause other router flood the malfunctioning router with traffic and cause a large portions of the internet to become disconnected for up to several hours.<br>\n\n## 4.5.3 Hierarchical Routing\nIn our study of LS and DV algorithm , In practice , this model and its view of homogeneous set of routers all executing the same routing algorithm is a bit simplistic for at least two important reasons:<br>\n\n- **Scale** :Because , today's public internet consist of hundreds of millions hosts , LS algorithm updates among all of the router in public internet world would leave no bandwidth left for sending data packets, and under DV algorithm that iterated among such a large number of routers would surely never converge.\n\n- **Administrative autonomy:** The corporation / organization / individual want to run and administer its network as it wishes.<br>\n\n**Both of these problems can be solve by organizing routers into autonomous systems (ASs)**<br>\n\nEach AS consisting of a group of routers that are typically under the same administrative control ( eg : operated by the same ISP or belonging to the same company network).\n\nThe routing algorithm running within a autonomous system is called an **Intra-autonomous-system routing protocol**\nOne or more router in the AS being responsible for forwarding packets to destinations outside other AS : there routers are called **gateway router**, Obtaining reachability information from neighboring AS and propagating the reachability information to all router internal to AS are handled by the **inter-AS-routing-protocol**<br>\n![autonomous-system-graph.png](autonomous-system-graph.png)<br>\nIf a destination router of outside AS can be reached by more than one gateway router , the router inside AS can using **Hot-Potato-Algorithm** to choose which gateway router should be select. The hot-potato-algorithm is using information from Intra-AS-Routing-Protocol to choose the lease-cost path of gateway routers.\n![hot-potato-algorithm.png](hot-potato-algorithm.png)<br>\n\n\n# 4.6 Routing in the internet\n\n## 4.6.1 Intra-AS Routing in the Internet : RIP\nRIP is a distance-vector algorithm that operates in a manner very close to idealized DV protocol . Each router maintains a RIP table is known as a routing table. RIP is implemented as an application-layer process can send and receive the (require/response) message over a standard socket (port 520) and using UDP protocol.<br>\n![RIP-UDP-Application.png](RIP-UDP-Application.png)<br>\nIn RIP , routing updates are exchanged between neighbors approximately every 30 seconds using a **RIP response message**(RIP response message also known as **RIP advertisements**) . If a router does not hear from its neighbor at least once every 180 seconds , that neighbor is considered to be no longer reachable ; that is , either neighbor is died or the connecting link has gone down , when this happen , RIP modifies the local routing table and then propagates this information by sending advertisement to still alive neighbors.<br>\n\n**Let us see a simple example:**<br>\nDotted lines indicate that still has other AS connect on  ; thus this autonomous systems have many more routers and link than figure shown follow.\n![ASs-connection-graph-RIP.png](ASs-connection-graph-RIP.png)<br>\n**Routing table of Router-D before receiving advertisement from Router-A:**<br>\n![Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png](Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png)<br>\n\n**Advertisement from router A:**<br>\n![Advertisement-From-RouterA.png](Advertisement-From-RouterA.png)<br>\n**Routing table of Router-D after receiving advertisement from Router-A:**<br>\n![Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png](Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png)<br>\n\n## 4.6.2 Intra-AS Routing in the Internet : OSPF\nOSPF is a link-state algorithm that uses flooding of link-state information and dijkstra least-cost path algorithm . With OSPF protocol , a router constructs a complete topological map of the entire autonomous system , The router then locally run dijkstra algorithm to determine the shortest-path tree to all subnet. Individual link cost can be configured by the network administrator .<br>\n\nUnder OSPF protocol , A router broadcast link-state information whenever there is change in a link's state , It also broadcast information periodically (at least once every 30 minutes) even if the link's state has not changed. OSPF protocol advertisements are contains in OSPF message that carried directly by IP protocol , with a upper-layer protocol 89 for OSPF.<br>\n\nThe OSPF protocol also checks that link are operational and allows an OPSF router to obtain a neighboring router's database of network-wide link state.\n\nOPSF is conceived as the successor to RIP and as has a number of advanced feature. The advanced feature is include the following:<br>\n\n- **Security:** Exchanged between OPSF router can be authenticated , with authentication ,only trusted router can participate in OPSF protocol within an AS. Two type of authentication is can be configured -- **simple and MD5**( discuss in chapter 8).\n\n- **Multiple same-cost path:** OPSF allow multiple same-cost path to be used , don't need to select a path to carry all traffic.\n\n- **Integrated support to unicast and multicast routing:** Multicast OSPF (MOSPF).<br>\n- **Support a hierarchy within a single routing domain:** An OPSF autonomous system can be configured hierarchically into areas , Each area run its own OSPF link-state-algorithm , with each router in an area broadcasting its link-state to all other in that area. Within each area of a autonomous system has one or more **area border router** are responsible for routing packets to outside the area . And exactly one OPSF area in the AS is configured to be the **backbone** area. The primary role of the backbone area is to route traffic between the other area in the AS. *Inter-area routing* within the AS requires that the packet be first route to a area border router , and routed through the backbone to the area border router that is in the destination area , and then routed to the final destination.\n\n## 4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)\nLet's us examine how path are determined for source-destination pair span multiple ASs.<br>\nUnder BGP protocol , pair of router exchange information through semi-permanent TCP connection using port 179.<br>\nThe BGP protocol TCP connection has two type of connection : <br>\n- BGP TCP connection between router within a same AS.\n- BGP TCP connection between routers in two different ASs.\n\nTwo interconnecting router corresponding source and destination router that using TCP are called **BGP peers** . The TCP connection along with all BGP message sent over the connection is called **BGP session**.<br>\n**Two type of BGP session:**<br>\n- External BGP session (eBGP session) : The BGP message is sent span two routers.\n- Internal BGP session (iBGP session) : The BGP message is sent within an AS.\n![BGP-sessions.png](BGP-sessions.png)<br>\nIn the BGP , destinations are not a host but instead are CIDRized prefixes with each prefixes is representing a subnet or a collection of subnet.<br>\n\nIn the BGP , some ASs has a globally unique **autonomous system numbers(ASN)** , the ASs hasn't ASN is called stub AS. ASN similar to IP address are assigned by ICANN regional register.<br>\n\nWhen a router advertise prefix to outside ASs , it include with a number of **BGP attributes :** , in BGP jargon , a prefix along with its attributes is called a route. The BGP  attributes is following: <br>\n- **AS-PATH :** The attributes contain the ASN that the prefix have been passed.\n- **NEXT-HOP:** The NEXT-HOP is router interface that begins the AS-PATH. \n\n### BGP Route selection\nUnder BGP protocol , a router may be receive more than one route to the same prefix . Then BGP must be sequentially invokes the following elimination rules until one possible remain , The elimination rules is following:<br>\n\n- Routes are assigned a local preference values as one of their attributes , the routes with the highest local preference value are selected.\n- From the remaining routes ( all routes has same preference value ) with the shortest AS-PATH are selected.\n- From the remaining routes ( all routes has same preference value and same AS-PATH length) with closest NEXT-HOP are selected, here closest mean the least-cost path of a router itself interface and its corresponding eBGP session interface.\n- If more than one route still remains , the router use the BGP identifiers to select the route.\n\n### Putting all together : How does an entry get into a router's forwarding table ? \n**How does the packet is forwarded within a router ?<br>**\nWhen a packet arrive to the router , the packet's destination IP address compared with the prefixes in the forwarding table and find a longest prefix match . Then the packet is forwarded to router's port that associated with that matched prefix.<br>\n**How does an entry get into a router's forwarding table ?**<br>\n*In order to get an entry into a router's forwarding table , first , the router must be aware of the prefix. The router become aware of the prefix via a BGP route advertisement , such a route advertisement may be sent over a eBGP session or over a iBGP session. After the router become aware of prefix , it need to determine appropriate output port to which datagram destined to that prefix will be forwarded. Before it can enter that entry (prefix + port) into its forwarding table . If router receive more than one route advertisement for this prefix , it is uses the BGP selection process to select to best route for the prefix , suppose the route have been selected , the selected route include NEXT-HOP attribute , which is IP address of first router outside the router's AS along this best route. Then the router uses its Intra-AS routing protocol (typically OSPF) , to determine the shortest path to the NEXT-HOP router. The router finally determines the port number to associate with the prefix by identifying the first link along the shortest path . The router finally can enter the prefix-port pair into the forwarding table.*\n\n# 4.7 Broadcast and Multicast Routing\n\n## 4.7.1 Broadcast Routing Algorithm\n**Two type of Broadcast routing algorithm: <br>**\n- **Source-Duplication:** A packet is created and duplicated by a source router , and source router broadcast to all router in the network by unicast. This approach has several drawback is following:\n\t- inefficiency : The source router is required to copy a large amount of same packet and send these via a single link.\n\t- Additional protocol mechanisms to obtain the address of the broadcast recipient ,would add more overhead and make the system more complex .\n- **In-network duplication:** The source router broadcast by sending only one packet to attached routers , and then the attached routers copy the packet and send it to next attached routers .\n![Source-duplication-In-network-duplication.png](Source-duplication-In-network-duplication.png)<br>\n\n### Uncontrolled Flooding \nThe most obvious technique for broadcast is **Flooding** approach in which the source node send its copy of packet to its neighbor.<br>\nAlthough this approach is simple and elegant , it has a fatal flaw , that is , if the graph has a cycles , then one or more broadcast packet will cycle indefinitely .<br>\nThis broadcast storm along with broadcast packet increasingly would cause the network crash (network useless).\n\n### Controlled Flooding\nIn practice , we have several way to solve the problem of uncontrolled flooding .<br>\n- **Sequence-number-controlled-flooding:** A source node put its address or other unique identifies as well as broadcast sequence number into broadcast packet , then send it to all neighbors. Each node maintain a list of the source address and sequence number of broadcast packet , it first checks whether the packet is in this list , if so , the packet is dropped , if not , the packet is duplicated and forwarded to all node's neighbors.<br>\n\n- **Reverse path forwarding (RPF):** Reverse path forwarding is also known as Reverse path broadcast (RPB) , When a node receives a broadcast packet with the source node address , **the node transmits the packet on all of its outgoing link (expect one that outgoing link of its receive that packet)only if the packet arrived on the link that is on its own shortest unicast path back to the source. Otherwise , this packet is discarded simply.**\nAs likely the figure following , the router E transmits only the packet that arrived from router C to all neighbors(because it is the shortest path from router D to source router A), Otherwise , the packet is discarded simply.\n![RPF.png](RPF.png)<br>\n\n### Spanning-Tree Broadcast  \nAlthough The sequence-number-controlled-flooding algorithm and RPF algorithm avoid the broadcast storm , these don't completely avoid the transmission of redundant broadcast packet.<br>\nActually , every node receive only one broadcast packet is enough. The Spanning-Tree Broadcast algorithm can solve this problem .<br>\n\nThus , a node first have to construct a spanning-tree , when it wants to provide broadcast for all network node.<br>\n\nWe consider only one simple algorithm here , that is **Center-based approach** to build a spanning-tree.<br>\n- First determine a center node (also known as **core** and **rendezvous point**)\n- The network node then unicast **tree-join message** addressed to center node. A tree-join message is forwarded using unicast routing toward the center until either arrives at a node that has already belong to the spanning tree or arrives at the center node.\n\n*If each link associated cost , then a spanning-tree whose cost is the minimum of all of graph's spanning-tree is called a **minimum spanning-tree** .* <br>\n\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/Uj47dxYPow8\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n## 4.7.2 Multicast\nIn multicast communication , we are immediately faced with two problem .<br>\n- How to identify the receiver of multicast packet.\n- How to address a packet send to these receivers.\nNetwork layer multicast in the internet consist of two complementary components : **IGMP (Internet Group Management Protocol) and Multicast routing protocol**. The IGMP is used to solve first problem. The Multicast routing protocol is used to solve second problem.<br>\n\n### Internet Group Management Protocol\nThe IGMP protocol version 3 operates between a host and its directly attached router. The figure following , shows three fist-hop multicast protocol each connected to its attached hosts via one outgoing local interface.<br>\n![IGMP-component.png](IGMP-component.png)<br>\nIGMP provide the mean for a host to inform its attached router that an application running on the host want to join a specific multicast group.<br>\n\n**IGMP has three message types.**<br>\n- **Membership_query message:** That is sent by router to all host on an attached interface to determine which hosts on attached network are member of which multicast group.\n- **Membership_report message :** This message is used to respond to Membership_query message for inform the attached router that it still in multicast group and also be used to first joins a multicast group.\n- **Leave_group message :** This message is used to inform the router stops forwarding the multicast message to it. Interesting this message is optional , but it is optional , how to detect when a host leave the multicast group , The answer is the router infer this host have been leaved a multicast if this host no longer respond to Membership_query message. This example is called **soft state** in the internet protocol.<br>\n\n### Multicast Routing Algorithm \nThe goal of multicast routing , then is find a tree of links that connects all of routers that have attached hosts belonging to the multicast group . Multicast packet will be routed along with this tree from the multicast sender to all of the host belong to this multicast tree , of course , the tree also can contain some router that haven't hosts belong to Multicast group.<br>\n\nTwo approach have been adopted for determining the multicast router tree.<br>\n- **A group shared tree :** As in the case of Spanning-tree broadcast , multicast routing over a group-shared tree is base on building a tree that include all edge router with attached host belonging to multicast group. In practice , a center-based approach is used to construct the multicast routing tree with edge router with attached hosts belonging to multicast group send (via unicast) join-message addressed to center router.<br>\n- **A source base tree :** The group shared tree constructs a single, shared routing tree to route packet from all senders . This approach is constructs a multicast routing tree for each source in the multicast group . In practice , an RPF algorithm is used to construct a multicast forwarding tree for multicast datagram originating at source x. The RPF broadcast algorithm require a bits of tweaking when it is used to multicast. To see why consider router D in Figure following. Under broadcast RPF , it forward packets to router G , even though router has no attached hosts that are joined to multicast group . While this is not so bad for this case , where router D has only one downstream router G , imagine what would happen if router D has thousand of downstream router ? Each of these downstream router would receive unwanted multicast packets. The solution of this problem is known as **pruning**.\n![RPF-Multicast.png](RPF-Multicast.png)<br>\n","slug":"Chapter4-The-Network-Layer","published":1,"updated":"2020-11-14T14:40:36.600Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckivbi4tp002vr8s836212foz","content":"<p><strong>In summary , this chapter has three major parts , The first past , section 4.1 and 4.2 cover the network layer function and services. The second part , section 4.3 and 4.4 covers forwarding , finally , the third past ,  section 4.5 through 4.7 covers routing.<br></strong></p>\n<h1 id=\"4-1-Introduction\"><a href=\"#4-1-Introduction\" class=\"headerlink\" title=\"4.1 Introduction\"></a>4.1 Introduction</h1><p>The first past is used to introduce network layer function and services.<br></p>\n<h2 id=\"4-1-1-Forwarding-and-Routing\"><a href=\"#4-1-1-Forwarding-and-Routing\" class=\"headerlink\" title=\"4.1.1 Forwarding and Routing\"></a>4.1.1 Forwarding and Routing</h2><ul>\n<li><p><strong>Forwarding :</strong> When the packet arrives at router’s input link , the router must move the packet to the appropriate output link. Section 4.3 we will look inside router and examine how a packet is actually forwarded from an input link to output link within a router.<br></p>\n</li>\n<li><p><strong>Routing :</strong> The network layer must determine the route or path taken by packets as they flow from sender to receiver. The algorithm that calculated these paths are referred to as routing algorithm . We will discuss routing algorithm inside at section 4.5<br></p>\n</li>\n</ul>\n<p><strong>Forwarding table :</strong> A router forwards a packet by examining the value of a field in the arrived packet’s header and use the header value to index into the router’s forwarding table. The value stored in forwarding table entry for indicate the router’s outgoing link interface to which that packet is to be forwarded .<br><br><img src=\"Routing-algorithm-determine-value-in-forwarding-tables.png\" alt=\"Routing-algorithm-determine-value-in-forwarding-table\"><br></p>\n<p><strong>How to configure the forwarding table of all router at the network.</strong><br><br>The answer is though the routing algorithm. The router receive the routing protocol message which are used to configure its forwarding table.<br></p>\n<p><strong>Routing algorithm:</strong> The routing algorithm has two kinds , one is centralized , another is decentralized.<br></p>\n<ul>\n<li><em>centralized :</em>  Every router has complete information about all other router in the network and the traffic status of the network. These algorithm is known as LS (link state) algorithm.<br></li>\n<li><em>decentralized :</em> Earn router have information about the routers it is directly connected to — it doesn’t know every router in the network. (These algorithm also known as DV (distance vector) algorithm.)</li>\n</ul>\n<h2 id=\"Connection-Setup\"><a href=\"#Connection-Setup\" class=\"headerlink\" title=\"Connection Setup\"></a>Connection Setup</h2><p>Addition to the two importance function (forward and routing) , the third importance function is <strong>connection setup.</strong><br><br>We will examine connection setup in Section 4.2.<br></p>\n<h2 id=\"4-1-2-Network-Service-Models\"><a href=\"#4-1-2-Network-Service-Models\" class=\"headerlink\" title=\"4.1.2 Network Service Models\"></a>4.1.2 Network Service Models</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"><strong>Questions:</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><em>When the transport layer at a sending host transmits a packet into the network layer , can transport layer rely on the network layer to deliver the packet to destination ?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>When multiple packets is sent , will they be delivered to the transport layer in the receiver’s host in order in which they were sent ?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>will the amount of time between the send of two sequential packet transmission be same as the amount of time between their reception?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>will the network provide the feedback about the congestion in the network?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>what is the abstract view(properties) of the channel connecting the transport layer in the sending and receiving hosts?</em></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>The answer depend on provided network service model.<br><br>The specific services that could be provide by network layer include :<br></strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Network Service Models</th>\n<th style=\"text-align:center\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed delivery</em></td>\n<td style=\"text-align:center\">This service guaranteed that packet will eventually arrive at destination.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed delivery with bounded delay</em></td>\n<td style=\"text-align:center\">This service not only guaranteed delivery of packets , but also delivery within a specified host-to-host delay bounded.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>In-order packet delivery</em></td>\n<td style=\"text-align:center\">This service guaranteed that packet arrived at the destination in the order that they were sent.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed minimal bandwidth</em></td>\n<td style=\"text-align:center\">The network layer service emulates the behavior of transmission a specified bit rate (for example 1Mbps) between sending and receiving host. As long as sending host transmits bits at a rate below the specified bit rate , then no packet lost and packet arrived within a prespecified host-to-host delay.(for example 40 msc).</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed maximum jitter</em></td>\n<td style=\"text-align:center\">The service guaranteed that the amount of time between the transmission of two successive packets at the sender is equal to the amount of time between their receipt at destination.(or that this spacing changes by no more than some specified value).</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Security service</em></td>\n<td style=\"text-align:center\">Using a secret session key known by a source and destination host , the network layer in the source host could encrypt the payloads of all datagrams being sent to the destination , the network layer in the destination host would then be responsible for decrypting the payloads. In addition to confidentiality, the network layer could provide data integrity and source authentication services.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"Internet-ATM-CBR-and-ATM-ABR-service-models\"><a href=\"#Internet-ATM-CBR-and-ATM-ABR-service-models\" class=\"headerlink\" title=\"Internet , ATM CBR and ATM ABR service models.\"></a>Internet , ATM CBR and ATM ABR service models.</h3><ul>\n<li><strong>Internet-Best-effort-service</strong></li>\n<li><strong>Constant bit rate (CBR) ATM network service</strong></li>\n<li><strong>Available bit rate (ABR) ATM network service</strong><br><img src=\"Internet-ATM.png\" alt=\"Internet-ATM\"><br></li>\n</ul>\n<h1 id=\"4-2-Virtual-Circuit-and-Datagram-Networks\"><a href=\"#4-2-Virtual-Circuit-and-Datagram-Networks\" class=\"headerlink\" title=\"4.2 Virtual Circuit and Datagram Networks\"></a>4.2 Virtual Circuit and Datagram Networks</h1><p>Similar to UDP and TCP , the network layer also provide the connectionless service and connection-oriented service.<br></p>\n<p>In all computer network architectures to data (Internet , ATM , frame relay , and so on ) the network layer provides either a host-to-host connectionless service or a host-to-host connection service , but not both . Computer networks that provide only a connection service at network layer are called <strong>Virtual-circuit(VC) networks</strong> , computer network that provide only connectionless service at the network layer are called <strong>datagram networks</strong>.</p>\n<h2 id=\"4-2-1-Virtual-Circuit-Networks\"><a href=\"#4-2-1-Virtual-Circuit-Networks\" class=\"headerlink\" title=\"4.2.1 Virtual-Circuit Networks\"></a>4.2.1 Virtual-Circuit Networks</h2><p><strong>A VC consists of :</strong><br><br>(1). A path (that is , a series of links and routers) between the source and the destination hosts <br><br>(2). VC number one number for each link along the path .<br><br>(3). Entries in the forwarding table in each router along the path. A packet belonging to a virtual circuit will carry a VC number in its header. Because a virtual circuit may have a different VC number on each link. Each intervening router must replace the VC number of each traversing packet with a new VC number . The new VC number is obtained from forwarding table.<br></p>\n<p><strong>For example:</strong><br><br>suppose The host A request to establish VC connection between itself and host B , We choose the path is A-R1-R2-B , suppose we set 12 , 22 and 32 to these three link. Hence , the value of VC number field is 12 when the packet leave  host A , the value of VC number field is 22 when the packet leave  R1 , the value of VC number field is 32 when the packet leave  R2 .<br><img src=\"Simple-Virtual-Circult-Network.png\" alt=\"Simple-Virtual-Circult-Network.png\"><br><br><img src=\"Simple-VC-Path.png\" alt=\"Simple-VC-Path.png\"><br></p>\n<p>Whenever a new VC is established across a router , an entry is added to the forwarding table . Similarly , whenever a VC terminates , the appropriate entry in each table along its path are removed. — <strong>In a VC network , the network router must maintain connection state information for each ongoing connection</strong><br></p>\n<p><strong>Three identifiable phases in a virtual-circuit network.</strong><br></p>\n<ul>\n<li><strong>VC setup:</strong> The network layer determines the path between sender and receiver , that is the series of link and routers through which all packets of VC will travel. The network layer also determines the VC number for each link along the path. Finally , the network layer add the entry to forwarding table in each router along the path. During the VC setup , the network layer may also reserve resource (for example : bandwidth) along the path of VC.</li>\n<li><strong>Data transfer :</strong> The VC connection have been established , packets can being flow along the VC.</li>\n<li><strong>VC teardown:</strong> This is initiated when the sender (or receiver) informs the network layer of its desire to terminate the VC connection , The network layer will typically inform the end system on the other side of the network of call termination and update the forwarding tables in each of packet routers on the path to indicate that the VC no long exist.<br></li>\n</ul>\n<p><strong>Signaling Message and Signaling Protocol</strong><br></p>\n<ul>\n<li><strong>Signaling Message:</strong> The message that the end systems send into the network to initiate or terminate a VC , the message passed between the routers to setup the VC (that is to modify connection state in router table ).</li>\n<li><strong>Signaling Protocol :</strong> The protocol used to exchange signaling message are often referred to as signaling protocol.<br><img src=\"Virtual-Circuit-Setup.png\" alt=\"Virtual-Circuit-Setup.png\"><br></li>\n</ul>\n<p><em>More detail about the signaling protocol and signaling message see [Black 1997] for a general discussion of signaling in connection-oriented networksand [ITU-T Q.2931 1995] for the specification of ATM’s Q.2931 signaling protocol.</em><br></p>\n<h2 id=\"4-2-2-Datagram-Networks\"><a href=\"#4-2-2-Datagram-Networks\" class=\"headerlink\" title=\"4.2.2 Datagram Networks\"></a>4.2.2 Datagram Networks</h2><p>In the datagram networks , each time and end system want to send a packet , it stamps the packet with the address of the destination end system and then pop the packet into the network . As shown in figure follow , <strong>these is no VC setup and routers do not maintain any VC state information (because there are no VCs)</strong><br><img src=\"Datagram-Network.png\" alt=\"Datagram-Network.png\"><br></p>\n<p>As a packet is transmitted from source to destination , it passes through a series of routers , Each of these router use the packet’s destination address to forward the packet , Specifically , each router these of router has a forwarding table map the destination address to link interfaces , When a packet arrived at the router , the router use the packet’s destination address to look up appropriate link interface in the forwarding table , the router then intentionally forwards the packet to the output link interface. <br></p>\n<p><img src=\"Datagram-Forwarding-Table.png\" alt=\"Datagram-Forwarding-Table.png\"><br><br>When these are multiple matches , the router uses the <strong>longest prefix matching rule</strong> that is finding the longest matching entry in the forwarding table , and then forwards the packet to link interface associated with the longest prefix match.<br></p>\n<p><em>The time scale at which this forward state information (forward table entry) change is relatively slow. Indeed in a datagram network the forwarding table are modified by routing algorithm. which typically update a forwarding table every one-to-five minutes or so.</em> </p>\n<h1 id=\"4-3-What’s-Inside-a-Router\"><a href=\"#4-3-What’s-Inside-a-Router\" class=\"headerlink\" title=\"4.3 What’s Inside a Router?\"></a>4.3 What’s Inside a Router?</h1><p>A high-level view of a generic router architecture is shown in figure follow . Four router components can be identified :<br></p>\n<ul>\n<li><strong>Input port :</strong> An input port perform several key functions .<ul>\n<li>It performs the physical layer function of terminating an incoming physical link at router. (Occurring in leftmost box of input port<br>and rightmost box of output port.)<br></li>\n<li>It performs the link-layer functions needed to interoperate<br>with the link layer at other side of incoming link . (Occurring in middle box in the input and output ports)<br></li>\n<li>It perform the lookup functions that is the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. (Occurring in the rightmost box of input port)</li>\n</ul>\n</li>\n<li><strong>Switching Fabric :</strong> The switching fabric connects the router’s input port to its output port.<br></li>\n<li><strong>Output port:</strong> An output port store the packet from switching fabric and transmits these packets on outgoing link by performing the necessary link-layer and physical-layer functions.<br></li>\n<li><strong>Routing Processor :</strong> The routing processor executes the routing protocol (study in section 4.6) maintain routing table and attached link state information and computer the forwarding table for the router .It also perform the network management (study in chapter 9).<br><img src=\"Router-Architecture.png\" alt=\"Router-Architecture.png\"><br></li>\n</ul>\n<p>A router input port , output port and switch fabric together implement the forwarding function and almost always implemented in the hardware.<br></p>\n<h2 id=\"4-3-1-Input-Processing\"><a href=\"#4-3-1-Input-Processing\" class=\"headerlink\" title=\"4.3.1 Input Processing\"></a>4.3.1 Input Processing</h2><p>The lookup performed in the input port is central to the router’s operation — it is here that the router uses the forwarding table to lookup the output port to which an arrived packet will be forwarded via switching fabric , the forwarding table is computed and updated by the router processor. The forwarding table is copied from the routing processor to the line cards over separate bus (eg: PCI bus). With the forwarding table copies , forwarding decision can be made locally , at each input port , without invoking the centralized routing processor. Once a packet’s output port have been determined via the lookup , the packet can be sent into the switching fabric.<br><br><img src=\"Input-Port-Processing.png\" alt=\"Input-Port-Processing.png\"><br></p>\n<p><strong>Although lookup is arguably the most importance action in input port processing many other action must be taken :</strong> <br></p>\n<ul>\n<li>Physical and link layer processing must be occur as discussed above;</li>\n<li>The packet’s version number , checksum and time-to-live-field (We will study in section 4.4.1)<br></li>\n<li>counter used to network management (such as the number of IP datagram received) must be updated.</li>\n</ul>\n<h2 id=\"4-3-2-Switching\"><a href=\"#4-3-2-Switching\" class=\"headerlink\" title=\"4.3.2 Switching\"></a>4.3.2 Switching</h2><p><img src=\"Three-Switching-Techniques.png\" alt=\"Three-Switching-Techniques.png\"><br><br><strong>Switching can be accomplished in a number of way , as shown in figure above.<br></strong></p>\n<ul>\n<li><p><strong>Switching via memory :</strong> The simplest , earliest routers were traditional computers with switching between the input ports and output ports being done direct control of the CPU (routing process). Input port and output ports functioned as traditional I/O devices in traditional operating system. An input ports with an arriving packet signaled the routing process via an interrupt , The packet was then copied from input port to processor memory. The routing process was then extracted the destination address from the header , look up the appropriate outpost in the forwarding table , and copied the packet to the output post’s buffer.<br><strong>Note that two packet can not be forwarded at the same time even if they has different destination ports. So that packets transferring speed is very slow.</strong> Many modern routers switch via memory. A major difference from early routers,however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards.</p>\n</li>\n<li><p><strong>Switching via bus:</strong> In this approach , an input port transfers packet directly to output port without intervention by the routing process. This is typically done by having the input port pre-pend a switching internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. The packet is received by all output posts , but only the port that matches the label will keep this packet. The label is then removed at the outpost port. <strong>If multiple packets arrive to the router at the same , each at a different input ports , all but one must wait since only one packet can cross the bus at a time .(The roundabout could only contain one car at a time)</strong></p>\n</li>\n<li><p><strong>Switching via an interconnection network:</strong> A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports and N output ports . Each vertical bus intersects intersects each horizontal bus at a crosspoint , which can opened and closed at any time by switching fabric controller. When a packet arrives from post A and need to be forwarded to post B , the switch controller closes the crosspoint at intersection of buses A and Y and port A sends the packet onto its bus , which is picked up (only) by bus Y. Note that the packet from B need to be forwarded to post X at the same time , <strong>crossbar network are capable of forwarding multiple packet in parallel, However if two different input post destined to same output post , the one have to wait at the input port.</strong></p>\n</li>\n</ul>\n<h2 id=\"4-3-3-Output-processing\"><a href=\"#4-3-3-Output-processing\" class=\"headerlink\" title=\"4.3.3 Output processing\"></a>4.3.3 Output processing</h2><p>Output post processing take packets that have been stored in the output port’s memory and then transmit them over the output link. This include selecting and de-queueing packet for transmission and performing the needed link-layer and physical-layer transmission functions.<br><br><img src=\"Output-Port-Processing.png\" alt=\"Output-Port-Processing.png\"><br></p>\n<h2 id=\"4-3-4-Where-Does-Queueing-Occur\"><a href=\"#4-3-4-Where-Does-Queueing-Occur\" class=\"headerlink\" title=\"4.3.4 Where Does Queueing Occur ?\"></a>4.3.4 Where Does Queueing Occur ?</h2><p>It’s clear that packet queue may form at both the input port and the output port.<br><br><img src=\"Output-Port-Queueing.png\" alt=\"Output-Port-Queueing.png\"><br><br>In this scenario (<em>$R<em>{switch}$ fast enough $R</em>{link}$</em> ), packets arriving at each of N input ports and destined to same the output port. Since the output port can transmit only a single packet in a unit of time(a packet transmission time) . The N arriving packets will have to queue(wait) for transmission over to outgoing link. Eventually if the number of queued packets grow large enough to exhaust available memory at the output port , in which case packet are dropped.<br><br>A consequence of output port queueing is that <strong>packet scheduler</strong> at the output port must choose a packet among those queued for transmission. The selection may be first-come-fist-served (FCFS) , weighted fair queueing (WFQ) which shares the outgoing link fairy among the different end-to-end connections that have packets queued for transmission.<br><br>Similarly , if there is not enough memory to buffer an incoming packet , a decision must be made to either drop arriving packet or remove one or more already-queued packets to make room for newly arriving packet.<br>For example : <em>Active Queue Management (AQM) algorithm</em> and <em>Random Early Detection (RED) algorithm</em><br><br>If <em>$R<em>{switch}$ not fast enough $R</em>{link}$</em> The switch fabric to transfer all arriving packets though the fabric without delay , then packet queueing can also occur at the input ports that is packets must join input port to wait turn to be transferred though the switching fabric to output port.<br><br><img src=\"HOL-Block-At-An-Input-Queued-Switch.png\" alt=\"HOL-Block-At-An-Input-Queued-Switch.png\"><br><br>Figure above shown an example , and suppose that<br><br><strong>(1)</strong>.the switching fabric is crossbar switching fabric.<br><br><strong>(2)</strong>.Packets are moved from a given input queue to their desired output queue in an FCFS manner. Two packets (<em>darkly shaded, port 1,3</em>) at the front of their input port queues are destined for the same upper-right output port. Suppose that the switching fabric choose to transfer the packet from the front of the upper-left queue. In this case the packet in lower-left queue must wait , not only darkly shaded must be wait , but also the lightly shaded packet that behind the darkly shaded in the lower-left queue even though it destined for middle-right output port . This phenomenon is knowns as <strong>head-of-the-line (HOL) blocking.</strong></p>\n<h1 id=\"4-4-The-Internet-Protocol-IP-Forwarding-and-Addressing-in-the-Internet\"><a href=\"#4-4-The-Internet-Protocol-IP-Forwarding-and-Addressing-in-the-Internet\" class=\"headerlink\" title=\"4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.\"></a>4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.</h1><p><strong>Inside of the Internet’s Network Layer:</strong><br><br><img src=\"A-Look-Inside-The-Internet-Network-Layer.png\" alt=\"A-Look-Inside-The-Internet-Network-Layer.png\"><br><br><strong>The three major component inside the internet network:</strong></p>\n<ul>\n<li><strong>IP Protocol</strong></li>\n<li><strong>Routing Component (Routing protocol study in section 4.6)</strong></li>\n<li><strong>Report error and in datagram and respond to request for certain network-layer information. Internet Contorl Message Protocol (ICMP) studied in section 4.4.3</strong></li>\n</ul>\n<h2 id=\"4-4-1-Datagram-Format\"><a href=\"#4-4-1-Datagram-Format\" class=\"headerlink\" title=\"4.4.1 Datagram Format\"></a>4.4.1 Datagram Format</h2><p>The network-layer packet is referred to as a datagram.<br><br><strong>Ipv4-Datagram-Format:</strong><br><br><img src=\"Ipv4-Datagram-Format.png\" alt=\"Ipv4-Datagram-Format.png\"><br><br><strong>The key field of Datagram format are following:</strong><br></p>\n<ul>\n<li><strong>Version number :</strong> These 4 bits specify the IP protocol version of the datagram , by look at the version number , the router can determine how to interpret the remainder of IP datagram . Different Version of IP use different datagram format.<br></li>\n<li><strong>Header length:</strong> Because the IPv4 datagram contain a variable number of options (which are included in the IPv4 datagram header) This 4 bits is needed to determine where the data actually being in the datagram . Most Ipv4 datagram don’t contain option , so the typical IP datagram has a 20 bytes header.</li>\n<li><strong>Type of service:</strong> The type of service bits were included in ipv4 header to allow different types of datagram (for example : requiring low delay , hight throughput or reliability).</li>\n<li><strong>Datagram length:</strong> This is a total length of the IP datagram (Header Plus Data) , since this field is 16 bits , so that the maximum size of the IP datagram is 65535 bytes, however datagram rarely larger than 1500 bytes.</li>\n<li><strong>Identifier , flags , fragmentation offset:</strong> These three field we will consider depth in shortly.</li>\n<li><strong>Time-to-live:</strong> The field used to ensure that datagram don’t circulate forever in the network.</li>\n<li><strong>Protocol :</strong> The value of this field is used to indicates the specific transport-layer-protocol to which the data portion of this datagram should be passed , for example the value 6 represent TCP and the value 17 represent UDP.</li>\n<li><strong>Header Checksum :</strong> The header checksum aids a router detecting bit error in a received IP datagram.<br><br><strong>Why does TCP/IP perform error checking at both the transport and network layer.</strong><br><ul>\n<li><em>only the IP header is checksummed at the IP layer while the TCP/UDP checksum is computed over the entire TCP/UDP segment.</em></li>\n<li><em>TCP/UDP and IP do not necessarily both have to belong to the same protocol stack. IP also can service other protocol (different to TCP/UDP).</em></li>\n</ul>\n</li>\n<li><strong>Source and Destination IP Addresses</strong></li>\n<li><strong>Options :</strong> The options flied allow an IP header to be extended.</li>\n<li><strong>Data field (payload):</strong> In most circumstance , the data field of the IP datagram contains the transport-layer segment (for example UDP/TCP) . However , the data field can carry other types of data such as ICMP message .</li>\n</ul>\n<h3 id=\"IP-datagram-fragmentation\"><a href=\"#IP-datagram-fragmentation\" class=\"headerlink\" title=\"IP datagram fragmentation\"></a>IP datagram fragmentation</h3><p>Since not all link-layer protocol can carry network-layer protocol of the same size . Some protocol can carry big datagrams , whereas other protocols can only a little packets. (for example : Ethernet frames carry 1500 bytes of data, the wide-area links can no more than 576 bytes.)<br></p>\n<p><em>Because each IP datagram is encapsulated within the link-layer frame for transport from one router to next router. The problem is that each of link along the router between sender and destination can use different link-layer protocols and each of those protocol can have different MTUs(maximum transmission unit).<br></em></p>\n<p>Suppose the router have MTU that is smaller than the length of the IP datagram . How to squeeze this oversize IP datagram into the payload field of the link-layer frame?<br><br>The solution is to fragment the data in the IP datagram into two or more smaller IP datagrams , encapsulate each of these smaller IP datagram in a separate link-layer frame and send these frames over the outgoing link . Each of these smaller datagram is referred to as a fragment.<br><br>Fragment need to reassembled before they reached the transport layer at the destination . Indeed both TCP and UDP expecting to complete, unfragmented segment from the network layer.<br></p>\n<p><strong>How to determine a packet whether or not a fragment , how to reassemble these fragment and when the destination host have received the last fragment of some original larger datagram.</strong><br><br>The answer is three field in the ipv4 datagram header.<br></p>\n<ul>\n<li><strong>16-bits-identifier field:</strong> When a datagram is created , the sending host stamps the datagram with an identification number as well as source and destination address. Typically , the sending host increments the identification number of each datagram it sends.<br></li>\n<li><p><strong>13-bits Fragmentation offset:</strong> When a router need to fragment a datagram , each resulting fragment is stamped with the source and destination address , and identification number of original datagram , and then the Fragmentation offset field is used to specify where the fragment fit within the original IP datagram.<em>(unit is bit)</em></p>\n</li>\n<li><p><strong>Flags field:</strong> This field is used to identify the last fragment of Original Ipv4 datagram . The last fragment has a flags bit set to 0 , and other fragment has a flags bit set to 1.<br><br><img src=\"IP-fragmentation-and-reassembly.png\" alt=\"IP-fragmentation-and-reassembly.png\"><br><br><img src=\"Ip-fragments.png\" alt=\"Ip-fragments.png\"><br><br>If one or more fragment does not arrive , the incomplete fragments is discarded and not passed to transport layer , and The transport layer protocol is TCP , TCP will recover this loss by retransmission.<br></p>\n</li>\n</ul>\n<h2 id=\"4-4-2-IPv4-Addressing\"><a href=\"#4-4-2-IPv4-Addressing\" class=\"headerlink\" title=\"4.4.2 IPv4 Addressing\"></a>4.4.2 IPv4 Addressing</h2><ul>\n<li><strong>Interface :</strong> The boundary between the host and physical link is called an interface.</li>\n</ul>\n<p><strong>A router has multiple interfaces and each of these interfaces have its own unique IP address.</strong><br><img src=\"Interface-Address-And-Subnets.png\" alt=\"Interface-Address-And-Subnets.png\"><br></p>\n<ul>\n<li><strong>Subnet:</strong> To determine the subnet detach each interface from its host and router , creating islands of isolated networks with interfaces terminating the end points of isolated networks , Each of these isolated networks is called a subnet.<br></li>\n</ul>\n<p>Shown as figure above , In the upper-left , this network interconnecting three host interfaces and one router interface forms a <strong>subnet</strong>. IP addressing assigns an address to this subnet : 223.1.1.0/24 , where the /24 notation , sometime known as <strong>subnet mask</strong>, Indicate that the leftmost 24-bits of 32-bits quantity define the subnet address.</p>\n<p>The internet’s addressing assignment strategy is known as <strong>Classless Interdomain Routing (CIDR)</strong> As with subnet addressing , the 32-bits IP address is divided into two parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the number of bits in the first past of the address (<strong>network prefix</strong>) . When we cover the internet BGP routing protocol in the section 4.6 , we will see that only these leading x prefix bits are considered by routers the organization’s network. That is when a router outside the organization forwards a datagram whose destination address is inside the organization only these leading x bits of the address need be considered . The remaining $32-x$ bits of an address can be though of as distinguishing among the devices within the organization. These bits will be considered when forwarding packets at routers within the organization.<br></p>\n<p><em>The special IP address : 255.255.255.255 (IP broadcast address), when a host send a datagram with destination address 255.255.255.255, this message is delivered to all host on the same subnet.</em></p>\n<h3 id=\"Obtaining-a-Block-of-Address\"><a href=\"#Obtaining-a-Block-of-Address\" class=\"headerlink\" title=\"Obtaining a Block of Address\"></a>Obtaining a Block of Address</h3><p><em>Internet corporation  for Assigned Name and Number (ICANN) has responsibility for managing the IP address space and allocating address blocks to ISPs and other organizations.<br></em></p>\n<p>In order to obtain a block of IP addresses for use within an organization’s subnet , a network administrator might first contract its ISP , while would provide addresses from a larger block of addresses that had already been allocated to the ISP. For example , the ISP may itself have been allocated the address block 200.23.16.0/20 ,the ISP divide its address block into eight equal-sized contiguous address block and give one of these address block out to each of up to eight organizations.<br><br><img src=\"Organization-Address.png\" alt=\"Organization-Address.png\"><br></p>\n<h3 id=\"Obtaining-a-host-Address-The-Dynamic-Host-Configuration-Protocol\"><a href=\"#Obtaining-a-host-Address-The-Dynamic-Host-Configuration-Protocol\" class=\"headerlink\" title=\"Obtaining a host Address : The Dynamic Host Configuration Protocol\"></a>Obtaining a host Address : The Dynamic Host Configuration Protocol</h3><p>Once an organization obtained a block of addresses it can assign individual IP address to host and router interface in its organization.<br>The router IP address typically manually configure by a system administrator. The host IP address typically configure by using <strong>Dynamic Host Configuration Protocol (DHCP)</strong> DHCP allows a host obtain an IP address automatically. As the host join and leave , the DHCP server need to update its list of available IP addresses.<br></p>\n<p>DHCP is a client-service protocol . A client is typically a newly arriving host wanting to obtain network configuration informations. Each subnet have a DHCP service . If no server is present on the subnet , a DHCP relay agent (typically a router) that knows the address of a DHCP service for that network is needed , for example show as figure below , DHCP service attached to subnet 223.1.2/24 , with the router serving as relay agent for arriving clients attached to subnet 223.1.1/24 and 223.1.3/24 .<br><br><img src=\"DHCP-Client-Server-Scenario.png\" alt=\"DHCP-Client-Server-Scenario.png\"><br></p>\n<p><strong>When a newly arriving host income to subnet , The DHCP has four steps for assign a IP address to new host.<br></strong></p>\n<ul>\n<li><p><strong>DHCP server discovery:</strong>  This is done using <strong>DHCP discovery message</strong> The new host send a DHCP discovery message with a UDP packet , port 67 source IP address : 0.0.0.0 (since , new host hasn’t IP address) and destination IP address : 255.255.255.255 (broadcast address). The UDP packet is encapsulated in a IP datagram and then passed to the link-layer. (We will cover the detail of broadcast in section 5.4)<br></p>\n</li>\n<li><p><strong>DHCP server offer(s) :</strong> A DHCP server receiving a DHCP discovery message responds to the client with the <strong>DHCP offset message</strong> that is broadcast to all notes on the subnet using the broadcast IP address : 255.255.255.255. Each server offer message contain the transaction ID of the receiver discovery message , the proposed IP address for the client , the network mask , and an IP address lease time . </p>\n</li>\n<li><p><strong>DHCP request :</strong> The newly arriving client will choose from among one or more server offers and respond to its selected offer with <strong>DHCP request message</strong> echoing back the configuration parameters.</p>\n</li>\n<li><p><strong>DHCP ACK:</strong> The server responds to the DHCP request message with a <strong>DHCP ACK message</strong> confirming the requested parameters.<br></p>\n</li>\n</ul>\n<p><em>yiaddr(as in “your Internet address”)</em><br><img src=\"DHCP-Client-Server-Interaction.png\" alt=\"DHCP-Client-Server-Interaction.png\"><br><br>Once the clients receives the DHCP ACK , the interaction is compelte and client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease’s expiration , DHCP also provide a mechanism that allow a client to renew its lease on an IP address.<br></p>\n<h3 id=\"Network-Address-Translation-NAT\"><a href=\"#Network-Address-Translation-NAT\" class=\"headerlink\" title=\"Network Address Translation (NAT)\"></a>Network Address Translation (NAT)</h3><p>With proliferation of small office , home office (for example , the kid at home not only their computer but have one or more smartphone and networked game ..etc) , the ISP have not enough IP address to handle this scenarios , what should we do in this scenarios.<br></p>\n<p>The answer is NAT (Network Address Translation)<br><br><strong>Figure follow is show the operation of NAT-enabled router.<br></strong><br><img src=\"Network-Address-Translation.png\" alt=\"Network-Address-Translation.png\"><br><br>In figure above all traffic leaving the home router for for the larger internet has a source IP address of 138.76.29.7 and all traffic entering the home router must have a destination IP address 138.76.29.7. In essence the NAT-enabled router is hiding the detail of the home network from the outside world.<br></p>\n<ul>\n<li><p><strong>Question: How the home network computer (or other network device) get their home IP address (for example 10.0.0.0/24)?</strong><br><br>The answer is DHCP , The router get its IP address from the ISP’s DHCP server and the router runs a DHCP server to provide addresses to computer (or other device ) within the NAT-DHCP-router-controlled-home-network’s-address-space.<br></p>\n</li>\n<li><p><strong>Question : If all datagram arriving at the NAT-Router from the WAN have the same destination IP address , how does the router know the internal host which it should forward a given datagram.</strong> <br><br>The trick is use a <strong>NAT translation table</strong> at the NAT router , and to include port number as well as IP addresses in table entries. For example shown as figure above , the host computer 10.0.0.1 request a web page on some web server (port 80) with IP address 128.119.40.186 . The host 10.0.0.1 assigns the (arbitrary) source port number 3345 and send the datagram into the LAN , The NAT-Router receives the datagram , genarates a new source port number 5001 , replace the source IP address with it WAN-side IP address 138.76.29.7 and replace the original source number 3345 with its new source port number 5001. NAT-Router adds an new entry to its NAT translation table and send a new datagram to WAN , when a datagram arriving at the NAT-Router , the NAT-Router use the destination IP address and destination port to obtain appropriate IP address (10.0.0.1) and destination port (3345) , then send a datagram to home network.</p>\n</li>\n</ul>\n<h3 id=\"UPnP\"><a href=\"#UPnP\" class=\"headerlink\" title=\"UPnP\"></a>UPnP</h3><p>The detail we can see the textbook page 352.</p>\n<h2 id=\"4-4-3-Internet-Control-Message-Protocol-ICMP\"><a href=\"#4-4-3-Internet-Control-Message-Protocol-ICMP\" class=\"headerlink\" title=\"4.4.3 Internet Control Message Protocol (ICMP)\"></a>4.4.3 Internet Control Message Protocol (ICMP)</h2><p>ICMP protocol is used by hosts and router communicate network-layer informations to each other. The most typical use of ICMP is error reporting.<br><br>The ICMP message is carried inside the IP datagrams , that is ICMP messages are carried as IP payload.<br></p>\n<p>ICMP message have a type field and a code field and checksum field.<br><br><img src=\"General-en.svg.png\" alt=\"General-en.svg.png\"><br></p>\n<p><strong>The ICMP control message :</strong><br><br><img src=\"ICMP-Message-Types.png\" alt=\"ICMP-Message-Types.png\"><br></p>\n<h2 id=\"4-4-4-IPv6\"><a href=\"#4-4-4-IPv6\" class=\"headerlink\" title=\"4.4.4 IPv6\"></a>4.4.4 IPv6</h2><h3 id=\"IPv6-Datagram-Format\"><a href=\"#IPv6-Datagram-Format\" class=\"headerlink\" title=\"IPv6 Datagram Format\"></a>IPv6 Datagram Format</h3><p><strong>Most importance changes introduced in IPv6 :<br></strong></p>\n<ul>\n<li><p><strong>Expanded addressing capabilities :</strong> IPv6 increases the size of the IP address from 32 bits to 128 bits . This ensure that the world won’t run out of IP address. In addition to unicast and multicast address , IPv6 introduced a new type of address called <strong>anycast address</strong><br></p>\n</li>\n<li><p><strong>A streamlined 40-byte header :</strong> A number of IPv4 fields have been dropped or made optional , The resulting 40-bytes-fixed-length header allows for faster processing of the IP datagram . A new encoding of option allow for more flexible option processing.</p>\n</li>\n<li><p><strong>Flow labeling and priority :</strong> The IPv6 header also has an 8-bits traffic class field. This field can be used to give priority to certain datagram within a flow or it can be used to give priority to datagram from certain application (for example ICMP) over datagram from other applications (for example : network new).</p>\n</li>\n</ul>\n<p><img src=\"IPv6-Datagram-Format.png\" alt=\"IPv6-Datagram-Format.png\"><br></p>\n<p><strong>The following fields defined in IPv6:</strong></p>\n<ul>\n<li><strong>Version :</strong> This 4-bits field identifies the IP version number.<br></li>\n<li><strong>Traffic class :</strong> This 8-bits field is similar in spirit to the TOS (Type of service) field we saw in IPv4.</li>\n<li><strong>Flow label :</strong> This 20-bits is used to identify a flow of datagrams.<br></li>\n<li><strong>Payload length :</strong> This 16-bits is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fix-length 40-byte datagram header.</li>\n<li><strong>Next header :</strong> This field is used identifies the protocol to which the content of this datagram will be delivered. This field uses the same values as the protocol field in the IPv4 field.</li>\n<li><strong>Hop limit :</strong> The content of this field are decremented by one by each router that forward the datagram . If the hop limit count reaches zero , the datagram is discarded.</li>\n<li><strong>Source and destination address :</strong> 128-bits IP address.</li>\n<li><strong>Data :</strong> This is the payload portion of the IPv6 datagram.</li>\n</ul>\n<p><strong>The several fields appearing in the IPv4 datagram are no longer present in the IPv6 datagram.</strong><br></p>\n<ul>\n<li><strong>Fragmentation/Reassembly :</strong> IPv6 do not allow for fragmentation and reassembly at intermediate . These operations performed only by the source and destination . If an IPv6 datagram received by a router is too large to be forwarded over the outgoing link , the router simply drops the datagram and sends “a packet too big” ICMP error message back to the sender , the sender can then resend the packet using a smaller IP datagram size. Fragmentation and reassembly is a time-consuming operation ; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up IP forwarding within the network.</li>\n<li><strong>Header checksum :</strong> Because the transport-layer and link-layer protocols in the internet layers perform checksumming , the designers of IP protocol felt that this functionality was sufficiently redundant in the network layer could be removed. The IPv4 header checksum needed to recomputed at every router , As with fragmentation and reassembly , this too was a costly operation in IPv4.</li>\n<li><strong>Options :</strong> An options field is no longer a part of the standard IP header. However , it has not gone away . Instead the option field is one of possible next header pointed to from within the IPv6 header . Just as TCP or UDP protocol headers can be the next header within an IP packet .</li>\n</ul>\n<p><em>A new version of ICMP protocol is known as ICMPv6 , that is used to service for IPv6</em></p>\n<h3 id=\"Transitioning-from-IPv4-to-IPv6\"><a href=\"#Transitioning-from-IPv4-to-IPv6\" class=\"headerlink\" title=\"Transitioning from IPv4 to IPv6\"></a>Transitioning from IPv4 to IPv6</h3><p>We have two approaches for gradually integrating IPv6 hosts and routers into an IPv4 world (with the long-term goal, of course, of having all Ipv4 node eventually translation to IPv4).<br></p>\n<p><strong>Dual-Stack Approach :</strong><br><br>That is IPv6 nodes also have complete IPv4 implementation. That has the ability to send and receive an both IPv4 and IPv6 datagram ; when interoprating with an IPv4 node an IPv6/IPv4 node can use IPv4 datagram , when interopratig with an IPv6 node it can speak IPv6. IPv6 and IPv4 nodes must have both IPv6 and Ipv4 address.<br><br><img src=\"A-Dual-Stack-Approachs.png\" alt=\"A-Dual-Stack-Approachs.png\"><br></p>\n<p><strong>Problem :</strong> <br><br>As figure above , The node A communicate with node F , and node A send a datagram to node F , when a datagram is sent from node B (IPv6) to node C (IPv4) , The node B must create a new datagram to send to node C , the data field of the IPv6 can be copied into the data field of the IPv4 datagram and appropriate address mapping can be done . However , in performing the conversion from IPv6 to IPv4 , there will be IPv6-specific fields in the datagram (for example the flow identifier field) that have no counterpart in IPv4 , The information in these fields will be lost.<br></p>\n<p><strong>Tunneling (An alternative to the dual-stack approach):</strong><br><br><em>Tunneling can solve the problem note above.</em><br><br><img src=\"Tunneling.png\" alt=\"Tunneling.png\"><br><br>Suppose two IPv6 nodes (for example : B and E in the figure above) want to interoperate using IPv6 datagram but are connected to each other by intervening IPv4 routers. We refer to the intervening set of IPv4 router between two IPv6 router as a <strong>tunnel</strong>. With tunneling , the IPv6 node on the send side of the tunnel (node B) **takes the entire IPv6 datagram and put it into the data field (payload) of IPv4 datagram.<br>This IPv4 datagram is then addressed to the IPv6 node on the receiving side of the tunnel (node E) and sent to the first node in the tunnel (node C). The IPv6 node on the receiving side of the tunnel eventually receives the IPv4 datagram (it is a destination of IPv4 datagram!) determine that IPv4 datagram contain an IPv6 datagram , extract the IPv6 datagram and then routes the IPv6 datagram exactly as it would if it had received the IPv6 datagram from a directly connected IPv6 neighbor.<br></p>\n<h2 id=\"4-4-5-A-Brief-Foray-into-IP-Security\"><a href=\"#4-4-5-A-Brief-Foray-into-IP-Security\" class=\"headerlink\" title=\"4.4.5 A Brief Foray into IP Security\"></a>4.4.5 A Brief Foray into IP Security</h2><p>Using IPsec protocol provide security service . (more detail see the chapter 8).</p>\n<h1 id=\"4-5-Routing-Algorithm\"><a href=\"#4-5-Routing-Algorithm\" class=\"headerlink\" title=\"4.5 Routing Algorithm\"></a>4.5 Routing Algorithm</h1><p><strong>Routing Algorithm operating in network routers , exchange and compute the information that is used to configure these forwarding table .</strong><br><br>Whether network layer provide datagram service (packet between the source and destination may takes many different routes)or VC service (packet between the source and destination take the same path) , the network layer must determine the path that packets take from sender to receiver.<br></p>\n<p><em>We will see the job of routing is determine the good paths <strong>(least-cost-path)</strong> from senders to receivers through the network of routers.</em></p>\n<p><strong>Classify routing algorithm according to whether they are global or decentralized.</strong><br></p>\n<ul>\n<li><strong>A global routing algorithm :</strong> Computes the least-cost path between a source and destination using complete global knowledge about the network.(complete global knowledge is mean all node connectively relationship and link cost in the network). In practice algorithm with global state information are often referred to as <strong>Link-state(LS) algorithm</strong>.<br></li>\n<li><strong>A decentralized routing algorithm :</strong> The calculation of least-cost path is carried out in an iterative , distributed manner. No node have complete information about the cost of all network link , instead each node begins with only the knowledge of the cost of its own directly attached links. Then through an iterative process of the calculation and exchange of information with its neighboring nodes , a node gradually calculates the least-cost path to destination or set of destinations. The decentralized routing algorithm is called distance-vector (DV) algorithm .</li>\n</ul>\n<h2 id=\"4-5-1-The-Link-State-LS-Routing-Algorithm\"><a href=\"#4-5-1-The-Link-State-LS-Routing-Algorithm\" class=\"headerlink\" title=\"4.5.1 The Link-State (LS) Routing Algorithm\"></a>4.5.1 The Link-State (LS) Routing Algorithm</h2><p>In practice , The Link-State Routing Algorithm is accomplished by having each node broadcast link-state packets to all other nodes in the network , with each link-state packet containing the identifies and cost of it attached links. The result of the note’s broadcast is that all node have an identical and complete view of the network.  Each node can then run the LS algorithm and compute the same set of least-cost paths as every other node.</p>\n<p>The LS algorithm is known as <strong>Dijkstra’s Algorithm</strong> name after its inventor. A closely related algorithm is Prim’s Algorithm .</p>\n<p><strong>Let us define the following notation:</strong><br></p>\n<ul>\n<li><strong>D(v) :</strong> Cost of the least-cost path from the source to destination v as of this iteration of the algorithm.</li>\n<li><strong>P(v) :</strong> Previous node (neighbor of node v) along the current least-cost path from source to node v.</li>\n<li><strong>N’:</strong> subset of nodes , if v in <strong>N’</strong> represent the least-cost path from source to v have been definitely known.</li>\n</ul>\n<p><img src=\"Graph-Of-Link-State-Algorithm.png\" alt=\"Graph-Of-Link-State-Algorithm.png\"><br></p>\n<p><em>Link-State Algorithm For Source Node u</em><br></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\">Initialization :<br>\tN<span class=\"hljs-number\">&#x27;</span> = &#123;u&#125;;<br>\t<span class=\"hljs-keyword\">for</span> all nodes v <br>\t\t<span class=\"hljs-keyword\">if</span> v is a neighbor of u <br>\t\t\t<span class=\"hljs-function\">then <span class=\"hljs-title\">D</span><span class=\"hljs-params\">(v)</span> </span>= c(u,v)<br>\t\t<span class=\"hljs-keyword\">else</span> D(v) = ∞<br>Loop :<br>\tFind w <span class=\"hljs-keyword\">not</span> in N<span class=\"hljs-number\">&#x27;</span> simultaneously D(w) is a minimum<br>\tAdd w to N<span class=\"hljs-number\">&#x27;</span><br>\tUpdate D(v) <span class=\"hljs-keyword\">for</span> each neighbor v of w <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> in N<span class=\"hljs-number\">&#x27;</span> : <br>\tD(v) = min ( D(v) , D(w)+c(w,v) );<br>Until : N<span class=\"hljs-number\">&#x27;</span> = N ( N is <span class=\"hljs-built_in\">set</span> of all node )<br></code></pre></td></tr></table></figure>\n<p><img src=\"Result-Of-LS-Algorithm.png\" alt=\"Result-Of-LS-Algorithm.png\"><br></p>\n<p><strong>The detail of step can watch the video follow:</strong><br> </p>\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/ud7qWRBirsk\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n<p><strong>Problem of LS algorithm :</strong><br></p>\n<p><strong>Figure follow shown a simple network topology where link costs are equal to the load carried on the link.</strong><br>In this example , link cost are not symmetric that is the C(u,v) equal to C(v,u) only if the load carried on the both directions on the link(u,v) is same . <br></p>\n<p><strong>In this example , node z originates a unit of traffic destined for node w , node x also originates a unit of traffic destined for node w and node y injects an amount of traffic equal to e also destined for node w .</strong><br></p>\n<p><strong>The order of looking at figure is a-&gt;b-&gt;c-&gt;d</strong><br></p>\n<p><img src=\"Oscillations-With-Congestion-Sensitive-Routing.png\" alt=\"Oscillations-With-Congestion-Sensitive-Routing.png\"><br></p>\n<p>We can see the <strong>Oscillation</strong> with congestion sensitive routing.<br></p>\n<p>What can be done to prevent such oscillation ?<br><br>One solution would be to mandate that link costs not depend on the amount of traffic carried — an unacceptable solution since one goal of routing is to avoid highly congested links, Another solution is to ensure that not all routers run the LS algorithm at the same time.</p>\n<h2 id=\"4-5-2-The-Distance-Vector-DV-Routing-Algorithm\"><a href=\"#4-5-2-The-Distance-Vector-DV-Routing-Algorithm\" class=\"headerlink\" title=\"4.5.2 The Distance-Vector (DV) Routing Algorithm\"></a>4.5.2 The Distance-Vector (DV) Routing Algorithm</h2><p>Whereas the LS algorithm is an algorithm using global information , the <strong>distance-vector algorithm</strong> is <em>iterative , asynchronous , and distributed. <br></em></p>\n<ul>\n<li><p>It is distributed in that each node receive some information from its directly attached neighbors , perform a calculation and distributed the result of its calculation back to its neighbors.<br></p>\n</li>\n<li><p>It is iterative in that , this process continue on until no more information is exchanged between the neighbors.<br></p>\n</li>\n<li><p>It is asynchronous in that is does not require all of the nodes to operate in lockstep with each other.<br></p>\n</li>\n</ul>\n<p><strong>The Distance-Vector Routing Algorithm also known as Bellman-Ford Algorithm</strong><br></p>\n<p>For get the least-cost paths , we need to using the celebrated <strong>Bellman-Ford equations:</strong><br> <strong>$d_{v}(y)$ is distance from $v$ to $y$</strong></p>\n<script type=\"math/tex; mode=display\">d_{x}(y)=min_v{c(x,y)+d_v(y)}</script><p>Where the $min<em>{v}$ in the equation is taken over all of x’s neighbors.After traveling from x to v , if we then take the least-cost path from v to y , the path cost will be $c(x,y)+d</em>{v}(y)$ . Since we must begin by traveling to some neighbor $v$ , the least cost from $x$ to $y$ is the minimum of $c(x,y)+d_{v}(y)$ taken over all neighbor $v$.</p>\n<p><strong>Distance-Vector (DV) Algorithm:</strong> <br><br>at each node ,x:<br></p>\n<p><strong>Initialization :</strong> <br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for all destinations $y$ in $N$ : <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp;$D<em>{x}(y)$ = $c(x,y)$  &nbsp; /* if y is not a neighbor then $c(x,y)$ = $\\infty$ */ <br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; $D</em>{w}(y)$ = $?$ &nbsp; /* for all destinations $y$ in $N$ */<br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; send distance vector $D<em>{x} = [ D</em>{x}(y) : y$ in $N ]$ to $w$<br><br><strong>Loop</strong><br><br>&nbsp; &nbsp; <strong>wait</strong> (until i see a link cost change to some neighbor $w$ <br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    &nbsp;&nbsp;or until i receive a distance vector from some neighbor $w$) <br><br>&nbsp;&nbsp;&nbsp; for each $y$ in $N$ :<br><br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    $D<em>{x}(y)$ = $min</em>{v} {c(x,y) + D<em>{v}(y)}$<br><br>&nbsp;&nbsp;&nbsp;if $D</em>{x}(y)$ changed for any destination $y$ <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; send the distance vector $D<em>{x}$ = $[D</em>{x}(y) : y$ in $N]$ to all neighbors<br><br><strong>Forever</strong> <br></p>\n<p><strong>A simple three node illustrates the operation of DV algorithm</strong><br><br><img src=\"DV-Simple-Example.png\" alt=\"DV-Simple-Example.png\"></p>\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/dmS1t2twFrI\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n<h3 id=\"Distance-Vector-Algorithm-Link-Cost-Changes-and-Link-failure\"><a href=\"#Distance-Vector-Algorithm-Link-Cost-Changes-and-Link-failure\" class=\"headerlink\" title=\"Distance-Vector Algorithm : Link-Cost Changes and Link failure\"></a>Distance-Vector Algorithm : Link-Cost Changes and Link failure</h3><p><img src=\"Changes-in-link-cost.png\" alt=\"Changes-in-link-cost.png\"><br></p>\n<p>Figure (a) above illustrates a scenario where link cost from y to x distance vector change from 4 to 1. We force here only on y’ and z’ distance table entires to destination x. The Dv algorithm causes the following sequence of events to occur :<br></p>\n<ul>\n<li>At time $t_{0}$ , $y$ detects the link-cost change (the cost has change from 4 to 1 ) updates its distance vector and inform the neighbors of this change since its distance has changed.</li>\n<li>At time $t_{1}$ , $z$ receives the update from $y$ and update its table . It computer a new least cost of $x$ (it has decreased from a cost of 5 to cost of 2 ) and send its new distance vector to its neighbors.</li>\n<li>At time $t_{2}$ , $y$ receive $z’s$ update and updates its distance table . $y’s$ least cost do not change hence $y$ does not send any message to $z$. The algorithm come to a quiescent state.</li>\n</ul>\n<p>Thus only two iterations are requited for the DV algorithm to reach a quiescent state. <br></p>\n<p>Let now consider what happen when a link cost increases , support that support the link cost between $x$ and $y$ increases from 4 to 60 as shown in figure (b) above.<br></p>\n<ul>\n<li>Before the link cost changes , $D<em>{x}(y) = 4$ , $D</em>{y}(z) =1$ , $D<em>{z}(y) = 1$ and $D</em>{z}(x) = 5$ , $y$ detect the link cost change (the cost change from 4 to 60) , $y$ computes its new minimum-cost path to x have a cost of  <script type=\"math/tex; mode=display\">D_{y}(x) = min \\{C(y,x) + D_{x}(x) , C(y,z)+ D_{z}(x)\\}= min \\{ 60+0,1+5\\} = 6</script>  of course , with out global view of the network , we can see that this new cost via $z$ is wrong . But the only information node $y$ has is that its direct cost to $x$ is 60 and that $z$ has last told $y$ that $z$ could get $x$ with a cost of 5 . So in order to get to $x$, $y$ would now route through $z$ , fully expecting that $z$ will be able to get to $x$ with cost of 5.</li>\n<li>Since node $y$ has computed a new minimum cost to $x$ , it inform $z$ of new distance vector at time $t_{1}$.</li>\n<li>Sometime after $t_{1}$ , $z$ receive the $y’s$ new distance vector ,which indicates that $y’s$ minimum cost to $x$ is 6 . $z$ know get to $y$ with a cost of 1 and computes a new least cost to x of <script type=\"math/tex; mode=display\">D_{z}(x) = min \\{50+0, 1+6\\}=7</script>  Since $z’s$ least-cost to $x$ is increased , and then it inform $y$ of its new distance vector at $t<em>{2}$ at $t</em>{2}$.</li>\n<li>In a similar manner , after receiving $z’s$ a new distance vector , $y$ determines $D<em>{y}(x)=8$ and send $z$ its distance vector . $z$ then determine $D</em>{z}(x) = 9$ and sends $y$ its new distance vector over and over again until $D<em>{z}(x)= min{C</em>{z}(y)+D<em>{y}(x) , C</em>{z}(x)+D_{x}(x)}= min{50+1 ,50+0 }=50$ , at this point , $z$ finally ! determine that its lease-cost path to $x$ is via its direct connection to $x$.</li>\n</ul>\n<p><strong>What way could solve the problem noted above ?</strong><br><br>The answer is <em>Poisoned Reverse.</em><br></p>\n<h3 id=\"Distance-Vector-Algorithm-Adding-Poisoned-Reverse\"><a href=\"#Distance-Vector-Algorithm-Adding-Poisoned-Reverse\" class=\"headerlink\" title=\"Distance-Vector Algorithm : Adding Poisoned Reverse\"></a>Distance-Vector Algorithm : Adding Poisoned Reverse</h3><p>The specific looping scenario just described can be avoided using a technique known as <em>poisoned reverse.</em> The idea is simple <strong>if $z$ routers through $y$ to get to destination $x$ , then $z$ will advertise to $y$ that its distance to $x$ is infinity</strong>, $z$ will advertise to $y$ that $D<em>{z}(x) = \\infty$ ( even though $z$ known $D</em>{x}(z) = 5$ in truth) $z$ will continue telling this little white lie to $y$ as long as it route $x$ via $y$ . Since $y$ believes that $z$ had no path to $x$ ,$y$ will never attempt to route to $x$ via $z$ , as long as $z$ continues to route to $x$ via $y$<br>Let now see how <em>Poisoned Reverse</em> solved the particular looping problem :  When the link-cost $(x,y)$ change from 4 to 60 , $y’s$ distance table indicate $D_{z}(x) = \\infty$ .</p>\n<ul>\n<li>At the time $t<em>{0}$ ,$y$ update its table and continues to route directly to $x$ , albeit at the higher cost of 60 and then inform $z$ of the new distance vector to $x$ , that is $D</em>{y}(x) =60$ .</li>\n<li>After receiving the update at $t<em>{1}$ , $z$ immediately shits the its route to $x$ to be via the direct $(z,x)$ link at the cost of 50, and then $z$ inform $y$ of new cost of $D</em>{z}(x) = 50$ .</li>\n<li>After receiving the update from $z$ , $y$ update its distance table at $D<em>{y}(x)=51$, also , since $z$ is now on $y$’s lease-cost path to $x$ , $y$ poisoned the reverse from $z$ to $x$ by informing $z$ at time $t</em>{3}$ that $D<em>{y}(x) = \\infty$ (even though $y$ know $D</em>{y}(x)=51$ in trush)</li>\n</ul>\n<p><strong>Does poisoned reverse solve the general count-to-infinity problem ? It dose not , when looping involving three or more nodes will not be detected by poisoned reverse.</strong><br></p>\n<h3 id=\"A-comparison-of-LS-and-DV-Algorithm\"><a href=\"#A-comparison-of-LS-and-DV-Algorithm\" class=\"headerlink\" title=\"A comparison of LS and DV Algorithm\"></a>A comparison of LS and DV Algorithm</h3><ul>\n<li><p><strong>Message complexity :</strong> <strong>In LS algorithm</strong> requires each node know all cost of link in the network . The require O(|E|*|N|) to be sent. Also , whenever a link cost changes , the new link cost must be sent to all node in the internet. <strong>In the DV algorithm</strong> The node only need to exchange the information between directly connection neighbors. When a link cost change , the DV algorithm will propagate the results of the changed link cost only if the new cost results in a changed lease-cost path for one of nodes attached to that link.</p>\n</li>\n<li><p><strong>Speed of convergence :</strong> LS is O($|N|^2$) algorithm require O(|N||E|) messages to be sent. DV algorithm can converge slowly and can have routing loops while the algorithm is converging . DV algorithm also suffers from the count-to-infinity problem. </p>\n</li>\n<li><p><strong>Robustness:</strong> What can happen if route fails misbehaves or is sabotage? Because LS algorithm only compute own forwarding table of each node in the network , This mean route calculation are somewhat separated under LS . Providing a degree of robustness. Under DV algorithm , a node must advertise incorrect least-cost path to any all destination , so that a malfunctioning router may be cause other router flood the malfunctioning router with traffic and cause a large portions of the internet to become disconnected for up to several hours.<br></p>\n</li>\n</ul>\n<h2 id=\"4-5-3-Hierarchical-Routing\"><a href=\"#4-5-3-Hierarchical-Routing\" class=\"headerlink\" title=\"4.5.3 Hierarchical Routing\"></a>4.5.3 Hierarchical Routing</h2><p>In our study of LS and DV algorithm , In practice , this model and its view of homogeneous set of routers all executing the same routing algorithm is a bit simplistic for at least two important reasons:<br></p>\n<ul>\n<li><p><strong>Scale</strong> :Because , today’s public internet consist of hundreds of millions hosts , LS algorithm updates among all of the router in public internet world would leave no bandwidth left for sending data packets, and under DV algorithm that iterated among such a large number of routers would surely never converge.</p>\n</li>\n<li><p><strong>Administrative autonomy:</strong> The corporation / organization / individual want to run and administer its network as it wishes.<br></p>\n</li>\n</ul>\n<p><strong>Both of these problems can be solve by organizing routers into autonomous systems (ASs)</strong><br></p>\n<p>Each AS consisting of a group of routers that are typically under the same administrative control ( eg : operated by the same ISP or belonging to the same company network).</p>\n<p>The routing algorithm running within a autonomous system is called an <strong>Intra-autonomous-system routing protocol</strong><br>One or more router in the AS being responsible for forwarding packets to destinations outside other AS : there routers are called <strong>gateway router</strong>, Obtaining reachability information from neighboring AS and propagating the reachability information to all router internal to AS are handled by the <strong>inter-AS-routing-protocol</strong><br><br><img src=\"autonomous-system-graph.png\" alt=\"autonomous-system-graph.png\"><br><br>If a destination router of outside AS can be reached by more than one gateway router , the router inside AS can using <strong>Hot-Potato-Algorithm</strong> to choose which gateway router should be select. The hot-potato-algorithm is using information from Intra-AS-Routing-Protocol to choose the lease-cost path of gateway routers.<br><img src=\"hot-potato-algorithm.png\" alt=\"hot-potato-algorithm.png\"><br></p>\n<h1 id=\"4-6-Routing-in-the-internet\"><a href=\"#4-6-Routing-in-the-internet\" class=\"headerlink\" title=\"4.6 Routing in the internet\"></a>4.6 Routing in the internet</h1><h2 id=\"4-6-1-Intra-AS-Routing-in-the-Internet-RIP\"><a href=\"#4-6-1-Intra-AS-Routing-in-the-Internet-RIP\" class=\"headerlink\" title=\"4.6.1 Intra-AS Routing in the Internet : RIP\"></a>4.6.1 Intra-AS Routing in the Internet : RIP</h2><p>RIP is a distance-vector algorithm that operates in a manner very close to idealized DV protocol . Each router maintains a RIP table is known as a routing table. RIP is implemented as an application-layer process can send and receive the (require/response) message over a standard socket (port 520) and using UDP protocol.<br><br><img src=\"RIP-UDP-Application.png\" alt=\"RIP-UDP-Application.png\"><br><br>In RIP , routing updates are exchanged between neighbors approximately every 30 seconds using a <strong>RIP response message</strong>(RIP response message also known as <strong>RIP advertisements</strong>) . If a router does not hear from its neighbor at least once every 180 seconds , that neighbor is considered to be no longer reachable ; that is , either neighbor is died or the connecting link has gone down , when this happen , RIP modifies the local routing table and then propagates this information by sending advertisement to still alive neighbors.<br></p>\n<p><strong>Let us see a simple example:</strong><br><br>Dotted lines indicate that still has other AS connect on  ; thus this autonomous systems have many more routers and link than figure shown follow.<br><img src=\"ASs-connection-graph-RIP.png\" alt=\"ASs-connection-graph-RIP.png\"><br><br><strong>Routing table of Router-D before receiving advertisement from Router-A:</strong><br><br><img src=\"Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png\" alt=\"Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png\"><br></p>\n<p><strong>Advertisement from router A:</strong><br><br><img src=\"Advertisement-From-RouterA.png\" alt=\"Advertisement-From-RouterA.png\"><br><br><strong>Routing table of Router-D after receiving advertisement from Router-A:</strong><br><br><img src=\"Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png\" alt=\"Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png\"><br></p>\n<h2 id=\"4-6-2-Intra-AS-Routing-in-the-Internet-OSPF\"><a href=\"#4-6-2-Intra-AS-Routing-in-the-Internet-OSPF\" class=\"headerlink\" title=\"4.6.2 Intra-AS Routing in the Internet : OSPF\"></a>4.6.2 Intra-AS Routing in the Internet : OSPF</h2><p>OSPF is a link-state algorithm that uses flooding of link-state information and dijkstra least-cost path algorithm . With OSPF protocol , a router constructs a complete topological map of the entire autonomous system , The router then locally run dijkstra algorithm to determine the shortest-path tree to all subnet. Individual link cost can be configured by the network administrator .<br></p>\n<p>Under OSPF protocol , A router broadcast link-state information whenever there is change in a link’s state , It also broadcast information periodically (at least once every 30 minutes) even if the link’s state has not changed. OSPF protocol advertisements are contains in OSPF message that carried directly by IP protocol , with a upper-layer protocol 89 for OSPF.<br></p>\n<p>The OSPF protocol also checks that link are operational and allows an OPSF router to obtain a neighboring router’s database of network-wide link state.</p>\n<p>OPSF is conceived as the successor to RIP and as has a number of advanced feature. The advanced feature is include the following:<br></p>\n<ul>\n<li><p><strong>Security:</strong> Exchanged between OPSF router can be authenticated , with authentication ,only trusted router can participate in OPSF protocol within an AS. Two type of authentication is can be configured — <strong>simple and MD5</strong>( discuss in chapter 8).</p>\n</li>\n<li><p><strong>Multiple same-cost path:</strong> OPSF allow multiple same-cost path to be used , don’t need to select a path to carry all traffic.</p>\n</li>\n<li><p><strong>Integrated support to unicast and multicast routing:</strong> Multicast OSPF (MOSPF).<br></p>\n</li>\n<li><strong>Support a hierarchy within a single routing domain:</strong> An OPSF autonomous system can be configured hierarchically into areas , Each area run its own OSPF link-state-algorithm , with each router in an area broadcasting its link-state to all other in that area. Within each area of a autonomous system has one or more <strong>area border router</strong> are responsible for routing packets to outside the area . And exactly one OPSF area in the AS is configured to be the <strong>backbone</strong> area. The primary role of the backbone area is to route traffic between the other area in the AS. <em>Inter-area routing</em> within the AS requires that the packet be first route to a area border router , and routed through the backbone to the area border router that is in the destination area , and then routed to the final destination.</li>\n</ul>\n<h2 id=\"4-6-3-Inter-AS-Routing-BGP-Border-Gateway-Protocol\"><a href=\"#4-6-3-Inter-AS-Routing-BGP-Border-Gateway-Protocol\" class=\"headerlink\" title=\"4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)\"></a>4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)</h2><p>Let’s us examine how path are determined for source-destination pair span multiple ASs.<br><br>Under BGP protocol , pair of router exchange information through semi-permanent TCP connection using port 179.<br><br>The BGP protocol TCP connection has two type of connection : <br></p>\n<ul>\n<li>BGP TCP connection between router within a same AS.</li>\n<li>BGP TCP connection between routers in two different ASs.</li>\n</ul>\n<p>Two interconnecting router corresponding source and destination router that using TCP are called <strong>BGP peers</strong> . The TCP connection along with all BGP message sent over the connection is called <strong>BGP session</strong>.<br><br><strong>Two type of BGP session:</strong><br></p>\n<ul>\n<li>External BGP session (eBGP session) : The BGP message is sent span two routers.</li>\n<li>Internal BGP session (iBGP session) : The BGP message is sent within an AS.<br><img src=\"BGP-sessions.png\" alt=\"BGP-sessions.png\"><br><br>In the BGP , destinations are not a host but instead are CIDRized prefixes with each prefixes is representing a subnet or a collection of subnet.<br></li>\n</ul>\n<p>In the BGP , some ASs has a globally unique <strong>autonomous system numbers(ASN)</strong> , the ASs hasn’t ASN is called stub AS. ASN similar to IP address are assigned by ICANN regional register.<br></p>\n<p>When a router advertise prefix to outside ASs , it include with a number of <strong>BGP attributes :</strong> , in BGP jargon , a prefix along with its attributes is called a route. The BGP  attributes is following: <br></p>\n<ul>\n<li><strong>AS-PATH :</strong> The attributes contain the ASN that the prefix have been passed.</li>\n<li><strong>NEXT-HOP:</strong> The NEXT-HOP is router interface that begins the AS-PATH. </li>\n</ul>\n<h3 id=\"BGP-Route-selection\"><a href=\"#BGP-Route-selection\" class=\"headerlink\" title=\"BGP Route selection\"></a>BGP Route selection</h3><p>Under BGP protocol , a router may be receive more than one route to the same prefix . Then BGP must be sequentially invokes the following elimination rules until one possible remain , The elimination rules is following:<br></p>\n<ul>\n<li>Routes are assigned a local preference values as one of their attributes , the routes with the highest local preference value are selected.</li>\n<li>From the remaining routes ( all routes has same preference value ) with the shortest AS-PATH are selected.</li>\n<li>From the remaining routes ( all routes has same preference value and same AS-PATH length) with closest NEXT-HOP are selected, here closest mean the least-cost path of a router itself interface and its corresponding eBGP session interface.</li>\n<li>If more than one route still remains , the router use the BGP identifiers to select the route.</li>\n</ul>\n<h3 id=\"Putting-all-together-How-does-an-entry-get-into-a-router’s-forwarding-table\"><a href=\"#Putting-all-together-How-does-an-entry-get-into-a-router’s-forwarding-table\" class=\"headerlink\" title=\"Putting all together : How does an entry get into a router’s forwarding table ?\"></a>Putting all together : How does an entry get into a router’s forwarding table ?</h3><p><strong>How does the packet is forwarded within a router ?<br></strong><br>When a packet arrive to the router , the packet’s destination IP address compared with the prefixes in the forwarding table and find a longest prefix match . Then the packet is forwarded to router’s port that associated with that matched prefix.<br><br><strong>How does an entry get into a router’s forwarding table ?</strong><br><br><em>In order to get an entry into a router’s forwarding table , first , the router must be aware of the prefix. The router become aware of the prefix via a BGP route advertisement , such a route advertisement may be sent over a eBGP session or over a iBGP session. After the router become aware of prefix , it need to determine appropriate output port to which datagram destined to that prefix will be forwarded. Before it can enter that entry (prefix + port) into its forwarding table . If router receive more than one route advertisement for this prefix , it is uses the BGP selection process to select to best route for the prefix , suppose the route have been selected , the selected route include NEXT-HOP attribute , which is IP address of first router outside the router’s AS along this best route. Then the router uses its Intra-AS routing protocol (typically OSPF) , to determine the shortest path to the NEXT-HOP router. The router finally determines the port number to associate with the prefix by identifying the first link along the shortest path . The router finally can enter the prefix-port pair into the forwarding table.</em></p>\n<h1 id=\"4-7-Broadcast-and-Multicast-Routing\"><a href=\"#4-7-Broadcast-and-Multicast-Routing\" class=\"headerlink\" title=\"4.7 Broadcast and Multicast Routing\"></a>4.7 Broadcast and Multicast Routing</h1><h2 id=\"4-7-1-Broadcast-Routing-Algorithm\"><a href=\"#4-7-1-Broadcast-Routing-Algorithm\" class=\"headerlink\" title=\"4.7.1 Broadcast Routing Algorithm\"></a>4.7.1 Broadcast Routing Algorithm</h2><p><strong>Two type of Broadcast routing algorithm: <br></strong></p>\n<ul>\n<li><strong>Source-Duplication:</strong> A packet is created and duplicated by a source router , and source router broadcast to all router in the network by unicast. This approach has several drawback is following:<ul>\n<li>inefficiency : The source router is required to copy a large amount of same packet and send these via a single link.</li>\n<li>Additional protocol mechanisms to obtain the address of the broadcast recipient ,would add more overhead and make the system more complex .</li>\n</ul>\n</li>\n<li><strong>In-network duplication:</strong> The source router broadcast by sending only one packet to attached routers , and then the attached routers copy the packet and send it to next attached routers .<br><img src=\"Source-duplication-In-network-duplication.png\" alt=\"Source-duplication-In-network-duplication.png\"><br></li>\n</ul>\n<h3 id=\"Uncontrolled-Flooding\"><a href=\"#Uncontrolled-Flooding\" class=\"headerlink\" title=\"Uncontrolled Flooding\"></a>Uncontrolled Flooding</h3><p>The most obvious technique for broadcast is <strong>Flooding</strong> approach in which the source node send its copy of packet to its neighbor.<br><br>Although this approach is simple and elegant , it has a fatal flaw , that is , if the graph has a cycles , then one or more broadcast packet will cycle indefinitely .<br><br>This broadcast storm along with broadcast packet increasingly would cause the network crash (network useless).</p>\n<h3 id=\"Controlled-Flooding\"><a href=\"#Controlled-Flooding\" class=\"headerlink\" title=\"Controlled Flooding\"></a>Controlled Flooding</h3><p>In practice , we have several way to solve the problem of uncontrolled flooding .<br></p>\n<ul>\n<li><p><strong>Sequence-number-controlled-flooding:</strong> A source node put its address or other unique identifies as well as broadcast sequence number into broadcast packet , then send it to all neighbors. Each node maintain a list of the source address and sequence number of broadcast packet , it first checks whether the packet is in this list , if so , the packet is dropped , if not , the packet is duplicated and forwarded to all node’s neighbors.<br></p>\n</li>\n<li><p><strong>Reverse path forwarding (RPF):</strong> Reverse path forwarding is also known as Reverse path broadcast (RPB) , When a node receives a broadcast packet with the source node address , <strong>the node transmits the packet on all of its outgoing link (expect one that outgoing link of its receive that packet)only if the packet arrived on the link that is on its own shortest unicast path back to the source. Otherwise , this packet is discarded simply.</strong><br>As likely the figure following , the router E transmits only the packet that arrived from router C to all neighbors(because it is the shortest path from router D to source router A), Otherwise , the packet is discarded simply.<br><img src=\"RPF.png\" alt=\"RPF.png\"><br></p>\n</li>\n</ul>\n<h3 id=\"Spanning-Tree-Broadcast\"><a href=\"#Spanning-Tree-Broadcast\" class=\"headerlink\" title=\"Spanning-Tree Broadcast\"></a>Spanning-Tree Broadcast</h3><p>Although The sequence-number-controlled-flooding algorithm and RPF algorithm avoid the broadcast storm , these don’t completely avoid the transmission of redundant broadcast packet.<br><br>Actually , every node receive only one broadcast packet is enough. The Spanning-Tree Broadcast algorithm can solve this problem .<br></p>\n<p>Thus , a node first have to construct a spanning-tree , when it wants to provide broadcast for all network node.<br></p>\n<p>We consider only one simple algorithm here , that is <strong>Center-based approach</strong> to build a spanning-tree.<br></p>\n<ul>\n<li>First determine a center node (also known as <strong>core</strong> and <strong>rendezvous point</strong>)</li>\n<li>The network node then unicast <strong>tree-join message</strong> addressed to center node. A tree-join message is forwarded using unicast routing toward the center until either arrives at a node that has already belong to the spanning tree or arrives at the center node.</li>\n</ul>\n<p><em>If each link associated cost , then a spanning-tree whose cost is the minimum of all of graph’s spanning-tree is called a <strong>minimum spanning-tree</strong> .</em> <br></p>\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/Uj47dxYPow8\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n<h2 id=\"4-7-2-Multicast\"><a href=\"#4-7-2-Multicast\" class=\"headerlink\" title=\"4.7.2 Multicast\"></a>4.7.2 Multicast</h2><p>In multicast communication , we are immediately faced with two problem .<br></p>\n<ul>\n<li>How to identify the receiver of multicast packet.</li>\n<li>How to address a packet send to these receivers.<br>Network layer multicast in the internet consist of two complementary components : <strong>IGMP (Internet Group Management Protocol) and Multicast routing protocol</strong>. The IGMP is used to solve first problem. The Multicast routing protocol is used to solve second problem.<br></li>\n</ul>\n<h3 id=\"Internet-Group-Management-Protocol\"><a href=\"#Internet-Group-Management-Protocol\" class=\"headerlink\" title=\"Internet Group Management Protocol\"></a>Internet Group Management Protocol</h3><p>The IGMP protocol version 3 operates between a host and its directly attached router. The figure following , shows three fist-hop multicast protocol each connected to its attached hosts via one outgoing local interface.<br><br><img src=\"IGMP-component.png\" alt=\"IGMP-component.png\"><br><br>IGMP provide the mean for a host to inform its attached router that an application running on the host want to join a specific multicast group.<br></p>\n<p><strong>IGMP has three message types.</strong><br></p>\n<ul>\n<li><strong>Membership_query message:</strong> That is sent by router to all host on an attached interface to determine which hosts on attached network are member of which multicast group.</li>\n<li><strong>Membership_report message :</strong> This message is used to respond to Membership_query message for inform the attached router that it still in multicast group and also be used to first joins a multicast group.</li>\n<li><strong>Leave_group message :</strong> This message is used to inform the router stops forwarding the multicast message to it. Interesting this message is optional , but it is optional , how to detect when a host leave the multicast group , The answer is the router infer this host have been leaved a multicast if this host no longer respond to Membership_query message. This example is called <strong>soft state</strong> in the internet protocol.<br></li>\n</ul>\n<h3 id=\"Multicast-Routing-Algorithm\"><a href=\"#Multicast-Routing-Algorithm\" class=\"headerlink\" title=\"Multicast Routing Algorithm\"></a>Multicast Routing Algorithm</h3><p>The goal of multicast routing , then is find a tree of links that connects all of routers that have attached hosts belonging to the multicast group . Multicast packet will be routed along with this tree from the multicast sender to all of the host belong to this multicast tree , of course , the tree also can contain some router that haven’t hosts belong to Multicast group.<br></p>\n<p>Two approach have been adopted for determining the multicast router tree.<br></p>\n<ul>\n<li><strong>A group shared tree :</strong> As in the case of Spanning-tree broadcast , multicast routing over a group-shared tree is base on building a tree that include all edge router with attached host belonging to multicast group. In practice , a center-based approach is used to construct the multicast routing tree with edge router with attached hosts belonging to multicast group send (via unicast) join-message addressed to center router.<br></li>\n<li><strong>A source base tree :</strong> The group shared tree constructs a single, shared routing tree to route packet from all senders . This approach is constructs a multicast routing tree for each source in the multicast group . In practice , an RPF algorithm is used to construct a multicast forwarding tree for multicast datagram originating at source x. The RPF broadcast algorithm require a bits of tweaking when it is used to multicast. To see why consider router D in Figure following. Under broadcast RPF , it forward packets to router G , even though router has no attached hosts that are joined to multicast group . While this is not so bad for this case , where router D has only one downstream router G , imagine what would happen if router D has thousand of downstream router ? Each of these downstream router would receive unwanted multicast packets. The solution of this problem is known as <strong>pruning</strong>.<br><img src=\"RPF-Multicast.png\" alt=\"RPF-Multicast.png\"><br></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><strong>In summary , this chapter has three major parts , The first past , section 4.1 and 4.2 cover the network layer function and services. The second part , section 4.3 and 4.4 covers forwarding , finally , the third past ,  section 4.5 through 4.7 covers routing.<br></strong></p>\n<h1 id=\"4-1-Introduction\"><a href=\"#4-1-Introduction\" class=\"headerlink\" title=\"4.1 Introduction\"></a>4.1 Introduction</h1><p>The first past is used to introduce network layer function and services.<br></p>\n<h2 id=\"4-1-1-Forwarding-and-Routing\"><a href=\"#4-1-1-Forwarding-and-Routing\" class=\"headerlink\" title=\"4.1.1 Forwarding and Routing\"></a>4.1.1 Forwarding and Routing</h2><ul>\n<li><p><strong>Forwarding :</strong> When the packet arrives at router’s input link , the router must move the packet to the appropriate output link. Section 4.3 we will look inside router and examine how a packet is actually forwarded from an input link to output link within a router.<br></p>\n</li>\n<li><p><strong>Routing :</strong> The network layer must determine the route or path taken by packets as they flow from sender to receiver. The algorithm that calculated these paths are referred to as routing algorithm . We will discuss routing algorithm inside at section 4.5<br></p>\n</li>\n</ul>\n<p><strong>Forwarding table :</strong> A router forwards a packet by examining the value of a field in the arrived packet’s header and use the header value to index into the router’s forwarding table. The value stored in forwarding table entry for indicate the router’s outgoing link interface to which that packet is to be forwarded .<br><br><img src=\"Routing-algorithm-determine-value-in-forwarding-tables.png\" alt=\"Routing-algorithm-determine-value-in-forwarding-table\"><br></p>\n<p><strong>How to configure the forwarding table of all router at the network.</strong><br><br>The answer is though the routing algorithm. The router receive the routing protocol message which are used to configure its forwarding table.<br></p>\n<p><strong>Routing algorithm:</strong> The routing algorithm has two kinds , one is centralized , another is decentralized.<br></p>\n<ul>\n<li><em>centralized :</em>  Every router has complete information about all other router in the network and the traffic status of the network. These algorithm is known as LS (link state) algorithm.<br></li>\n<li><em>decentralized :</em> Earn router have information about the routers it is directly connected to — it doesn’t know every router in the network. (These algorithm also known as DV (distance vector) algorithm.)</li>\n</ul>\n<h2 id=\"Connection-Setup\"><a href=\"#Connection-Setup\" class=\"headerlink\" title=\"Connection Setup\"></a>Connection Setup</h2><p>Addition to the two importance function (forward and routing) , the third importance function is <strong>connection setup.</strong><br><br>We will examine connection setup in Section 4.2.<br></p>\n<h2 id=\"4-1-2-Network-Service-Models\"><a href=\"#4-1-2-Network-Service-Models\" class=\"headerlink\" title=\"4.1.2 Network Service Models\"></a>4.1.2 Network Service Models</h2><div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"><strong>Questions:</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><em>When the transport layer at a sending host transmits a packet into the network layer , can transport layer rely on the network layer to deliver the packet to destination ?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>When multiple packets is sent , will they be delivered to the transport layer in the receiver’s host in order in which they were sent ?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>will the amount of time between the send of two sequential packet transmission be same as the amount of time between their reception?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>will the network provide the feedback about the congestion in the network?</em></td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>what is the abstract view(properties) of the channel connecting the transport layer in the sending and receiving hosts?</em></td>\n</tr>\n</tbody>\n</table>\n</div>\n<p><strong>The answer depend on provided network service model.<br><br>The specific services that could be provide by network layer include :<br></strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">Network Service Models</th>\n<th style=\"text-align:center\">Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed delivery</em></td>\n<td style=\"text-align:center\">This service guaranteed that packet will eventually arrive at destination.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed delivery with bounded delay</em></td>\n<td style=\"text-align:center\">This service not only guaranteed delivery of packets , but also delivery within a specified host-to-host delay bounded.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>In-order packet delivery</em></td>\n<td style=\"text-align:center\">This service guaranteed that packet arrived at the destination in the order that they were sent.</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed minimal bandwidth</em></td>\n<td style=\"text-align:center\">The network layer service emulates the behavior of transmission a specified bit rate (for example 1Mbps) between sending and receiving host. As long as sending host transmits bits at a rate below the specified bit rate , then no packet lost and packet arrived within a prespecified host-to-host delay.(for example 40 msc).</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Guaranteed maximum jitter</em></td>\n<td style=\"text-align:center\">The service guaranteed that the amount of time between the transmission of two successive packets at the sender is equal to the amount of time between their receipt at destination.(or that this spacing changes by no more than some specified value).</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><em>Security service</em></td>\n<td style=\"text-align:center\">Using a secret session key known by a source and destination host , the network layer in the source host could encrypt the payloads of all datagrams being sent to the destination , the network layer in the destination host would then be responsible for decrypting the payloads. In addition to confidentiality, the network layer could provide data integrity and source authentication services.</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"Internet-ATM-CBR-and-ATM-ABR-service-models\"><a href=\"#Internet-ATM-CBR-and-ATM-ABR-service-models\" class=\"headerlink\" title=\"Internet , ATM CBR and ATM ABR service models.\"></a>Internet , ATM CBR and ATM ABR service models.</h3><ul>\n<li><strong>Internet-Best-effort-service</strong></li>\n<li><strong>Constant bit rate (CBR) ATM network service</strong></li>\n<li><strong>Available bit rate (ABR) ATM network service</strong><br><img src=\"Internet-ATM.png\" alt=\"Internet-ATM\"><br></li>\n</ul>\n<h1 id=\"4-2-Virtual-Circuit-and-Datagram-Networks\"><a href=\"#4-2-Virtual-Circuit-and-Datagram-Networks\" class=\"headerlink\" title=\"4.2 Virtual Circuit and Datagram Networks\"></a>4.2 Virtual Circuit and Datagram Networks</h1><p>Similar to UDP and TCP , the network layer also provide the connectionless service and connection-oriented service.<br></p>\n<p>In all computer network architectures to data (Internet , ATM , frame relay , and so on ) the network layer provides either a host-to-host connectionless service or a host-to-host connection service , but not both . Computer networks that provide only a connection service at network layer are called <strong>Virtual-circuit(VC) networks</strong> , computer network that provide only connectionless service at the network layer are called <strong>datagram networks</strong>.</p>\n<h2 id=\"4-2-1-Virtual-Circuit-Networks\"><a href=\"#4-2-1-Virtual-Circuit-Networks\" class=\"headerlink\" title=\"4.2.1 Virtual-Circuit Networks\"></a>4.2.1 Virtual-Circuit Networks</h2><p><strong>A VC consists of :</strong><br><br>(1). A path (that is , a series of links and routers) between the source and the destination hosts <br><br>(2). VC number one number for each link along the path .<br><br>(3). Entries in the forwarding table in each router along the path. A packet belonging to a virtual circuit will carry a VC number in its header. Because a virtual circuit may have a different VC number on each link. Each intervening router must replace the VC number of each traversing packet with a new VC number . The new VC number is obtained from forwarding table.<br></p>\n<p><strong>For example:</strong><br><br>suppose The host A request to establish VC connection between itself and host B , We choose the path is A-R1-R2-B , suppose we set 12 , 22 and 32 to these three link. Hence , the value of VC number field is 12 when the packet leave  host A , the value of VC number field is 22 when the packet leave  R1 , the value of VC number field is 32 when the packet leave  R2 .<br><img src=\"Simple-Virtual-Circult-Network.png\" alt=\"Simple-Virtual-Circult-Network.png\"><br><br><img src=\"Simple-VC-Path.png\" alt=\"Simple-VC-Path.png\"><br></p>\n<p>Whenever a new VC is established across a router , an entry is added to the forwarding table . Similarly , whenever a VC terminates , the appropriate entry in each table along its path are removed. — <strong>In a VC network , the network router must maintain connection state information for each ongoing connection</strong><br></p>\n<p><strong>Three identifiable phases in a virtual-circuit network.</strong><br></p>\n<ul>\n<li><strong>VC setup:</strong> The network layer determines the path between sender and receiver , that is the series of link and routers through which all packets of VC will travel. The network layer also determines the VC number for each link along the path. Finally , the network layer add the entry to forwarding table in each router along the path. During the VC setup , the network layer may also reserve resource (for example : bandwidth) along the path of VC.</li>\n<li><strong>Data transfer :</strong> The VC connection have been established , packets can being flow along the VC.</li>\n<li><strong>VC teardown:</strong> This is initiated when the sender (or receiver) informs the network layer of its desire to terminate the VC connection , The network layer will typically inform the end system on the other side of the network of call termination and update the forwarding tables in each of packet routers on the path to indicate that the VC no long exist.<br></li>\n</ul>\n<p><strong>Signaling Message and Signaling Protocol</strong><br></p>\n<ul>\n<li><strong>Signaling Message:</strong> The message that the end systems send into the network to initiate or terminate a VC , the message passed between the routers to setup the VC (that is to modify connection state in router table ).</li>\n<li><strong>Signaling Protocol :</strong> The protocol used to exchange signaling message are often referred to as signaling protocol.<br><img src=\"Virtual-Circuit-Setup.png\" alt=\"Virtual-Circuit-Setup.png\"><br></li>\n</ul>\n<p><em>More detail about the signaling protocol and signaling message see [Black 1997] for a general discussion of signaling in connection-oriented networksand [ITU-T Q.2931 1995] for the specification of ATM’s Q.2931 signaling protocol.</em><br></p>\n<h2 id=\"4-2-2-Datagram-Networks\"><a href=\"#4-2-2-Datagram-Networks\" class=\"headerlink\" title=\"4.2.2 Datagram Networks\"></a>4.2.2 Datagram Networks</h2><p>In the datagram networks , each time and end system want to send a packet , it stamps the packet with the address of the destination end system and then pop the packet into the network . As shown in figure follow , <strong>these is no VC setup and routers do not maintain any VC state information (because there are no VCs)</strong><br><img src=\"Datagram-Network.png\" alt=\"Datagram-Network.png\"><br></p>\n<p>As a packet is transmitted from source to destination , it passes through a series of routers , Each of these router use the packet’s destination address to forward the packet , Specifically , each router these of router has a forwarding table map the destination address to link interfaces , When a packet arrived at the router , the router use the packet’s destination address to look up appropriate link interface in the forwarding table , the router then intentionally forwards the packet to the output link interface. <br></p>\n<p><img src=\"Datagram-Forwarding-Table.png\" alt=\"Datagram-Forwarding-Table.png\"><br><br>When these are multiple matches , the router uses the <strong>longest prefix matching rule</strong> that is finding the longest matching entry in the forwarding table , and then forwards the packet to link interface associated with the longest prefix match.<br></p>\n<p><em>The time scale at which this forward state information (forward table entry) change is relatively slow. Indeed in a datagram network the forwarding table are modified by routing algorithm. which typically update a forwarding table every one-to-five minutes or so.</em> </p>\n<h1 id=\"4-3-What’s-Inside-a-Router\"><a href=\"#4-3-What’s-Inside-a-Router\" class=\"headerlink\" title=\"4.3 What’s Inside a Router?\"></a>4.3 What’s Inside a Router?</h1><p>A high-level view of a generic router architecture is shown in figure follow . Four router components can be identified :<br></p>\n<ul>\n<li><strong>Input port :</strong> An input port perform several key functions .<ul>\n<li>It performs the physical layer function of terminating an incoming physical link at router. (Occurring in leftmost box of input port<br>and rightmost box of output port.)<br></li>\n<li>It performs the link-layer functions needed to interoperate<br>with the link layer at other side of incoming link . (Occurring in middle box in the input and output ports)<br></li>\n<li>It perform the lookup functions that is the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. (Occurring in the rightmost box of input port)</li>\n</ul>\n</li>\n<li><strong>Switching Fabric :</strong> The switching fabric connects the router’s input port to its output port.<br></li>\n<li><strong>Output port:</strong> An output port store the packet from switching fabric and transmits these packets on outgoing link by performing the necessary link-layer and physical-layer functions.<br></li>\n<li><strong>Routing Processor :</strong> The routing processor executes the routing protocol (study in section 4.6) maintain routing table and attached link state information and computer the forwarding table for the router .It also perform the network management (study in chapter 9).<br><img src=\"Router-Architecture.png\" alt=\"Router-Architecture.png\"><br></li>\n</ul>\n<p>A router input port , output port and switch fabric together implement the forwarding function and almost always implemented in the hardware.<br></p>\n<h2 id=\"4-3-1-Input-Processing\"><a href=\"#4-3-1-Input-Processing\" class=\"headerlink\" title=\"4.3.1 Input Processing\"></a>4.3.1 Input Processing</h2><p>The lookup performed in the input port is central to the router’s operation — it is here that the router uses the forwarding table to lookup the output port to which an arrived packet will be forwarded via switching fabric , the forwarding table is computed and updated by the router processor. The forwarding table is copied from the routing processor to the line cards over separate bus (eg: PCI bus). With the forwarding table copies , forwarding decision can be made locally , at each input port , without invoking the centralized routing processor. Once a packet’s output port have been determined via the lookup , the packet can be sent into the switching fabric.<br><br><img src=\"Input-Port-Processing.png\" alt=\"Input-Port-Processing.png\"><br></p>\n<p><strong>Although lookup is arguably the most importance action in input port processing many other action must be taken :</strong> <br></p>\n<ul>\n<li>Physical and link layer processing must be occur as discussed above;</li>\n<li>The packet’s version number , checksum and time-to-live-field (We will study in section 4.4.1)<br></li>\n<li>counter used to network management (such as the number of IP datagram received) must be updated.</li>\n</ul>\n<h2 id=\"4-3-2-Switching\"><a href=\"#4-3-2-Switching\" class=\"headerlink\" title=\"4.3.2 Switching\"></a>4.3.2 Switching</h2><p><img src=\"Three-Switching-Techniques.png\" alt=\"Three-Switching-Techniques.png\"><br><br><strong>Switching can be accomplished in a number of way , as shown in figure above.<br></strong></p>\n<ul>\n<li><p><strong>Switching via memory :</strong> The simplest , earliest routers were traditional computers with switching between the input ports and output ports being done direct control of the CPU (routing process). Input port and output ports functioned as traditional I/O devices in traditional operating system. An input ports with an arriving packet signaled the routing process via an interrupt , The packet was then copied from input port to processor memory. The routing process was then extracted the destination address from the header , look up the appropriate outpost in the forwarding table , and copied the packet to the output post’s buffer.<br><strong>Note that two packet can not be forwarded at the same time even if they has different destination ports. So that packets transferring speed is very slow.</strong> Many modern routers switch via memory. A major difference from early routers,however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards.</p>\n</li>\n<li><p><strong>Switching via bus:</strong> In this approach , an input port transfers packet directly to output port without intervention by the routing process. This is typically done by having the input port pre-pend a switching internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. The packet is received by all output posts , but only the port that matches the label will keep this packet. The label is then removed at the outpost port. <strong>If multiple packets arrive to the router at the same , each at a different input ports , all but one must wait since only one packet can cross the bus at a time .(The roundabout could only contain one car at a time)</strong></p>\n</li>\n<li><p><strong>Switching via an interconnection network:</strong> A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports and N output ports . Each vertical bus intersects intersects each horizontal bus at a crosspoint , which can opened and closed at any time by switching fabric controller. When a packet arrives from post A and need to be forwarded to post B , the switch controller closes the crosspoint at intersection of buses A and Y and port A sends the packet onto its bus , which is picked up (only) by bus Y. Note that the packet from B need to be forwarded to post X at the same time , <strong>crossbar network are capable of forwarding multiple packet in parallel, However if two different input post destined to same output post , the one have to wait at the input port.</strong></p>\n</li>\n</ul>\n<h2 id=\"4-3-3-Output-processing\"><a href=\"#4-3-3-Output-processing\" class=\"headerlink\" title=\"4.3.3 Output processing\"></a>4.3.3 Output processing</h2><p>Output post processing take packets that have been stored in the output port’s memory and then transmit them over the output link. This include selecting and de-queueing packet for transmission and performing the needed link-layer and physical-layer transmission functions.<br><br><img src=\"Output-Port-Processing.png\" alt=\"Output-Port-Processing.png\"><br></p>\n<h2 id=\"4-3-4-Where-Does-Queueing-Occur\"><a href=\"#4-3-4-Where-Does-Queueing-Occur\" class=\"headerlink\" title=\"4.3.4 Where Does Queueing Occur ?\"></a>4.3.4 Where Does Queueing Occur ?</h2><p>It’s clear that packet queue may form at both the input port and the output port.<br><br><img src=\"Output-Port-Queueing.png\" alt=\"Output-Port-Queueing.png\"><br><br>In this scenario (<em>$R<em>{switch}$ fast enough $R</em>{link}$</em> ), packets arriving at each of N input ports and destined to same the output port. Since the output port can transmit only a single packet in a unit of time(a packet transmission time) . The N arriving packets will have to queue(wait) for transmission over to outgoing link. Eventually if the number of queued packets grow large enough to exhaust available memory at the output port , in which case packet are dropped.<br><br>A consequence of output port queueing is that <strong>packet scheduler</strong> at the output port must choose a packet among those queued for transmission. The selection may be first-come-fist-served (FCFS) , weighted fair queueing (WFQ) which shares the outgoing link fairy among the different end-to-end connections that have packets queued for transmission.<br><br>Similarly , if there is not enough memory to buffer an incoming packet , a decision must be made to either drop arriving packet or remove one or more already-queued packets to make room for newly arriving packet.<br>For example : <em>Active Queue Management (AQM) algorithm</em> and <em>Random Early Detection (RED) algorithm</em><br><br>If <em>$R<em>{switch}$ not fast enough $R</em>{link}$</em> The switch fabric to transfer all arriving packets though the fabric without delay , then packet queueing can also occur at the input ports that is packets must join input port to wait turn to be transferred though the switching fabric to output port.<br><br><img src=\"HOL-Block-At-An-Input-Queued-Switch.png\" alt=\"HOL-Block-At-An-Input-Queued-Switch.png\"><br><br>Figure above shown an example , and suppose that<br><br><strong>(1)</strong>.the switching fabric is crossbar switching fabric.<br><br><strong>(2)</strong>.Packets are moved from a given input queue to their desired output queue in an FCFS manner. Two packets (<em>darkly shaded, port 1,3</em>) at the front of their input port queues are destined for the same upper-right output port. Suppose that the switching fabric choose to transfer the packet from the front of the upper-left queue. In this case the packet in lower-left queue must wait , not only darkly shaded must be wait , but also the lightly shaded packet that behind the darkly shaded in the lower-left queue even though it destined for middle-right output port . This phenomenon is knowns as <strong>head-of-the-line (HOL) blocking.</strong></p>\n<h1 id=\"4-4-The-Internet-Protocol-IP-Forwarding-and-Addressing-in-the-Internet\"><a href=\"#4-4-The-Internet-Protocol-IP-Forwarding-and-Addressing-in-the-Internet\" class=\"headerlink\" title=\"4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.\"></a>4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.</h1><p><strong>Inside of the Internet’s Network Layer:</strong><br><br><img src=\"A-Look-Inside-The-Internet-Network-Layer.png\" alt=\"A-Look-Inside-The-Internet-Network-Layer.png\"><br><br><strong>The three major component inside the internet network:</strong></p>\n<ul>\n<li><strong>IP Protocol</strong></li>\n<li><strong>Routing Component (Routing protocol study in section 4.6)</strong></li>\n<li><strong>Report error and in datagram and respond to request for certain network-layer information. Internet Contorl Message Protocol (ICMP) studied in section 4.4.3</strong></li>\n</ul>\n<h2 id=\"4-4-1-Datagram-Format\"><a href=\"#4-4-1-Datagram-Format\" class=\"headerlink\" title=\"4.4.1 Datagram Format\"></a>4.4.1 Datagram Format</h2><p>The network-layer packet is referred to as a datagram.<br><br><strong>Ipv4-Datagram-Format:</strong><br><br><img src=\"Ipv4-Datagram-Format.png\" alt=\"Ipv4-Datagram-Format.png\"><br><br><strong>The key field of Datagram format are following:</strong><br></p>\n<ul>\n<li><strong>Version number :</strong> These 4 bits specify the IP protocol version of the datagram , by look at the version number , the router can determine how to interpret the remainder of IP datagram . Different Version of IP use different datagram format.<br></li>\n<li><strong>Header length:</strong> Because the IPv4 datagram contain a variable number of options (which are included in the IPv4 datagram header) This 4 bits is needed to determine where the data actually being in the datagram . Most Ipv4 datagram don’t contain option , so the typical IP datagram has a 20 bytes header.</li>\n<li><strong>Type of service:</strong> The type of service bits were included in ipv4 header to allow different types of datagram (for example : requiring low delay , hight throughput or reliability).</li>\n<li><strong>Datagram length:</strong> This is a total length of the IP datagram (Header Plus Data) , since this field is 16 bits , so that the maximum size of the IP datagram is 65535 bytes, however datagram rarely larger than 1500 bytes.</li>\n<li><strong>Identifier , flags , fragmentation offset:</strong> These three field we will consider depth in shortly.</li>\n<li><strong>Time-to-live:</strong> The field used to ensure that datagram don’t circulate forever in the network.</li>\n<li><strong>Protocol :</strong> The value of this field is used to indicates the specific transport-layer-protocol to which the data portion of this datagram should be passed , for example the value 6 represent TCP and the value 17 represent UDP.</li>\n<li><strong>Header Checksum :</strong> The header checksum aids a router detecting bit error in a received IP datagram.<br><br><strong>Why does TCP/IP perform error checking at both the transport and network layer.</strong><br><ul>\n<li><em>only the IP header is checksummed at the IP layer while the TCP/UDP checksum is computed over the entire TCP/UDP segment.</em></li>\n<li><em>TCP/UDP and IP do not necessarily both have to belong to the same protocol stack. IP also can service other protocol (different to TCP/UDP).</em></li>\n</ul>\n</li>\n<li><strong>Source and Destination IP Addresses</strong></li>\n<li><strong>Options :</strong> The options flied allow an IP header to be extended.</li>\n<li><strong>Data field (payload):</strong> In most circumstance , the data field of the IP datagram contains the transport-layer segment (for example UDP/TCP) . However , the data field can carry other types of data such as ICMP message .</li>\n</ul>\n<h3 id=\"IP-datagram-fragmentation\"><a href=\"#IP-datagram-fragmentation\" class=\"headerlink\" title=\"IP datagram fragmentation\"></a>IP datagram fragmentation</h3><p>Since not all link-layer protocol can carry network-layer protocol of the same size . Some protocol can carry big datagrams , whereas other protocols can only a little packets. (for example : Ethernet frames carry 1500 bytes of data, the wide-area links can no more than 576 bytes.)<br></p>\n<p><em>Because each IP datagram is encapsulated within the link-layer frame for transport from one router to next router. The problem is that each of link along the router between sender and destination can use different link-layer protocols and each of those protocol can have different MTUs(maximum transmission unit).<br></em></p>\n<p>Suppose the router have MTU that is smaller than the length of the IP datagram . How to squeeze this oversize IP datagram into the payload field of the link-layer frame?<br><br>The solution is to fragment the data in the IP datagram into two or more smaller IP datagrams , encapsulate each of these smaller IP datagram in a separate link-layer frame and send these frames over the outgoing link . Each of these smaller datagram is referred to as a fragment.<br><br>Fragment need to reassembled before they reached the transport layer at the destination . Indeed both TCP and UDP expecting to complete, unfragmented segment from the network layer.<br></p>\n<p><strong>How to determine a packet whether or not a fragment , how to reassemble these fragment and when the destination host have received the last fragment of some original larger datagram.</strong><br><br>The answer is three field in the ipv4 datagram header.<br></p>\n<ul>\n<li><strong>16-bits-identifier field:</strong> When a datagram is created , the sending host stamps the datagram with an identification number as well as source and destination address. Typically , the sending host increments the identification number of each datagram it sends.<br></li>\n<li><p><strong>13-bits Fragmentation offset:</strong> When a router need to fragment a datagram , each resulting fragment is stamped with the source and destination address , and identification number of original datagram , and then the Fragmentation offset field is used to specify where the fragment fit within the original IP datagram.<em>(unit is bit)</em></p>\n</li>\n<li><p><strong>Flags field:</strong> This field is used to identify the last fragment of Original Ipv4 datagram . The last fragment has a flags bit set to 0 , and other fragment has a flags bit set to 1.<br><br><img src=\"IP-fragmentation-and-reassembly.png\" alt=\"IP-fragmentation-and-reassembly.png\"><br><br><img src=\"Ip-fragments.png\" alt=\"Ip-fragments.png\"><br><br>If one or more fragment does not arrive , the incomplete fragments is discarded and not passed to transport layer , and The transport layer protocol is TCP , TCP will recover this loss by retransmission.<br></p>\n</li>\n</ul>\n<h2 id=\"4-4-2-IPv4-Addressing\"><a href=\"#4-4-2-IPv4-Addressing\" class=\"headerlink\" title=\"4.4.2 IPv4 Addressing\"></a>4.4.2 IPv4 Addressing</h2><ul>\n<li><strong>Interface :</strong> The boundary between the host and physical link is called an interface.</li>\n</ul>\n<p><strong>A router has multiple interfaces and each of these interfaces have its own unique IP address.</strong><br><img src=\"Interface-Address-And-Subnets.png\" alt=\"Interface-Address-And-Subnets.png\"><br></p>\n<ul>\n<li><strong>Subnet:</strong> To determine the subnet detach each interface from its host and router , creating islands of isolated networks with interfaces terminating the end points of isolated networks , Each of these isolated networks is called a subnet.<br></li>\n</ul>\n<p>Shown as figure above , In the upper-left , this network interconnecting three host interfaces and one router interface forms a <strong>subnet</strong>. IP addressing assigns an address to this subnet : 223.1.1.0/24 , where the /24 notation , sometime known as <strong>subnet mask</strong>, Indicate that the leftmost 24-bits of 32-bits quantity define the subnet address.</p>\n<p>The internet’s addressing assignment strategy is known as <strong>Classless Interdomain Routing (CIDR)</strong> As with subnet addressing , the 32-bits IP address is divided into two parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the number of bits in the first past of the address (<strong>network prefix</strong>) . When we cover the internet BGP routing protocol in the section 4.6 , we will see that only these leading x prefix bits are considered by routers the organization’s network. That is when a router outside the organization forwards a datagram whose destination address is inside the organization only these leading x bits of the address need be considered . The remaining $32-x$ bits of an address can be though of as distinguishing among the devices within the organization. These bits will be considered when forwarding packets at routers within the organization.<br></p>\n<p><em>The special IP address : 255.255.255.255 (IP broadcast address), when a host send a datagram with destination address 255.255.255.255, this message is delivered to all host on the same subnet.</em></p>\n<h3 id=\"Obtaining-a-Block-of-Address\"><a href=\"#Obtaining-a-Block-of-Address\" class=\"headerlink\" title=\"Obtaining a Block of Address\"></a>Obtaining a Block of Address</h3><p><em>Internet corporation  for Assigned Name and Number (ICANN) has responsibility for managing the IP address space and allocating address blocks to ISPs and other organizations.<br></em></p>\n<p>In order to obtain a block of IP addresses for use within an organization’s subnet , a network administrator might first contract its ISP , while would provide addresses from a larger block of addresses that had already been allocated to the ISP. For example , the ISP may itself have been allocated the address block 200.23.16.0/20 ,the ISP divide its address block into eight equal-sized contiguous address block and give one of these address block out to each of up to eight organizations.<br><br><img src=\"Organization-Address.png\" alt=\"Organization-Address.png\"><br></p>\n<h3 id=\"Obtaining-a-host-Address-The-Dynamic-Host-Configuration-Protocol\"><a href=\"#Obtaining-a-host-Address-The-Dynamic-Host-Configuration-Protocol\" class=\"headerlink\" title=\"Obtaining a host Address : The Dynamic Host Configuration Protocol\"></a>Obtaining a host Address : The Dynamic Host Configuration Protocol</h3><p>Once an organization obtained a block of addresses it can assign individual IP address to host and router interface in its organization.<br>The router IP address typically manually configure by a system administrator. The host IP address typically configure by using <strong>Dynamic Host Configuration Protocol (DHCP)</strong> DHCP allows a host obtain an IP address automatically. As the host join and leave , the DHCP server need to update its list of available IP addresses.<br></p>\n<p>DHCP is a client-service protocol . A client is typically a newly arriving host wanting to obtain network configuration informations. Each subnet have a DHCP service . If no server is present on the subnet , a DHCP relay agent (typically a router) that knows the address of a DHCP service for that network is needed , for example show as figure below , DHCP service attached to subnet 223.1.2/24 , with the router serving as relay agent for arriving clients attached to subnet 223.1.1/24 and 223.1.3/24 .<br><br><img src=\"DHCP-Client-Server-Scenario.png\" alt=\"DHCP-Client-Server-Scenario.png\"><br></p>\n<p><strong>When a newly arriving host income to subnet , The DHCP has four steps for assign a IP address to new host.<br></strong></p>\n<ul>\n<li><p><strong>DHCP server discovery:</strong>  This is done using <strong>DHCP discovery message</strong> The new host send a DHCP discovery message with a UDP packet , port 67 source IP address : 0.0.0.0 (since , new host hasn’t IP address) and destination IP address : 255.255.255.255 (broadcast address). The UDP packet is encapsulated in a IP datagram and then passed to the link-layer. (We will cover the detail of broadcast in section 5.4)<br></p>\n</li>\n<li><p><strong>DHCP server offer(s) :</strong> A DHCP server receiving a DHCP discovery message responds to the client with the <strong>DHCP offset message</strong> that is broadcast to all notes on the subnet using the broadcast IP address : 255.255.255.255. Each server offer message contain the transaction ID of the receiver discovery message , the proposed IP address for the client , the network mask , and an IP address lease time . </p>\n</li>\n<li><p><strong>DHCP request :</strong> The newly arriving client will choose from among one or more server offers and respond to its selected offer with <strong>DHCP request message</strong> echoing back the configuration parameters.</p>\n</li>\n<li><p><strong>DHCP ACK:</strong> The server responds to the DHCP request message with a <strong>DHCP ACK message</strong> confirming the requested parameters.<br></p>\n</li>\n</ul>\n<p><em>yiaddr(as in “your Internet address”)</em><br><img src=\"DHCP-Client-Server-Interaction.png\" alt=\"DHCP-Client-Server-Interaction.png\"><br><br>Once the clients receives the DHCP ACK , the interaction is compelte and client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease’s expiration , DHCP also provide a mechanism that allow a client to renew its lease on an IP address.<br></p>\n<h3 id=\"Network-Address-Translation-NAT\"><a href=\"#Network-Address-Translation-NAT\" class=\"headerlink\" title=\"Network Address Translation (NAT)\"></a>Network Address Translation (NAT)</h3><p>With proliferation of small office , home office (for example , the kid at home not only their computer but have one or more smartphone and networked game ..etc) , the ISP have not enough IP address to handle this scenarios , what should we do in this scenarios.<br></p>\n<p>The answer is NAT (Network Address Translation)<br><br><strong>Figure follow is show the operation of NAT-enabled router.<br></strong><br><img src=\"Network-Address-Translation.png\" alt=\"Network-Address-Translation.png\"><br><br>In figure above all traffic leaving the home router for for the larger internet has a source IP address of 138.76.29.7 and all traffic entering the home router must have a destination IP address 138.76.29.7. In essence the NAT-enabled router is hiding the detail of the home network from the outside world.<br></p>\n<ul>\n<li><p><strong>Question: How the home network computer (or other network device) get their home IP address (for example 10.0.0.0/24)?</strong><br><br>The answer is DHCP , The router get its IP address from the ISP’s DHCP server and the router runs a DHCP server to provide addresses to computer (or other device ) within the NAT-DHCP-router-controlled-home-network’s-address-space.<br></p>\n</li>\n<li><p><strong>Question : If all datagram arriving at the NAT-Router from the WAN have the same destination IP address , how does the router know the internal host which it should forward a given datagram.</strong> <br><br>The trick is use a <strong>NAT translation table</strong> at the NAT router , and to include port number as well as IP addresses in table entries. For example shown as figure above , the host computer 10.0.0.1 request a web page on some web server (port 80) with IP address 128.119.40.186 . The host 10.0.0.1 assigns the (arbitrary) source port number 3345 and send the datagram into the LAN , The NAT-Router receives the datagram , genarates a new source port number 5001 , replace the source IP address with it WAN-side IP address 138.76.29.7 and replace the original source number 3345 with its new source port number 5001. NAT-Router adds an new entry to its NAT translation table and send a new datagram to WAN , when a datagram arriving at the NAT-Router , the NAT-Router use the destination IP address and destination port to obtain appropriate IP address (10.0.0.1) and destination port (3345) , then send a datagram to home network.</p>\n</li>\n</ul>\n<h3 id=\"UPnP\"><a href=\"#UPnP\" class=\"headerlink\" title=\"UPnP\"></a>UPnP</h3><p>The detail we can see the textbook page 352.</p>\n<h2 id=\"4-4-3-Internet-Control-Message-Protocol-ICMP\"><a href=\"#4-4-3-Internet-Control-Message-Protocol-ICMP\" class=\"headerlink\" title=\"4.4.3 Internet Control Message Protocol (ICMP)\"></a>4.4.3 Internet Control Message Protocol (ICMP)</h2><p>ICMP protocol is used by hosts and router communicate network-layer informations to each other. The most typical use of ICMP is error reporting.<br><br>The ICMP message is carried inside the IP datagrams , that is ICMP messages are carried as IP payload.<br></p>\n<p>ICMP message have a type field and a code field and checksum field.<br><br><img src=\"General-en.svg.png\" alt=\"General-en.svg.png\"><br></p>\n<p><strong>The ICMP control message :</strong><br><br><img src=\"ICMP-Message-Types.png\" alt=\"ICMP-Message-Types.png\"><br></p>\n<h2 id=\"4-4-4-IPv6\"><a href=\"#4-4-4-IPv6\" class=\"headerlink\" title=\"4.4.4 IPv6\"></a>4.4.4 IPv6</h2><h3 id=\"IPv6-Datagram-Format\"><a href=\"#IPv6-Datagram-Format\" class=\"headerlink\" title=\"IPv6 Datagram Format\"></a>IPv6 Datagram Format</h3><p><strong>Most importance changes introduced in IPv6 :<br></strong></p>\n<ul>\n<li><p><strong>Expanded addressing capabilities :</strong> IPv6 increases the size of the IP address from 32 bits to 128 bits . This ensure that the world won’t run out of IP address. In addition to unicast and multicast address , IPv6 introduced a new type of address called <strong>anycast address</strong><br></p>\n</li>\n<li><p><strong>A streamlined 40-byte header :</strong> A number of IPv4 fields have been dropped or made optional , The resulting 40-bytes-fixed-length header allows for faster processing of the IP datagram . A new encoding of option allow for more flexible option processing.</p>\n</li>\n<li><p><strong>Flow labeling and priority :</strong> The IPv6 header also has an 8-bits traffic class field. This field can be used to give priority to certain datagram within a flow or it can be used to give priority to datagram from certain application (for example ICMP) over datagram from other applications (for example : network new).</p>\n</li>\n</ul>\n<p><img src=\"IPv6-Datagram-Format.png\" alt=\"IPv6-Datagram-Format.png\"><br></p>\n<p><strong>The following fields defined in IPv6:</strong></p>\n<ul>\n<li><strong>Version :</strong> This 4-bits field identifies the IP version number.<br></li>\n<li><strong>Traffic class :</strong> This 8-bits field is similar in spirit to the TOS (Type of service) field we saw in IPv4.</li>\n<li><strong>Flow label :</strong> This 20-bits is used to identify a flow of datagrams.<br></li>\n<li><strong>Payload length :</strong> This 16-bits is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fix-length 40-byte datagram header.</li>\n<li><strong>Next header :</strong> This field is used identifies the protocol to which the content of this datagram will be delivered. This field uses the same values as the protocol field in the IPv4 field.</li>\n<li><strong>Hop limit :</strong> The content of this field are decremented by one by each router that forward the datagram . If the hop limit count reaches zero , the datagram is discarded.</li>\n<li><strong>Source and destination address :</strong> 128-bits IP address.</li>\n<li><strong>Data :</strong> This is the payload portion of the IPv6 datagram.</li>\n</ul>\n<p><strong>The several fields appearing in the IPv4 datagram are no longer present in the IPv6 datagram.</strong><br></p>\n<ul>\n<li><strong>Fragmentation/Reassembly :</strong> IPv6 do not allow for fragmentation and reassembly at intermediate . These operations performed only by the source and destination . If an IPv6 datagram received by a router is too large to be forwarded over the outgoing link , the router simply drops the datagram and sends “a packet too big” ICMP error message back to the sender , the sender can then resend the packet using a smaller IP datagram size. Fragmentation and reassembly is a time-consuming operation ; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up IP forwarding within the network.</li>\n<li><strong>Header checksum :</strong> Because the transport-layer and link-layer protocols in the internet layers perform checksumming , the designers of IP protocol felt that this functionality was sufficiently redundant in the network layer could be removed. The IPv4 header checksum needed to recomputed at every router , As with fragmentation and reassembly , this too was a costly operation in IPv4.</li>\n<li><strong>Options :</strong> An options field is no longer a part of the standard IP header. However , it has not gone away . Instead the option field is one of possible next header pointed to from within the IPv6 header . Just as TCP or UDP protocol headers can be the next header within an IP packet .</li>\n</ul>\n<p><em>A new version of ICMP protocol is known as ICMPv6 , that is used to service for IPv6</em></p>\n<h3 id=\"Transitioning-from-IPv4-to-IPv6\"><a href=\"#Transitioning-from-IPv4-to-IPv6\" class=\"headerlink\" title=\"Transitioning from IPv4 to IPv6\"></a>Transitioning from IPv4 to IPv6</h3><p>We have two approaches for gradually integrating IPv6 hosts and routers into an IPv4 world (with the long-term goal, of course, of having all Ipv4 node eventually translation to IPv4).<br></p>\n<p><strong>Dual-Stack Approach :</strong><br><br>That is IPv6 nodes also have complete IPv4 implementation. That has the ability to send and receive an both IPv4 and IPv6 datagram ; when interoprating with an IPv4 node an IPv6/IPv4 node can use IPv4 datagram , when interopratig with an IPv6 node it can speak IPv6. IPv6 and IPv4 nodes must have both IPv6 and Ipv4 address.<br><br><img src=\"A-Dual-Stack-Approachs.png\" alt=\"A-Dual-Stack-Approachs.png\"><br></p>\n<p><strong>Problem :</strong> <br><br>As figure above , The node A communicate with node F , and node A send a datagram to node F , when a datagram is sent from node B (IPv6) to node C (IPv4) , The node B must create a new datagram to send to node C , the data field of the IPv6 can be copied into the data field of the IPv4 datagram and appropriate address mapping can be done . However , in performing the conversion from IPv6 to IPv4 , there will be IPv6-specific fields in the datagram (for example the flow identifier field) that have no counterpart in IPv4 , The information in these fields will be lost.<br></p>\n<p><strong>Tunneling (An alternative to the dual-stack approach):</strong><br><br><em>Tunneling can solve the problem note above.</em><br><br><img src=\"Tunneling.png\" alt=\"Tunneling.png\"><br><br>Suppose two IPv6 nodes (for example : B and E in the figure above) want to interoperate using IPv6 datagram but are connected to each other by intervening IPv4 routers. We refer to the intervening set of IPv4 router between two IPv6 router as a <strong>tunnel</strong>. With tunneling , the IPv6 node on the send side of the tunnel (node B) **takes the entire IPv6 datagram and put it into the data field (payload) of IPv4 datagram.<br>This IPv4 datagram is then addressed to the IPv6 node on the receiving side of the tunnel (node E) and sent to the first node in the tunnel (node C). The IPv6 node on the receiving side of the tunnel eventually receives the IPv4 datagram (it is a destination of IPv4 datagram!) determine that IPv4 datagram contain an IPv6 datagram , extract the IPv6 datagram and then routes the IPv6 datagram exactly as it would if it had received the IPv6 datagram from a directly connected IPv6 neighbor.<br></p>\n<h2 id=\"4-4-5-A-Brief-Foray-into-IP-Security\"><a href=\"#4-4-5-A-Brief-Foray-into-IP-Security\" class=\"headerlink\" title=\"4.4.5 A Brief Foray into IP Security\"></a>4.4.5 A Brief Foray into IP Security</h2><p>Using IPsec protocol provide security service . (more detail see the chapter 8).</p>\n<h1 id=\"4-5-Routing-Algorithm\"><a href=\"#4-5-Routing-Algorithm\" class=\"headerlink\" title=\"4.5 Routing Algorithm\"></a>4.5 Routing Algorithm</h1><p><strong>Routing Algorithm operating in network routers , exchange and compute the information that is used to configure these forwarding table .</strong><br><br>Whether network layer provide datagram service (packet between the source and destination may takes many different routes)or VC service (packet between the source and destination take the same path) , the network layer must determine the path that packets take from sender to receiver.<br></p>\n<p><em>We will see the job of routing is determine the good paths <strong>(least-cost-path)</strong> from senders to receivers through the network of routers.</em></p>\n<p><strong>Classify routing algorithm according to whether they are global or decentralized.</strong><br></p>\n<ul>\n<li><strong>A global routing algorithm :</strong> Computes the least-cost path between a source and destination using complete global knowledge about the network.(complete global knowledge is mean all node connectively relationship and link cost in the network). In practice algorithm with global state information are often referred to as <strong>Link-state(LS) algorithm</strong>.<br></li>\n<li><strong>A decentralized routing algorithm :</strong> The calculation of least-cost path is carried out in an iterative , distributed manner. No node have complete information about the cost of all network link , instead each node begins with only the knowledge of the cost of its own directly attached links. Then through an iterative process of the calculation and exchange of information with its neighboring nodes , a node gradually calculates the least-cost path to destination or set of destinations. The decentralized routing algorithm is called distance-vector (DV) algorithm .</li>\n</ul>\n<h2 id=\"4-5-1-The-Link-State-LS-Routing-Algorithm\"><a href=\"#4-5-1-The-Link-State-LS-Routing-Algorithm\" class=\"headerlink\" title=\"4.5.1 The Link-State (LS) Routing Algorithm\"></a>4.5.1 The Link-State (LS) Routing Algorithm</h2><p>In practice , The Link-State Routing Algorithm is accomplished by having each node broadcast link-state packets to all other nodes in the network , with each link-state packet containing the identifies and cost of it attached links. The result of the note’s broadcast is that all node have an identical and complete view of the network.  Each node can then run the LS algorithm and compute the same set of least-cost paths as every other node.</p>\n<p>The LS algorithm is known as <strong>Dijkstra’s Algorithm</strong> name after its inventor. A closely related algorithm is Prim’s Algorithm .</p>\n<p><strong>Let us define the following notation:</strong><br></p>\n<ul>\n<li><strong>D(v) :</strong> Cost of the least-cost path from the source to destination v as of this iteration of the algorithm.</li>\n<li><strong>P(v) :</strong> Previous node (neighbor of node v) along the current least-cost path from source to node v.</li>\n<li><strong>N’:</strong> subset of nodes , if v in <strong>N’</strong> represent the least-cost path from source to v have been definitely known.</li>\n</ul>\n<p><img src=\"Graph-Of-Link-State-Algorithm.png\" alt=\"Graph-Of-Link-State-Algorithm.png\"><br></p>\n<p><em>Link-State Algorithm For Source Node u</em><br></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs c++\">Initialization :<br>\tN<span class=\"hljs-number\">&#x27;</span> = &#123;u&#125;;<br>\t<span class=\"hljs-keyword\">for</span> all nodes v <br>\t\t<span class=\"hljs-keyword\">if</span> v is a neighbor of u <br>\t\t\t<span class=\"hljs-function\">then <span class=\"hljs-title\">D</span><span class=\"hljs-params\">(v)</span> </span>= c(u,v)<br>\t\t<span class=\"hljs-keyword\">else</span> D(v) = ∞<br>Loop :<br>\tFind w <span class=\"hljs-keyword\">not</span> in N<span class=\"hljs-number\">&#x27;</span> simultaneously D(w) is a minimum<br>\tAdd w to N<span class=\"hljs-number\">&#x27;</span><br>\tUpdate D(v) <span class=\"hljs-keyword\">for</span> each neighbor v of w <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> in N<span class=\"hljs-number\">&#x27;</span> : <br>\tD(v) = min ( D(v) , D(w)+c(w,v) );<br>Until : N<span class=\"hljs-number\">&#x27;</span> = N ( N is <span class=\"hljs-built_in\">set</span> of all node )<br></code></pre></td></tr></table></figure>\n<p><img src=\"Result-Of-LS-Algorithm.png\" alt=\"Result-Of-LS-Algorithm.png\"><br></p>\n<p><strong>The detail of step can watch the video follow:</strong><br> </p>\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/ud7qWRBirsk\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n<p><strong>Problem of LS algorithm :</strong><br></p>\n<p><strong>Figure follow shown a simple network topology where link costs are equal to the load carried on the link.</strong><br>In this example , link cost are not symmetric that is the C(u,v) equal to C(v,u) only if the load carried on the both directions on the link(u,v) is same . <br></p>\n<p><strong>In this example , node z originates a unit of traffic destined for node w , node x also originates a unit of traffic destined for node w and node y injects an amount of traffic equal to e also destined for node w .</strong><br></p>\n<p><strong>The order of looking at figure is a-&gt;b-&gt;c-&gt;d</strong><br></p>\n<p><img src=\"Oscillations-With-Congestion-Sensitive-Routing.png\" alt=\"Oscillations-With-Congestion-Sensitive-Routing.png\"><br></p>\n<p>We can see the <strong>Oscillation</strong> with congestion sensitive routing.<br></p>\n<p>What can be done to prevent such oscillation ?<br><br>One solution would be to mandate that link costs not depend on the amount of traffic carried — an unacceptable solution since one goal of routing is to avoid highly congested links, Another solution is to ensure that not all routers run the LS algorithm at the same time.</p>\n<h2 id=\"4-5-2-The-Distance-Vector-DV-Routing-Algorithm\"><a href=\"#4-5-2-The-Distance-Vector-DV-Routing-Algorithm\" class=\"headerlink\" title=\"4.5.2 The Distance-Vector (DV) Routing Algorithm\"></a>4.5.2 The Distance-Vector (DV) Routing Algorithm</h2><p>Whereas the LS algorithm is an algorithm using global information , the <strong>distance-vector algorithm</strong> is <em>iterative , asynchronous , and distributed. <br></em></p>\n<ul>\n<li><p>It is distributed in that each node receive some information from its directly attached neighbors , perform a calculation and distributed the result of its calculation back to its neighbors.<br></p>\n</li>\n<li><p>It is iterative in that , this process continue on until no more information is exchanged between the neighbors.<br></p>\n</li>\n<li><p>It is asynchronous in that is does not require all of the nodes to operate in lockstep with each other.<br></p>\n</li>\n</ul>\n<p><strong>The Distance-Vector Routing Algorithm also known as Bellman-Ford Algorithm</strong><br></p>\n<p>For get the least-cost paths , we need to using the celebrated <strong>Bellman-Ford equations:</strong><br> <strong>$d_{v}(y)$ is distance from $v$ to $y$</strong></p>\n<script type=\"math/tex; mode=display\">d_{x}(y)=min_v{c(x,y)+d_v(y)}</script><p>Where the $min<em>{v}$ in the equation is taken over all of x’s neighbors.After traveling from x to v , if we then take the least-cost path from v to y , the path cost will be $c(x,y)+d</em>{v}(y)$ . Since we must begin by traveling to some neighbor $v$ , the least cost from $x$ to $y$ is the minimum of $c(x,y)+d_{v}(y)$ taken over all neighbor $v$.</p>\n<p><strong>Distance-Vector (DV) Algorithm:</strong> <br><br>at each node ,x:<br></p>\n<p><strong>Initialization :</strong> <br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for all destinations $y$ in $N$ : <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp;$D<em>{x}(y)$ = $c(x,y)$  &nbsp; /* if y is not a neighbor then $c(x,y)$ = $\\infty$ */ <br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; $D</em>{w}(y)$ = $?$ &nbsp; /* for all destinations $y$ in $N$ */<br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; send distance vector $D<em>{x} = [ D</em>{x}(y) : y$ in $N ]$ to $w$<br><br><strong>Loop</strong><br><br>&nbsp; &nbsp; <strong>wait</strong> (until i see a link cost change to some neighbor $w$ <br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    &nbsp;&nbsp;or until i receive a distance vector from some neighbor $w$) <br><br>&nbsp;&nbsp;&nbsp; for each $y$ in $N$ :<br><br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    $D<em>{x}(y)$ = $min</em>{v} {c(x,y) + D<em>{v}(y)}$<br><br>&nbsp;&nbsp;&nbsp;if $D</em>{x}(y)$ changed for any destination $y$ <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; send the distance vector $D<em>{x}$ = $[D</em>{x}(y) : y$ in $N]$ to all neighbors<br><br><strong>Forever</strong> <br></p>\n<p><strong>A simple three node illustrates the operation of DV algorithm</strong><br><br><img src=\"DV-Simple-Example.png\" alt=\"DV-Simple-Example.png\"></p>\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/dmS1t2twFrI\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n<h3 id=\"Distance-Vector-Algorithm-Link-Cost-Changes-and-Link-failure\"><a href=\"#Distance-Vector-Algorithm-Link-Cost-Changes-and-Link-failure\" class=\"headerlink\" title=\"Distance-Vector Algorithm : Link-Cost Changes and Link failure\"></a>Distance-Vector Algorithm : Link-Cost Changes and Link failure</h3><p><img src=\"Changes-in-link-cost.png\" alt=\"Changes-in-link-cost.png\"><br></p>\n<p>Figure (a) above illustrates a scenario where link cost from y to x distance vector change from 4 to 1. We force here only on y’ and z’ distance table entires to destination x. The Dv algorithm causes the following sequence of events to occur :<br></p>\n<ul>\n<li>At time $t_{0}$ , $y$ detects the link-cost change (the cost has change from 4 to 1 ) updates its distance vector and inform the neighbors of this change since its distance has changed.</li>\n<li>At time $t_{1}$ , $z$ receives the update from $y$ and update its table . It computer a new least cost of $x$ (it has decreased from a cost of 5 to cost of 2 ) and send its new distance vector to its neighbors.</li>\n<li>At time $t_{2}$ , $y$ receive $z’s$ update and updates its distance table . $y’s$ least cost do not change hence $y$ does not send any message to $z$. The algorithm come to a quiescent state.</li>\n</ul>\n<p>Thus only two iterations are requited for the DV algorithm to reach a quiescent state. <br></p>\n<p>Let now consider what happen when a link cost increases , support that support the link cost between $x$ and $y$ increases from 4 to 60 as shown in figure (b) above.<br></p>\n<ul>\n<li>Before the link cost changes , $D<em>{x}(y) = 4$ , $D</em>{y}(z) =1$ , $D<em>{z}(y) = 1$ and $D</em>{z}(x) = 5$ , $y$ detect the link cost change (the cost change from 4 to 60) , $y$ computes its new minimum-cost path to x have a cost of  <script type=\"math/tex; mode=display\">D_{y}(x) = min \\{C(y,x) + D_{x}(x) , C(y,z)+ D_{z}(x)\\}= min \\{ 60+0,1+5\\} = 6</script>  of course , with out global view of the network , we can see that this new cost via $z$ is wrong . But the only information node $y$ has is that its direct cost to $x$ is 60 and that $z$ has last told $y$ that $z$ could get $x$ with a cost of 5 . So in order to get to $x$, $y$ would now route through $z$ , fully expecting that $z$ will be able to get to $x$ with cost of 5.</li>\n<li>Since node $y$ has computed a new minimum cost to $x$ , it inform $z$ of new distance vector at time $t_{1}$.</li>\n<li>Sometime after $t_{1}$ , $z$ receive the $y’s$ new distance vector ,which indicates that $y’s$ minimum cost to $x$ is 6 . $z$ know get to $y$ with a cost of 1 and computes a new least cost to x of <script type=\"math/tex; mode=display\">D_{z}(x) = min \\{50+0, 1+6\\}=7</script>  Since $z’s$ least-cost to $x$ is increased , and then it inform $y$ of its new distance vector at $t<em>{2}$ at $t</em>{2}$.</li>\n<li>In a similar manner , after receiving $z’s$ a new distance vector , $y$ determines $D<em>{y}(x)=8$ and send $z$ its distance vector . $z$ then determine $D</em>{z}(x) = 9$ and sends $y$ its new distance vector over and over again until $D<em>{z}(x)= min{C</em>{z}(y)+D<em>{y}(x) , C</em>{z}(x)+D_{x}(x)}= min{50+1 ,50+0 }=50$ , at this point , $z$ finally ! determine that its lease-cost path to $x$ is via its direct connection to $x$.</li>\n</ul>\n<p><strong>What way could solve the problem noted above ?</strong><br><br>The answer is <em>Poisoned Reverse.</em><br></p>\n<h3 id=\"Distance-Vector-Algorithm-Adding-Poisoned-Reverse\"><a href=\"#Distance-Vector-Algorithm-Adding-Poisoned-Reverse\" class=\"headerlink\" title=\"Distance-Vector Algorithm : Adding Poisoned Reverse\"></a>Distance-Vector Algorithm : Adding Poisoned Reverse</h3><p>The specific looping scenario just described can be avoided using a technique known as <em>poisoned reverse.</em> The idea is simple <strong>if $z$ routers through $y$ to get to destination $x$ , then $z$ will advertise to $y$ that its distance to $x$ is infinity</strong>, $z$ will advertise to $y$ that $D<em>{z}(x) = \\infty$ ( even though $z$ known $D</em>{x}(z) = 5$ in truth) $z$ will continue telling this little white lie to $y$ as long as it route $x$ via $y$ . Since $y$ believes that $z$ had no path to $x$ ,$y$ will never attempt to route to $x$ via $z$ , as long as $z$ continues to route to $x$ via $y$<br>Let now see how <em>Poisoned Reverse</em> solved the particular looping problem :  When the link-cost $(x,y)$ change from 4 to 60 , $y’s$ distance table indicate $D_{z}(x) = \\infty$ .</p>\n<ul>\n<li>At the time $t<em>{0}$ ,$y$ update its table and continues to route directly to $x$ , albeit at the higher cost of 60 and then inform $z$ of the new distance vector to $x$ , that is $D</em>{y}(x) =60$ .</li>\n<li>After receiving the update at $t<em>{1}$ , $z$ immediately shits the its route to $x$ to be via the direct $(z,x)$ link at the cost of 50, and then $z$ inform $y$ of new cost of $D</em>{z}(x) = 50$ .</li>\n<li>After receiving the update from $z$ , $y$ update its distance table at $D<em>{y}(x)=51$, also , since $z$ is now on $y$’s lease-cost path to $x$ , $y$ poisoned the reverse from $z$ to $x$ by informing $z$ at time $t</em>{3}$ that $D<em>{y}(x) = \\infty$ (even though $y$ know $D</em>{y}(x)=51$ in trush)</li>\n</ul>\n<p><strong>Does poisoned reverse solve the general count-to-infinity problem ? It dose not , when looping involving three or more nodes will not be detected by poisoned reverse.</strong><br></p>\n<h3 id=\"A-comparison-of-LS-and-DV-Algorithm\"><a href=\"#A-comparison-of-LS-and-DV-Algorithm\" class=\"headerlink\" title=\"A comparison of LS and DV Algorithm\"></a>A comparison of LS and DV Algorithm</h3><ul>\n<li><p><strong>Message complexity :</strong> <strong>In LS algorithm</strong> requires each node know all cost of link in the network . The require O(|E|*|N|) to be sent. Also , whenever a link cost changes , the new link cost must be sent to all node in the internet. <strong>In the DV algorithm</strong> The node only need to exchange the information between directly connection neighbors. When a link cost change , the DV algorithm will propagate the results of the changed link cost only if the new cost results in a changed lease-cost path for one of nodes attached to that link.</p>\n</li>\n<li><p><strong>Speed of convergence :</strong> LS is O($|N|^2$) algorithm require O(|N||E|) messages to be sent. DV algorithm can converge slowly and can have routing loops while the algorithm is converging . DV algorithm also suffers from the count-to-infinity problem. </p>\n</li>\n<li><p><strong>Robustness:</strong> What can happen if route fails misbehaves or is sabotage? Because LS algorithm only compute own forwarding table of each node in the network , This mean route calculation are somewhat separated under LS . Providing a degree of robustness. Under DV algorithm , a node must advertise incorrect least-cost path to any all destination , so that a malfunctioning router may be cause other router flood the malfunctioning router with traffic and cause a large portions of the internet to become disconnected for up to several hours.<br></p>\n</li>\n</ul>\n<h2 id=\"4-5-3-Hierarchical-Routing\"><a href=\"#4-5-3-Hierarchical-Routing\" class=\"headerlink\" title=\"4.5.3 Hierarchical Routing\"></a>4.5.3 Hierarchical Routing</h2><p>In our study of LS and DV algorithm , In practice , this model and its view of homogeneous set of routers all executing the same routing algorithm is a bit simplistic for at least two important reasons:<br></p>\n<ul>\n<li><p><strong>Scale</strong> :Because , today’s public internet consist of hundreds of millions hosts , LS algorithm updates among all of the router in public internet world would leave no bandwidth left for sending data packets, and under DV algorithm that iterated among such a large number of routers would surely never converge.</p>\n</li>\n<li><p><strong>Administrative autonomy:</strong> The corporation / organization / individual want to run and administer its network as it wishes.<br></p>\n</li>\n</ul>\n<p><strong>Both of these problems can be solve by organizing routers into autonomous systems (ASs)</strong><br></p>\n<p>Each AS consisting of a group of routers that are typically under the same administrative control ( eg : operated by the same ISP or belonging to the same company network).</p>\n<p>The routing algorithm running within a autonomous system is called an <strong>Intra-autonomous-system routing protocol</strong><br>One or more router in the AS being responsible for forwarding packets to destinations outside other AS : there routers are called <strong>gateway router</strong>, Obtaining reachability information from neighboring AS and propagating the reachability information to all router internal to AS are handled by the <strong>inter-AS-routing-protocol</strong><br><br><img src=\"autonomous-system-graph.png\" alt=\"autonomous-system-graph.png\"><br><br>If a destination router of outside AS can be reached by more than one gateway router , the router inside AS can using <strong>Hot-Potato-Algorithm</strong> to choose which gateway router should be select. The hot-potato-algorithm is using information from Intra-AS-Routing-Protocol to choose the lease-cost path of gateway routers.<br><img src=\"hot-potato-algorithm.png\" alt=\"hot-potato-algorithm.png\"><br></p>\n<h1 id=\"4-6-Routing-in-the-internet\"><a href=\"#4-6-Routing-in-the-internet\" class=\"headerlink\" title=\"4.6 Routing in the internet\"></a>4.6 Routing in the internet</h1><h2 id=\"4-6-1-Intra-AS-Routing-in-the-Internet-RIP\"><a href=\"#4-6-1-Intra-AS-Routing-in-the-Internet-RIP\" class=\"headerlink\" title=\"4.6.1 Intra-AS Routing in the Internet : RIP\"></a>4.6.1 Intra-AS Routing in the Internet : RIP</h2><p>RIP is a distance-vector algorithm that operates in a manner very close to idealized DV protocol . Each router maintains a RIP table is known as a routing table. RIP is implemented as an application-layer process can send and receive the (require/response) message over a standard socket (port 520) and using UDP protocol.<br><br><img src=\"RIP-UDP-Application.png\" alt=\"RIP-UDP-Application.png\"><br><br>In RIP , routing updates are exchanged between neighbors approximately every 30 seconds using a <strong>RIP response message</strong>(RIP response message also known as <strong>RIP advertisements</strong>) . If a router does not hear from its neighbor at least once every 180 seconds , that neighbor is considered to be no longer reachable ; that is , either neighbor is died or the connecting link has gone down , when this happen , RIP modifies the local routing table and then propagates this information by sending advertisement to still alive neighbors.<br></p>\n<p><strong>Let us see a simple example:</strong><br><br>Dotted lines indicate that still has other AS connect on  ; thus this autonomous systems have many more routers and link than figure shown follow.<br><img src=\"ASs-connection-graph-RIP.png\" alt=\"ASs-connection-graph-RIP.png\"><br><br><strong>Routing table of Router-D before receiving advertisement from Router-A:</strong><br><br><img src=\"Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png\" alt=\"Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png\"><br></p>\n<p><strong>Advertisement from router A:</strong><br><br><img src=\"Advertisement-From-RouterA.png\" alt=\"Advertisement-From-RouterA.png\"><br><br><strong>Routing table of Router-D after receiving advertisement from Router-A:</strong><br><br><img src=\"Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png\" alt=\"Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png\"><br></p>\n<h2 id=\"4-6-2-Intra-AS-Routing-in-the-Internet-OSPF\"><a href=\"#4-6-2-Intra-AS-Routing-in-the-Internet-OSPF\" class=\"headerlink\" title=\"4.6.2 Intra-AS Routing in the Internet : OSPF\"></a>4.6.2 Intra-AS Routing in the Internet : OSPF</h2><p>OSPF is a link-state algorithm that uses flooding of link-state information and dijkstra least-cost path algorithm . With OSPF protocol , a router constructs a complete topological map of the entire autonomous system , The router then locally run dijkstra algorithm to determine the shortest-path tree to all subnet. Individual link cost can be configured by the network administrator .<br></p>\n<p>Under OSPF protocol , A router broadcast link-state information whenever there is change in a link’s state , It also broadcast information periodically (at least once every 30 minutes) even if the link’s state has not changed. OSPF protocol advertisements are contains in OSPF message that carried directly by IP protocol , with a upper-layer protocol 89 for OSPF.<br></p>\n<p>The OSPF protocol also checks that link are operational and allows an OPSF router to obtain a neighboring router’s database of network-wide link state.</p>\n<p>OPSF is conceived as the successor to RIP and as has a number of advanced feature. The advanced feature is include the following:<br></p>\n<ul>\n<li><p><strong>Security:</strong> Exchanged between OPSF router can be authenticated , with authentication ,only trusted router can participate in OPSF protocol within an AS. Two type of authentication is can be configured — <strong>simple and MD5</strong>( discuss in chapter 8).</p>\n</li>\n<li><p><strong>Multiple same-cost path:</strong> OPSF allow multiple same-cost path to be used , don’t need to select a path to carry all traffic.</p>\n</li>\n<li><p><strong>Integrated support to unicast and multicast routing:</strong> Multicast OSPF (MOSPF).<br></p>\n</li>\n<li><strong>Support a hierarchy within a single routing domain:</strong> An OPSF autonomous system can be configured hierarchically into areas , Each area run its own OSPF link-state-algorithm , with each router in an area broadcasting its link-state to all other in that area. Within each area of a autonomous system has one or more <strong>area border router</strong> are responsible for routing packets to outside the area . And exactly one OPSF area in the AS is configured to be the <strong>backbone</strong> area. The primary role of the backbone area is to route traffic between the other area in the AS. <em>Inter-area routing</em> within the AS requires that the packet be first route to a area border router , and routed through the backbone to the area border router that is in the destination area , and then routed to the final destination.</li>\n</ul>\n<h2 id=\"4-6-3-Inter-AS-Routing-BGP-Border-Gateway-Protocol\"><a href=\"#4-6-3-Inter-AS-Routing-BGP-Border-Gateway-Protocol\" class=\"headerlink\" title=\"4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)\"></a>4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)</h2><p>Let’s us examine how path are determined for source-destination pair span multiple ASs.<br><br>Under BGP protocol , pair of router exchange information through semi-permanent TCP connection using port 179.<br><br>The BGP protocol TCP connection has two type of connection : <br></p>\n<ul>\n<li>BGP TCP connection between router within a same AS.</li>\n<li>BGP TCP connection between routers in two different ASs.</li>\n</ul>\n<p>Two interconnecting router corresponding source and destination router that using TCP are called <strong>BGP peers</strong> . The TCP connection along with all BGP message sent over the connection is called <strong>BGP session</strong>.<br><br><strong>Two type of BGP session:</strong><br></p>\n<ul>\n<li>External BGP session (eBGP session) : The BGP message is sent span two routers.</li>\n<li>Internal BGP session (iBGP session) : The BGP message is sent within an AS.<br><img src=\"BGP-sessions.png\" alt=\"BGP-sessions.png\"><br><br>In the BGP , destinations are not a host but instead are CIDRized prefixes with each prefixes is representing a subnet or a collection of subnet.<br></li>\n</ul>\n<p>In the BGP , some ASs has a globally unique <strong>autonomous system numbers(ASN)</strong> , the ASs hasn’t ASN is called stub AS. ASN similar to IP address are assigned by ICANN regional register.<br></p>\n<p>When a router advertise prefix to outside ASs , it include with a number of <strong>BGP attributes :</strong> , in BGP jargon , a prefix along with its attributes is called a route. The BGP  attributes is following: <br></p>\n<ul>\n<li><strong>AS-PATH :</strong> The attributes contain the ASN that the prefix have been passed.</li>\n<li><strong>NEXT-HOP:</strong> The NEXT-HOP is router interface that begins the AS-PATH. </li>\n</ul>\n<h3 id=\"BGP-Route-selection\"><a href=\"#BGP-Route-selection\" class=\"headerlink\" title=\"BGP Route selection\"></a>BGP Route selection</h3><p>Under BGP protocol , a router may be receive more than one route to the same prefix . Then BGP must be sequentially invokes the following elimination rules until one possible remain , The elimination rules is following:<br></p>\n<ul>\n<li>Routes are assigned a local preference values as one of their attributes , the routes with the highest local preference value are selected.</li>\n<li>From the remaining routes ( all routes has same preference value ) with the shortest AS-PATH are selected.</li>\n<li>From the remaining routes ( all routes has same preference value and same AS-PATH length) with closest NEXT-HOP are selected, here closest mean the least-cost path of a router itself interface and its corresponding eBGP session interface.</li>\n<li>If more than one route still remains , the router use the BGP identifiers to select the route.</li>\n</ul>\n<h3 id=\"Putting-all-together-How-does-an-entry-get-into-a-router’s-forwarding-table\"><a href=\"#Putting-all-together-How-does-an-entry-get-into-a-router’s-forwarding-table\" class=\"headerlink\" title=\"Putting all together : How does an entry get into a router’s forwarding table ?\"></a>Putting all together : How does an entry get into a router’s forwarding table ?</h3><p><strong>How does the packet is forwarded within a router ?<br></strong><br>When a packet arrive to the router , the packet’s destination IP address compared with the prefixes in the forwarding table and find a longest prefix match . Then the packet is forwarded to router’s port that associated with that matched prefix.<br><br><strong>How does an entry get into a router’s forwarding table ?</strong><br><br><em>In order to get an entry into a router’s forwarding table , first , the router must be aware of the prefix. The router become aware of the prefix via a BGP route advertisement , such a route advertisement may be sent over a eBGP session or over a iBGP session. After the router become aware of prefix , it need to determine appropriate output port to which datagram destined to that prefix will be forwarded. Before it can enter that entry (prefix + port) into its forwarding table . If router receive more than one route advertisement for this prefix , it is uses the BGP selection process to select to best route for the prefix , suppose the route have been selected , the selected route include NEXT-HOP attribute , which is IP address of first router outside the router’s AS along this best route. Then the router uses its Intra-AS routing protocol (typically OSPF) , to determine the shortest path to the NEXT-HOP router. The router finally determines the port number to associate with the prefix by identifying the first link along the shortest path . The router finally can enter the prefix-port pair into the forwarding table.</em></p>\n<h1 id=\"4-7-Broadcast-and-Multicast-Routing\"><a href=\"#4-7-Broadcast-and-Multicast-Routing\" class=\"headerlink\" title=\"4.7 Broadcast and Multicast Routing\"></a>4.7 Broadcast and Multicast Routing</h1><h2 id=\"4-7-1-Broadcast-Routing-Algorithm\"><a href=\"#4-7-1-Broadcast-Routing-Algorithm\" class=\"headerlink\" title=\"4.7.1 Broadcast Routing Algorithm\"></a>4.7.1 Broadcast Routing Algorithm</h2><p><strong>Two type of Broadcast routing algorithm: <br></strong></p>\n<ul>\n<li><strong>Source-Duplication:</strong> A packet is created and duplicated by a source router , and source router broadcast to all router in the network by unicast. This approach has several drawback is following:<ul>\n<li>inefficiency : The source router is required to copy a large amount of same packet and send these via a single link.</li>\n<li>Additional protocol mechanisms to obtain the address of the broadcast recipient ,would add more overhead and make the system more complex .</li>\n</ul>\n</li>\n<li><strong>In-network duplication:</strong> The source router broadcast by sending only one packet to attached routers , and then the attached routers copy the packet and send it to next attached routers .<br><img src=\"Source-duplication-In-network-duplication.png\" alt=\"Source-duplication-In-network-duplication.png\"><br></li>\n</ul>\n<h3 id=\"Uncontrolled-Flooding\"><a href=\"#Uncontrolled-Flooding\" class=\"headerlink\" title=\"Uncontrolled Flooding\"></a>Uncontrolled Flooding</h3><p>The most obvious technique for broadcast is <strong>Flooding</strong> approach in which the source node send its copy of packet to its neighbor.<br><br>Although this approach is simple and elegant , it has a fatal flaw , that is , if the graph has a cycles , then one or more broadcast packet will cycle indefinitely .<br><br>This broadcast storm along with broadcast packet increasingly would cause the network crash (network useless).</p>\n<h3 id=\"Controlled-Flooding\"><a href=\"#Controlled-Flooding\" class=\"headerlink\" title=\"Controlled Flooding\"></a>Controlled Flooding</h3><p>In practice , we have several way to solve the problem of uncontrolled flooding .<br></p>\n<ul>\n<li><p><strong>Sequence-number-controlled-flooding:</strong> A source node put its address or other unique identifies as well as broadcast sequence number into broadcast packet , then send it to all neighbors. Each node maintain a list of the source address and sequence number of broadcast packet , it first checks whether the packet is in this list , if so , the packet is dropped , if not , the packet is duplicated and forwarded to all node’s neighbors.<br></p>\n</li>\n<li><p><strong>Reverse path forwarding (RPF):</strong> Reverse path forwarding is also known as Reverse path broadcast (RPB) , When a node receives a broadcast packet with the source node address , <strong>the node transmits the packet on all of its outgoing link (expect one that outgoing link of its receive that packet)only if the packet arrived on the link that is on its own shortest unicast path back to the source. Otherwise , this packet is discarded simply.</strong><br>As likely the figure following , the router E transmits only the packet that arrived from router C to all neighbors(because it is the shortest path from router D to source router A), Otherwise , the packet is discarded simply.<br><img src=\"RPF.png\" alt=\"RPF.png\"><br></p>\n</li>\n</ul>\n<h3 id=\"Spanning-Tree-Broadcast\"><a href=\"#Spanning-Tree-Broadcast\" class=\"headerlink\" title=\"Spanning-Tree Broadcast\"></a>Spanning-Tree Broadcast</h3><p>Although The sequence-number-controlled-flooding algorithm and RPF algorithm avoid the broadcast storm , these don’t completely avoid the transmission of redundant broadcast packet.<br><br>Actually , every node receive only one broadcast packet is enough. The Spanning-Tree Broadcast algorithm can solve this problem .<br></p>\n<p>Thus , a node first have to construct a spanning-tree , when it wants to provide broadcast for all network node.<br></p>\n<p>We consider only one simple algorithm here , that is <strong>Center-based approach</strong> to build a spanning-tree.<br></p>\n<ul>\n<li>First determine a center node (also known as <strong>core</strong> and <strong>rendezvous point</strong>)</li>\n<li>The network node then unicast <strong>tree-join message</strong> addressed to center node. A tree-join message is forwarded using unicast routing toward the center until either arrives at a node that has already belong to the spanning tree or arrives at the center node.</li>\n</ul>\n<p><em>If each link associated cost , then a spanning-tree whose cost is the minimum of all of graph’s spanning-tree is called a <strong>minimum spanning-tree</strong> .</em> <br></p>\n<iframe \n    width=\"800\" \n    height=\"450\" \n    src=\"https://www.youtube.com/embed/Uj47dxYPow8\"\n    frameborder=\"0\" \n    allowfullscreen>\n</iframe>\n\n<h2 id=\"4-7-2-Multicast\"><a href=\"#4-7-2-Multicast\" class=\"headerlink\" title=\"4.7.2 Multicast\"></a>4.7.2 Multicast</h2><p>In multicast communication , we are immediately faced with two problem .<br></p>\n<ul>\n<li>How to identify the receiver of multicast packet.</li>\n<li>How to address a packet send to these receivers.<br>Network layer multicast in the internet consist of two complementary components : <strong>IGMP (Internet Group Management Protocol) and Multicast routing protocol</strong>. The IGMP is used to solve first problem. The Multicast routing protocol is used to solve second problem.<br></li>\n</ul>\n<h3 id=\"Internet-Group-Management-Protocol\"><a href=\"#Internet-Group-Management-Protocol\" class=\"headerlink\" title=\"Internet Group Management Protocol\"></a>Internet Group Management Protocol</h3><p>The IGMP protocol version 3 operates between a host and its directly attached router. The figure following , shows three fist-hop multicast protocol each connected to its attached hosts via one outgoing local interface.<br><br><img src=\"IGMP-component.png\" alt=\"IGMP-component.png\"><br><br>IGMP provide the mean for a host to inform its attached router that an application running on the host want to join a specific multicast group.<br></p>\n<p><strong>IGMP has three message types.</strong><br></p>\n<ul>\n<li><strong>Membership_query message:</strong> That is sent by router to all host on an attached interface to determine which hosts on attached network are member of which multicast group.</li>\n<li><strong>Membership_report message :</strong> This message is used to respond to Membership_query message for inform the attached router that it still in multicast group and also be used to first joins a multicast group.</li>\n<li><strong>Leave_group message :</strong> This message is used to inform the router stops forwarding the multicast message to it. Interesting this message is optional , but it is optional , how to detect when a host leave the multicast group , The answer is the router infer this host have been leaved a multicast if this host no longer respond to Membership_query message. This example is called <strong>soft state</strong> in the internet protocol.<br></li>\n</ul>\n<h3 id=\"Multicast-Routing-Algorithm\"><a href=\"#Multicast-Routing-Algorithm\" class=\"headerlink\" title=\"Multicast Routing Algorithm\"></a>Multicast Routing Algorithm</h3><p>The goal of multicast routing , then is find a tree of links that connects all of routers that have attached hosts belonging to the multicast group . Multicast packet will be routed along with this tree from the multicast sender to all of the host belong to this multicast tree , of course , the tree also can contain some router that haven’t hosts belong to Multicast group.<br></p>\n<p>Two approach have been adopted for determining the multicast router tree.<br></p>\n<ul>\n<li><strong>A group shared tree :</strong> As in the case of Spanning-tree broadcast , multicast routing over a group-shared tree is base on building a tree that include all edge router with attached host belonging to multicast group. In practice , a center-based approach is used to construct the multicast routing tree with edge router with attached hosts belonging to multicast group send (via unicast) join-message addressed to center router.<br></li>\n<li><strong>A source base tree :</strong> The group shared tree constructs a single, shared routing tree to route packet from all senders . This approach is constructs a multicast routing tree for each source in the multicast group . In practice , an RPF algorithm is used to construct a multicast forwarding tree for multicast datagram originating at source x. The RPF broadcast algorithm require a bits of tweaking when it is used to multicast. To see why consider router D in Figure following. Under broadcast RPF , it forward packets to router G , even though router has no attached hosts that are joined to multicast group . While this is not so bad for this case , where router D has only one downstream router G , imagine what would happen if router D has thousand of downstream router ? Each of these downstream router would receive unwanted multicast packets. The solution of this problem is known as <strong>pruning</strong>.<br><img src=\"RPF-Multicast.png\" alt=\"RPF-Multicast.png\"><br></li>\n</ul>\n"}],"PostAsset":[{"_id":"source/_posts/377-Combination-Sum-IV/377-Combination-Sum-IV-1.png","slug":"377-Combination-Sum-IV-1.png","post":"ckivbi4rm0001r8s8cq184jgu","modified":0,"renderable":0},{"_id":"source/_posts/377-Combination-Sum-IV/377-Combination-Sum-IV-2.png","slug":"377-Combination-Sum-IV-2.png","post":"ckivbi4rm0001r8s8cq184jgu","modified":0,"renderable":0},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-09_21:03_select.png","slug":"2020-03-09_21:03_select.png","post":"ckivbi4rt0007r8s86hiv2h01","modified":0,"renderable":0},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-10_15:03_select.png","slug":"2020-03-10_15:03_select.png","post":"ckivbi4rt0007r8s86hiv2h01","modified":0,"renderable":0},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-11_09:03_select.png","slug":"2020-03-11_09:03_select.png","post":"ckivbi4rt0007r8s86hiv2h01","modified":0,"renderable":0},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-11_14:03:1583906551_select.png","slug":"2020-03-11_14:03:1583906551_select.png","post":"ckivbi4rt0007r8s86hiv2h01","modified":0,"renderable":0},{"_id":"source/_posts/Chapter1-Review-Questions/2020-03-11_20:03:1583929611_select.png","slug":"2020-03-11_20:03:1583929611_select.png","post":"ckivbi4rt0007r8s86hiv2h01","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/1.png","slug":"1.png","post":"ckivbi4ru0008r8s8aeem85px","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/2.png","slug":"2.png","post":"ckivbi4ru0008r8s8aeem85px","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/3.png","slug":"3.png","post":"ckivbi4ru0008r8s8aeem85px","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/4.png","slug":"4.png","post":"ckivbi4ru0008r8s8aeem85px","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/5.png","slug":"5.png","post":"ckivbi4ru0008r8s8aeem85px","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Homework-Problems-and-Questions/6.png","slug":"6.png","post":"ckivbi4ru0008r8s8aeem85px","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/BL1.png","slug":"BL1.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/BL2.png","slug":"BL2.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/BL3.png","slug":"BL3.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/BL4.png","slug":"BL4.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/BL5.png","slug":"BL5.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/BL6.png","slug":"BL6.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/KMP举例1.png","slug":"KMP举例1.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/KMP举例2.png","slug":"KMP举例2.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/next1.png","slug":"next1.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/next2.png","slug":"next2.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/next3.png","slug":"next3.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/next4.png","slug":"next4.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/next5.png","slug":"next5.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/next6.png","slug":"next6.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/证明1.png","slug":"证明1.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/证明2.png","slug":"证明2.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/证明3.png","slug":"证明3.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/KMP算法/证明１.png","slug":"证明１.png","post":"ckivbi4rv0009r8s8cwdne9fr","modified":0,"renderable":0},{"_id":"source/_posts/Manjaro-System-configuran/albert.png","slug":"albert.png","post":"ckivbi4ry000cr8s87kusf251","modified":0,"renderable":0},{"_id":"source/_posts/Manjaro-System-configuran/albert1.png","slug":"albert1.png","post":"ckivbi4ry000cr8s87kusf251","modified":0,"renderable":0},{"_id":"source/_posts/Manjaro-System-configuran/albert2.png","slug":"albert2.png","post":"ckivbi4ry000cr8s87kusf251","modified":0,"renderable":0},{"_id":"source/_posts/Manjaro-System-configuran/manjaro_System_finish.png","slug":"manjaro_System_finish.png","post":"ckivbi4ry000cr8s87kusf251","modified":0,"renderable":0},{"_id":"source/_posts/Spring-Cloud-Eureka-初入门/eureka-architecture.png","slug":"eureka-architecture.png","post":"ckivbi4s3000jr8s85nmu9pr5","modified":0,"renderable":0},{"_id":"source/_posts/The Network Edge/2020-02-27 14-34-38 的屏幕截图.png","slug":"2020-02-27 14-34-38 的屏幕截图.png","post":"ckivbi4s5000or8s89cn2dlh8","modified":0,"renderable":0},{"_id":"source/_posts/The Network Edge/2020-02-27 20-56-20 的屏幕截图.png","slug":"2020-02-27 20-56-20 的屏幕截图.png","post":"ckivbi4s5000or8s89cn2dlh8","modified":0,"renderable":0},{"_id":"source/_posts/The Network Edge/2020-02-27 21-43-25 的屏幕截图.png","slug":"2020-02-27 21-43-25 的屏幕截图.png","post":"ckivbi4s5000or8s89cn2dlh8","modified":0,"renderable":0},{"_id":"source/_posts/The Network Edge/2020-02-27 23-49-06 的屏幕截图.png","slug":"2020-02-27 23-49-06 的屏幕截图.png","post":"ckivbi4s5000or8s89cn2dlh8","modified":0,"renderable":0},{"_id":"source/_posts/The Network Edge/2020-02-28 00-21-20 的屏幕截图.png","slug":"2020-02-28 00-21-20 的屏幕截图.png","post":"ckivbi4s5000or8s89cn2dlh8","modified":0,"renderable":0},{"_id":"source/_posts/The-Network-Core/2020-02-28 19-47-00 的屏幕截图.png","slug":"2020-02-28 19-47-00 的屏幕截图.png","post":"ckivbi4s6000qr8s87a251zyl","modified":0,"renderable":0},{"_id":"source/_posts/The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png","slug":"2020-02-28 19-54-24 的屏幕截图.png","post":"ckivbi4s6000qr8s87a251zyl","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/1.png","slug":"1.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/2.png","slug":"2.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/3.png","slug":"3.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/4.png","slug":"4.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/5.png","slug":"5.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/6.png","slug":"6.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter4-Homework-problems-and-Questions/7.png","slug":"7.png","post":"ckivbi4s9000wr8s8h1y6e8du","modified":0,"renderable":0},{"_id":"source/_posts/chapter2-Homework-problems-and-Questions/Messagesheader.png","slug":"Messagesheader.png","post":"ckivbi4sa0010r8s86q91dy1j","modified":0,"renderable":0},{"_id":"source/_posts/chapter2-Homework-problems-and-Questions/TCP-handshake.png","slug":"TCP-handshake.png","post":"ckivbi4sa0010r8s86q91dy1j","modified":0,"renderable":0},{"_id":"source/_posts/二元组和图形描述逻辑结构/870358-20160102224630526-1483051229.jpg","slug":"870358-20160102224630526-1483051229.jpg","post":"ckivbi4sb0012r8s81jek38a2","modified":0,"renderable":0},{"_id":"source/_posts/对于指针的一些理解/指针.png","slug":"指针.png","post":"ckivbi4sd001ar8s8c8lucdj1","modified":0,"renderable":0},{"_id":"source/_posts/面试题35-复杂链表的复制/优化迭代法-图解.png","slug":"优化迭代法-图解.png","post":"ckivbi4ss002jr8s8ccxkf2tn","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/Circle-DHT.png","slug":"Circle-DHT.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/Cookie-process.png","slug":"Cookie-process.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-Messagas-dig.png","slug":"DNS-Messagas-dig.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-Messages.png","slug":"DNS-Messages.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-hierarchy.png","slug":"DNS-hierarchy.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-server-iterative-queries.png","slug":"DNS-server-iterative-queries.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/DNS-server-recursive-queries.png","slug":"DNS-server-recursive-queries.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/FTP-TCP-connections.png","slug":"FTP-TCP-connections.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/FTP-transfer-file.png","slug":"FTP-transfer-file.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/HTTP_requires.png","slug":"HTTP_requires.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/HTTP_respont.png","slug":"HTTP_respont.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/SMTP-access-mail.png","slug":"SMTP-access-mail.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/SMTP-transfer.png","slug":"SMTP-transfer.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/Chapter-2-Application-Layer/Web-cache.png","slug":"Web-cache.png","post":"ckivbi4st002kr8s83wq73z1v","modified":0,"renderable":0},{"_id":"source/_posts/process-switch-base-on-stack-switch/wm.png","slug":"wm.png","post":"ckivbi4su002mr8s803omeyft","modified":0,"renderable":0},{"_id":"source/_posts/process-switch-base-on-stack-switch/wm1.png","slug":"wm1.png","post":"ckivbi4su002mr8s803omeyft","modified":0,"renderable":0},{"_id":"source/_posts/process-switch-base-on-stack-switch/wm2.png","slug":"wm2.png","post":"ckivbi4su002mr8s803omeyft","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Code-snippet-of-fast-retransmit.png","slug":"Code-snippet-of-fast-retransmit.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png","slug":"Congestion-scenario-1-throughput-and-delay.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png","slug":"Congestion-scenario-1-two-connection.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Congestion-window-size-changes-along-with-time.png","slug":"Congestion-window-size-changes-along-with-time.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Fast-retransmit.png","slug":"Fast-retransmit.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/GBN's-FSM-description-senderi.png","slug":"GBN's-FSM-description-senderi.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/GBN's-FSM-receiver.png","slug":"GBN's-FSM-receiver.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/GBN-in-operation.png","slug":"GBN-in-operation.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/RTT-sample-and-RTT-estimates.png","slug":"RTT-sample-and-RTT-estimates.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Reliable-data-tranfer.png","slug":"Reliable-data-tranfer.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/SR-operation.png","slug":"SR-operation.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/SR-receiver-dilemma-a.png","slug":"SR-receiver-dilemma-a.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/SR-receiver-dilemma-b.png","slug":"SR-receiver-dilemma-b.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-2-performance.png","slug":"Scenario-2-performance.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-2-two-hosts.png","slug":"Scenario-2-two-hosts.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-3-Four-senders.png","slug":"Scenario-3-Four-senders.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Scenario-3-performance.png","slug":"Scenario-3-performance.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png","slug":"Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Sender's-view-of-sequence-numbers-in-the-Go-Back-N.png","slug":"Sender's-view-of-sequence-numbers-in-the-Go-Back-N.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Slow-Start.png","slug":"Slow-Start.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Stop-and-wait-versus-pipelined-protocol.png","slug":"Stop-and-wait-versus-pipelined-protocol.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-ACK-Generation-Recommendation.png","slug":"TCP-ACK-Generation-Recommendation.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-RcvBuffer.png","slug":"TCP-RcvBuffer.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-Segment-structure.png","slug":"TCP-Segment-structure.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-1.png","slug":"TCP-connection-manage-1.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-2.png","slug":"TCP-connection-manage-2.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-3.png","slug":"TCP-connection-manage-3.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection-manage-4.png","slug":"TCP-connection-manage-4.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-connection.png","slug":"TCP-connection.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/TCP-sender-and-receiver-buffer.png","slug":"TCP-sender-and-receiver-buffer.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/The-three-state-of-congestion-algorithm.png","slug":"The-three-state-of-congestion-algorithm.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/Two-feedback-way.png","slug":"Two-feedback-way.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/operation-of-rdt3.0-1.png","slug":"operation-of-rdt3.0-1.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/operation-of-rdt3.0-2.png","slug":"operation-of-rdt3.0-2.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt1.0-finite-state-machine.png","slug":"rdt1.0-finite-state-machine.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.0-A-protocol.png","slug":"rdt2.0-A-protocol.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.1-receiver.png","slug":"rdt2.1-receiver.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.1-sender.png","slug":"rdt2.1-sender.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.2-receiver.png","slug":"rdt2.2-receiver.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt2.2-sender.png","slug":"rdt2.2-sender.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter3-Transport-Layer/rdt3.0-sender.png","slug":"rdt3.0-sender.png","post":"ckivbi4sx002sr8s8d3deb4b4","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/A-Dual-Stack-Approachs.png","slug":"A-Dual-Stack-Approachs.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/A-Look-Inside-The-Internet-Network-Layer.png","slug":"A-Look-Inside-The-Internet-Network-Layer.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/ASs-connection-graph-RIP.png","slug":"ASs-connection-graph-RIP.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Advertisement-From-RouterA.png","slug":"Advertisement-From-RouterA.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/BGP-sessions.png","slug":"BGP-sessions.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Changes-in-link-cost.png","slug":"Changes-in-link-cost.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/DHCP-Client-Server-Interaction.png","slug":"DHCP-Client-Server-Interaction.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/DHCP-Client-Server-Scenario.png","slug":"DHCP-Client-Server-Scenario.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/DV-Simple-Example.png","slug":"DV-Simple-Example.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Datagram-Forwarding-Table.png","slug":"Datagram-Forwarding-Table.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Datagram-Network.png","slug":"Datagram-Network.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/General-en.svg.png","slug":"General-en.svg.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Graph-Of-Link-State-Algorithm.png","slug":"Graph-Of-Link-State-Algorithm.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/HOL-Block-At-An-Input-Queued-Switch.png","slug":"HOL-Block-At-An-Input-Queued-Switch.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/ICMP-Message-Types.png","slug":"ICMP-Message-Types.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/IGMP-component.png","slug":"IGMP-component.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/IP-fragmentation-and-reassembly.png","slug":"IP-fragmentation-and-reassembly.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/IPv6-Datagram-Format.png","slug":"IPv6-Datagram-Format.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Input-Port-Processing.png","slug":"Input-Port-Processing.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Interface-Address-And-Subnets.png","slug":"Interface-Address-And-Subnets.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Internet-ATM.png","slug":"Internet-ATM.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Ip-fragments.png","slug":"Ip-fragments.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Ipv4-Datagram-Format.png","slug":"Ipv4-Datagram-Format.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Network-Address-Translation.png","slug":"Network-Address-Translation.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Organization-Address.png","slug":"Organization-Address.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Oscillations-With-Congestion-Sensitive-Routing.png","slug":"Oscillations-With-Congestion-Sensitive-Routing.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Output-Port-Processing.png","slug":"Output-Port-Processing.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Output-Port-Queueing.png","slug":"Output-Port-Queueing.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/RIP-UDP-Application.png","slug":"RIP-UDP-Application.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/RPF-Multicast.png","slug":"RPF-Multicast.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/RPF.png","slug":"RPF.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Result-Of-LS-Algorithm.png","slug":"Result-Of-LS-Algorithm.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Router-Architecture.png","slug":"Router-Architecture.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png","slug":"Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png","slug":"Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Routing-algorithm-determine-value-in-forwarding-tables.png","slug":"Routing-algorithm-determine-value-in-forwarding-tables.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Simple-VC-Path.png","slug":"Simple-VC-Path.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Simple-Virtual-Circult-Network.png","slug":"Simple-Virtual-Circult-Network.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Source-duplication-In-network-duplication.png","slug":"Source-duplication-In-network-duplication.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Three-Switching-Techniques.png","slug":"Three-Switching-Techniques.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Tunneling.png","slug":"Tunneling.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/Virtual-Circuit-Setup.png","slug":"Virtual-Circuit-Setup.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/autonomous-system-graph.png","slug":"autonomous-system-graph.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0},{"_id":"source/_posts/Chapter4-The-Network-Layer/hot-potato-algorithm.png","slug":"hot-potato-algorithm.png","post":"ckivbi4tp002vr8s836212foz","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ckivbi4rm0001r8s8cq184jgu","category_id":"ckivbi4rq0004r8s87vc684jm","_id":"ckivbi4s1000fr8s8b8whaeia"},{"post_id":"ckivbi4rp0003r8s8d2lr715a","category_id":"ckivbi4rq0004r8s87vc684jm","_id":"ckivbi4s4000kr8s87g5n4vk5"},{"post_id":"ckivbi4rt0007r8s86hiv2h01","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4s7000sr8s8912mbt0m"},{"post_id":"ckivbi4ru0008r8s8aeem85px","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4s9000xr8s878ri5kqm"},{"post_id":"ckivbi4rv0009r8s8cwdne9fr","category_id":"ckivbi4s7000rr8s8d4ui1vm9","_id":"ckivbi4sc0014r8s8go7va2z0"},{"post_id":"ckivbi4s9000wr8s8h1y6e8du","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4sd0019r8s862ke6a0c"},{"post_id":"ckivbi4sa0010r8s86q91dy1j","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4se001cr8s8bx673ybw"},{"post_id":"ckivbi4ry000cr8s87kusf251","category_id":"ckivbi4s9000yr8s808uua0wa","_id":"ckivbi4sg001hr8s8bn3t19x7"},{"post_id":"ckivbi4sb0012r8s81jek38a2","category_id":"ckivbi4s7000rr8s8d4ui1vm9","_id":"ckivbi4si001kr8s8byxe2grl"},{"post_id":"ckivbi4sd001ar8s8c8lucdj1","category_id":"ckivbi4s7000rr8s8d4ui1vm9","_id":"ckivbi4sj001pr8s89vmc7g8o"},{"post_id":"ckivbi4rz000dr8s80hxr7czb","category_id":"ckivbi4sc0015r8s8g0c4hwzw","_id":"ckivbi4sk001rr8s81tdjf0h2"},{"post_id":"ckivbi4se001dr8s8dbhy0dwe","category_id":"ckivbi4s9000yr8s808uua0wa","_id":"ckivbi4sk001ur8s8czheg7j3"},{"post_id":"ckivbi4s3000jr8s85nmu9pr5","category_id":"ckivbi4si001mr8s84xt1ec51","_id":"ckivbi4sl001xr8s8085peo6u"},{"post_id":"ckivbi4s8000ur8s8gk3gg8hy","category_id":"ckivbi4sk001sr8s8fucj070k","_id":"ckivbi4sl0021r8s8buw1ckao"},{"post_id":"ckivbi4sc0017r8s873nhgwn0","category_id":"ckivbi4sl001yr8s85dkz52yw","_id":"ckivbi4sm0025r8s8anhi48au"},{"post_id":"ckivbi4sh001ir8s83e5dd86n","category_id":"ckivbi4sl0022r8s8hot4fvdx","_id":"ckivbi4sn0029r8s86itd9snm"},{"post_id":"ckivbi4s2000hr8s8fmov9a6v","category_id":"ckivbi4s9000yr8s808uua0wa","_id":"ckivbi4sp002cr8s81jcn0knf"},{"post_id":"ckivbi4s2000hr8s8fmov9a6v","category_id":"ckivbi4sm0026r8s8hlv18l25","_id":"ckivbi4sp002er8s8avu9a71b"},{"post_id":"ckivbi4ss002jr8s8ccxkf2tn","category_id":"ckivbi4rq0004r8s87vc684jm","_id":"ckivbi4sv002or8s82g55en43"},{"post_id":"ckivbi4st002kr8s83wq73z1v","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4sv002qr8s89uov8csh"},{"post_id":"ckivbi4sx002sr8s8d3deb4b4","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4sy002ur8s82xjfhuva"},{"post_id":"ckivbi4tp002vr8s836212foz","category_id":"ckivbi4s0000er8s8b73w3bm6","_id":"ckivbi4tr002xr8s80loc2d9d"}],"PostTag":[{"post_id":"ckivbi4rm0001r8s8cq184jgu","tag_id":"ckivbi4rs0005r8s81tcn64iu","_id":"ckivbi4s3000ir8s85qpmc9nd"},{"post_id":"ckivbi4rm0001r8s8cq184jgu","tag_id":"ckivbi4rw000br8s88gff3g83","_id":"ckivbi4s4000lr8s8drsa5r2b"},{"post_id":"ckivbi4rp0003r8s8d2lr715a","tag_id":"ckivbi4rs0005r8s81tcn64iu","_id":"ckivbi4s6000pr8s80rrv8h59"},{"post_id":"ckivbi4rt0007r8s86hiv2h01","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4s9000vr8s8gs7s61rx"},{"post_id":"ckivbi4ru0008r8s8aeem85px","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4sb0011r8s8an7k7r2t"},{"post_id":"ckivbi4s9000wr8s8h1y6e8du","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4sc0013r8s87iws6e3a"},{"post_id":"ckivbi4sa0010r8s86q91dy1j","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4sd0018r8s87m90h9fb"},{"post_id":"ckivbi4rv0009r8s8cwdne9fr","tag_id":"ckivbi4sa000zr8s87uz22qmq","_id":"ckivbi4se001br8s80ow06r3b"},{"post_id":"ckivbi4sb0012r8s81jek38a2","tag_id":"ckivbi4sa000zr8s87uz22qmq","_id":"ckivbi4sg001gr8s867er61x5"},{"post_id":"ckivbi4sd001ar8s8c8lucdj1","tag_id":"ckivbi4sa000zr8s87uz22qmq","_id":"ckivbi4si001jr8s8cizd6l49"},{"post_id":"ckivbi4ry000cr8s87kusf251","tag_id":"ckivbi4sc0016r8s8d2wi1ccg","_id":"ckivbi4sj001or8s8faraeozp"},{"post_id":"ckivbi4se001dr8s8dbhy0dwe","tag_id":"ckivbi4sc0016r8s8d2wi1ccg","_id":"ckivbi4sk001qr8s86d5j5jno"},{"post_id":"ckivbi4rz000dr8s80hxr7czb","tag_id":"ckivbi4sf001fr8s84c2fglsm","_id":"ckivbi4sk001tr8s8ed5w4ykq"},{"post_id":"ckivbi4s2000hr8s8fmov9a6v","tag_id":"ckivbi4sj001nr8s895vw3obb","_id":"ckivbi4sk001wr8s8f4bg97o4"},{"post_id":"ckivbi4s3000jr8s85nmu9pr5","tag_id":"ckivbi4sk001vr8s86lxib5h8","_id":"ckivbi4sl0020r8s85hiu69t4"},{"post_id":"ckivbi4s5000or8s89cn2dlh8","tag_id":"ckivbi4sl001zr8s886gtfs0r","_id":"ckivbi4sm0024r8s87cxr6fqz"},{"post_id":"ckivbi4s6000qr8s87a251zyl","tag_id":"ckivbi4sl001zr8s886gtfs0r","_id":"ckivbi4sn0028r8s8ht7fh0a0"},{"post_id":"ckivbi4s8000ur8s8gk3gg8hy","tag_id":"ckivbi4sn0027r8s89ednarcc","_id":"ckivbi4sn002br8s8b2im19z4"},{"post_id":"ckivbi4sc0017r8s873nhgwn0","tag_id":"ckivbi4sn002ar8s897or29tk","_id":"ckivbi4sp002fr8s864go9211"},{"post_id":"ckivbi4sh001ir8s83e5dd86n","tag_id":"ckivbi4sp002dr8s87mpo4ou8","_id":"ckivbi4sq002hr8s85w6a2ba6"},{"post_id":"ckivbi4si001lr8s87ummfq2v","tag_id":"ckivbi4sp002gr8s82cv78d8a","_id":"ckivbi4sq002ir8s8cesi8n0k"},{"post_id":"ckivbi4ss002jr8s8ccxkf2tn","tag_id":"ckivbi4rs0005r8s81tcn64iu","_id":"ckivbi4su002lr8s88l90g02f"},{"post_id":"ckivbi4st002kr8s83wq73z1v","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4sv002nr8s8h6tk4mde"},{"post_id":"ckivbi4su002mr8s803omeyft","tag_id":"ckivbi4sv002pr8s88qnw099c","_id":"ckivbi4sv002rr8s8d4z2h4rd"},{"post_id":"ckivbi4sx002sr8s8d3deb4b4","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4sy002tr8s80jpv425b"},{"post_id":"ckivbi4tp002vr8s836212foz","tag_id":"ckivbi4s4000nr8s80ot4b6mh","_id":"ckivbi4tr002wr8s8d4asdfzy"}],"Tag":[{"name":"力扣","_id":"ckivbi4rs0005r8s81tcn64iu"},{"name":"动态规划","_id":"ckivbi4rw000br8s88gff3g83"},{"name":"Computer Network A Top-Down Approach","_id":"ckivbi4s4000nr8s80ot4b6mh"},{"name":"数据结构","_id":"ckivbi4sa000zr8s87uz22qmq"},{"name":"操作系统","_id":"ckivbi4sc0016r8s8d2wi1ccg"},{"name":"PA","_id":"ckivbi4sf001fr8s84c2fglsm"},{"name":"Shell","_id":"ckivbi4sj001nr8s895vw3obb"},{"name":"微服务学习","_id":"ckivbi4sk001vr8s86lxib5h8"},{"name":"-Computer Network A Top-Down Approach","_id":"ckivbi4sl001zr8s886gtfs0r"},{"name":"vim","_id":"ckivbi4sn0027r8s89ednarcc"},{"name":"计算机组成原理","_id":"ckivbi4sn002ar8s897or29tk"},{"name":"C/C++","_id":"ckivbi4sp002dr8s87mpo4ou8"},{"name":"-英语学习","_id":"ckivbi4sp002gr8s82cv78d8a"},{"name":"-操作系统","_id":"ckivbi4sv002pr8s88qnw099c"}]}}