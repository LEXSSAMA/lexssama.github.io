<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>CS144-lab6</title>
    <link href="/2021/04/19/CS144-lab6/"/>
    <url>/2021/04/19/CS144-lab6/</url>
    
    <content type="html"><![CDATA[<h1 id="实现route-cc"><a href="#实现route-cc" class="headerlink" title="实现route.cc"></a>实现route.cc</h1><p>这个lab是实现路由器,路由转发的功能,需要维护一个路由转发表，通过目标IP地址与路由转发表中存储的IP地址进行最长前缀匹配来决定数据报要从路由器上面的哪一个网络接口<code>Network Interface</code>发出。<br></p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><strong>route.hh</strong><br></p><pre><code class="lang-C++">class Router &#123;.....    //! The router&#39;s collection of network interfaces    struct Table &#123;        const uint32_t route_prefix;        const uint8_t prefix_length;        const std::optional&lt;Address&gt; next_hop;        const size_t interface_num;    &#125;;    std::vector&lt;AsyncNetworkInterface&gt; _interfaces&#123;&#125;;    std::vector&lt;Table&gt; _route_table&#123;&#125;;....   &#125;</code></pre><p><strong>route.cc</strong><br></p><pre><code class="lang-C++">#include &quot;router.hh&quot;#include &lt;iostream&gt;using namespace std;void Router::add_route(const uint32_t route_prefix,                       const uint8_t prefix_length,                       const optional&lt;Address&gt; next_hop,                       const size_t interface_num) &#123;    cerr &lt;&lt; &quot;DEBUG: adding route &quot; &lt;&lt; Address::from_ipv4_numeric(route_prefix).ip() &lt;&lt; &quot;/&quot; &lt;&lt; int(prefix_length)         &lt;&lt; &quot; =&gt; &quot; &lt;&lt; (next_hop.has_value() ? next_hop-&gt;ip() : &quot;(direct)&quot;) &lt;&lt; &quot; on interface &quot; &lt;&lt; interface_num &lt;&lt; &quot;\n&quot;;    // Your code here.    _route_table.push_back(Table&#123;route_prefix, prefix_length, next_hop, interface_num&#125;);&#125;void Router::route_one_datagram(InternetDatagram &amp;dgram) &#123;    int size = _route_table.size();    int fix_interface = -1;    uint8_t longest = 0;    for (int i = 0; i &lt; size; ++i) &#123;        if (_route_table[i].prefix_length &gt;= longest) &#123;            uint32_t mask =                _route_table[i].prefix_length == 0 ? 0 : (0xFFFFFFFF &lt;&lt; (32 - _route_table[i].prefix_length));            uint32_t tmp = dgram.header().dst &amp; mask;            if (tmp == (_route_table[i].route_prefix &amp; mask)) &#123;                longest = _route_table[i].prefix_length;                fix_interface = _route_table[i].interface_num;            &#125;        &#125;    &#125;    if (fix_interface == -1 || dgram.header().ttl &lt;= 1)        return;    --dgram.header().ttl;    if (_route_table[fix_interface].next_hop.has_value())        interface(fix_interface).send_datagram(dgram, _route_table[fix_interface].next_hop.value());    else        interface(fix_interface).send_datagram(dgram, Address::from_ipv4_numeric(dgram.header().dst));&#125;void Router::route() &#123;    // Go through all the interfaces, and route every incoming datagram to its proper outgoing interface.    for (auto &amp;interface : _interfaces) &#123;        auto &amp;queue = interface.datagrams_out();        while (not queue.empty()) &#123;            route_one_datagram(queue.front());            queue.pop();        &#125;    &#125;&#125;</code></pre><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>CS144的项目到这里算是告一段落了，前前后后大概做了20多天，理论上理解TCP/IP和动手写TCP/IP确实完全不同,真正学习计算机就是要动手写代码!!<br></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab4</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS144-lab5</title>
    <link href="/2021/04/19/CS144-lab5/"/>
    <url>/2021/04/19/CS144-lab5/</url>
    
    <content type="html"><![CDATA[<h1 id="实现Network-Interface"><a href="#实现Network-Interface" class="headerlink" title="实现Network Interface"></a>实现Network Interface</h1><p>网络接口<code>Network Interface</code>是网络层和链路层链接的桥梁，它的作用就是将网络层传下来的<code>Internet datagrams</code>封装成链路层的<code>Ethernet frames</code>,然后将封装好的<code>Ethernet frames</code>发出。<br></p><h2 id="封装Ethernet-frames"><a href="#封装Ethernet-frames" class="headerlink" title="封装Ethernet frames"></a>封装Ethernet frames</h2><p>想将<code>Internet datagrams</code>封装成<code>Ethernet frames</code>我们需要知道<code>Destination Mac Address</code>和<code>Source Mac Address</code> 和 <code>EtherType</code>。</p><ul><li><strong>Source Mac Address</strong> : 本机的Mac地址。</li><li><strong>Destination Mac Address</strong> : 目标主机的Mac地址会被存储到本机的目标IP和目标Mac地址的映射数据结构中,如果本机维护的这个数据结构不存在目标IP的Mac地址，那么我们就需要使用ARP协议向局域网中的其他主机询问目标IP的Mac地址。(APR协议的细节:<a href="https://en.wikipedia.org/wiki/Address_Resolution_Protocol">Address Resolution Protocol</a>)</li><li><strong>EtherType</strong> : 表示上层<code>Internet datagrames</code>使用的协议类型，lab5中只涉及到<code>ARP</code>和<code>IPv4</code>协议。</li></ul><h2 id="细节"><a href="#细节" class="headerlink" title="细节"></a>细节</h2><ol><li>因为目标Mac地址缺失而没发出的<code>Ethernet frames</code>，得到目标Mac地址后需要重发。</li><li>不能在<code>5秒内</code>向使用<code>ARP Request</code> 询问同一个目标IP的Mac地址。</li><li>每一个存储在数据结构中的目标ip-mac映射对过了<code>30秒</code>后需要被清理。</li></ol><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p><strong>network_interface.hh</strong><br></p><pre><code class="lang-c++">class NetworkInterface &#123;  private:....    struct Dgram_nextHop &#123;        const InternetDatagram dgram;        Address next_hop;    &#125;;    struct EtherAddress_Time &#123;        EthernetAddress mac_addr;        size_t time;    &#125;;    std::queue&lt;Dgram_nextHop&gt; _frames_track&#123;&#125;;    std::map&lt;uint32_t, EtherAddress_Time&gt; _ip_eth_map&#123;&#125;;    std::map&lt;uint32_t, size_t&gt; _ip_msTime_map&#123;&#125;;    size_t _ms_clock&#123;0&#125;;    void send_arp(uint16_t opcode, EthernetAddress &amp;dst, uint32_t dst_ip);....&#125;</code></pre><p><strong>network_interface.cc</strong><br></p><pre><code class="lang-c++">#include &quot;network_interface.hh&quot;#include &quot;arp_message.hh&quot;#include &quot;ethernet_frame.hh&quot;#include &lt;iostream&gt;// Dummy implementation of a network interface// Translates from &#123;IP datagram, next hop address&#125; to link-layer frame, and from link-layer frame to IP datagram// For Lab 5, please replace with a real implementation that passes the// automated checks run by `make check_lab5`.// You will need to add private members to the class declaration in `network_interface.hh`template &lt;typename... Targs&gt;void DUMMY_CODE(Targs &amp;&amp;... /* unused */) &#123;&#125;using namespace std;//! \param[in] ethernet_address Ethernet (what ARP calls &quot;hardware&quot;) address of the interface//! \param[in] ip_address IP (what ARP calls &quot;protocol&quot;) address of the interfaceNetworkInterface::NetworkInterface(const EthernetAddress &amp;ethernet_address, const Address &amp;ip_address)    : _ethernet_address(ethernet_address), _ip_address(ip_address) &#123;    cerr &lt;&lt; &quot;DEBUG: Network interface has Ethernet address &quot; &lt;&lt; to_string(_ethernet_address) &lt;&lt; &quot; and IP address &quot;         &lt;&lt; ip_address.ip() &lt;&lt; &quot;\n&quot;;&#125;//! \param[in] dgram the IPv4 datagram to be sent//! \param[in] next_hop the IP address of the interface to send it to (typically a router or default gateway, but may also be another host if directly connected to the same network as the destination)//! (Note: the Address type can be converted to a uint32_t (raw 32-bit IP address) with the Address::ipv4_numeric() method.)bool NetworkInterface::send_datagram(const InternetDatagram &amp;dgram, const Address &amp;next_hop) &#123;    // convert IP address of next hop to raw 32-bit representation (used in ARP header)    const uint32_t next_hop_ip = next_hop.ipv4_numeric();    if (_ip_eth_map.count(next_hop_ip)) &#123;        if (_ms_clock - _ip_eth_map[next_hop_ip].time &gt;= 30 * 1000) &#123;            _ip_eth_map.erase(next_hop_ip);            _frames_track.push(Dgram_nextHop&#123;dgram, next_hop&#125;);            send_arp(ARPMessage::OPCODE_REQUEST, const_cast&lt;EthernetAddress &amp;&gt;(ETHERNET_BROADCAST), next_hop_ip);            _ip_msTime_map[next_hop_ip];            return false;        &#125;        EthernetFrame frame;        frame.header().src = _ethernet_address;        frame.header().dst = _ip_eth_map[next_hop_ip].mac_addr;        frame.header().type = EthernetHeader::TYPE_IPv4;        frame.payload() = std::move(dgram.serialize());        _frames_out.push(std::move(frame));        return true;    &#125;    if (!_ip_msTime_map.count(next_hop_ip)) &#123;        _frames_track.push(Dgram_nextHop&#123;dgram, next_hop&#125;);        send_arp(ARPMessage::OPCODE_REQUEST, const_cast&lt;EthernetAddress &amp;&gt;(ETHERNET_BROADCAST), next_hop_ip);        _ip_msTime_map[next_hop_ip];    &#125; else if (_ms_clock - _ip_msTime_map[next_hop_ip] &gt;= 5 * 1000) &#123;        send_arp(ARPMessage::OPCODE_REQUEST, const_cast&lt;EthernetAddress &amp;&gt;(ETHERNET_BROADCAST), next_hop_ip);        _ip_msTime_map.erase(next_hop_ip);    &#125;    return false;&#125;void NetworkInterface::send_arp(uint16_t opcode, EthernetAddress &amp;dst, uint32_t dst_ip) &#123;    ARPMessage arp;    EthernetFrame frame;    arp.opcode = opcode;    arp.sender_ethernet_address = _ethernet_address;    arp.sender_ip_address = _ip_address.ipv4_numeric();    if (opcode != ARPMessage::OPCODE_REQUEST) &#123;        arp.target_ethernet_address = dst;    &#125;    arp.target_ip_address = dst_ip;    frame.header().src = _ethernet_address;    frame.header().dst = dst;    frame.header().type = EthernetHeader::TYPE_ARP;    frame.payload() = arp.serialize();    _frames_out.push(std::move(frame));&#125;//! \param[in] frame the incoming Ethernet frameoptional&lt;InternetDatagram&gt; NetworkInterface::recv_frame(const EthernetFrame &amp;frame) &#123;    if (frame.header().dst != _ethernet_address &amp;&amp; frame.header().dst != ETHERNET_BROADCAST)        return nullopt;    if (frame.header().type == EthernetHeader::TYPE_ARP) &#123;        ARPMessage arp;        if (arp.parse(frame.payload()) != ParseResult::NoError) &#123;            return std::nullopt;        &#125;        if (arp.target_ip_address != _ip_address.ipv4_numeric()) &#123;            return std::nullopt;        &#125;        if (arp.opcode == ARPMessage::OPCODE_REQUEST) &#123;            send_arp(ARPMessage::OPCODE_REPLY, arp.sender_ethernet_address, arp.sender_ip_address);        &#125;        _ip_eth_map[arp.sender_ip_address] = &#123;arp.sender_ethernet_address, _ms_clock&#125;;        while (!_frames_track.empty()) &#123;            if (send_datagram(_frames_track.front().dgram, _frames_track.front().next_hop)) &#123;                _frames_track.pop();            &#125; else                break;        &#125;    &#125; else if (frame.header().type == EthernetHeader::TYPE_IPv4) &#123;        InternetDatagram dgram;        if (dgram.parse(frame.payload()) != ParseResult::NoError)            return nullopt;        return dgram;    &#125;    return std::nullopt;&#125;//! \param[in] ms_since_last_tick the number of milliseconds since the last call to this methodvoid NetworkInterface::tick(const size_t ms_since_last_tick) &#123; _ms_clock += ms_since_last_tick; &#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab4</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS144-lab4</title>
    <link href="/2021/04/16/CS144-lab4/"/>
    <url>/2021/04/16/CS144-lab4/</url>
    
    <content type="html"><![CDATA[<h1 id="实现TCPConnection"><a href="#实现TCPConnection" class="headerlink" title="实现TCPConnection"></a>实现TCPConnection</h1><p><code>TCPConnection</code>实际上就是结合<code>TCPReceiver</code>和<code>TCPSender</code>结合实现一个TCP的有限状态机<strong>(TCP Finite State Machine (FSM))</strong>,也就是实现下面这一张实际运行的逻辑图<br><br><strong>实现TCPConnection我修改了TCPReceiver和TCPSender一些接口的返回值例如将返回void修改成返回bool</strong><br><br><img src="tcpfsm.png" alt="TCP Finite State Machine "><br></p><p><strong>详细的FSM可以看这个网页:</strong> <a href="http://tcpipguide.com/free/t_TCPOperationalOverviewandtheTCPFiniteStateMachineF-2.htm">TCP Finite State Machine</a></p><p>其次就是研究透彻<code>tcp_state.cc</code>,这个文件中描述了<code>TCPConnection</code>处于某个状态的时候，<code>TCPSender</code>和<code>TCPReceiver</code>应该处于什么状态，例如:当<code>TCPConnection</code>处于<code>LISTEN</code>状态的时候，TCPSender和TCPReceiver应该分别处于<code>CLOSED</code>和<code>LISTEN</code>状态,(TCPSender和TCPReceiver)的状态在lab2和lab3中有描述。</p><p><strong>TCPConnection.hh</strong><br></p><pre><code class="lang-C++">...//为实现TCPConnection而增添的代码    bool _active&#123;true&#125;;    bool _established&#123;false&#125;;    bool _rst&#123;false&#125;;    size_t _ms_since_last_segment_received&#123;0&#125;;    void send_segments();    void fill_queue(std::queue&lt;TCPSegment&gt; &amp;stream_queue);    void set_rst();    void test_end();....</code></pre><p><strong>TCPConnection.cc</strong><br></p><pre><code class="lang-C++">size_t TCPConnection::remaining_outbound_capacity() const &#123; return _sender.stream_in().remaining_capacity(); &#125;size_t TCPConnection::bytes_in_flight() const &#123; return _sender.bytes_in_flight(); &#125;size_t TCPConnection::unassembled_bytes() const &#123; return _receiver.unassembled_bytes(); &#125;size_t TCPConnection::time_since_last_segment_received() const &#123; return _ms_since_last_segment_received; &#125;void TCPConnection::set_rst() &#123;    _active = false;    _rst = true;    _linger_after_streams_finish = false;    _sender.stream_in().set_error();    _receiver.stream_out().set_error();    if (_established)        send_segments();&#125;void TCPConnection::test_end() &#123;    if (_receiver.stream_out().input_ended() &amp;&amp; !_sender.stream_in().eof() &amp;&amp; _sender.next_seqno_absolute() &gt; 0) &#123;        _linger_after_streams_finish = false;    &#125; else if (_receiver.stream_out().eof() &amp;&amp; _sender.stream_in().eof() &amp;&amp; unassembled_bytes() == 0 &amp;&amp;               bytes_in_flight() == 0 &amp;&amp; _sender.fin_sent()) &#123;        if (!_linger_after_streams_finish)            _active = false;        else if (_ms_since_last_segment_received &gt;= 10 * _cfg.rt_timeout)            _active = false;    &#125;&#125;void TCPConnection::fill_queue(std::queue&lt;TCPSegment&gt; &amp;stream_queue) &#123;    TCPSegment tmp = stream_queue.front();    stream_queue.pop();    if (_receiver.ackno().has_value()) &#123;        tmp.header().ack = true;        tmp.header().ackno = _receiver.ackno().value();    &#125;    tmp.header().rst = _rst;    size_t window_size = _receiver.window_size();    tmp.header().win = window_size &lt; std::numeric_limits&lt;uint16_t&gt;::max() ? static_cast&lt;uint16_t&gt;(window_size)                                                                          : std::numeric_limits&lt;uint16_t&gt;::max();    _segments_out.push(tmp);    return;&#125;void TCPConnection::send_segments() &#123;    std::queue&lt;TCPSegment&gt; &amp;stream_queue = _sender.segments_out();    if (stream_queue.empty()) &#123;        _sender.send_empty_segment();    &#125;    if (_rst) &#123;        fill_queue(stream_queue);        return;    &#125;    while (!stream_queue.empty()) &#123;        fill_queue(stream_queue);    &#125;&#125;void TCPConnection::segment_received(const TCPSegment &amp;seg) &#123;    if (!_active)        return;    _ms_since_last_segment_received = 0;    if (seg.header().rst) &#123;        set_rst();        return;    &#125;    _receiver.segment_received(seg);    bool right_ack = seg.header().ack ? _sender.ack_received(seg.header().ackno, seg.header().win) : false;    if (seg.header().syn &amp;&amp; !_established) &#123;        if (right_ack) &#123;            _established = true;        &#125; else &#123;            _sender.fill_window();        &#125;    &#125;        else if (!_established &amp;&amp; right_ack) &#123;            /*SYN-RECEIVE transition to ESTABLISHED*/            _established = true;        &#125;        //  reply if seg sequence length equal not to 0 or _sender have segments want to send;        if (seg.length_in_sequence_space() != 0 || !_sender.segments_out().empty())            send_segments();        test_end();    &#125;    bool TCPConnection::active() const &#123; return _active; &#125;    size_t TCPConnection::write(const string &amp;data) &#123;        size_t size = _sender.stream_in().write(data);        _sender.fill_window();        send_segments();        test_end();        return size;    &#125;//! \param[in] ms_since_last_tick number of milliseconds since the last call to this methodvoid TCPConnection::tick(const size_t ms_since_last_tick) &#123;    _ms_since_last_segment_received += ms_since_last_tick;    if (_sender.tick(ms_since_last_tick)) &#123;        if (_sender.consecutive_retransmissions() &gt; TCPConfig::MAX_RETX_ATTEMPTS) &#123;            set_rst();            return;        &#125;        send_segments();    &#125;    test_end();&#125;void TCPConnection::end_input_stream() &#123;    _sender.stream_in().end_input();    _sender.fill_window();    send_segments();    test_end();&#125;void TCPConnection::connect() &#123;    if (_sender.next_seqno_absolute() != 0)        return;    _sender.fill_window();    send_segments();    _active = true;&#125;TCPConnection::~TCPConnection() &#123;    try &#123;        if (active()) &#123;            cerr &lt;&lt; &quot;Warning: Unclean shutdown of TCPConnection\n&quot;;            // Your code here: need to send a RST segment to the peer            set_rst();        &#125;    &#125; catch (const exception &amp;e) &#123;        std::cerr &lt;&lt; &quot;Exception destructing TCP FSM: &quot; &lt;&lt; e.what() &lt;&lt; std::endl;    &#125;&#125;</code></pre><p><strong>结果:</strong><br><br><img src="result.png" alt="result"><br></p><h1 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h1><p>优化实际上就是减少内存的拷贝复制,这里涉及到<strong>右值引用</strong>和<strong>智能指针</strong>相关的知识,因为每个人实现的代码都不同，所以下面只是记录一下我对自己代码的优化。<br></p><p>主要的优化的地方就是<code>byte_stream.cc</code>这个文件，我将存储字符流容器的<code>std::deque&lt;char&gt;</code>改为使用CS144中给的<code>BufferList</code>,<strong>buffer.hh和buffer.cc这两个文件要好好读一读，这里使用了</strong>右值引用<strong>和</strong>智能指针<strong>,大大的减少了不需要的内存拷贝实在是妙！</strong>。<br></p><p>其次第二个优化的地方就是<strong>stream_reassembler.cc</strong>,我将插入<code>insert_pair()</code>函数中<code>window[index]=data</code>这段代码改为<code>window[index] = std::move(data)</code>。<br></p><p><strong>最后优化得到的成绩是</strong></p><pre><code class="lang-bash">CPU-limited throughput                : 2.85 Gbit/sCPU-limited throughput with reordering: 2.58 Gbit/s</code></pre>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab4</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS144-lab3</title>
    <link href="/2021/04/08/CS144-lab3/"/>
    <url>/2021/04/08/CS144-lab3/</url>
    
    <content type="html"><![CDATA[<h1 id="实现TCPSender"><a href="#实现TCPSender" class="headerlink" title="实现TCPSender"></a>实现TCPSender</h1><p>这个lab有几个难点,分别是:<br></p><ol><li><p>TCP中会维护好几种状态:</p><ul><li>CLOSE: SYN还没有被发送</li><li>SYN_SENT: SYN被发送了但是没有收到对应的ACK</li><li>SYN_ACKED: 正常状态，可以利用sender来通信了</li><li>SYN_ACKED_ASLO: sender已经发送完所以的字节流了，但是还没有发生FIN。</li><li>FIN_SENT: FIN已经被发送，但是还没有收到对应的ACK</li><li>FIN_ACKED: sender已经完成所以的任务。</li></ul></li><li><p>TCPSender使用的是<code>累计确认</code>的协议，也就是说如果收到<code>合法的ACK</code>,那么ACK之前的所有已经发送segments已经被成功接受。(如果收到的ACK大于我还未发送的Sequence Number那就是非法的ACK)</p></li><li><p>timer的开启，重启，关闭的时机。<br><br>在做这个是lab之前我一直以为是给每一个发出的segments安装一个timer，当segments超时的时候重发，但是看了<code>huangrt01</code>大佬的代码后，发现在这个lab中timer,timer记录的是在RTO时间内有没有收到<code>合法的ACK</code>,如果没有收到<code>合法的ACK</code>，那么就需要重传。<br><br><strong>下面简单的概括一下timer使用的时机:</strong><br></p><ul><li>当发送一个新的segment的时候，如果timer没有开启，那么需要开启timer。</li><li>当在RTO内收到一个<code>合法的ACK</code>,有两种情况: <ol><li>如果sender没发完segments那么需要<code>重启timer</code>,重启的意思是timer从0开始计时。</li><li>如果sender已经发完所有的segments了那么需要<code>关闭timer</code></li></ol></li><li>当超时的情况发生,也是两种情况:<br><ol><li>window_size = 0 : <code>重启timer</code>,<code>重传segments</code>。</li><li>window_size != 0 : <code>double RTO</code>, <code>重启timer</code>,<code>重传segments</code>。</li></ol></li></ul></li></ol><p><strong>timer实现更加规范看<a href="https://datatracker.ietf.org/doc/rfc6298/?include_text=1">RFC 6298</a>第五小节</strong></p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><p><strong>tcp_sender.hh</strong><br></p><pre><code class="lang-c++">//! \make by myselfclass TCPTimer &#123;  private:    //! true : timer start , false : timer not start    bool _start;    unsigned int init_time;    //! Transmission time    unsigned int transmission_time;    //! retransmission timeout    unsigned int RTO;  public:    //! Number of consecutive retransmissions    unsigned int num_of_retransmission;    TCPTimer(unsigned int time)        : _start(false)        , init_time(time)        , transmission_time(0)        , RTO(init_time)        , num_of_retransmission(0) &#123;&#125;    bool running() &#123; return _start; &#125;    void close() &#123;        _start = false;        num_of_retransmission = 0;    &#125;    void start() &#123;        _start = true;        RTO = init_time;        transmission_time = 0;        num_of_retransmission = 0;    &#125;//! if window == 0 then keep RTO , otherwise double RTO    void doubleOrkeep_RTO_and_restart(const size_t window) &#123;        if (!running())            return;        if (window != 0)            RTO *= 2;        transmission_time = 0;        num_of_retransmission++;    &#125;    bool timeout(const size_t ms_since_last_tick) &#123;        if (!running())            return false;        if (ms_since_last_tick + transmission_time &gt;= RTO)            return true;        transmission_time += ms_since_last_tick;        return false;    &#125;&#125;;class TCPSender &#123;  private:   .............    //! make by myself    uint64_t _ackno;    size_t _window_size;    uint64_t _bytes_in_flight;    TCPTimer timer;    std::queue&lt;TCPSegment&gt; _segments_track&#123;&#125;;    void send_no_empty_segments(TCPSegment &amp;seg);    .............&#125;</code></pre><p><strong>tcp_sender.cc</strong><br></p><pre><code class="lang-C++">#include &quot;tcp_sender.hh&quot;#include &quot;tcp_config.hh&quot;#include &lt;random&gt;template &lt;typename... Targs&gt;void DUMMY_CODE(Targs &amp;&amp;... /* unused */) &#123;&#125;using namespace std;TCPSender::TCPSender(const size_t capacity, const uint16_t retx_timeout            ,const std::optional&lt;WrappingInt32&gt; fixed_isn)    : _isn(fixed_isn.value_or(WrappingInt32&#123;random_device()()&#125;))    , _initial_retransmission_timeout&#123;retx_timeout&#125;    , _stream(capacity)    , _ackno(0)    , _window_size(1)    , _bytes_in_flight(0)    , timer(retx_timeout) &#123;&#125;uint64_t TCPSender::bytes_in_flight() const &#123; return _bytes_in_flight; &#125;void TCPSender::send_no_empty_segments(TCPSegment &amp;seg) &#123;    seg.header().seqno = wrap(_next_seqno, _isn);    _next_seqno += seg.length_in_sequence_space();    _bytes_in_flight += seg.length_in_sequence_space();    _segments_out.push(seg);    _segments_track.push(seg);    if (!timer.running()) &#123;        timer.start();    &#125;&#125;void TCPSender::fill_window() &#123;    /*Status: CLOSED -&gt; stream waiting to begin*/    if (_next_seqno == 0) &#123;        TCPSegment seg;        seg.header().syn = true;        seg.header().seqno = next_seqno();        send_no_empty_segments(seg);    &#125;    /*Status: SYN_SENT -&gt; stream start but nothing acknowledged*/    else if (_next_seqno == _bytes_in_flight) &#123;        return;    &#125;    size_t window_size = _window_size == 0 ? 1 : _window_size;    size_t remain = 0;//! 这里window_size 一定是大于 (_next_seqno - _ackno),不用担心溢出问题。文章后面解释    while ((remain = window_size - (_next_seqno - _ackno))) &#123;        TCPSegment seg;size_t len = TCPConfig::MAX_PAYLOAD_SIZE &gt; remain ? remain : TCPConfig::MAX_PAYLOAD_SIZE;        /*Status: SYN_ACKED -&gt; stream ongoing*/        if (!_stream.eof()) &#123;            seg.payload() = Buffer(_stream.read(len));            if (_stream.eof() &amp;&amp; remain - seg.length_in_sequence_space() &gt; 0)                seg.header().fin = true;            if (seg.length_in_sequence_space() == 0)                return;            send_no_empty_segments(seg);        &#125;/*Status: SYN_ACKED -&gt; stream ongoing (stream has reached EOF but FIN hasn&#39;t been send yet)*/        else if (_stream.eof()) &#123;            if (_next_seqno &lt; _stream.bytes_written() + 2) &#123;                seg.header().fin = true;                send_no_empty_segments(seg);            &#125;         /*Status: FIN_SENT and FIN_ACKED both do nothing Just return */            else                return;        &#125;    &#125;&#125;void TCPSender::ack_received(const WrappingInt32 ackno, const uint16_t window_size) &#123;    uint64_t abs_ackno = unwrap(ackno, _isn, _ackno);    //! 超出范围 _next_seqno还没发呢，哪来的abs_ackno &gt; _next_seqno    if (abs_ackno &gt; _next_seqno) &#123;        return;    &#125;    _window_size = static_cast&lt;size_t&gt;(window_size);    //! 比abs_ackno大的先来了    if (abs_ackno &lt;= _ackno) &#123;        return;    &#125;    _ackno = abs_ackno;    //! 成功接受到新的ackno    timer.start();    while (!_segments_track.empty()) &#123;        TCPSegment seg = _segments_track.front();        if (ackno.raw_value() &lt; seg.header().seqno.raw_value()         + static_cast&lt;uint32_t&gt;(seg.length_in_sequence_space()))            break;        _bytes_in_flight -= seg.length_in_sequence_space();        _segments_track.pop();    &#125;    fill_window();    if (_segments_track.empty()) &#123;        timer.close();    &#125;&#125;void TCPSender::tick(const size_t ms_since_last_tick) &#123;    if (!timer.running() || !timer.timeout(ms_since_last_tick))        return;    if (_segments_track.empty()) &#123;        timer.close();        return;    &#125;    timer.doubleOrkeep_RTO_and_restart(_window_size);    _segments_out.push(_segments_track.front());&#125;unsigned int TCPSender::consecutive_retransmissions() const &#123;     return timer.num_of_retransmission; &#125;void TCPSender::send_empty_segment() &#123;    TCPSegment seg;    seg.header().seqno = wrap(_next_seqno, _isn);    _segments_out.push(seg);&#125;</code></pre><p><strong>解释remain = window_size - (_next_seqno - _ackno))不会溢出</strong><br><br>要解释这里就要联系一下lab2中实现的TCPReceiver<br><br>这里的window_size指的是receiver中buffer剩余的空间,当receiver往buffer中放入字节流的时候window_size变小，当上层应用读取buffer中的字节流的时候，window_size变大。<br><br><strong>注意:</strong><br>不是sender发送segment给receiver,receiver就立刻将segement放入buffer中了,而是当segments连续了才会被放入buffer中<br></p><p>这里我假设上次发送时的窗口大小为window_size_pre,同时上次 <strong>发送的首个segments就没有被receiver接收到</strong> ,而其他的都被接收到了, <strong>这个时候receiver不会把这批segments放入buffer中</strong> ，所以发回来的ACK中装的window_size是等于window_size_pre的，所以window_size 不会大于(_next_seqno - _ackno);</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab3</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS144-lab2</title>
    <link href="/2021/04/04/CS144-lab2/"/>
    <url>/2021/04/04/CS144-lab2/</url>
    
    <content type="html"><![CDATA[<h1 id="实现wrapping-integers-cc"><a href="#实现wrapping-integers-cc" class="headerlink" title="实现wrapping_integers.cc"></a>实现wrapping_integers.cc</h1><p><strong>1.wrapping_integers.cc这个文件是干什么的呢？</strong><br><br>wrapping_integers.cc主要做两件事情，一是将64位表示的数包装成32位表示的数。二是将32位的数解包装还原为64位的数。至于为什么要这么做我们下面解释。<br></p><p><strong>2.为什么要将64位数转化成32位数，32位数还原为64位数呢?</strong><br><br>因为TCP的<code>Sequence Number</code>和<code>Acknowledgement Number</code>是32位的,最多最多也就只能表示4G大小数据的传输,如果将32位其转化为64位后，就可以表示2^64-1这么大的空间(目前看说几乎是无限大),<br><br><em>那么怎么转化呢?</em><br><br>我们用<code>Initial Sequence Number = 0</code>,来举例,我们称呼转化后的64位的数字为<code>Absolute Sequence Number</code> 。<br><br>当TCP传输的数据小于4G的时候(这里假设<code>Initial Sequence Number = 0</code>),TCP的<code>Sequence Number</code> 与 <code>Absolute Sequence Number</code>相同,当TCP传输的数据大于4G后，TCP中的<code>Sequence Number</code>又从<code>0</code>开始计算，而<code>Absolute Sequence Number</code>则等于<code>Absolute Sequence Number + Sequence Number</code>。<br><br>正是应为如此我们就不知道<code>TCP</code>传入的<code>Sequence Number</code>，表示的<code>Absolute Sequence Number</code>是多少。<br><br>举个例子:传入的<code>Sequence Number</code>是10,可能表示的<code>Absolute Sequence Number</code> 是<code>&#123;10,2^32+10,2^33+10.....&#125;</code>,所以我们需要实现wrapping_integers.cc中的函数，将<code>Sequence Number</code>还原成正确的<code>Absoulte Sequence Number</code>。<br><br>同理: 我们要发送<code>ACK</code>回去给<code>Peer</code>,所以我们也要将<code>Absolute Sequence Number</code>转换成正确的32位数发送回去给<code>Peer</code>。<br></p><pre><code class="lang-C++">WrappingInt32 wrap(uint64_t n, WrappingInt32 isn) &#123;    uint32_t n32 = n &amp; UINT32_MAX;    return WrappingInt32&#123;n32 + isn.raw_value()&#125;;&#125;/*这段是受到清华大佬(huangrt01)博客的启发*/uint64_t unwrap(WrappingInt32 n, WrappingInt32 isn, uint64_t checkpoint) &#123;    uint32_t offset = n.raw_value() - wrap(checkpoint, isn).raw_value();    uint64_t result = checkpoint + offset;    /*如果新位置距离checkpoint的偏移offset大于1&lt;&lt;32的一半也就是1&lt;&lt;31,    那么离checkpoint最近的应该是checkpoint前面的元素    举个例子: 1---------7(checkpoint)----------------1&lt;&lt;32+1;    由于是无符号数相减所以1-7 == 1&lt;&lt;32+1 - 7;    所以应该是1距离7最近所以应该选1     */    if (offset &gt; (1u &lt;&lt; 31) &amp;&amp; result &gt;= (1ul &lt;&lt; 32))        result -= (1ul &lt;&lt; 32);    return result;&#125;</code></pre><h1 id="实现tcp-receiver-cc"><a href="#实现tcp-receiver-cc" class="headerlink" title="实现tcp_receiver.cc"></a>实现tcp_receiver.cc</h1><p><code>tcp_receiver</code>的工作就非常简单了，大概有三个部分:<br></p><ol><li>将接受到的<code>tcp_segment</code>塞进lab1实现的<code>StreamReassembler</code>中重组字节流，</li><li>维护一个<code>Acknowledgement Number</code></li><li>维护一个<code>Window Size</code> <code>Window size  = first unacceptable - first unassembled</code> ;</li></ol><p>这一部分比较困难的点在于更新<code>Acknowledgement Number</code>，因为传入的<code>tcp_segment</code>可能是乱序的，更新<code>Acknowledgement Number</code>,就需要知道<code>StreamReassembler</code>中一次排序了多少个字节，而且<code>SYN</code>和<code>FIN</code>分别算一个字节,同样要更新<code>Acknowledgement Number</code>。<br></p><p>直接上代码<br></p><p>在tcp_receiver.hh中我的修改如下<br></p><pre><code class="lang-C++">class TCPReceiver &#123;    size_t _capacity;    std::optional&lt;WrappingInt32&gt; init_seq_peer;    std::optional&lt;WrappingInt32&gt; ack_no;    bool syn;    bool fin;    ......&#125;</code></pre><p>tcp_receiver.cc中<br></p><pre><code class="lang-C++">#include &quot;tcp_receiver.hh&quot;#include &lt;cstdlib&gt;using namespace std;void TCPReceiver::segment_received(const TCPSegment &amp;seg) &#123;    /*只接受第一次的syn所以要满足!init_seq_peer.has_value()*/    if (seg.header().syn &amp;&amp; !init_seq_peer.has_value())        init_seq_peer = seg.header().seqno;    if (init_seq_peer.has_value()) &#123;    /*size_t expected_index = _reassembler.expected_bytes_index();     *size_t abs_seq = unwrap(seg.header().seqno,init_seq_peer.value(),expected_index);     *_reassembler.push_substring(seg.payload().copy(),abs_seq,seg.header().fin);     */    //上面三句可以合并成这一句       _reassembler.push_substring(           seg.payload().copy(),           unwrap(seg.header().seqno, init_seq_peer.value(), _reassembler.expected_bytes_index()),           seg.header().fin);        ack_no = wrap(_reassembler.expected_bytes_index(), init_seq_peer.value());    &#125;    fin = fin ? fin : seg.header().fin;    /*这个判断只会进入一次,(!syn)保证了这个判断只会执行一次*/    if (!syn &amp;&amp; seg.header().syn &amp;&amp; ack_no.has_value()) &#123;    /*这里的代码的主要目的是将Init Sequence Number设置为带Payload的第一个Sequence Number*/        ack_no = WrappingInt32(ack_no.value().raw_value() + 1);        init_seq_peer = ack_no;        syn = true;    &#125;    /*只有建立了连接(即init_seq_peer.has_value()为true),    同时fin来过(即fin==true)，    而且字符流重组完成(即_reassembler.stream_out().input_ended()返回true)才能为ack_no+1*/    if (init_seq_peer.has_value() &amp;&amp; fin &amp;&amp; _reassembler.stream_out().input_ended()) &#123;        ack_no = WrappingInt32(ack_no.value().raw_value() + 1);    &#125;    return;&#125;optional&lt;WrappingInt32&gt; TCPReceiver::ackno() const &#123; return ack_no; &#125;size_t TCPReceiver::window_size() const &#123; return this-&gt;stream_out().remaining_capacity(); &#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab2</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS144-lab1</title>
    <link href="/2021/03/30/CS144-lab1/"/>
    <url>/2021/03/30/CS144-lab1/</url>
    
    <content type="html"><![CDATA[<h1 id="实现-stream-reassembly"><a href="#实现-stream-reassembly" class="headerlink" title="实现 stream reassembly"></a>实现 stream reassembly</h1><ol><li><p>什么是 stream reassembly ？<br>stream reassembly 是一个字符流重组器 , 主要的功能是将传入的没一份打乱的字符流重新组合形成原来的有序的字符流。<br></p></li><li><p>实现 stream reassembly<br>stream reassembly 被包装成一个类，也就是lab1要实现的<code>StreamReassembler</code>类 。</p></li></ol><p>为了实现这个类的功能，我在类中添加了一下的一些变量和函数。</p><pre><code class="lang-C++">class StreamReassembler &#123;  private:     size_t expected_index;        bool _eof_appear_sign;            size_t _eof_index ;        std::map&lt;size_t,std::string&gt; window;    void write_substring();    void insert_pair(const std::string &amp;data,const size_t index)    ............    &#125;</code></pre><ul><li><strong>expected_index</strong><ul><li>表示小于expected_index前面的Bytes全部已经有序,期待的下一个Bytes的index等于expected_index</li></ul></li><li><strong>_eof_appear_sign</strong><ul><li><code>_eof_apper_sign == true</code> 表示eof标志已经出现，因为字符流进来是乱序的,最后的一个字符流可能比前面的字符流先进入StreamReassembler,所以当eof传入的时候我们要记录下eof已经出现</li></ul></li><li><strong>_eof_index</strong><ul><li>_eof_index 用来记录出现eof的字符流的最后一个bytes的index , 当<code>_eof_apper_sign == true &amp;&amp; expected_index &gt;= _eof_index</code>的时候，设置字符流已经完成重组。</li></ul></li><li><strong>std::map<size_t,std::string> window</strong><ul><li><code>window[index] = string</code> , 用map来存储传进来的字符流 , 其中index表示传入字符流的第一个bytes的index, string表示传入字符流中存储的字符。</li></ul></li><li><strong>write_substring() &amp;&amp; insert_pair(const std::string &amp;data,const size_t index)</strong><ul><li>insert_pair 用来插入{index,string}映射对到window中， write_substring()用来重新排列window存储的乱序的字符流。</li></ul></li></ul><h2 id="实现-push-substring-data-index-eof"><a href="#实现-push-substring-data-index-eof" class="headerlink" title="实现 push_substring(data,index,eof);"></a>实现 push_substring(data,index,eof);</h2><p>直接上代码:<br></p><pre><code class="lang-C++">void StreamReassembler::push_substring(const string &amp;data, const size_t index, const bool eof) &#123;    if(eof)&#123;    /*如果遇到eof，更新_eof_appear_sign和_eof_index*/        _eof_appear_sign = true;        _eof_index = index + data.length();    &#125;/*如果传入的字符流第一个Byte的index小于等于expected_index同时最后一个Byte的index大于等于expected_index,表示期待的字符流来了这个时候要进行字符流的重排操作, 如下图一所示;*/    if(index&lt;=expected_index &amp;&amp; data.length()+index&gt;=expected_index)&#123;        insert_pair(data,index);    //先将最新的字符流插入到window中        write_substring();            //重排    &#125;/*如果传入的字符流第一个Byte的index大于expected_index,这个时候不着急重排，先将其插入window中，等待重排,如下图二所示; */    else if(index&gt;expected_index)&#123;        insert_pair(data,index);    &#125;&#125;void StreamReassembler::insert_pair(const string &amp;data,const size_t index)&#123;    size_t data_len = data.length();    if(window[index].length()&lt;data_len)&#123;            window[index] = data;        &#125;&#125;void StreamReassembler::write_substring()&#123;    auto it = window.begin();    for(;it!=window.end();it++)&#123;        size_t data_len = it-&gt;second.length();        if(it-&gt;first&lt;=expected_index)&#123;            if((data_len+it-&gt;first)&lt;=expected_index)&#123;                continue;            &#125;            size_t writed_len = it-&gt;first + data_len - expected_index;            /*这里_output.wirte()是lab0实现的函数,函数返回成功写入字符的数量*/            expected_index += _output.write(it-&gt;second.substr(expected_index-it-&gt;first,writed_len));        &#125;        else break;    &#125;    /*删除已经处理过的字符流*/    window.erase(window.begin(),it);    /*如果已经处理好最后一个流了就设置eof*/    if(_eof_appear_sign &amp;&amp; _eof_index &lt;= expected_index)&#123;        _output.end_input();    &#125;&#125;</code></pre><p><em>图1:</em><br><img src="lab1_1.png" alt="lab1_1"></p><p><em>图2:</em><br><img src="lab1_2.png" alt="lab1_2"></p><p>unassembled_bytes()和empty()的实现比较简单。</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab1</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS144-lab0</title>
    <link href="/2021/03/27/CS144-lab0/"/>
    <url>/2021/03/27/CS144-lab0/</url>
    
    <content type="html"><![CDATA[<h1 id="实现webget-cc"><a href="#实现webget-cc" class="headerlink" title="实现webget.cc"></a>实现webget.cc</h1><p>实现webget.cc实际上就是补充<code>get_URL()</code>函数。<br><br><strong>这里比较值得注意的是通过套接字与采用http协议的服务器沟通的语法是这样的:</strong><br></p><pre><code class="lang-http">GET /hello HTTP/1.1        //注意这里换行符号为\r\nHost: cs144.keithw.orgConnection:  close</code></pre><p>在程序上表现为:<br><br><code>&quot;GET &quot; + path + &quot; &quot; + &quot;HTTP/1.1\r\nHost: &quot; + host + &quot;\r\nConnection: close\r\n\r\n&quot;</code><br></p><pre><code class="lang-C++">void get_URL(const string &amp;host, const string &amp;path) &#123;    TCPSocket sock1;    Address addr = Address(host, &quot;http&quot;);    sock1.connect(addr);    sock1.write(&quot;GET &quot; + path + &quot; &quot; + &quot;HTTP/1.1\r\nHost: &quot; + host + &quot;\r\nConnection: close\r\n\r\n&quot;);    while (1) &#123;        auto recv = sock1.read(RECV_SIZE);        cout &lt;&lt; recv;        if (sock1.eof())            break;    &#125;    sock1.close();&#125;</code></pre><h1 id="实现byte-stream-hh"><a href="#实现byte-stream-hh" class="headerlink" title="实现byte_stream.hh"></a>实现byte_stream.hh</h1><p>实现byte_stream.hh即是实现byteStream这个类内部的一些函数，达到实现内存中可靠字节流的任务。<br></p><p>什么叫做内存中可靠字节流 \<An in-memory reliable byte stream\>呢?<br></p><p>其实就是将数据流写入一个buffer中然后再读出来，由于是单线程操作，所以这个实现也比较简单。</p><p>使用数据结构<code>std::deque</code>即完成。<br></p><h2 id="坑点1"><a href="#坑点1" class="headerlink" title="坑点1"></a>坑点1</h2><p>实现文件<code>EOF</code>的时候，并不是文件读完就设置<code>EOF</code>为<code>true</code>。<br></p><p>那什么时候设置<code>EOF</code>为<code>True</code>呢?<br></p><p>答案是: 当程序调用<code>end_input()</code>的时候，这个时候程序表示输入已经完成,在这个之后的读出<code>buffer_size==0</code>的时候才可以将<code>EOF</code>设置为<code>true</code>。</p><h2 id="坑点2"><a href="#坑点2" class="headerlink" title="坑点2"></a>坑点2</h2><p>一开始我并没有使用<code>std::deque</code>，而是用一个<code>char* Stream</code>在构造函数中使用<code>new</code>得到空间，存储数据,但是给出的byteStream类中没有析构函数，所以为了不将byteStream类改变太大，我决定使用<code>std:;deque</code>。</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>CS144</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS144</tag>
      
      <tag>lab0</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The rule of Three/Five</title>
    <link href="/2021/02/21/The-rule-of-Three-Five/"/>
    <url>/2021/02/21/The-rule-of-Three-Five/</url>
    
    <content type="html"><![CDATA[<p><strong>引用</strong>:</p><ul><li><a href="https://en.wikipedia.org/wiki/Rule_of_three_(C%2B%2B_programming">Rule of three (C++ programming)</a>)</li><li><a href="https://www.feabhas.com/sites/default/files/2016-06/Rule%20of%20the%20Big%20Five.pdf">C++11: The Rule of the Big Five</a></li></ul><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The Rule of Three/Five （三法则/五法则）是为了编写异常安全代码(<a href="https://en.wikipedia.org/wiki/Exception_safety">Exception-safe code</a>)和为了资源管理而提出的经验法则。<br></p><h1 id="The-Rule-of-Three"><a href="#The-Rule-of-Three" class="headerlink" title="The Rule of Three"></a>The Rule of Three</h1><p>首先介绍编译器会自动生成的三个特殊的成员函数(<a href="https://en.wikipedia.org/wiki/Special_member_functions">Special member funtions</a>)<br></p><ul><li><strong>Desturctor (析构函数)</strong></li><li><strong>Copy Constructor (拷贝构造函数)</strong></li><li><strong>Copy assignment operator (拷贝赋值运算符)</strong></li></ul><p>三法则规定:如果类中定义了以下三个特殊的成员函数的其中一个，则这个应该显式的定义所有的三个特殊的成员函数。<br><br>因为默认生成的三个函数通常不能满足我们的使用要求。<br></p><p>默认生成的<code>Copy Constructor</code>和<code>Copy assignment operator</code>执行的是浅拷贝(<a href="https://en.wikipedia.org/wiki/Object_copying#Shallow_copy">Shallow Copy</a>)。而我们的类中如果存在指针这类的成员变量,使用默认生成的这两个函数，可能会引起内存泄漏及一系列无法定义的行为。<br></p><p>下面分别介绍这三个特殊的成员函数。<br></p><h2 id="The-Desturctor"><a href="#The-Desturctor" class="headerlink" title="The Desturctor"></a>The Desturctor</h2><p>当类结束它的生命周期的时候，类会自动调用析构函数去销毁这个类。<br><br><img src="png1.png" alt="String class"><br><br>如上图，当<code>String</code>类运行到<code>main</code>块的末尾的时候结束其生命周期，这个时候类会自动调用析构函数去销毁这个类。<br></p><p><strong>输出如下:</strong><br></p><pre><code class="lang-c++">Done!</code></pre><h2 id="The-assignment-operator"><a href="#The-assignment-operator" class="headerlink" title="The assignment operator"></a>The assignment operator</h2><p><img src="png2.png" alt="defalut assignment"><br><br>使用默认的拷贝赋值符得到的效果就如上图，问题有二个:<br></p><ul><li>1 . 当执行<code>tmp = s</code>的时候原<code>tmp</code>指向的那块内存，就永远不会被<code>delete[]</code>，这造成了内存泄漏。</li><li>2 . 当<code>func()</code>执行结束的时候对象<code>tmp</code>的生命周期结束，将会调用<code>String</code>类的析构函数去销毁其申请的资源，这样就把指向<code>LiQiBin</code>处的内存<code>delete[]</code>了，当<code>main</code>函数执行完后,对象<code>a</code>也要销毁其持有的资源，这样就会<code>delete</code>已经<code>delete</code>过的资源，系统报错！</li></ul><p>怎么解决这个问题呢? 答案是：使用自己定义的可执行<strong>深拷贝</strong>的<code>copy assignment operator</code>。<br></p><p><strong>修改代码如下:</strong></p><pre><code class="lang-c++">/*修改String类即可*/class String&#123;    char* data;public:    String(const char* p) &#123;        size_t size = std::strlen(p) + 1;        data = new char[size];        std::memcpy(data, p, size);    &#125;   ~String() &#123;     printf(&quot;Done!\n&quot;);        delete[] data;    &#125;    String&amp; operator=(const String&amp; that) &#123;        size_t size = std::strlen(that.data) + 1;    delete[] data;        data = new char[size];        std::memcpy(data, that.data, size);    return *this;    &#125;&#125;;</code></pre><p>修改代码后执行的结果如下图:<br><br><img src="png3.png" alt="user-defined assignment"><br></p><h2 id="The-copy-constructor"><a href="#The-copy-constructor" class="headerlink" title="The copy constructor"></a>The copy constructor</h2><p><code>copy constructor</code>做的事情其实和<code>copy assignment</code>非常类似，都是复制传入的参数类。默认生成的<code>copy constructor</code>也是做<code>shallow copy</code>，类似的默认的情况一般不满足我们的要求，所以我们一般要自己定义深拷贝的版本。<br><br><strong>添加copy constructor代码:</strong><br><br><img src="png4.png" alt="copy constructor"><br></p><p><strong>与<code>copy assignment</code>用户显式的调用不同<code>copy constructor</code>有时会被编译器隐式的调用,我们必须了解什么时候<code>copy constructor</code>会被调用。</strong></p><p>下面的四种情况<code>copy constructor</code>会被调用:<br></p><ul><li><strong>1.显式调用copy constructor</strong><pre><code class="lang-c++">  int main()&#123;      String a(&quot;LiQiBin&quot;);      String b(a);    /*显式调用copy constructor*/      return 0;  &#125;</code></pre></li><li><strong>2.对象初始化的时候调用copy constructor</strong><pre><code class="lang-c++">  int main()&#123;      String a(&quot;LiQiBin&quot;);      String b = a;    /*对象初始化的时候调用copy constructor*/      return 0;  &#125;</code></pre>  <strong>注意这种情况与调用copy assignment的区分</strong><br><pre><code class="lang-c++">  int main()&#123;      String a(&quot;LiQiBin&quot;);      String b(&quot;tmp&quot;);      b = a;    /*调用copy assignment*/      return 0;  &#125;</code></pre></li><li><strong>3.传入参数时调用copy constructor</strong><pre><code class="lang-c++">  void func(String s)&#123;      /*Do something!*/  &#125;  int main()&#123;      String a(&quot;LiQiBin&quot;);      func(a);    /*传入参数时会调用一次copy constructor生成传参*/      return 0;  &#125;</code></pre></li><li><p><strong>4.作为函数的返回值</strong><br></p><p>  <strong>这段来自维基百科:<a href="https://en.wikipedia.org/wiki/Copy_elision#Return_value_optimization">Return value Optimization</a><Br></strong></p><pre><code class="lang-c++">  #include &lt;iostream&gt;  struct C &#123;    C() = default;    C(const C&amp;) &#123; std::cout &lt;&lt; &quot;A copy was made.\n&quot;; &#125;  &#125;;  C f() &#123;    return C();    /*这里是作为函数的返回值调用copy constructor*/  &#125;  int main() &#123;    std::cout &lt;&lt; &quot;Hello World!\n&quot;;    C obj = f();    /*这里是第二点的情况调用copy constructor*/  &#125;</code></pre><p>  但是在不同的编译器有不同的优化,所以得到的结果可能是下面三种情况:<br></p><pre><code class="lang-c++">   Hello World!   A copy was made.   A copy was made.</code></pre><pre><code class="lang-c++">   Hello World!   A copy was made.</code></pre><pre><code class="lang-c++">   Hello World!    /*本人电脑是这种情况*/</code></pre></li></ul><h1 id="The-Rule-of-Five"><a href="#The-Rule-of-Five" class="headerlink" title="The Rule of Five"></a>The Rule of Five</h1><p>五法制:其实也就是比三法制增加了两个特殊成员函数。<br></p><ul><li><strong>The move constructor</strong></li><li><strong>The move assignment</strong></li></ul><h2 id="The-move-constructor"><a href="#The-move-constructor" class="headerlink" title="The move constructor"></a>The move constructor</h2><p>实际上<code>copy constructor</code>并不能完全覆盖程序员的需求，例如:频繁的创造,复制，删除临时变量是非常的昂贵的，所以就有了<code>move constructor</code><br><br><strong>关于<code>move constructor</code>需要理解左值(lvalue)和右值(rvalue),可以看我以前的一篇博客<a href="https://lexssama.github.io/2021/02/18/lvalue-and-rvalue/">lvalue and rvalue</a>,<code>move constructor</code>在这篇博客的<code>move semantics</code>部分中做了介绍。<br></strong></p><h2 id="The-move-assignment"><a href="#The-move-assignment" class="headerlink" title="The move assignment"></a>The move assignment</h2><p><code>move assignment</code>的作用和<code>move constructor</code>差不多,<code>move assignment</code>通常用来转移资源的管理权。<br></p><p><strong>Example:</strong><br><br>在String类中添加<code>move assignment</code>:</p><pre><code class="lang-c++">String&amp; operator=(String&amp;&amp; that)&#123;    printf(&quot;move assignment!\n&quot;);    if(this!=&amp;that)&#123;        delete[] data;        data = that.data;        that.data = nullptr;    &#125;    return *this;&#125;</code></pre><p>调用<code>move assignment</code>:</p><pre><code class="lang-c++">int main()&#123;    String a(&quot;10&quot;);    String b(&quot;20&quot;);    b = a;    /*调用copy assignment*/    b = (String&amp;&amp;) a;    /*强制转换为右值引用后调用move assignment*/    /*String(&quot;Hello UnderWorld&quot;)是右值引用,调用move assignment*/    b = String(&quot;Hello UnderWorld&quot;);        return 0;&#125;</code></pre><p><strong>注意上面执行了<code>b = (String&amp;&amp;) a;</code>就相当于a将资源的管理权转移给了b,所以a在这之后不可用了。<br></strong></p>]]></content>
    
    
    <categories>
      
      <category>C/C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lvalue and rvalue</title>
    <link href="/2021/02/18/lvalue-and-rvalue/"/>
    <url>/2021/02/18/lvalue-and-rvalue/</url>
    
    <content type="html"><![CDATA[<p>如果有小伙伴看到我的文章的话，建议优先去看下面的这些文章,因为我写的质量不及下面文章的十分之一(哭脸)<br></p><ul><li><a href="https://devblogs.microsoft.com/cppblog/rvalue-references-c0x-features-in-vc10-part-2/">Rvalue References: C++0x Features in VC10, Part 2</a><br></li><li><a href="https://stackoverflow.com/questions/3106110/what-is-move-semantics">What is move semantics?</a><br></li><li><a href="https://stackoverflow.com/questions/3279543/what-is-the-copy-and-swap-idiom">What is the copy-and-swap idiom?</a></li><li><a href="https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/">lvalue VS rvalue, rvalue Reference, and Move Semantics in C++</a></li><li><a href="https://zhuanlan.zhihu.com/p/55229582">C++笔记 · 右值引用，移动语义，移动构造函数和移动赋值运算符</a></li></ul><p>还有这些视频:<br></p><ul><li><a href="https://www.youtube.com/watch?v=ehMg6zvXuMY">Move Semantics in C++</a></li><li><a href="https://www.youtube.com/watch?v=UTUdhjzws5g&amp;t=354s">Advanced C++: Understanding rvalue and lvalue</a></li></ul><h1 id="lvalue-and-rvalue"><a href="#lvalue-and-rvalue" class="headerlink" title="lvalue and rvalue"></a>lvalue and rvalue</h1><p><strong>在C++中，每一个表达式都是由lvalue和rvalue组成.</strong><br></p><p><strong>Example</strong></p><pre><code class="lang-C++">int i = 0;    /*i为lvalue,0为rvalue*/int a = i+1;        /*a为lvalue,i+1是rvalue*/1        /*1为rvalue*/</code></pre><p><em>lvalue和rvalue具体的定义是什么?</em><br></p><p>实际上lvalue和rvalue很难给出一个具体的定义，但是我们可以给出<strong>简单的,概括的,应对大部分情况的说明。</strong><br></p><ul><li><strong>lvalue :</strong> 一个对象在内存中占据了可识别位置的，有地址的，持久的(脱离了单个表达式语句还依然存在的).<ul><li>例如: 上面提到的<code>int a = i+1</code>,程序运行到了下一条语句<code>a</code>依然存在内存中为，<code>&amp;a</code>是合法的，lvalue，<code>i+1</code>则不存在内存中，不是持久的，<code>&amp;(i+1)</code>是不合法的，所以为rvalue。</li></ul></li><li><strong>rvalue :</strong> 表达式中任何不是lvalue的对象就是rvalue.</li></ul><p><strong>下面解释出自Lei Mao的博客<a href="https://leimao.github.io/blog/CPP-lvalue-rvalue-Reference/">lvalue VS rvalue, rvalue Reference, and Move Semantics in C++</a>:</strong><br><br><code>lvalue expression is associated with a specific piece of memory, the lifetime of the associated memory is the lifetime of lvalue expression, and we could get the memory address of it. rvalue expression might or might not take memory. Even if an rvalue expression takes memory, the memory taken would be temporary and the program would not usually allow us to get the memory address of it.</code></p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p>一个变量的引用可以理解为一个变量的别名,我们可以通过这个别名来实际操作这个变量。<br></p><h2 id="lvalue-Reference-左值引用"><a href="#lvalue-Reference-左值引用" class="headerlink" title="lvalue Reference (左值引用)"></a>lvalue Reference (左值引用)</h2><p>T&amp; 表示lvalue Reference , lvalue Reference能绑定lvalue和rvalue(例外)。<br></p><p><strong>Example</strong><br></p><pre><code class="lang-C++">int i = 1;    int&amp; a = i;        /*a为变量i的lvalue Reference*/int&amp; b = (a+1)        /*Error! , (a+1)为rvalue*/a = 2;            /*a==2 ; i==2*/i = 3;            /*a==3;i==3*/int const&amp; c = 20;    /*例外:这样可以做到将一个rvalue绑定到一个lvalue reference上*/</code></pre><h2 id="rvalue-Reference-右值引用"><a href="#rvalue-Reference-右值引用" class="headerlink" title="rvalue Reference (右值引用)"></a>rvalue Reference (右值引用)</h2><p>T&amp;&amp; 用来表示rvalue Reference , rvalue Reference只能绑定rvalue。<br><br><strong>Example</strong><br></p><pre><code class="lang-C++">int a = 1;int &amp;&amp; b = a+1;    /*b为rvalue Reference*/</code></pre><p>rvalue Reference 常常用于 <strong>Move Semantics</strong> 和 <strong>Perfect Forward</strong>。</p><h3 id="Move-Semantics"><a href="#Move-Semantics" class="headerlink" title="Move Semantics"></a>Move Semantics</h3><p>我们先引入一段代码再做介绍:<br></p><pre><code class="lang-C++">#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;cstring&gt;class String&#123;    char* data;public:    /*Command Constructor*/    String(const char* p)    &#123;    printf(&quot;Command Constructor!\n&quot;);        size_t size = std::strlen(p) + 1;        data = new char[size];        std::memcpy(data, p, size);    &#125;   ~String()    &#123;    printf(&quot;Destoryed!\n&quot;);        delete[] data;    &#125;    /*Copy Constructor*/    String(const String&amp; that)    &#123;    printf(&quot;Copy Constructor!\n&quot;);        size_t size = std::strlen(that.data) + 1;        data = new char[size];        std::memcpy(data, that.data, size);    &#125;    /*Move Constructor*/    String(String&amp;&amp; that)   // string&amp;&amp; is an rvalue reference to a string    &#123;    printf(&quot;Move Constructor!\n&quot;);        data = that.data;        that.data = nullptr;    &#125;    char* getData()&#123;        return data;    &#125;    void printfString()&#123;        printf(&quot;%s\n&quot;,data);    &#125;&#125;;class student &#123;    private:        String name;    public:        student(const String&amp; s):name(s)&#123;&#125;        //student(String&amp;&amp; s):name((String&amp;&amp;) s)&#123;&#125;    void printfName()&#123;        name.printfString();    &#125;&#125;;int main()&#123;    student a(&quot;LiQiBin&quot;);    a.printfName();    return 0;&#125;</code></pre><p>通常情况下我们想创建一个<code>student</code>类，我们调用函数<code>student a(&quot;LiQiBin&quot;)</code>,函数首先会调用<code>String</code>类中的<code>Command Constructor</code>来创建一个传入参数，传入参数为<code>lvalue Reference</code>，虽然<code>LiQiBin</code>是一个<code>rvalue</code>但是会被转化为<code>lvalue Reference</code>，参照上文<code>lvalue Reference</code>的介绍,然后当<code>student</code>的构造器执行到<code>name(s)</code>时，程序又会调用<code>String</code>类中的<code>Copy Constructor</code>，最后才得到完整的<code>student</code>参数。</p><p><strong>输出如下:</strong><br></p><pre><code class="lang-C++">Command Constructor!Copy Constructor!Destoryed!LiQiBinDestoryed!</code></pre><p>这个过程中分别调用了<code>String</code>类的<code>Command Constructor</code>和<code>Copy Constructor</code>这就意味着执行了两次内存的分配(<code>new</code>操作)和复制<code>memcpy()</code>操作,<code>String</code>类中的字符数非常少还可以接受，如果被操作的<code>String</code>类内的字符数量极其庞大,两次内存的分配和复制就是对资源相当大的浪费! 是否有办法，只执行一次复制就可以构造出student类呢?<br><br>答案是右值引用(rvalue Reference)的<strong>Move Semantics</strong><br></p><p>我们取消代码中的<code>student(String&amp;&amp; s):name((String&amp;&amp;) s)&#123;&#125;</code>这行注释，这样rvalue<code>LiQiBin</code>就会优先被解释为<code>rvalue Reference</code>,程序就会先执行<code>String</code>类中的<code>Command Constructor</code>构造出一个传入参数,然后执行<code>name((String&amp;&amp;)s)</code>,即执行<code>String</code>类中的<code>Move Constructor</code>。<br></p><p><strong>下面是Move Constructor的代码：</strong><br></p><pre><code class="lang-C++">    /*Move Constructor*/    String(String&amp;&amp; that)   // string&amp;&amp; is an rvalue reference to a string    &#123;        printf(&quot;Move Constructor!\n&quot;);        data = that.data;        that.data = nullptr;    &#125;</code></pre><p>可以看到<code>Move Constructor</code>没有调用<code>new</code>和<code>memcpy</code>而只是将<code>rvalue Reference</code>中的<code>that.data</code>指向的地址<strong>偷来</strong>给自己用，再将<code>that.data</code>指向<code>nullptr</code>,因为<code>rvalue</code>是暂时的，不持久的参数，<code>student a(&quot;LiQiBin&quot;)</code>执行结束后生成的临时<code>String</code>类就会调用析构函数将得到的资源收回，所以将<code>that.data</code>指向<code>nullptr</code>就避免了,临时<code>String</code>类收回资源时将指向<code>LiQiBin</code>位置收回，<strong>就相当于<code>Move Constructor</code>将<code>rvalue Reference</code>中的资源偷来</strong>,成功只用一次<code>new</code>和<code>memcpy</code>就构建出了<code>student</code>类。<br></p><p><strong>输出如下:</strong><br></p><pre><code class="lang-C++">Command Constructor!Move Constructor!Destoryed!LiQiBinDestoryed!</code></pre>]]></content>
    
    
    <categories>
      
      <category>C/C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
      <tag>Reference</tag>
      
      <tag>lvalue rvalue</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PA3.2必答题</title>
    <link href="/2020/12/30/PA3-2%E5%BF%85%E7%AD%94%E9%A2%98/"/>
    <url>/2020/12/30/PA3-2%E5%BF%85%E7%AD%94%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="必答题-hello程序是什么-它从而何来-要到哪里去"><a href="#必答题-hello程序是什么-它从而何来-要到哪里去" class="headerlink" title="必答题-hello程序是什么, 它从而何来, 要到哪里去"></a>必答题-hello程序是什么, 它从而何来, 要到哪里去</h1><p><strong>到此为止, PA中的所有组件已经全部亮相了, 整个计算机系统也开始趋于完整. 你也已经在这个自己创造的计算机系统上跑起了hello这个第一个还说得过去的用户程序 (dummy是给大家热身用的, 不算), 好消息是, 我们已经距离运行仙剑奇侠传不远了(下一个阶段就是啦).<br></strong></p><p><strong>不过按照PA的传统, 光是跑起来还是不够的, 你还要明白它究竟怎么跑起来才行. 于是来回答这道必答题吧:</strong></p><p><em>我们知道navy-apps/tests/hello/hello.c只是一个C源文件, 它会被编译链接成一个ELF文件. 那么, hello程序一开始在哪里? 它是怎么出现内存中的? 为什么会出现在目前的内存位置? 它的第一条指令在哪里? 究竟是怎么执行到它的第一条指令的? hello程序在不断地打印字符串, 每一个字符又是经历了什么才会最终出现在终端上?</em></p><p><strong>上面一口气问了很多问题, 我们想说的是, 这其中蕴含着非常多需要你理解的细节. 我们希望你能够认真整理其中涉及的每一行代码, 然后用自己的语言融会贯通地把这个过程的理解描述清楚, 而不是机械地分点回答这几个问题.</strong></p><p><strong>同样地, 上一阶段的必答题”理解穿越时空的旅程”也已经涵盖了一部分内容, 你可以把它的回答包含进来, 但需要描述清楚有差异的地方. 另外, C库中printf()到write()的过程比较繁琐, 而且也不属于PA的主线内容, 这一部分不必展开回答. 而且你也已经在PA2中实现了自己的printf()了, 相信你也不难理解字符串格式化的过程. 如果你对Newlib的实现感兴趣, 你也可以RTFSC.</strong></p><p><strong>总之, 扣除C库中printf()到write()转换的部分, 剩下的代码就是你应该理解透彻的了. 于是, 努力去理解每一行代码吧!)))))””))</strong></p><h1 id="hello-c程序是怎么被编译链接成一个可执行文件的"><a href="#hello-c程序是怎么被编译链接成一个可执行文件的" class="headerlink" title="hello.c程序是怎么被编译链接成一个可执行文件的"></a>hello.c程序是怎么被编译链接成一个可执行文件的</h1><p>首先我们是在nanos-lite文件中执行命令<code>make ARCH=x86-nemu run</code>,make程序进入nanos-lite/Makefile文件中寻找run伪目标执行,nanos-lite/Makefile中并没有run伪目标,但是由于nanos-lite/Makefile通过命令:<br></p><pre><code class="lang-makefile">include $(AM_HOME)/Makefile.app)</code></pre><p>将nexus-am/Makefile.app文件包含在了nanos-lite/Makefile文件中,所以我们可以在nexus-am/Makefile中找到run伪目标.<br><br><strong>Note! 这里只是将nexus-am/Makefile.app包含在nanos-lite/Makefile文件中而不是跳转到nexus-am/Makefile文件中执行!所以当前目录还是在nanos-lite</strong><br></p><p>现在让我们把目光转向nexus-am/Makefil.app文件<br></p><p>在nexus-am/Makefile.app中我们找到run伪目标</p><pre><code class="lang-makefile">default: image$(OBJS): $(PREBUILD)image:   $(OBJS) am $(LIBS) promptprompt:  $(OBJS) am $(LIBS)run:     defaultprompt:    @echo \# Creating binary image [$(ARCH))]</code></pre><p>但这里的run伪目标并不是完整的,nexus-am/Makefile.app中通过命令</p><pre><code class="lang-makefile">include $(AM_HOME)/Makefile.check)</code></pre><p>将nexus-am/Makefile.check文件包含到nanos-lite/Makefile中,而nexus-am/Makefile.check又通过命令</p><pre><code class="lang-Makefile">#ARCH=x86-nemu,这是我们使用make命令传入的参数include $(AM_HOME)/am/arch/$(ARCH).mk</code></pre><p>将nexus-am/am/arch/x86-nemu.mk文件包含到nanos-lite/Makefile中,同样nexus-am/am/arch/x86-nemu.mk也通过命令</p><pre><code class="lang-makefile">include $(AM_HOME)/am/arch/platform/nemu.mk</code></pre><p>将nexus-am/am/arch/platform/nemu.mk包含到nanos-lite/Makefile中而nexus-am/am/arch/platform/nemu.mk中也包含着run伪命令.</p><pre><code class="lang-makefile">run:    $(MAKE) -C $(NEMU_HOME) ISA=$(ISA) run ARGS=&quot;$(NEMU_ARGS))&quot;</code></pre><p>所以完整的run伪目标可以看成这样</p><pre><code class="lang-makefile">run: default    $(MAKE) -C $(NEMU_HOME) ISA=$(ISA) run ARGS=&quot;$(NEMU_ARGS))&quot;</code></pre><p>default也是一个伪目标，所以defalut也会被决议执行由于<code>defalut: image</code>,image同样也是伪目标所以image会被决议执行.<code>image:   $(OBJS) am $(LIBS) prompt</code>,和run一样image也不是完整的伪目标，而另一部分的image同样被存在nexus-am/am/arch/platform/nemu.mk中.<br><br>所以完整的image伪目标可以被看作:<br></p><pre><code class="lang-makefile">image:    $(OBJS) am $(LIBS) prompt    @echo + LD &quot;-&gt;&quot; $(BINARY_REL).elf    @$(LD) $(LDFLAGS) --gc-sections -T $(LD_SCRIPT) -e _start -o $(BINARY).elf $(LINK_FILES)    @$(OBJDUMP) -d $(BINARY).elf &gt; $(BINARY).txt    @echo + OBJCOPY &quot;-&gt;&quot; $(BINARY_REL).bin    @$(OBJCOPY) -S --set-section-flags .bss=alloc,contents -O binary $(BINARY).elf $(BINARY).bin</code></pre><p>make命令会依次执行$(OBJS),am,$(LIBS),prompt等伪目标然后在执行image伪目标下面的shell指令.<br></p><p><strong>让我们稍微整理一下make执行的顺序<br></strong><br>make ARCH=x86-nemu run命令下达后,make会在先找到run伪目标<br></p><pre><code class="lang-makefile">run: default    $(MAKE) -C $(NEMU_HOME) ISA=$(ISA) run ARGS=&quot;$(NEMU_ARGS))&quot;</code></pre><p>执行defalut伪目标</p><pre><code class="lang-makefile">default: image</code></pre><p>执行image伪目标</p><pre><code class="lang-makefile">image:    $(OBJS) am $(LIBS) prompt    @echo + LD &quot;-&gt;&quot; $(BINARY_REL).elf    @$(LD) $(LDFLAGS) --gc-sections -T $(LD_SCRIPT) -e _start -o $(BINARY).elf $(LINK_FILES)    @$(OBJDUMP) -d $(BINARY).elf &gt; $(BINARY).txt    @echo + OBJCOPY &quot;-&gt;&quot; $(BINARY_REL).bin    @$(OBJCOPY) -S --set-section-flags .bss=alloc,contents -O binary $(BINARY).elf $(BINARY).bin</code></pre><p>依次执行$(OBJS) am $(LIBS) prompt,会生成后缀为.o和后缀为.a的一系列文件$(LINK_FILES),这里就不再深入展开，具体可以看源代码<br></p><p>执行完毕后会执行image下的shell命令,将这系列$(LINK_FILES)链接成$(BINARY).elf文件，最后通过$(OBJCOPY)命令将$(BINARY).elf转化为$(BINARY).bin文件.<br></p><p>最后执行run伪目标下的shell命令</p><pre><code class="lang-makefile">    $(MAKE) -C $(NEMU_HOME) ISA=$(ISA) run ARGS=&quot;$(NEMU_ARGS)&quot;</code></pre><p>这条命令表示进入$(NEMU_HOME)目录执行make run命令.<strong>Note!这里是进入$(NEMU_HOME)执行make</strong><br><br>在nemu/Makefile文件中执行编译链接完成之后会执行一条命令</p><pre><code class="lang-makefile">    $(NEMU_EXEC)</code></pre><p>这条命令实际就是</p><pre><code class="lang-makefile">#这里$(IMG)为空忽略,$(ARGS)为我们上面run伪目标shell指令中传入的参数$(NEMU_ARGS)nemu/build/x86-nemu $(ARGS) $(IMG)NEMU_ARGS = -b $(MAINARGS) -l $(shell dirname $(BINARY))/nemu-log.txt $(BINARY).bin)</code></pre><p>这里NEMU_ARGS就相当与<code>int main(int argc, char *argv[])</code>的argv[]参数.<br><br>NEMU_ARGS会被nemu中的<code>parse_args(argc, argv);</code>函数解析，最后$(BINARY).bin会被<code>long img_size = load_img();</code>函数装入模拟器内存中,最后函数<code>init_isa();</code>更新pc指针，最后模拟器取指执行<br></p><h1 id="hello-c中的每一个字符是怎么被输出到终端上的"><a href="#hello-c中的每一个字符是怎么被输出到终端上的" class="headerlink" title="hello.c中的每一个字符是怎么被输出到终端上的?"></a>hello.c中的每一个字符是怎么被输出到终端上的?</h1><p>printf()-&gt;write()-&gt;<em>write_r ()-&gt;_write()<br><br>-&gt;_syscall\</em>(SYS<em>write,fd,buf,count)-&gt;<strong>am_vecsys<br><br>-&gt;</strong>am_asm_trap</em>-&gt;  call __am_irq_handle-&gt;user_handler()user_handler是函数指针，指向do_event()<br><br>-&gt;do_syscall()-&gt;sys_write()-&gt;fs_write()-&gt;invalid_write()-&gt;_put()-&gt;outb(SERIAL_PORT, ch)<br><br>-&gt;asm volatile (“outb %%al, %%dx” : : “a”(data), “d”((uint16_t)port))-&gt;调用nemu中的out指令输出到屏幕上<br></p>]]></content>
    
    
    <categories>
      
      <category>计算机组成原理</category>
      
      <category>PA</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PA</tag>
      
      <tag>计算机组成原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PA2实验报告</title>
    <link href="/2020/12/18/PA2%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/"/>
    <url>/2020/12/18/PA2%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A/</url>
    
    <content type="html"><![CDATA[<p><strong>1.RTFSC 请整理一条指令在NEMU中的执行过程. (我们其实已经在PA2.1阶段提到过这道题了)</strong><br><br>    程序在nexus-am中被交叉编译成二进制指令被装入NEMU的内存中，NEMU通过一系列函数来取指令，解码指令，执行指令<br><br>函数调用历程如图:<br></p><pre><code class="lang-mermaid">graph LR;    A[cpu_exec];    B[exec_once];    C[isa_exec];    D[update_pc];    E[instr_fetch];    F[set_width];    G[idex];    A--&gt;B;    B--&gt;C;    B--&gt;D;    C--&gt;E;    C--&gt;F;    C--&gt;G;</code></pre><p>以指令0x00为例cpu执行模拟函数cpu_exec一路执行到instr_fetch在内存中取出指令0x00然后查询<em>NEMU模拟器中存储的符合x指令集规范的表opcode_table(需要我们手动实现)</em>得到对应的0x00这一条指令的执行宽度,opcode_table[0x00].width,调用宽度设置函数set_width设置宽度,然后进入idex函数运行对应的内置解码程序opcode_table[0x00].decode,和指令对于的内置执行程序opcode_table[0x00].execute,最后调用update_pc函数，更新pc寄存器.<br></p><p><strong>2.编译与链接 在nemu/include/rtl/rtl.h中, 你会看到由static inline开头定义的各种RTL指令函数. 选择其中一个函数, 分别尝试去掉static, 去掉inline或去掉两者, 然后重新进行编译, 你可能会看到发生错误. 请分别解释为什么这些错误会发生/不发生? 你有办法证明你的想法吗?</strong><br></p><p><strong>static:</strong>&lt;解释来自stackoverflow&gt;<br></p><ul><li><ol><li>Static defined <strong>local</strong> variables do not lose their value between function calls. In other words they are global variables, but scoped to the local function they are defined in.&lt;函数内定义的变量用static关键字修饰就会被编译器放入静态存储区，应该是被放在.data表内，其实就相当于一个另类的全局变量了.&gt;</li></ol></li><li><ol><li>A static <strong>global</strong> variable or a function is “seen” only in the file it’s declared in.&lt;字面意思&gt;</li></ol></li></ul><p><strong>inline:</strong><br><br>每次函数调用都要执行押入参数，保存返回地址，保存寄存器等工作会让函数调用变慢,inline的作用有点像define,可以将代码直接展开到调用处直接执行就可以让函数调用变快，但是缺点是这个操作可能让可执行文件变得更大或者更小无法预测<br></p><p>有了这些基础现在开始回答问题:<br></p><ul><li><ol><li>去掉inline:<br></li></ol></li></ul><p>static 和 static inline 其实没有很大的不同,只是函数的调用方式改变了,但是我试图编译时出现了这个错误:</p><pre><code class="lang-c">./include/rtl/rtl.h:138:14: error: ‘rtl_sext’ defined but not used [-Werror=unused-function] static  void rtl_sext(rtlreg_t* dest, const rtlreg_t* src1, int width) &#123;              ^~~~~~~~</code></pre><p>原因是我们在gcc中加入了-Werror把所有的警告都当成error来处理,把-Werror去掉就可以了<br></p><ul><li><ol><li>去掉static:<br><br>因为有inline关键字的存在所以，程序就像define一样会在调用处展开所以定义在头文件中的无static有inline的函数不会出现多次定义,只要把makefile文件中的-Werror去掉就可以编译链接成功<br></li></ol></li><li><p>3.去掉static inline:<br><br>因为头文件会被许多文件引用所以如果去掉static inline,这个函数就会被多次定义，在链接的时候会报一下错误:<br></p></li></ul><pre><code class="lang-c">+ LD build/x86-nemubuild/obj-x86/isa/x86/decode/decode.o: In function `rtl_setrelopi&#39;:/home/oeoe/Documents/ICS-PA-2019/nemu/./include/rtl/rtl.h:145: multiple definition of `rtl_setrelopi&#39;</code></pre><p><strong>3.编译与链接</strong></p><ul><li><ol><li>在nemu/include/common.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问重新编译后的NEMU含有多少个dummy变量的实体? 你是如何得到这个结果的?**</li></ol></li><li><ol><li>添加上题中的代码后, 再在nemu/include/debug.h中添加一行volatile static int dummy; 然后重新编译NEMU. 请问此时的NEMU含有多少个dummy变量的实体? 与上题中dummy变量实体数目进行比较, 并解释本题的结果.**</li></ol></li><li><ol><li>修改添加的代码, 为两处dummy变量进行初始化:volatile static int dummy = 0; 然后重新编译NEMU. 你发现了什么问题? 为什么之前没有出现这样的问题? (回答完本题后可以删除添加的代码.)**</li></ol></li></ul><p><strong>Volatile tells the compiler not to optimize anything that has to do with the volatile variable. &lt;来自stackoverflow&gt;<br></strong></p><ol><li>答案是74个，在build/obj中利用<code>grep  -r -c  &#39;dummy&#39; ./* | grep &#39;\.o:[1-9]&#39;| wc -l</code>命令得出.</li><li>答案仍然是74个.</li><li>两个初始化后会出现多次定义的错误:<br></li></ol><pre><code class="lang-c">./include/common.h:2:21: note: previous definition of ‘dummy’ was here volatile static int dummy=0;                     ^~~~~In file included from ./include/device/map.h:4:0,                 from src/memory/memory.c:2:./include/common.h:2:21: error: redefinition of ‘dummy’</code></pre><p>原因是强弱定义的问题，当两个dummy都没有初始化的时候dummy是一个弱符号,编译器不会报错,编译器会选择占用内存最大的那个弱符号，当把两个dummy都初始化后，两个dummy就变成强符号了，链接器不允许强符号被多次定义，如果一个是强符号一个是弱符号，那么弱符号会被强符号覆盖(当然这个弱符号的占用内存大小不能大于强符号，否则会报错).<br></p><p><strong>4. 了解Makefile 请描述你在nemu/目录下敲入make 后, make程序如何组织.c和.h文件, 最终生成可执行文件nemu/build/$ISA-nemu. (这个问题包括两个方面:Makefile的工作方式和编译链接的过程.) 关于Makefile工作方式的提示:</strong><br></p><ul><li><ol><li>Makefile中使用了变量, 包含文件等特性</li></ol></li><li><ol><li>Makefile运用并重写了一些implicit rules</li></ol></li><li><ol><li>在man make中搜索-n选项, 也许会对你有帮助</li></ol></li></ul><pre><code class="lang-makefile">NAME = nemu#如果$(MAKECMDGOALS)和clean）不相等则执行ifneq ...endif内的语句#$MAKECMDGOALS是一个特殊参数:这个参数存放你在命令行指定的目标列表,如果什么都没指定则为空ifneq ($(MAKECMDGOALS),clean) # ignore check for make clean# ?=用来设置变量，当没有设置ISA值或者没有ISA这个变量的时候ISA ?= x86#相当于执行一条shell命令ISAS = $(shell ls src/isa/)#打印信息到标准输出$(info Building $(ISA)-$(NAME))#$(filter pattern…,text):#Returns all whitespace-separated words in text that#do match any of the pattern words, removing any words that do not match. ifeq ($(filter $(ISAS), $(ISA)), ) # ISA must be valid#产生致命错误，并提示Invalid ISA. Supported: $(ISAS)给用户$(error Invalid ISA. Supported: $(ISAS))endifendifINC_DIR += ./include ./src/isa/$(ISA)/includeBUILD_DIR ?= ./build#如果SHARE的值不为空就为trueifdef SHARESO = -so# -D_SHARE:-Dmacro=defn  相当于 C 语言中的 #define macro=defn# -fPIC:生成位置无关代码SO_CFLAGS = -fPIC -D_SHARE=1SO_LDLAGS = -shared -fPICendifOBJ_DIR ?= $(BUILD_DIR)/obj-$(ISA)$(SO)BINARY ?= $(BUILD_DIR)/$(ISA)-$(NAME)$(SO)#类似C中的#includeinclude Makefile.git#设置默认目标，如果没有在命令行指定目标则使用默认目标.DEFAULT_GOAL = app# Compilation flagsCC = gccLD = gcc#$(addprefix,prefix,names...):The value of prefix is prepended to the front of # each individual name and the resulting larger names are concatenated with single# spaces between them INCLUDES  = $(addprefix -I, $(INC_DIR))# -O2:允许编译器对代码进行优化,级别为2# -MMD:生成文件关联信息但是忽略由#include&lt;file&gt;造成的依赖关系并且写入filename.d文件中，可以去看看-M# -Wall:开启所有警告信息# -Werror: every warning is treated as an error# -ggdb3:(搞不懂是什么意思)produces extra debugging information, for example: including macro definitions.# -D__ISA__:-Dmacro=defn  相当于 C 语言中的 #define macro=defn# -fomit-frame-pointer :(这个参数有关于栈指针)看这篇文章:https://stackoverflow.com/questions/14666665/trying-to-understand-gcc-option-fomit-frame-pointerCFLAGS   += -O2 -MMD -Wall -Werror -ggdb3 $(INCLUDES) -D__ISA__=$(ISA) -fomit-frame-pointerQEMU_DIFF_PATH = $(NEMU_HOME)/tools/qemu-diffQEMU_SO = $(QEMU_DIFF_PATH)/build/$(ISA)-qemu-so#执行make指令$(MAkE)是特殊变量 -C用来指定目录$(QEMU_SO):    $(MAKE) -C $(QEMU_DIFF_PATH)# Files to be compiled# -v 表示不匹配“isa&quot;SRCS = $(shell find src/ -name &quot;*.c&quot; | grep -v &quot;isa&quot;)SRCS += $(shell find src/isa/$(ISA) -name &quot;*.c&quot;)#$(var:a=b)，是将 var 变量中每一个单词后面的 a 替换为 bOBJS = $(SRCS:src/%.c=$(OBJ_DIR)/%.o)# Compilation patterns#@表示不显示执行的指令#$&lt;代表第一个依赖项#$(dir NAMES...):取出每个文件名的目录部分$(OBJ_DIR)/%.o: src/%.c    @echo + CC $&lt;    @mkdir -p $(dir $@)    @$(CC) $(CFLAGS) $(SO_CFLAGS) -c -o $@ $&lt;#看这篇文章https://blog.csdn.net/xiaozhi_su/article/details/4202779# Depencies#将OBJS中的文件后缀为.o的文件然后把后缀改为.d-include $(OBJS:.o=.d)# Some convenient rules.PHONY: app run gdb clean run-env $(QEMU_SO)app: $(BINARY)override ARGS ?= -l $(BUILD_DIR)/nemu-log.txtoverride ARGS += -d $(QEMU_SO)# Command to execute NEMUIMG :=NEMU_EXEC := $(BINARY) $(ARGS) $(IMG)$(BINARY): $(OBJS)    $(call git_commit, &quot;compile&quot;)    @echo + LD $@    @$(LD) -O2 -rdynamic $(SO_LDLAGS) -o $@ $^ -lSDL2 -lreadline -ldlrun-env: $(BINARY) $(QEMU_SO)run: run-env    $(call git_commit, &quot;run&quot;)    $(NEMU_EXEC)gdb: run-env    $(call git_commit, &quot;gdb&quot;)    gdb -s $(BINARY) --args $(NEMU_EXEC)clean:    -rm -rf $(BUILD_DIR)    $(MAKE) -C tools/gen-expr clean    $(MAKE) -C tools/qemu-diff cleancount:    @echo  &quot;\e[1;32m&quot;    @echo &quot;The .c and .h file total number of row equal to :&quot;    @find ./ -name &quot;*.[ch]&quot; | xargs wc -l | awk &#39;END&#123;printf &quot;%s\n&quot;,$$1&#125;&#39;    @echo &quot;The .c and .h file (without blank line) total number of row equal to :&quot;    @find ./ -name &quot;*.[ch]&quot; | xargs cat | grep -v &#39;^\s*$$&#39;| wc -l    @echo &quot;\e[0m&quot;</code></pre>]]></content>
    
    
    <categories>
      
      <category>计算机组成原理</category>
      
      <category>PA</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PA</tag>
      
      <tag>计算机组成原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>有符号数右移32位</title>
    <link href="/2020/11/28/%E6%9C%89%E7%AC%A6%E5%8F%B7%E6%95%B0%E5%8F%B3%E7%A7%BB32%E4%BD%8D/"/>
    <url>/2020/11/28/%E6%9C%89%E7%AC%A6%E5%8F%B7%E6%95%B0%E5%8F%B3%E7%A7%BB32%E4%BD%8D/</url>
    
    <content type="html"><![CDATA[<p>在做项目的过程中把右移31位写成了右移32位，造成了大错，找了好久的bug，心累!!<br><br>于是我发现一个我无法理解的情况，<strong>有符号右移32位得到的数和原来未移动的数相同。</strong><br></p><pre><code class="lang-c++">#include&lt;iostream&gt;using namespace std;int main() &#123;    int n = 0x11;    int n1 = n&gt;&gt;32;    printf(&quot;n1==0x%x\n&quot;,n1);    return 0;&#125;</code></pre><p><strong>Output:</strong><br><br><code>n1==0x11</code><br></p><p><em>为什么会发生这样的事情呢?</em><br></p><p><strong>原因是: 对于32-bit的int,<code>n&gt;&gt;32</code>这一指令是未定义行为(undefined behaviour),所以处理器做出32%32的处理，所以最终<code>n&gt;&gt;32</code>就相当于<code>n&gt;&gt;0</code>,所以移动后的数和未移动的数相等。<br></strong></p><p>下面我们做一下验证:<code>n&gt;&gt;33</code><br></p><pre><code class="lang-c++">#include&lt;iostream&gt;using namespace std;int main() &#123;    int n = 0x11;    int n1 = n&gt;&gt;33;    printf(&quot;n1==0x%x\n&quot;,n1);    return 0;&#125;</code></pre><p>Output:<br><br><code>n1==0x8</code><br></p><p>n&gt;&gt;33 就相当与n&gt;&gt;1;<br></p>]]></content>
    
    
    <categories>
      
      <category>C/C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于汇编中EFLAGS寄存器中CF和OF标志位</title>
    <link href="/2020/11/15/%E5%85%B3%E4%BA%8E%E6%B1%87%E7%BC%96%E4%B8%ADEFLAGS%E5%AF%84%E5%AD%98%E5%99%A8%E4%B8%ADCF%E5%92%8COF%E6%A0%87%E5%BF%97%E4%BD%8D/"/>
    <url>/2020/11/15/%E5%85%B3%E4%BA%8E%E6%B1%87%E7%BC%96%E4%B8%ADEFLAGS%E5%AF%84%E5%AD%98%E5%99%A8%E4%B8%ADCF%E5%92%8COF%E6%A0%87%E5%BF%97%E4%BD%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>近来在写项目过程中遇到了EFLAGS的OF和CF标志位，这两个功能有点相似，有点搞不清楚，所以去搜索一下，以下的内容是我对回答的粗略的翻译，原回答在此: <a href="https://stackoverflow.com/questions/791991/about-assembly-cfcarry-and-ofoverflow-flag">about assembly CF(Carry) and OF(Overflow) flag</a><br></p><h1 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h1><p>我知道CF用来解释无符号数的进位，OF解释有符号数的溢出,所以对于有符号数和无符号数都是一串01序列,汇编程序是如何进行区分(differntiate)的？(通过用额外的存储空间记录类型信息?或是通过位置信息？) 还有就是OF和CF两个标志位能否互换(interchangeably)来使用.<br></p><h1 id="回答"><a href="#回答" class="headerlink" title="回答"></a>回答</h1><p><strong>有符号数和无符号数的区别在于用什么指令来操作数据，而非数据本身</strong> , 现代计算机(自1970以来)用补码来表示整型数据，所以有符号数和无符号数的加法和减法的其实操作是一样的<br></p><ul><li><p>有符号数和无符号数的不同关键在于如何对最高有效位 (sign bit) 解释，对于有符号数sign bit 用来代表正负(0代表正,1代表负),无符号数则正常计算。</p></li><li><p>不同的指令可能对同一个bit的解释不同。</p></li><li><p><strong>OF(overflow flag)标志位告诉进位是否将结果最高有效位的符号翻转，以使其与原变量的最高有效位不同,对于无符号数OF标志位没有意义,但是对于有符号数,OF可以表示两数运算是否有溢出(例如:Positive + Positive = Negative)</strong></p></li><li><p><strong>CF(carry flag)标志位用来表示计算时是否存在超过算数逻辑单元长度的进位/借位。<br><br>例如:两个8bits的数相加产生超出算数逻辑单元长度的进位,CF被置为1<br></strong></p></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">11111111</th><th style="text-align:center">CF</th></tr></thead><tbody><tr><td style="text-align:center">+</td><td style="text-align:center">00000001</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">=</td><td style="text-align:center">00000000</td><td style="text-align:center">1</td></tr></tbody></table></div><p><strong>所以对于无符号数来说CF位可以解释为另类的溢出,对于有符号数CF标志位无意义</strong><br></p>]]></content>
    
    
    <categories>
      
      <category>计算机组成原理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机组成原理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>377. Combination Sum IV</title>
    <link href="/2020/11/14/377-Combination-Sum-IV/"/>
    <url>/2020/11/14/377-Combination-Sum-IV/</url>
    
    <content type="html"><![CDATA[<p><img src="377-Combination-Sum-IV-1.png" alt="377-Combination-Sum-IV-1.png"><br><br><img src="377-Combination-Sum-IV-2.png" alt="377-Combination-Sum-IV-2.png"><br></p><pre><code class="lang-java">class Solution &#123;    public int combinationSum4(int[] nums, int target) &#123;        int[] fina = new int[target+1];        //到达target=0时到达target==0的方式有1种,就是什么都不选        fina[0]=1;        //fina[i]表示target=i时有几种方式(路)可以到达target=0.        for(int i=1;i&lt;=target;++i)        &#123;            for(int j=0;j&lt;nums.length;++j)            &#123;                if(nums[j]&lt;=i)                fina[i]+=fina[i-nums[j]];            &#125;        &#125;        return fina[target];    &#125;&#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>力扣</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
      <tag>动态规划</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>52. N-Queens II</title>
    <link href="/2020/11/14/52-N-Queens-II/"/>
    <url>/2020/11/14/52-N-Queens-II/</url>
    
    <content type="html"><![CDATA[<h1 id="N皇后"><a href="#N皇后" class="headerlink" title="N皇后"></a>N皇后</h1><p>N皇后是经典题目了，这篇文章不写解题思路,看解题思路可以看这一篇力扣的官方文章<a href="https://leetcode-cn.com/problems/n-queens-ii/solution/nhuang-hou-ii-by-leetcode-solution/">52. N-Queens</a><br><strong>这篇文章主要记录一下用二进制数解N皇后的疑问和解答</strong><br></p><p>先贴代码:</p><pre><code class="lang-java">class Solution &#123;    public int totalNQueens(int n) &#123;        return solve(n, 0, 0, 0, 0);    &#125;    public int solve(int n, int row, int columns, int diagonals1, int diagonals2) &#123;        if(n==row)            return 1;        int count =0;        int availablePosition = ~(columns|diagonals1|diagonals2)&amp;((1&lt;&lt;n)-1);        while(availablePosition&gt;0)        &#123;            int position = availablePosition&amp;(-availablePosition);            count += solve(n,row+1,columns|position,(diagonals1|position)&lt;&lt;1,(diagonals2|position)&gt;&gt;1);            availablePosition &amp;=(availablePosition-1);        &#125;        return count ;    &#125;&#125;</code></pre><h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p><strong>疑问一: int position = availablePosition&amp;(-availablePosition);这段代码的作用是什么?</strong><br><br>二进制位运算:正数x与其相反数-x的与操作x&amp;(-x)得到的数是二进制x第一个出现的1代表的值(这里说的不太清楚看下面例子)<br></p><div class="table-container"><table><thead><tr><th style="text-align:center">注意：负数在计算机中用补码表示</th><th style="text-align:center">二进制</th><th style="text-align:center">十进制</th></tr></thead><tbody><tr><td style="text-align:center">x</td><td style="text-align:center">01100100</td><td style="text-align:center">100</td></tr><tr><td style="text-align:center">-x</td><td style="text-align:center">10011100</td><td style="text-align:center">-100</td></tr><tr><td style="text-align:center">x&amp;(-x)</td><td style="text-align:center">00000100</td><td style="text-align:center">4</td></tr></tbody></table></div><p>由上表可以看出我们可以通过x&amp;(-x)提取出x的二进制表示时第一个不为0的数.</p><p><strong>疑问二: availablePosition &amp;=(availablePosition-1);这段代码的作用是?</strong><br></p><p>我们把availablePosition 看成x，这样好表示一点.<br><br>x&amp;=(x-1)是为了将x二进制中第一个不为0的数置为0,看下面例子<br></p><div class="table-container"><table><thead><tr><th>-</th><th>二进制</th><th>十进制</th></tr></thead><tbody><tr><td>x</td><td>01100100</td><td>100</td></tr><tr><td>x-1</td><td>01100010</td><td>99</td></tr><tr><td>x&amp;=(x-1)</td><td>01100000</td><td>这个数不重要</td></tr></tbody></table></div><p>通过上表可以看到x&amp;(x-1)成功把x中第一个不为0的数置为0.</p>]]></content>
    
    
    <categories>
      
      <category>力扣</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于进程Process的一篇写的很好的文章 </title>
    <link href="/2020/11/14/%E5%85%B3%E4%BA%8E%E8%BF%9B%E7%A8%8BProcess%E7%9A%84%E4%B8%80%E7%AF%87%E5%86%99%E7%9A%84%E5%BE%88%E5%A5%BD%E7%9A%84%E6%96%87%E7%AB%A0/"/>
    <url>/2020/11/14/%E5%85%B3%E4%BA%8E%E8%BF%9B%E7%A8%8BProcess%E7%9A%84%E4%B8%80%E7%AF%87%E5%86%99%E7%9A%84%E5%BE%88%E5%A5%BD%E7%9A%84%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="Process"><a href="#Process" class="headerlink" title="Process"></a>Process</h1><p>本来想翻译一下的，但是文章太长了，我又太懒，所以就贴一下网址吧<br><br><a href="https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html">Process</a>;</p>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spring Cloud Hystrix</title>
    <link href="/2020/07/05/Spring-Cloud-Hystrix/"/>
    <url>/2020/07/05/Spring-Cloud-Hystrix/</url>
    
    <content type="html"><![CDATA[<h1 id="Hystrix-还需要继续丰富）"><a href="#Hystrix-还需要继续丰富）" class="headerlink" title="Hystrix (还需要继续丰富）"></a>Hystrix (还需要继续丰富）</h1><p>服务熔断:提供线程池，不同的服务走不同的线程池，实现不同服务调用的隔离，避免了服务雪崩的问题</p><h2 id="Hystrix的使用详情"><a href="#Hystrix的使用详情" class="headerlink" title="Hystrix的使用详情"></a>Hystrix的使用详情</h2><h3 id="１．创建请求命令"><a href="#１．创建请求命令" class="headerlink" title="１．创建请求命令"></a>１．创建请求命令</h3><p>HystrixCommand 它用来封装具体的依赖服务调用逻辑</p><ul><li>同步执行</li><li>异步执行<h3 id="２．定义服务降级"><a href="#２．定义服务降级" class="headerlink" title="２．定义服务降级"></a>２．定义服务降级</h3>fallback是Hystrix命令执行失败时使用的后备方法，用来实现服务的降级处理逻辑，在HystrixCommand中可以通过重载getFallback()方法来实现降级逻辑<br><br>这些情况可以不去实现降级逻辑<br><br>执行写操作的命令<br>执行批处理或离线计算的命令<h3 id="３．异常处理"><a href="#３．异常处理" class="headerlink" title="３．异常处理"></a>３．异常处理</h3></li><li>异常传播<br><br>HystrixCommad实现run()方法中抛出异常时，除了HystrixBadRequestException之外，其他异常均会被Hystrix认为命令执行失败并触发服务降级的处理逻辑<br></li><li>异常获取<br><br>当Hystrix命令因为异常（除了HystrixBadRequest的异常）进入服务的降级逻辑之后，往往需要对不同异常做针对性处理<h3 id="４．命令名称，分组以及线程池划分"><a href="#４．命令名称，分组以及线程池划分" class="headerlink" title="４．命令名称，分组以及线程池划分"></a>４．命令名称，分组以及线程池划分</h3>通常情况下，尽量通过HystrixThreadPoolKey的方式来指定线程池的划分，而不是通过组名的默认方式实现划分，因为多个不同命令可能从业务逻辑上看属于同一个组,但是往往从实现本身上需要跟其他命令进行隔离<br></li><li>commandKey</li><li>groupKey</li><li>threadPoolKey<h3 id="５．请求缓存"><a href="#５．请求缓存" class="headerlink" title="５．请求缓存"></a>５．请求缓存</h3></li><li>开启请求缓存功能<br><br>当不同的外部请求处理逻辑调用了同一个依赖服务时，Hystrix会根据getCacheKey方法返回值来是否是重复请求，如果他们的cacheKey相同，那么该依赖服务只会在第一个请求到达时被真正地调用一次，另一个请求则是直接从请求缓存中返回结果<br></li><li><em>所以通过开启缓存可以让我们实现Hystrix命令具备下面几项好处<br></em><ul><li>减少重复的请求数，降低依赖服务的并发度</li><li>在同一用户请求的上下文中，相同的依赖服务返回数据始终保持一致</li><li>请求缓存在run()和construct()执行之前生效，所以可以减少不必要的线程开销</li><li>清理失效缓存功能</li><li>在使用请求缓存时，如果只是读操作，那么不需要考虑缓存内容是否正确的问题，但是如果请求命令中还有更新数据的写操作，那么缓存中的数据就需要</li><li>我们在进行写操作时进行及时的处理，以防止读操作的请求命令获取到了失效的数据<br></li></ul></li><li><em>使用注解实现请求缓存</em><ul><li>１．设置请求缓存＠CacheResult</li><li>２．定义缓存Key</li><li>３．缓存清理<h3 id="６．请求合并"><a href="#６．请求合并" class="headerlink" title="６．请求合并"></a>６．请求合并</h3>在高并发的情况下，因通信次数的增加，总的通信时间消耗将会变得不那么理想，同时，因为依赖服务线程池资源有限，将出现排队等待与响应延迟的情况，为了<br>优化这两个问题，Hystrix提供了HystrixCollapser来实现请求的合并，以减少通信消耗和线程数的占用</li></ul></li><li><strong>HystrixCollapser<br></strong><br>HystrixCollapser实现了在HystrixCommand之前放置一个合并处理器，将处于一个很短的时间窗（默认１０秒）内对同一个依赖的多个请求进行整合并以批量<br>的方式发起请求的功能（服务提供方也需要提供相应的批量实现的接口）</li><li><strong>请求合并的额外开销</strong><br><br>虽然通过请求合并可以减少请求的数量以缓解依赖服务线程池的资源，但是在使用的时候也需要注意它所带来的额外开销：用于请求合并的延迟时间窗会使得依赖服务的请求延迟提高：本来只需要５ms，请求合并后需要１５ms<br></li></ul><p><em>根据一下两个实际情况考虑是否使用请求合并器</em><br></p><ul><li>请求命令本身的延迟如果依赖服务的请求命令本身就是一个高延迟的命令，那么请求合并器所带来的延迟就可以忽略<br></li><li>延迟时间窗内的并发量,如果时间窗内只有１～２个请求，那么这样的依赖服务不适合使用请求合并器．这样的情况不单不能提高系统性能，反而会成为系统瓶颈<h3 id="７．Hystrix仪表盘"><a href="#７．Hystrix仪表盘" class="headerlink" title="７．Hystrix仪表盘"></a>７．Hystrix仪表盘</h3>Spring Cloud完美整合了它的仪表盘组件Hystrix Dashboard , 它主要用来实时监控Hystrix的各项指标信息．通过Hystrix Dashboard反馈的实时信息，<br>可以帮助我们快速发现系统中存在的问题，从而及时地采取应对措施<br></li><li>默认的集群监控</li><li>指定的集群监控（Turbine)</li><li>单体应用的监控<h4 id="Turbine"><a href="#Turbine" class="headerlink" title="Turbine"></a>Turbine</h4>Spring Cloud在分装Turbine的时候，还封装了基于消息代理的收集实现RabbitMQ<br></li><li>１．创建HystrixCommand 或　HystrixObservableCommand 对象<br>表示对依赖服务的操作请求，同时传递所需要的参数<ul><li>HystrixCommand：用在依赖服务返回单个操作结果的时候</li><li>HystrixObservableCommand:用在依赖的服务返回多个操作结果的时候</li></ul></li><li><p>２．命令执行<br></p><ul><li><p><em>HystrixCommand实现了下面两个执行方式</em><br></p><ul><li>execute():同步执行，从依赖的服务返回一个单一的结果对象，或是在发生错误的时候抛出异常．</li><li>queue():异步执行，直接返回一个Future对象，其中包括了服务执行结束时要返回的单一结果对象</li></ul></li><li><p><em>HystrixObservableCommand实现了另外两种执行方式</em><br></p><ul><li>Observe():返回Observable对象，它代表了操作的多个结果，它是一个Hot Observable<br></li><li>toObservable():同样会返回Observable对象，也代表了操作的多个结果，但它返回的是一个Cold Observable</li></ul></li></ul></li><li><p>３．结果是否被缓存<br>若当前命令的请求缓存功能是被启用的，并且该命令缓存命中，那么缓存的结果会立即以Observable对象的形式返回．</p></li><li>４．断路器是否打开<br>在命令结果没有缓存命中时，Hystrix在执行命令前需要检查断路器是否为打开状态<br>如果断路器是打开的，那么Hystrix不会执行命令，而是转接到fallback处理逻辑(对应下面第８步)<br>如果断路器是关闭的，那么Hystrix会跳到第5步，检查是否有可用资源来执行命令</li><li>５．线程池／请求队列／信号量是否占满<br>如果与命令有关的线程和请求队列，或者信号量(不使用线程池的时候)已经被占满，那么Hystrix也不会执行命令，而是转接到fallback处理逻辑（对应下面第８步）</li><li>６．HystrixObservableCommand.construct()或HystrixCommand.run()<ul><li>HystrixCommand.run():返回一个单一的结果，或者抛出异常fallbac;</li><li>HystrixObservableCommand,construct():返回一个Observable对象来发射多个结果，或通过onError发送错误通知</li></ul></li></ul><p><em>如果run()和construct()方法执行时间超过了命令设置的超时阈值，当前处理线程将会抛出一个TimeoutException(如果该命令不在其自身的线程中执行，则会通过单独的计时线程来抛出）．在这种情况下，Hystrix会转接到fallback处理逻辑，同时，如果当前命令没有被取消或中断，那么他最终会忽略run()或者construct()方法返回<br>如果命令没有抛出异常，那么Hystrix在记录一些日志并采集监控报告将该结果返回</em></p><ul><li>７．计算断路器的健康度<br>Hystrix会将＂成功＂，＂失败＂，＂拒绝＂，＂超时＂等信息报告给断路器，而断路器会维护一组计数器来统计这些数据<br>断路器会使用这些统计数据来决定是否要将断路器打开，来对某个依赖服务的请求进行＂熔断／短路＂，直到恢复期结束后，根据统计数据判断如果还是未达到健康指标，就再次＂熔断／短路＂</li><li>８．fallback处理<br>当命令执行失败时，Hystrix会进入fallback尝试回退处理，我们通常也称该操作为＂服务降级＂．而能够引起服务降级的情况有下面几种<br><ul><li>第４步，当前命令处于＂熔断／短路＂状态，断路器是打开的时候</li><li>第５步，当前命令的线程池，请求队列或者信号量被占满的时候</li><li>第６步，HystrixObservableCommand.construct()或HystrixCommand.run()抛出异常的时候．</li></ul></li><li>９．返回成功的响应</li></ul>]]></content>
    
    
    <categories>
      
      <category>微服务学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spring Cloud Eureka 初入门</title>
    <link href="/2020/06/17/Spring-Cloud-Eureka-%E5%88%9D%E5%85%A5%E9%97%A8/"/>
    <url>/2020/06/17/Spring-Cloud-Eureka-%E5%88%9D%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Eureka是什么？"><a href="#Eureka是什么？" class="headerlink" title="Eureka是什么？"></a>Eureka是什么？</h1><p>Eureka就是由Netflix公司开发的一款开源的服务注册和发现的的产品 SpringCloud将其集成到SpringCloud的子项目Spring-Cloud-netflix中实现SpringCloud的服务注册和发现功能</p><h1 id="Eureka解决什么实际问题？"><a href="#Eureka解决什么实际问题？" class="headerlink" title="Eureka解决什么实际问题？"></a>Eureka解决什么实际问题？</h1><p><strong>Eureka解决的是服务的硬编码问题提供服务地址的问题,也就是微服务客户端不用在代码中硬写出微服务服务端，如果微服务客户端和服务端都有很多例如100个，那么每个微服物客户端都要写下100个服务端的IP地址以及端口,如果由于业务需求增加客户端或服务端，就又需要添加相应的代码，这样很难维护.</strong></p><h1 id="Eureka的划分"><a href="#Eureka的划分" class="headerlink" title="Eureka的划分"></a>Eureka的划分</h1><p>Eureka可以分为Eureka Service端和Eureka Client端<br><br>Eureka Client可以建立在微服务的服务端(Application Service)和客户端(Application Client).<br></p><h1 id="Eureka的架构"><a href="#Eureka的架构" class="headerlink" title="Eureka的架构"></a>Eureka的架构</h1><p><img src="eureka-architecture.png" alt="eureka_architecture"><br></p><p>简单的解释上图: 每一个Eureka Client(包括ApplicationService和ApplicationClient)需要向Eureka Service(服务注册中心)注册，当ApplicationClient需要访问ApplicationServices时，ApplicationClient就会向Eureka Service发出GET请求获取ApplicationService的信息，然后再进行远程调用Make Remote Call<br></p><p> <strong>这样做的好处是什么呢？</strong><br><br><em>答:如果没有Eureka Service担任ApplicationService和ApplicationClient的第三方管理,那么ApplicationClient就需要在本地记住每一个ApplicationService的访问地址和端口，如果ApplicationService宕机或者开发者加入一个新的ApplicationService，这时就需要去修改每一个ApplicationClient的本地配置信息，如果ApplicationClient的数量很多例如100个，这样就会造成很大的工作量，另外Eureka还可以提供负载均衡的功能.</em></p><h1 id="Eureka的功能"><a href="#Eureka的功能" class="headerlink" title="Eureka的功能"></a>Eureka的功能</h1><p><strong>Eureka Client:</strong> 其实就是已经在注册中心注册了的微服务，Eureka Client内置负载均衡功能．<br><br><strong>Eureka Service:</strong> 提供服务注册功能，用来记录已注册微服务的相关信息.<br></p><h2 id="Eureka的服务的基本流程"><a href="#Eureka的服务的基本流程" class="headerlink" title="Eureka的服务的基本流程"></a>Eureka的服务的基本流程</h2><p>首先要写一个Eureka Service (服务注册中心) 提交上线例如上线到localhost:8761,接着需要写两个Eureka Client 分别是(Application Service 和 Application Client) , 分别通过Rest API的形式向Eureka Service注册,Eureka Service得到两个Eureka Client的相关信息，同时两个Eureka Client也获得了已在Eureka Service 中注册过得服务注册列表信息，这是ApplicationClient就知道了ApplicationService的IP地址，就可以通过HTTP远程调度来访问ApplicationService.<br></p><p>有关RESI API 的内容可以看这篇文章:<a href="https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/">Understanding And Using REST APIs</a></p><h2 id="Eureka-Renew（服务续约"><a href="#Eureka-Renew（服务续约" class="headerlink" title="Eureka Renew（服务续约)"></a>Eureka Renew（服务续约)</h2><p>Eureka Client默认每30秒发送一次心跳给Eureka Service 进行服务续约(告诉Eureka Service 我还活着) Eureka Service如果90秒没有收到Eureka Client的心跳，Eureka Service就会自动删除这个Eureka Client.</p><h2 id="Eureka-Fetch-Registries-获取服务列表信息"><a href="#Eureka-Fetch-Registries-获取服务列表信息" class="headerlink" title="Eureka Fetch Registries(获取服务列表信息)"></a>Eureka Fetch Registries(获取服务列表信息)</h2><p>Eureka Client本地有服务注册列表的的缓存信息而且默认每30秒Eureka Client会更新一次服务注册列表信息,Eureka Service中缓存了所有的注册信息，Eureka Client和Eureka Service可以通过XML或JSON的格式来通信，默认是JSON.</p><h2 id="Eureka-Cancel-服务下线"><a href="#Eureka-Cancel-服务下线" class="headerlink" title="Eureka Cancel(服务下线)"></a>Eureka Cancel(服务下线)</h2><p>Eureka Cancel在程序关闭时可以向Eureka Service发送下线请求，Eureka Service会将该Eureka Client的相关信息删除，该功能不会自动完成，需要在Eureka Client 程序中调用相关代码．</p><h2 id="Eureka-Eviction-服务剔除"><a href="#Eureka-Eviction-服务剔除" class="headerlink" title="Eureka Eviction(服务剔除)"></a>Eureka Eviction(服务剔除)</h2><p>当Eureka Client连续默认在90秒内没有给Eureka Service的发送心跳Eureka Service会把该Eureka Client实例剔除．</p><h2 id="Eureka的自我保护"><a href="#Eureka的自我保护" class="headerlink" title="Eureka的自我保护"></a>Eureka的自我保护</h2><p>正常情况下如果默认90秒内Eureka Service没有收到心跳，就会删除相关Eureka Client实例，但是有时并非Eureka Client宕机，而是由于网络原因导致Eureka Service大面积丢失Eureka Client,这时如果Eureka Service收到的心跳小于某个阈值，Eureka Service就会开启自我保护机制：即Eureka Service只能读写而不能执行删除操作，当Eureka Service收到的心跳高于该阈值其就会自动退出自我保护机制．<br>Eureka Service的阈值默认是0.85,默认自动开启.</p><h1 id="Eureka的优点以及不足"><a href="#Eureka的优点以及不足" class="headerlink" title="Eureka的优点以及不足"></a>Eureka的优点以及不足</h1><p><em>在了解Eureka的优点以及不知之前首先要先了解CAP原则．</em></p><h2 id="CAP原则"><a href="#CAP原则" class="headerlink" title="CAP原则"></a>CAP原则</h2><p>CAP原则指的是在一个分布式系统中Consistency(一致性),Availability(可用性)<br>Partition tolerance(分区容错性).<br></p><ul><li><strong>Consistency(一致性):</strong> 分布式系统中的所有数据备份，在同一时刻是否有同样的值,例如当服务器A和服务器B中的数据应该保持一致，当服务器A中的数据改变时，服务器B应该迅速同步.</li><li><strong>Avaliability(可用性):</strong> 意思就是服务器只要收到用户的请求，就必须立刻给用户做出回应．</li><li><strong>Partition tolerance (分区容错性):</strong> 大多数分布式系统都分布在多个子网络中，例如一个服务器A坐落在北京一个服务器B在广州，服务器A,B之间有可能无法通信，所以分区容错在CAP中是无法避免的.</li></ul><p><strong>CAP中P(分区容错)是无法避免的（即一定要保证分区容错性）同时可以看出C(一致性)和A(高可用性)是没有办法兼得，因为当服务A要与服务器B同步消息的某个时刻，用户向未更新消息的服务器B发送指令此时如果要保证一致性，服务器B就会忽略用户的请求，但是如果要保证高可用性,那么服务器B就必须立刻回应用户．</strong><br></p><p>更详细可以看阮一峰大大的博客:<br><a href="http://www.ruanyifeng.com/blog/2018/07/cap.html">CAP 定理的含义</a></p><h2 id="Eureka的优点"><a href="#Eureka的优点" class="headerlink" title="Eureka的优点"></a>Eureka的优点</h2><p>eureka 是保证AP,因此是保证可用性。Eureka Service几个节点宕机不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而eureka Client向某个eureka Service注册时如果发现连接失败，则会自动切换至其他Eureka Service。只要有一台eureka server 是正常的，就能保证服务可用(保证可用性)。不过查询到的信息可能不是最新的(不保证一致性)。</p><h2 id="Eureka的缺点"><a href="#Eureka的缺点" class="headerlink" title="Eureka的缺点"></a>Eureka的缺点</h2><p>很明显Eureka的缺点是不保证一致性．</p><h2 id="Eureka的竞品：Zookeeper"><a href="#Eureka的竞品：Zookeeper" class="headerlink" title="Eureka的竞品：Zookeeper"></a>Eureka的竞品：Zookeeper</h2><p>Zookeeper是保证CP,即保证一致性,即任何时间对Zookeeper的任何服务器访问请求都能到一致的数据结果.这个就不详细讲了.</p><p>感谢:<br><br><a href="http://www.jeepxie.net/article/667918.html">Eureka 与 zookeeper 的区别、原理及各自优缺点</a><br><br><a href="https://zhuanlan.zhihu.com/p/34976125">Spring Cloud Eureka 全解</a><br><br><a href="https://zhuanlan.zhihu.com/p/120377144">Spring Cloud-Eureka学习笔记-简介</a></p>]]></content>
    
    
    <categories>
      
      <category>微服务学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>chapter4-Homework-problems-and-Questions </title>
    <link href="/2020/05/28/chapter4-Homework-problems-and-Questions/"/>
    <url>/2020/05/28/chapter4-Homework-problems-and-Questions/</url>
    
    <content type="html"><![CDATA[<p><img src="1.png" alt="1.png"><br><br><img src="2.png" alt="2.png"><br><br><img src="3.png" alt="3.png"><br><br><img src="4.png" alt="4.png"><br><br><img src="5.png" alt="5.png"><br><br><img src="6.png" alt="6.png"><br><br><img src="7.png" alt="7.png"><br></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chapter4-The-Network-Layer</title>
    <link href="/2020/05/18/Chapter4-The-Network-Layer/"/>
    <url>/2020/05/18/Chapter4-The-Network-Layer/</url>
    
    <content type="html"><![CDATA[<p><strong>In summary , this chapter has three major parts , The first past , section 4.1 and 4.2 cover the network layer function and services. The second part , section 4.3 and 4.4 covers forwarding , finally , the third past ,  section 4.5 through 4.7 covers routing.<br></strong></p><h1 id="4-1-Introduction"><a href="#4-1-Introduction" class="headerlink" title="4.1 Introduction"></a>4.1 Introduction</h1><p>The first past is used to introduce network layer function and services.<br></p><h2 id="4-1-1-Forwarding-and-Routing"><a href="#4-1-1-Forwarding-and-Routing" class="headerlink" title="4.1.1 Forwarding and Routing"></a>4.1.1 Forwarding and Routing</h2><ul><li><p><strong>Forwarding :</strong> When the packet arrives at router’s input link , the router must move the packet to the appropriate output link. Section 4.3 we will look inside router and examine how a packet is actually forwarded from an input link to output link within a router.<br></p></li><li><p><strong>Routing :</strong> The network layer must determine the route or path taken by packets as they flow from sender to receiver. The algorithm that calculated these paths are referred to as routing algorithm . We will discuss routing algorithm inside at section 4.5<br></p></li></ul><p><strong>Forwarding table :</strong> A router forwards a packet by examining the value of a field in the arrived packet’s header and use the header value to index into the router’s forwarding table. The value stored in forwarding table entry for indicate the router’s outgoing link interface to which that packet is to be forwarded .<br><br><img src="Routing-algorithm-determine-value-in-forwarding-tables.png" alt="Routing-algorithm-determine-value-in-forwarding-table"><br></p><p><strong>How to configure the forwarding table of all router at the network.</strong><br><br>The answer is though the routing algorithm. The router receive the routing protocol message which are used to configure its forwarding table.<br></p><p><strong>Routing algorithm:</strong> The routing algorithm has two kinds , one is centralized , another is decentralized.<br></p><ul><li><em>centralized :</em>  Every router has complete information about all other router in the network and the traffic status of the network. These algorithm is known as LS (link state) algorithm.<br></li><li><em>decentralized :</em> Earn router have information about the routers it is directly connected to — it doesn’t know every router in the network. (These algorithm also known as DV (distance vector) algorithm.)</li></ul><h2 id="Connection-Setup"><a href="#Connection-Setup" class="headerlink" title="Connection Setup"></a>Connection Setup</h2><p>Addition to the two importance function (forward and routing) , the third importance function is <strong>connection setup.</strong><br><br>We will examine connection setup in Section 4.2.<br></p><h2 id="4-1-2-Network-Service-Models"><a href="#4-1-2-Network-Service-Models" class="headerlink" title="4.1.2 Network Service Models"></a>4.1.2 Network Service Models</h2><div class="table-container"><table><thead><tr><th style="text-align:center"><strong>Questions:</strong></th></tr></thead><tbody><tr><td style="text-align:center"><em>When the transport layer at a sending host transmits a packet into the network layer , can transport layer rely on the network layer to deliver the packet to destination ?</em></td></tr><tr><td style="text-align:center"><em>When multiple packets is sent , will they be delivered to the transport layer in the receiver’s host in order in which they were sent ?</em></td></tr><tr><td style="text-align:center"><em>will the amount of time between the send of two sequential packet transmission be same as the amount of time between their reception?</em></td></tr><tr><td style="text-align:center"><em>will the network provide the feedback about the congestion in the network?</em></td></tr><tr><td style="text-align:center"><em>what is the abstract view(properties) of the channel connecting the transport layer in the sending and receiving hosts?</em></td></tr></tbody></table></div><p><strong>The answer depend on provided network service model.<br><br>The specific services that could be provide by network layer include :<br></strong></p><div class="table-container"><table><thead><tr><th style="text-align:center">Network Service Models</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center"><em>Guaranteed delivery</em></td><td style="text-align:center">This service guaranteed that packet will eventually arrive at destination.</td></tr><tr><td style="text-align:center"><em>Guaranteed delivery with bounded delay</em></td><td style="text-align:center">This service not only guaranteed delivery of packets , but also delivery within a specified host-to-host delay bounded.</td></tr><tr><td style="text-align:center"><em>In-order packet delivery</em></td><td style="text-align:center">This service guaranteed that packet arrived at the destination in the order that they were sent.</td></tr><tr><td style="text-align:center"><em>Guaranteed minimal bandwidth</em></td><td style="text-align:center">The network layer service emulates the behavior of transmission a specified bit rate (for example 1Mbps) between sending and receiving host. As long as sending host transmits bits at a rate below the specified bit rate , then no packet lost and packet arrived within a prespecified host-to-host delay.(for example 40 msc).</td></tr><tr><td style="text-align:center"><em>Guaranteed maximum jitter</em></td><td style="text-align:center">The service guaranteed that the amount of time between the transmission of two successive packets at the sender is equal to the amount of time between their receipt at destination.(or that this spacing changes by no more than some specified value).</td></tr><tr><td style="text-align:center"><em>Security service</em></td><td style="text-align:center">Using a secret session key known by a source and destination host , the network layer in the source host could encrypt the payloads of all datagrams being sent to the destination , the network layer in the destination host would then be responsible for decrypting the payloads. In addition to confidentiality, the network layer could provide data integrity and source authentication services.</td></tr></tbody></table></div><h3 id="Internet-ATM-CBR-and-ATM-ABR-service-models"><a href="#Internet-ATM-CBR-and-ATM-ABR-service-models" class="headerlink" title="Internet , ATM CBR and ATM ABR service models."></a>Internet , ATM CBR and ATM ABR service models.</h3><ul><li><strong>Internet-Best-effort-service</strong></li><li><strong>Constant bit rate (CBR) ATM network service</strong></li><li><strong>Available bit rate (ABR) ATM network service</strong><br><img src="Internet-ATM.png" alt="Internet-ATM"><br></li></ul><h1 id="4-2-Virtual-Circuit-and-Datagram-Networks"><a href="#4-2-Virtual-Circuit-and-Datagram-Networks" class="headerlink" title="4.2 Virtual Circuit and Datagram Networks"></a>4.2 Virtual Circuit and Datagram Networks</h1><p>Similar to UDP and TCP , the network layer also provide the connectionless service and connection-oriented service.<br></p><p>In all computer network architectures to data (Internet , ATM , frame relay , and so on ) the network layer provides either a host-to-host connectionless service or a host-to-host connection service , but not both . Computer networks that provide only a connection service at network layer are called <strong>Virtual-circuit(VC) networks</strong> , computer network that provide only connectionless service at the network layer are called <strong>datagram networks</strong>.</p><h2 id="4-2-1-Virtual-Circuit-Networks"><a href="#4-2-1-Virtual-Circuit-Networks" class="headerlink" title="4.2.1 Virtual-Circuit Networks"></a>4.2.1 Virtual-Circuit Networks</h2><p><strong>A VC consists of :</strong><br><br>(1). A path (that is , a series of links and routers) between the source and the destination hosts <br><br>(2). VC number one number for each link along the path .<br><br>(3). Entries in the forwarding table in each router along the path. A packet belonging to a virtual circuit will carry a VC number in its header. Because a virtual circuit may have a different VC number on each link. Each intervening router must replace the VC number of each traversing packet with a new VC number . The new VC number is obtained from forwarding table.<br></p><p><strong>For example:</strong><br><br>suppose The host A request to establish VC connection between itself and host B , We choose the path is A-R1-R2-B , suppose we set 12 , 22 and 32 to these three link. Hence , the value of VC number field is 12 when the packet leave  host A , the value of VC number field is 22 when the packet leave  R1 , the value of VC number field is 32 when the packet leave  R2 .<br><img src="Simple-Virtual-Circult-Network.png" alt="Simple-Virtual-Circult-Network.png"><br><br><img src="Simple-VC-Path.png" alt="Simple-VC-Path.png"><br></p><p>Whenever a new VC is established across a router , an entry is added to the forwarding table . Similarly , whenever a VC terminates , the appropriate entry in each table along its path are removed. — <strong>In a VC network , the network router must maintain connection state information for each ongoing connection</strong><br></p><p><strong>Three identifiable phases in a virtual-circuit network.</strong><br></p><ul><li><strong>VC setup:</strong> The network layer determines the path between sender and receiver , that is the series of link and routers through which all packets of VC will travel. The network layer also determines the VC number for each link along the path. Finally , the network layer add the entry to forwarding table in each router along the path. During the VC setup , the network layer may also reserve resource (for example : bandwidth) along the path of VC.</li><li><strong>Data transfer :</strong> The VC connection have been established , packets can being flow along the VC.</li><li><strong>VC teardown:</strong> This is initiated when the sender (or receiver) informs the network layer of its desire to terminate the VC connection , The network layer will typically inform the end system on the other side of the network of call termination and update the forwarding tables in each of packet routers on the path to indicate that the VC no long exist.<br></li></ul><p><strong>Signaling Message and Signaling Protocol</strong><br></p><ul><li><strong>Signaling Message:</strong> The message that the end systems send into the network to initiate or terminate a VC , the message passed between the routers to setup the VC (that is to modify connection state in router table ).</li><li><strong>Signaling Protocol :</strong> The protocol used to exchange signaling message are often referred to as signaling protocol.<br><img src="Virtual-Circuit-Setup.png" alt="Virtual-Circuit-Setup.png"><br></li></ul><p><em>More detail about the signaling protocol and signaling message see [Black 1997] for a general discussion of signaling in connection-oriented networksand [ITU-T Q.2931 1995] for the specification of ATM’s Q.2931 signaling protocol.</em><br></p><h2 id="4-2-2-Datagram-Networks"><a href="#4-2-2-Datagram-Networks" class="headerlink" title="4.2.2 Datagram Networks"></a>4.2.2 Datagram Networks</h2><p>In the datagram networks , each time and end system want to send a packet , it stamps the packet with the address of the destination end system and then pop the packet into the network . As shown in figure follow , <strong>these is no VC setup and routers do not maintain any VC state information (because there are no VCs)</strong><br><img src="Datagram-Network.png" alt="Datagram-Network.png"><br></p><p>As a packet is transmitted from source to destination , it passes through a series of routers , Each of these router use the packet’s destination address to forward the packet , Specifically , each router these of router has a forwarding table map the destination address to link interfaces , When a packet arrived at the router , the router use the packet’s destination address to look up appropriate link interface in the forwarding table , the router then intentionally forwards the packet to the output link interface. <br></p><p><img src="Datagram-Forwarding-Table.png" alt="Datagram-Forwarding-Table.png"><br><br>When these are multiple matches , the router uses the <strong>longest prefix matching rule</strong> that is finding the longest matching entry in the forwarding table , and then forwards the packet to link interface associated with the longest prefix match.<br></p><p><em>The time scale at which this forward state information (forward table entry) change is relatively slow. Indeed in a datagram network the forwarding table are modified by routing algorithm. which typically update a forwarding table every one-to-five minutes or so.</em> </p><h1 id="4-3-What’s-Inside-a-Router"><a href="#4-3-What’s-Inside-a-Router" class="headerlink" title="4.3 What’s Inside a Router?"></a>4.3 What’s Inside a Router?</h1><p>A high-level view of a generic router architecture is shown in figure follow . Four router components can be identified :<br></p><ul><li><strong>Input port :</strong> An input port perform several key functions .<ul><li>It performs the physical layer function of terminating an incoming physical link at router. (Occurring in leftmost box of input port<br>and rightmost box of output port.)<br></li><li>It performs the link-layer functions needed to interoperate<br>with the link layer at other side of incoming link . (Occurring in middle box in the input and output ports)<br></li><li>It perform the lookup functions that is the forwarding table is consulted to determine the router output port to which an arriving packet will be forwarded via the switching fabric. (Occurring in the rightmost box of input port)</li></ul></li><li><strong>Switching Fabric :</strong> The switching fabric connects the router’s input port to its output port.<br></li><li><strong>Output port:</strong> An output port store the packet from switching fabric and transmits these packets on outgoing link by performing the necessary link-layer and physical-layer functions.<br></li><li><strong>Routing Processor :</strong> The routing processor executes the routing protocol (study in section 4.6) maintain routing table and attached link state information and computer the forwarding table for the router .It also perform the network management (study in chapter 9).<br><img src="Router-Architecture.png" alt="Router-Architecture.png"><br></li></ul><p>A router input port , output port and switch fabric together implement the forwarding function and almost always implemented in the hardware.<br></p><h2 id="4-3-1-Input-Processing"><a href="#4-3-1-Input-Processing" class="headerlink" title="4.3.1 Input Processing"></a>4.3.1 Input Processing</h2><p>The lookup performed in the input port is central to the router’s operation — it is here that the router uses the forwarding table to lookup the output port to which an arrived packet will be forwarded via switching fabric , the forwarding table is computed and updated by the router processor. The forwarding table is copied from the routing processor to the line cards over separate bus (eg: PCI bus). With the forwarding table copies , forwarding decision can be made locally , at each input port , without invoking the centralized routing processor. Once a packet’s output port have been determined via the lookup , the packet can be sent into the switching fabric.<br><br><img src="Input-Port-Processing.png" alt="Input-Port-Processing.png"><br></p><p><strong>Although lookup is arguably the most importance action in input port processing many other action must be taken :</strong> <br></p><ul><li>Physical and link layer processing must be occur as discussed above;</li><li>The packet’s version number , checksum and time-to-live-field (We will study in section 4.4.1)<br></li><li>counter used to network management (such as the number of IP datagram received) must be updated.</li></ul><h2 id="4-3-2-Switching"><a href="#4-3-2-Switching" class="headerlink" title="4.3.2 Switching"></a>4.3.2 Switching</h2><p><img src="Three-Switching-Techniques.png" alt="Three-Switching-Techniques.png"><br><br><strong>Switching can be accomplished in a number of way , as shown in figure above.<br></strong></p><ul><li><p><strong>Switching via memory :</strong> The simplest , earliest routers were traditional computers with switching between the input ports and output ports being done direct control of the CPU (routing process). Input port and output ports functioned as traditional I/O devices in traditional operating system. An input ports with an arriving packet signaled the routing process via an interrupt , The packet was then copied from input port to processor memory. The routing process was then extracted the destination address from the header , look up the appropriate outpost in the forwarding table , and copied the packet to the output post’s buffer.<br><strong>Note that two packet can not be forwarded at the same time even if they has different destination ports. So that packets transferring speed is very slow.</strong> Many modern routers switch via memory. A major difference from early routers,however, is that the lookup of the destination address and the storing of the packet into the appropriate memory location are performed by processing on the input line cards.</p></li><li><p><strong>Switching via bus:</strong> In this approach , an input port transfers packet directly to output port without intervention by the routing process. This is typically done by having the input port pre-pend a switching internal label (header) to the packet indicating the local output port to which this packet is being transferred and transmitting the packet onto the bus. The packet is received by all output posts , but only the port that matches the label will keep this packet. The label is then removed at the outpost port. <strong>If multiple packets arrive to the router at the same , each at a different input ports , all but one must wait since only one packet can cross the bus at a time .(The roundabout could only contain one car at a time)</strong></p></li><li><p><strong>Switching via an interconnection network:</strong> A crossbar switch is an interconnection network consisting of 2N buses that connect N input ports and N output ports . Each vertical bus intersects intersects each horizontal bus at a crosspoint , which can opened and closed at any time by switching fabric controller. When a packet arrives from post A and need to be forwarded to post B , the switch controller closes the crosspoint at intersection of buses A and Y and port A sends the packet onto its bus , which is picked up (only) by bus Y. Note that the packet from B need to be forwarded to post X at the same time , <strong>crossbar network are capable of forwarding multiple packet in parallel, However if two different input post destined to same output post , the one have to wait at the input port.</strong></p></li></ul><h2 id="4-3-3-Output-processing"><a href="#4-3-3-Output-processing" class="headerlink" title="4.3.3 Output processing"></a>4.3.3 Output processing</h2><p>Output post processing take packets that have been stored in the output port’s memory and then transmit them over the output link. This include selecting and de-queueing packet for transmission and performing the needed link-layer and physical-layer transmission functions.<br><br><img src="Output-Port-Processing.png" alt="Output-Port-Processing.png"><br></p><h2 id="4-3-4-Where-Does-Queueing-Occur"><a href="#4-3-4-Where-Does-Queueing-Occur" class="headerlink" title="4.3.4 Where Does Queueing Occur ?"></a>4.3.4 Where Does Queueing Occur ?</h2><p>It’s clear that packet queue may form at both the input port and the output port.<br><br><img src="Output-Port-Queueing.png" alt="Output-Port-Queueing.png"><br><br>In this scenario (<em>$R<em>{switch}$ fast enough $R</em>{link}$</em> ), packets arriving at each of N input ports and destined to same the output port. Since the output port can transmit only a single packet in a unit of time(a packet transmission time) . The N arriving packets will have to queue(wait) for transmission over to outgoing link. Eventually if the number of queued packets grow large enough to exhaust available memory at the output port , in which case packet are dropped.<br><br>A consequence of output port queueing is that <strong>packet scheduler</strong> at the output port must choose a packet among those queued for transmission. The selection may be first-come-fist-served (FCFS) , weighted fair queueing (WFQ) which shares the outgoing link fairy among the different end-to-end connections that have packets queued for transmission.<br><br>Similarly , if there is not enough memory to buffer an incoming packet , a decision must be made to either drop arriving packet or remove one or more already-queued packets to make room for newly arriving packet.<br>For example : <em>Active Queue Management (AQM) algorithm</em> and <em>Random Early Detection (RED) algorithm</em><br><br>If <em>$R<em>{switch}$ not fast enough $R</em>{link}$</em> The switch fabric to transfer all arriving packets though the fabric without delay , then packet queueing can also occur at the input ports that is packets must join input port to wait turn to be transferred though the switching fabric to output port.<br><br><img src="HOL-Block-At-An-Input-Queued-Switch.png" alt="HOL-Block-At-An-Input-Queued-Switch.png"><br><br>Figure above shown an example , and suppose that<br><br><strong>(1)</strong>.the switching fabric is crossbar switching fabric.<br><br><strong>(2)</strong>.Packets are moved from a given input queue to their desired output queue in an FCFS manner. Two packets (<em>darkly shaded, port 1,3</em>) at the front of their input port queues are destined for the same upper-right output port. Suppose that the switching fabric choose to transfer the packet from the front of the upper-left queue. In this case the packet in lower-left queue must wait , not only darkly shaded must be wait , but also the lightly shaded packet that behind the darkly shaded in the lower-left queue even though it destined for middle-right output port . This phenomenon is knowns as <strong>head-of-the-line (HOL) blocking.</strong></p><h1 id="4-4-The-Internet-Protocol-IP-Forwarding-and-Addressing-in-the-Internet"><a href="#4-4-The-Internet-Protocol-IP-Forwarding-and-Addressing-in-the-Internet" class="headerlink" title="4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet."></a>4.4 The Internet Protocol (IP) : Forwarding and Addressing in the Internet.</h1><p><strong>Inside of the Internet’s Network Layer:</strong><br><br><img src="A-Look-Inside-The-Internet-Network-Layer.png" alt="A-Look-Inside-The-Internet-Network-Layer.png"><br><br><strong>The three major component inside the internet network:</strong></p><ul><li><strong>IP Protocol</strong></li><li><strong>Routing Component (Routing protocol study in section 4.6)</strong></li><li><strong>Report error and in datagram and respond to request for certain network-layer information. Internet Contorl Message Protocol (ICMP) studied in section 4.4.3</strong></li></ul><h2 id="4-4-1-Datagram-Format"><a href="#4-4-1-Datagram-Format" class="headerlink" title="4.4.1 Datagram Format"></a>4.4.1 Datagram Format</h2><p>The network-layer packet is referred to as a datagram.<br><br><strong>Ipv4-Datagram-Format:</strong><br><br><img src="Ipv4-Datagram-Format.png" alt="Ipv4-Datagram-Format.png"><br><br><strong>The key field of Datagram format are following:</strong><br></p><ul><li><strong>Version number :</strong> These 4 bits specify the IP protocol version of the datagram , by look at the version number , the router can determine how to interpret the remainder of IP datagram . Different Version of IP use different datagram format.<br></li><li><strong>Header length:</strong> Because the IPv4 datagram contain a variable number of options (which are included in the IPv4 datagram header) This 4 bits is needed to determine where the data actually being in the datagram . Most Ipv4 datagram don’t contain option , so the typical IP datagram has a 20 bytes header.</li><li><strong>Type of service:</strong> The type of service bits were included in ipv4 header to allow different types of datagram (for example : requiring low delay , hight throughput or reliability).</li><li><strong>Datagram length:</strong> This is a total length of the IP datagram (Header Plus Data) , since this field is 16 bits , so that the maximum size of the IP datagram is 65535 bytes, however datagram rarely larger than 1500 bytes.</li><li><strong>Identifier , flags , fragmentation offset:</strong> These three field we will consider depth in shortly.</li><li><strong>Time-to-live:</strong> The field used to ensure that datagram don’t circulate forever in the network.</li><li><strong>Protocol :</strong> The value of this field is used to indicates the specific transport-layer-protocol to which the data portion of this datagram should be passed , for example the value 6 represent TCP and the value 17 represent UDP.</li><li><strong>Header Checksum :</strong> The header checksum aids a router detecting bit error in a received IP datagram.<br><br><strong>Why does TCP/IP perform error checking at both the transport and network layer.</strong><br><ul><li><em>only the IP header is checksummed at the IP layer while the TCP/UDP checksum is computed over the entire TCP/UDP segment.</em></li><li><em>TCP/UDP and IP do not necessarily both have to belong to the same protocol stack. IP also can service other protocol (different to TCP/UDP).</em></li></ul></li><li><strong>Source and Destination IP Addresses</strong></li><li><strong>Options :</strong> The options flied allow an IP header to be extended.</li><li><strong>Data field (payload):</strong> In most circumstance , the data field of the IP datagram contains the transport-layer segment (for example UDP/TCP) . However , the data field can carry other types of data such as ICMP message .</li></ul><h3 id="IP-datagram-fragmentation"><a href="#IP-datagram-fragmentation" class="headerlink" title="IP datagram fragmentation"></a>IP datagram fragmentation</h3><p>Since not all link-layer protocol can carry network-layer protocol of the same size . Some protocol can carry big datagrams , whereas other protocols can only a little packets. (for example : Ethernet frames carry 1500 bytes of data, the wide-area links can no more than 576 bytes.)<br></p><p><em>Because each IP datagram is encapsulated within the link-layer frame for transport from one router to next router. The problem is that each of link along the router between sender and destination can use different link-layer protocols and each of those protocol can have different MTUs(maximum transmission unit).<br></em></p><p>Suppose the router have MTU that is smaller than the length of the IP datagram . How to squeeze this oversize IP datagram into the payload field of the link-layer frame?<br><br>The solution is to fragment the data in the IP datagram into two or more smaller IP datagrams , encapsulate each of these smaller IP datagram in a separate link-layer frame and send these frames over the outgoing link . Each of these smaller datagram is referred to as a fragment.<br><br>Fragment need to reassembled before they reached the transport layer at the destination . Indeed both TCP and UDP expecting to complete, unfragmented segment from the network layer.<br></p><p><strong>How to determine a packet whether or not a fragment , how to reassemble these fragment and when the destination host have received the last fragment of some original larger datagram.</strong><br><br>The answer is three field in the ipv4 datagram header.<br></p><ul><li><strong>16-bits-identifier field:</strong> When a datagram is created , the sending host stamps the datagram with an identification number as well as source and destination address. Typically , the sending host increments the identification number of each datagram it sends.<br></li><li><p><strong>13-bits Fragmentation offset:</strong> When a router need to fragment a datagram , each resulting fragment is stamped with the source and destination address , and identification number of original datagram , and then the Fragmentation offset field is used to specify where the fragment fit within the original IP datagram.<em>(unit is bit)</em></p></li><li><p><strong>Flags field:</strong> This field is used to identify the last fragment of Original Ipv4 datagram . The last fragment has a flags bit set to 0 , and other fragment has a flags bit set to 1.<br><br><img src="IP-fragmentation-and-reassembly.png" alt="IP-fragmentation-and-reassembly.png"><br><br><img src="Ip-fragments.png" alt="Ip-fragments.png"><br><br>If one or more fragment does not arrive , the incomplete fragments is discarded and not passed to transport layer , and The transport layer protocol is TCP , TCP will recover this loss by retransmission.<br></p></li></ul><h2 id="4-4-2-IPv4-Addressing"><a href="#4-4-2-IPv4-Addressing" class="headerlink" title="4.4.2 IPv4 Addressing"></a>4.4.2 IPv4 Addressing</h2><ul><li><strong>Interface :</strong> The boundary between the host and physical link is called an interface.</li></ul><p><strong>A router has multiple interfaces and each of these interfaces have its own unique IP address.</strong><br><img src="Interface-Address-And-Subnets.png" alt="Interface-Address-And-Subnets.png"><br></p><ul><li><strong>Subnet:</strong> To determine the subnet detach each interface from its host and router , creating islands of isolated networks with interfaces terminating the end points of isolated networks , Each of these isolated networks is called a subnet.<br></li></ul><p>Shown as figure above , In the upper-left , this network interconnecting three host interfaces and one router interface forms a <strong>subnet</strong>. IP addressing assigns an address to this subnet : 223.1.1.0/24 , where the /24 notation , sometime known as <strong>subnet mask</strong>, Indicate that the leftmost 24-bits of 32-bits quantity define the subnet address.</p><p>The internet’s addressing assignment strategy is known as <strong>Classless Interdomain Routing (CIDR)</strong> As with subnet addressing , the 32-bits IP address is divided into two parts and again has the dotted-decimal form a.b.c.d/x , where x indicates the number of bits in the first past of the address (<strong>network prefix</strong>) . When we cover the internet BGP routing protocol in the section 4.6 , we will see that only these leading x prefix bits are considered by routers the organization’s network. That is when a router outside the organization forwards a datagram whose destination address is inside the organization only these leading x bits of the address need be considered . The remaining $32-x$ bits of an address can be though of as distinguishing among the devices within the organization. These bits will be considered when forwarding packets at routers within the organization.<br></p><p><em>The special IP address : 255.255.255.255 (IP broadcast address), when a host send a datagram with destination address 255.255.255.255, this message is delivered to all host on the same subnet.</em></p><h3 id="Obtaining-a-Block-of-Address"><a href="#Obtaining-a-Block-of-Address" class="headerlink" title="Obtaining a Block of Address"></a>Obtaining a Block of Address</h3><p><em>Internet corporation  for Assigned Name and Number (ICANN) has responsibility for managing the IP address space and allocating address blocks to ISPs and other organizations.<br></em></p><p>In order to obtain a block of IP addresses for use within an organization’s subnet , a network administrator might first contract its ISP , while would provide addresses from a larger block of addresses that had already been allocated to the ISP. For example , the ISP may itself have been allocated the address block 200.23.16.0/20 ,the ISP divide its address block into eight equal-sized contiguous address block and give one of these address block out to each of up to eight organizations.<br><br><img src="Organization-Address.png" alt="Organization-Address.png"><br></p><h3 id="Obtaining-a-host-Address-The-Dynamic-Host-Configuration-Protocol"><a href="#Obtaining-a-host-Address-The-Dynamic-Host-Configuration-Protocol" class="headerlink" title="Obtaining a host Address : The Dynamic Host Configuration Protocol"></a>Obtaining a host Address : The Dynamic Host Configuration Protocol</h3><p>Once an organization obtained a block of addresses it can assign individual IP address to host and router interface in its organization.<br>The router IP address typically manually configure by a system administrator. The host IP address typically configure by using <strong>Dynamic Host Configuration Protocol (DHCP)</strong> DHCP allows a host obtain an IP address automatically. As the host join and leave , the DHCP server need to update its list of available IP addresses.<br></p><p>DHCP is a client-service protocol . A client is typically a newly arriving host wanting to obtain network configuration informations. Each subnet have a DHCP service . If no server is present on the subnet , a DHCP relay agent (typically a router) that knows the address of a DHCP service for that network is needed , for example show as figure below , DHCP service attached to subnet 223.1.2/24 , with the router serving as relay agent for arriving clients attached to subnet 223.1.1/24 and 223.1.3/24 .<br><br><img src="DHCP-Client-Server-Scenario.png" alt="DHCP-Client-Server-Scenario.png"><br></p><p><strong>When a newly arriving host income to subnet , The DHCP has four steps for assign a IP address to new host.<br></strong></p><ul><li><p><strong>DHCP server discovery:</strong>  This is done using <strong>DHCP discovery message</strong> The new host send a DHCP discovery message with a UDP packet , port 67 source IP address : 0.0.0.0 (since , new host hasn’t IP address) and destination IP address : 255.255.255.255 (broadcast address). The UDP packet is encapsulated in a IP datagram and then passed to the link-layer. (We will cover the detail of broadcast in section 5.4)<br></p></li><li><p><strong>DHCP server offer(s) :</strong> A DHCP server receiving a DHCP discovery message responds to the client with the <strong>DHCP offset message</strong> that is broadcast to all notes on the subnet using the broadcast IP address : 255.255.255.255. Each server offer message contain the transaction ID of the receiver discovery message , the proposed IP address for the client , the network mask , and an IP address lease time . </p></li><li><p><strong>DHCP request :</strong> The newly arriving client will choose from among one or more server offers and respond to its selected offer with <strong>DHCP request message</strong> echoing back the configuration parameters.</p></li><li><p><strong>DHCP ACK:</strong> The server responds to the DHCP request message with a <strong>DHCP ACK message</strong> confirming the requested parameters.<br></p></li></ul><p><em>yiaddr(as in “your Internet address”)</em><br><img src="DHCP-Client-Server-Interaction.png" alt="DHCP-Client-Server-Interaction.png"><br><br>Once the clients receives the DHCP ACK , the interaction is compelte and client can use the DHCP-allocated IP address for the lease duration. Since a client may want to use its address beyond the lease’s expiration , DHCP also provide a mechanism that allow a client to renew its lease on an IP address.<br></p><h3 id="Network-Address-Translation-NAT"><a href="#Network-Address-Translation-NAT" class="headerlink" title="Network Address Translation (NAT)"></a>Network Address Translation (NAT)</h3><p>With proliferation of small office , home office (for example , the kid at home not only their computer but have one or more smartphone and networked game ..etc) , the ISP have not enough IP address to handle this scenarios , what should we do in this scenarios.<br></p><p>The answer is NAT (Network Address Translation)<br><br><strong>Figure follow is show the operation of NAT-enabled router.<br></strong><br><img src="Network-Address-Translation.png" alt="Network-Address-Translation.png"><br><br>In figure above all traffic leaving the home router for for the larger internet has a source IP address of 138.76.29.7 and all traffic entering the home router must have a destination IP address 138.76.29.7. In essence the NAT-enabled router is hiding the detail of the home network from the outside world.<br></p><ul><li><p><strong>Question: How the home network computer (or other network device) get their home IP address (for example 10.0.0.0/24)?</strong><br><br>The answer is DHCP , The router get its IP address from the ISP’s DHCP server and the router runs a DHCP server to provide addresses to computer (or other device ) within the NAT-DHCP-router-controlled-home-network’s-address-space.<br></p></li><li><p><strong>Question : If all datagram arriving at the NAT-Router from the WAN have the same destination IP address , how does the router know the internal host which it should forward a given datagram.</strong> <br><br>The trick is use a <strong>NAT translation table</strong> at the NAT router , and to include port number as well as IP addresses in table entries. For example shown as figure above , the host computer 10.0.0.1 request a web page on some web server (port 80) with IP address 128.119.40.186 . The host 10.0.0.1 assigns the (arbitrary) source port number 3345 and send the datagram into the LAN , The NAT-Router receives the datagram , genarates a new source port number 5001 , replace the source IP address with it WAN-side IP address 138.76.29.7 and replace the original source number 3345 with its new source port number 5001. NAT-Router adds an new entry to its NAT translation table and send a new datagram to WAN , when a datagram arriving at the NAT-Router , the NAT-Router use the destination IP address and destination port to obtain appropriate IP address (10.0.0.1) and destination port (3345) , then send a datagram to home network.</p></li></ul><h3 id="UPnP"><a href="#UPnP" class="headerlink" title="UPnP"></a>UPnP</h3><p>The detail we can see the textbook page 352.</p><h2 id="4-4-3-Internet-Control-Message-Protocol-ICMP"><a href="#4-4-3-Internet-Control-Message-Protocol-ICMP" class="headerlink" title="4.4.3 Internet Control Message Protocol (ICMP)"></a>4.4.3 Internet Control Message Protocol (ICMP)</h2><p>ICMP protocol is used by hosts and router communicate network-layer informations to each other. The most typical use of ICMP is error reporting.<br><br>The ICMP message is carried inside the IP datagrams , that is ICMP messages are carried as IP payload.<br></p><p>ICMP message have a type field and a code field and checksum field.<br><br><img src="General-en.svg.png" alt="General-en.svg.png"><br></p><p><strong>The ICMP control message :</strong><br><br><img src="ICMP-Message-Types.png" alt="ICMP-Message-Types.png"><br></p><h2 id="4-4-4-IPv6"><a href="#4-4-4-IPv6" class="headerlink" title="4.4.4 IPv6"></a>4.4.4 IPv6</h2><h3 id="IPv6-Datagram-Format"><a href="#IPv6-Datagram-Format" class="headerlink" title="IPv6 Datagram Format"></a>IPv6 Datagram Format</h3><p><strong>Most importance changes introduced in IPv6 :<br></strong></p><ul><li><p><strong>Expanded addressing capabilities :</strong> IPv6 increases the size of the IP address from 32 bits to 128 bits . This ensure that the world won’t run out of IP address. In addition to unicast and multicast address , IPv6 introduced a new type of address called <strong>anycast address</strong><br></p></li><li><p><strong>A streamlined 40-byte header :</strong> A number of IPv4 fields have been dropped or made optional , The resulting 40-bytes-fixed-length header allows for faster processing of the IP datagram . A new encoding of option allow for more flexible option processing.</p></li><li><p><strong>Flow labeling and priority :</strong> The IPv6 header also has an 8-bits traffic class field. This field can be used to give priority to certain datagram within a flow or it can be used to give priority to datagram from certain application (for example ICMP) over datagram from other applications (for example : network new).</p></li></ul><p><img src="IPv6-Datagram-Format.png" alt="IPv6-Datagram-Format.png"><br></p><p><strong>The following fields defined in IPv6:</strong></p><ul><li><strong>Version :</strong> This 4-bits field identifies the IP version number.<br></li><li><strong>Traffic class :</strong> This 8-bits field is similar in spirit to the TOS (Type of service) field we saw in IPv4.</li><li><strong>Flow label :</strong> This 20-bits is used to identify a flow of datagrams.<br></li><li><strong>Payload length :</strong> This 16-bits is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fix-length 40-byte datagram header.</li><li><strong>Next header :</strong> This field is used identifies the protocol to which the content of this datagram will be delivered. This field uses the same values as the protocol field in the IPv4 field.</li><li><strong>Hop limit :</strong> The content of this field are decremented by one by each router that forward the datagram . If the hop limit count reaches zero , the datagram is discarded.</li><li><strong>Source and destination address :</strong> 128-bits IP address.</li><li><strong>Data :</strong> This is the payload portion of the IPv6 datagram.</li></ul><p><strong>The several fields appearing in the IPv4 datagram are no longer present in the IPv6 datagram.</strong><br></p><ul><li><strong>Fragmentation/Reassembly :</strong> IPv6 do not allow for fragmentation and reassembly at intermediate . These operations performed only by the source and destination . If an IPv6 datagram received by a router is too large to be forwarded over the outgoing link , the router simply drops the datagram and sends “a packet too big” ICMP error message back to the sender , the sender can then resend the packet using a smaller IP datagram size. Fragmentation and reassembly is a time-consuming operation ; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up IP forwarding within the network.</li><li><strong>Header checksum :</strong> Because the transport-layer and link-layer protocols in the internet layers perform checksumming , the designers of IP protocol felt that this functionality was sufficiently redundant in the network layer could be removed. The IPv4 header checksum needed to recomputed at every router , As with fragmentation and reassembly , this too was a costly operation in IPv4.</li><li><strong>Options :</strong> An options field is no longer a part of the standard IP header. However , it has not gone away . Instead the option field is one of possible next header pointed to from within the IPv6 header . Just as TCP or UDP protocol headers can be the next header within an IP packet .</li></ul><p><em>A new version of ICMP protocol is known as ICMPv6 , that is used to service for IPv6</em></p><h3 id="Transitioning-from-IPv4-to-IPv6"><a href="#Transitioning-from-IPv4-to-IPv6" class="headerlink" title="Transitioning from IPv4 to IPv6"></a>Transitioning from IPv4 to IPv6</h3><p>We have two approaches for gradually integrating IPv6 hosts and routers into an IPv4 world (with the long-term goal, of course, of having all Ipv4 node eventually translation to IPv4).<br></p><p><strong>Dual-Stack Approach :</strong><br><br>That is IPv6 nodes also have complete IPv4 implementation. That has the ability to send and receive an both IPv4 and IPv6 datagram ; when interoprating with an IPv4 node an IPv6/IPv4 node can use IPv4 datagram , when interopratig with an IPv6 node it can speak IPv6. IPv6 and IPv4 nodes must have both IPv6 and Ipv4 address.<br><br><img src="A-Dual-Stack-Approachs.png" alt="A-Dual-Stack-Approachs.png"><br></p><p><strong>Problem :</strong> <br><br>As figure above , The node A communicate with node F , and node A send a datagram to node F , when a datagram is sent from node B (IPv6) to node C (IPv4) , The node B must create a new datagram to send to node C , the data field of the IPv6 can be copied into the data field of the IPv4 datagram and appropriate address mapping can be done . However , in performing the conversion from IPv6 to IPv4 , there will be IPv6-specific fields in the datagram (for example the flow identifier field) that have no counterpart in IPv4 , The information in these fields will be lost.<br></p><p><strong>Tunneling (An alternative to the dual-stack approach):</strong><br><br><em>Tunneling can solve the problem note above.</em><br><br><img src="Tunneling.png" alt="Tunneling.png"><br><br>Suppose two IPv6 nodes (for example : B and E in the figure above) want to interoperate using IPv6 datagram but are connected to each other by intervening IPv4 routers. We refer to the intervening set of IPv4 router between two IPv6 router as a <strong>tunnel</strong>. With tunneling , the IPv6 node on the send side of the tunnel (node B) **takes the entire IPv6 datagram and put it into the data field (payload) of IPv4 datagram.<br>This IPv4 datagram is then addressed to the IPv6 node on the receiving side of the tunnel (node E) and sent to the first node in the tunnel (node C). The IPv6 node on the receiving side of the tunnel eventually receives the IPv4 datagram (it is a destination of IPv4 datagram!) determine that IPv4 datagram contain an IPv6 datagram , extract the IPv6 datagram and then routes the IPv6 datagram exactly as it would if it had received the IPv6 datagram from a directly connected IPv6 neighbor.<br></p><h2 id="4-4-5-A-Brief-Foray-into-IP-Security"><a href="#4-4-5-A-Brief-Foray-into-IP-Security" class="headerlink" title="4.4.5 A Brief Foray into IP Security"></a>4.4.5 A Brief Foray into IP Security</h2><p>Using IPsec protocol provide security service . (more detail see the chapter 8).</p><h1 id="4-5-Routing-Algorithm"><a href="#4-5-Routing-Algorithm" class="headerlink" title="4.5 Routing Algorithm"></a>4.5 Routing Algorithm</h1><p><strong>Routing Algorithm operating in network routers , exchange and compute the information that is used to configure these forwarding table .</strong><br><br>Whether network layer provide datagram service (packet between the source and destination may takes many different routes)or VC service (packet between the source and destination take the same path) , the network layer must determine the path that packets take from sender to receiver.<br></p><p><em>We will see the job of routing is determine the good paths <strong>(least-cost-path)</strong> from senders to receivers through the network of routers.</em></p><p><strong>Classify routing algorithm according to whether they are global or decentralized.</strong><br></p><ul><li><strong>A global routing algorithm :</strong> Computes the least-cost path between a source and destination using complete global knowledge about the network.(complete global knowledge is mean all node connectively relationship and link cost in the network). In practice algorithm with global state information are often referred to as <strong>Link-state(LS) algorithm</strong>.<br></li><li><strong>A decentralized routing algorithm :</strong> The calculation of least-cost path is carried out in an iterative , distributed manner. No node have complete information about the cost of all network link , instead each node begins with only the knowledge of the cost of its own directly attached links. Then through an iterative process of the calculation and exchange of information with its neighboring nodes , a node gradually calculates the least-cost path to destination or set of destinations. The decentralized routing algorithm is called distance-vector (DV) algorithm .</li></ul><h2 id="4-5-1-The-Link-State-LS-Routing-Algorithm"><a href="#4-5-1-The-Link-State-LS-Routing-Algorithm" class="headerlink" title="4.5.1 The Link-State (LS) Routing Algorithm"></a>4.5.1 The Link-State (LS) Routing Algorithm</h2><p>In practice , The Link-State Routing Algorithm is accomplished by having each node broadcast link-state packets to all other nodes in the network , with each link-state packet containing the identifies and cost of it attached links. The result of the note’s broadcast is that all node have an identical and complete view of the network.  Each node can then run the LS algorithm and compute the same set of least-cost paths as every other node.</p><p>The LS algorithm is known as <strong>Dijkstra’s Algorithm</strong> name after its inventor. A closely related algorithm is Prim’s Algorithm .</p><p><strong>Let us define the following notation:</strong><br></p><ul><li><strong>D(v) :</strong> Cost of the least-cost path from the source to destination v as of this iteration of the algorithm.</li><li><strong>P(v) :</strong> Previous node (neighbor of node v) along the current least-cost path from source to node v.</li><li><strong>N’:</strong> subset of nodes , if v in <strong>N’</strong> represent the least-cost path from source to v have been definitely known.</li></ul><p><img src="Graph-Of-Link-State-Algorithm.png" alt="Graph-Of-Link-State-Algorithm.png"><br></p><p><em>Link-State Algorithm For Source Node u</em><br></p><pre><code class="lang-c++">Initialization :    N&#39; = &#123;u&#125;;    for all nodes v         if v is a neighbor of u             then D(v) = c(u,v)        else D(v) = ∞Loop :    Find w not in N&#39; simultaneously D(w) is a minimum    Add w to N&#39;    Update D(v) for each neighbor v of w and not in N&#39; :     D(v) = min ( D(v) , D(w)+c(w,v) );Until : N&#39; = N ( N is set of all node )</code></pre><p><img src="Result-Of-LS-Algorithm.png" alt="Result-Of-LS-Algorithm.png"><br></p><p><strong>The detail of step can watch the video follow:</strong><br> </p><iframe     width="800"     height="450"     src="https://www.youtube.com/embed/ud7qWRBirsk"    frameborder="0"     allowfullscreen></iframe><p><strong>Problem of LS algorithm :</strong><br></p><p><strong>Figure follow shown a simple network topology where link costs are equal to the load carried on the link.</strong><br>In this example , link cost are not symmetric that is the C(u,v) equal to C(v,u) only if the load carried on the both directions on the link(u,v) is same . <br></p><p><strong>In this example , node z originates a unit of traffic destined for node w , node x also originates a unit of traffic destined for node w and node y injects an amount of traffic equal to e also destined for node w .</strong><br></p><p><strong>The order of looking at figure is a-&gt;b-&gt;c-&gt;d</strong><br></p><p><img src="Oscillations-With-Congestion-Sensitive-Routing.png" alt="Oscillations-With-Congestion-Sensitive-Routing.png"><br></p><p>We can see the <strong>Oscillation</strong> with congestion sensitive routing.<br></p><p>What can be done to prevent such oscillation ?<br><br>One solution would be to mandate that link costs not depend on the amount of traffic carried — an unacceptable solution since one goal of routing is to avoid highly congested links, Another solution is to ensure that not all routers run the LS algorithm at the same time.</p><h2 id="4-5-2-The-Distance-Vector-DV-Routing-Algorithm"><a href="#4-5-2-The-Distance-Vector-DV-Routing-Algorithm" class="headerlink" title="4.5.2 The Distance-Vector (DV) Routing Algorithm"></a>4.5.2 The Distance-Vector (DV) Routing Algorithm</h2><p>Whereas the LS algorithm is an algorithm using global information , the <strong>distance-vector algorithm</strong> is <em>iterative , asynchronous , and distributed. <br></em></p><ul><li><p>It is distributed in that each node receive some information from its directly attached neighbors , perform a calculation and distributed the result of its calculation back to its neighbors.<br></p></li><li><p>It is iterative in that , this process continue on until no more information is exchanged between the neighbors.<br></p></li><li><p>It is asynchronous in that is does not require all of the nodes to operate in lockstep with each other.<br></p></li></ul><p><strong>The Distance-Vector Routing Algorithm also known as Bellman-Ford Algorithm</strong><br></p><p>For get the least-cost paths , we need to using the celebrated <strong>Bellman-Ford equations:</strong><br> <strong>$d_{v}(y)$ is distance from $v$ to $y$</strong></p><script type="math/tex; mode=display">d_{x}(y)=min_v{c(x,y)+d_v(y)}</script><p>Where the $min<em>{v}$ in the equation is taken over all of x’s neighbors.After traveling from x to v , if we then take the least-cost path from v to y , the path cost will be $c(x,y)+d</em>{v}(y)$ . Since we must begin by traveling to some neighbor $v$ , the least cost from $x$ to $y$ is the minimum of $c(x,y)+d_{v}(y)$ taken over all neighbor $v$.</p><p><strong>Distance-Vector (DV) Algorithm:</strong> <br><br>at each node ,x:<br></p><p><strong>Initialization :</strong> <br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for all destinations $y$ in $N$ : <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp;$D<em>{x}(y)$ = $c(x,y)$  &nbsp; /* if y is not a neighbor then $c(x,y)$ = $\infty$ */ <br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; $D</em>{w}(y)$ = $?$ &nbsp; /* for all destinations $y$ in $N$ */<br><br>&nbsp; &nbsp;  &nbsp; &nbsp; for each neighbor $w$ <br><br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;     &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; send distance vector $D<em>{x} = [ D</em>{x}(y) : y$ in $N ]$ to $w$<br><br><strong>Loop</strong><br><br>&nbsp; &nbsp; <strong>wait</strong> (until i see a link cost change to some neighbor $w$ <br> &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    &nbsp;&nbsp;or until i receive a distance vector from some neighbor $w$) <br><br>&nbsp;&nbsp;&nbsp; for each $y$ in $N$ :<br><br>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;    $D<em>{x}(y)$ = $min</em>{v} {c(x,y) + D<em>{v}(y)}$<br><br>&nbsp;&nbsp;&nbsp;if $D</em>{x}(y)$ changed for any destination $y$ <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; send the distance vector $D<em>{x}$ = $[D</em>{x}(y) : y$ in $N]$ to all neighbors<br><br><strong>Forever</strong> <br></p><p><strong>A simple three node illustrates the operation of DV algorithm</strong><br><br><img src="DV-Simple-Example.png" alt="DV-Simple-Example.png"></p><iframe     width="800"     height="450"     src="https://www.youtube.com/embed/dmS1t2twFrI"    frameborder="0"     allowfullscreen></iframe><h3 id="Distance-Vector-Algorithm-Link-Cost-Changes-and-Link-failure"><a href="#Distance-Vector-Algorithm-Link-Cost-Changes-and-Link-failure" class="headerlink" title="Distance-Vector Algorithm : Link-Cost Changes and Link failure"></a>Distance-Vector Algorithm : Link-Cost Changes and Link failure</h3><p><img src="Changes-in-link-cost.png" alt="Changes-in-link-cost.png"><br></p><p>Figure (a) above illustrates a scenario where link cost from y to x distance vector change from 4 to 1. We force here only on y’ and z’ distance table entires to destination x. The Dv algorithm causes the following sequence of events to occur :<br></p><ul><li>At time $t_{0}$ , $y$ detects the link-cost change (the cost has change from 4 to 1 ) updates its distance vector and inform the neighbors of this change since its distance has changed.</li><li>At time $t_{1}$ , $z$ receives the update from $y$ and update its table . It computer a new least cost of $x$ (it has decreased from a cost of 5 to cost of 2 ) and send its new distance vector to its neighbors.</li><li>At time $t_{2}$ , $y$ receive $z’s$ update and updates its distance table . $y’s$ least cost do not change hence $y$ does not send any message to $z$. The algorithm come to a quiescent state.</li></ul><p>Thus only two iterations are requited for the DV algorithm to reach a quiescent state. <br></p><p>Let now consider what happen when a link cost increases , support that support the link cost between $x$ and $y$ increases from 4 to 60 as shown in figure (b) above.<br></p><ul><li>Before the link cost changes , $D<em>{x}(y) = 4$ , $D</em>{y}(z) =1$ , $D<em>{z}(y) = 1$ and $D</em>{z}(x) = 5$ , $y$ detect the link cost change (the cost change from 4 to 60) , $y$ computes its new minimum-cost path to x have a cost of  <script type="math/tex; mode=display">D_{y}(x) = min \{C(y,x) + D_{x}(x) , C(y,z)+ D_{z}(x)\}= min \{ 60+0,1+5\} = 6</script>  of course , with out global view of the network , we can see that this new cost via $z$ is wrong . But the only information node $y$ has is that its direct cost to $x$ is 60 and that $z$ has last told $y$ that $z$ could get $x$ with a cost of 5 . So in order to get to $x$, $y$ would now route through $z$ , fully expecting that $z$ will be able to get to $x$ with cost of 5.</li><li>Since node $y$ has computed a new minimum cost to $x$ , it inform $z$ of new distance vector at time $t_{1}$.</li><li>Sometime after $t_{1}$ , $z$ receive the $y’s$ new distance vector ,which indicates that $y’s$ minimum cost to $x$ is 6 . $z$ know get to $y$ with a cost of 1 and computes a new least cost to x of <script type="math/tex; mode=display">D_{z}(x) = min \{50+0, 1+6\}=7</script>  Since $z’s$ least-cost to $x$ is increased , and then it inform $y$ of its new distance vector at $t<em>{2}$ at $t</em>{2}$.</li><li>In a similar manner , after receiving $z’s$ a new distance vector , $y$ determines $D<em>{y}(x)=8$ and send $z$ its distance vector . $z$ then determine $D</em>{z}(x) = 9$ and sends $y$ its new distance vector over and over again until $D<em>{z}(x)= min{C</em>{z}(y)+D<em>{y}(x) , C</em>{z}(x)+D_{x}(x)}= min{50+1 ,50+0 }=50$ , at this point , $z$ finally ! determine that its lease-cost path to $x$ is via its direct connection to $x$.</li></ul><p><strong>What way could solve the problem noted above ?</strong><br><br>The answer is <em>Poisoned Reverse.</em><br></p><h3 id="Distance-Vector-Algorithm-Adding-Poisoned-Reverse"><a href="#Distance-Vector-Algorithm-Adding-Poisoned-Reverse" class="headerlink" title="Distance-Vector Algorithm : Adding Poisoned Reverse"></a>Distance-Vector Algorithm : Adding Poisoned Reverse</h3><p>The specific looping scenario just described can be avoided using a technique known as <em>poisoned reverse.</em> The idea is simple <strong>if $z$ routers through $y$ to get to destination $x$ , then $z$ will advertise to $y$ that its distance to $x$ is infinity</strong>, $z$ will advertise to $y$ that $D<em>{z}(x) = \infty$ ( even though $z$ known $D</em>{x}(z) = 5$ in truth) $z$ will continue telling this little white lie to $y$ as long as it route $x$ via $y$ . Since $y$ believes that $z$ had no path to $x$ ,$y$ will never attempt to route to $x$ via $z$ , as long as $z$ continues to route to $x$ via $y$<br>Let now see how <em>Poisoned Reverse</em> solved the particular looping problem :  When the link-cost $(x,y)$ change from 4 to 60 , $y’s$ distance table indicate $D_{z}(x) = \infty$ .</p><ul><li>At the time $t<em>{0}$ ,$y$ update its table and continues to route directly to $x$ , albeit at the higher cost of 60 and then inform $z$ of the new distance vector to $x$ , that is $D</em>{y}(x) =60$ .</li><li>After receiving the update at $t<em>{1}$ , $z$ immediately shits the its route to $x$ to be via the direct $(z,x)$ link at the cost of 50, and then $z$ inform $y$ of new cost of $D</em>{z}(x) = 50$ .</li><li>After receiving the update from $z$ , $y$ update its distance table at $D<em>{y}(x)=51$, also , since $z$ is now on $y$’s lease-cost path to $x$ , $y$ poisoned the reverse from $z$ to $x$ by informing $z$ at time $t</em>{3}$ that $D<em>{y}(x) = \infty$ (even though $y$ know $D</em>{y}(x)=51$ in trush)</li></ul><p><strong>Does poisoned reverse solve the general count-to-infinity problem ? It dose not , when looping involving three or more nodes will not be detected by poisoned reverse.</strong><br></p><h3 id="A-comparison-of-LS-and-DV-Algorithm"><a href="#A-comparison-of-LS-and-DV-Algorithm" class="headerlink" title="A comparison of LS and DV Algorithm"></a>A comparison of LS and DV Algorithm</h3><ul><li><p><strong>Message complexity :</strong> <strong>In LS algorithm</strong> requires each node know all cost of link in the network . The require O(|E|*|N|) to be sent. Also , whenever a link cost changes , the new link cost must be sent to all node in the internet. <strong>In the DV algorithm</strong> The node only need to exchange the information between directly connection neighbors. When a link cost change , the DV algorithm will propagate the results of the changed link cost only if the new cost results in a changed lease-cost path for one of nodes attached to that link.</p></li><li><p><strong>Speed of convergence :</strong> LS is O($|N|^2$) algorithm require O(|N||E|) messages to be sent. DV algorithm can converge slowly and can have routing loops while the algorithm is converging . DV algorithm also suffers from the count-to-infinity problem. </p></li><li><p><strong>Robustness:</strong> What can happen if route fails misbehaves or is sabotage? Because LS algorithm only compute own forwarding table of each node in the network , This mean route calculation are somewhat separated under LS . Providing a degree of robustness. Under DV algorithm , a node must advertise incorrect least-cost path to any all destination , so that a malfunctioning router may be cause other router flood the malfunctioning router with traffic and cause a large portions of the internet to become disconnected for up to several hours.<br></p></li></ul><h2 id="4-5-3-Hierarchical-Routing"><a href="#4-5-3-Hierarchical-Routing" class="headerlink" title="4.5.3 Hierarchical Routing"></a>4.5.3 Hierarchical Routing</h2><p>In our study of LS and DV algorithm , In practice , this model and its view of homogeneous set of routers all executing the same routing algorithm is a bit simplistic for at least two important reasons:<br></p><ul><li><p><strong>Scale</strong> :Because , today’s public internet consist of hundreds of millions hosts , LS algorithm updates among all of the router in public internet world would leave no bandwidth left for sending data packets, and under DV algorithm that iterated among such a large number of routers would surely never converge.</p></li><li><p><strong>Administrative autonomy:</strong> The corporation / organization / individual want to run and administer its network as it wishes.<br></p></li></ul><p><strong>Both of these problems can be solve by organizing routers into autonomous systems (ASs)</strong><br></p><p>Each AS consisting of a group of routers that are typically under the same administrative control ( eg : operated by the same ISP or belonging to the same company network).</p><p>The routing algorithm running within a autonomous system is called an <strong>Intra-autonomous-system routing protocol</strong><br>One or more router in the AS being responsible for forwarding packets to destinations outside other AS : there routers are called <strong>gateway router</strong>, Obtaining reachability information from neighboring AS and propagating the reachability information to all router internal to AS are handled by the <strong>inter-AS-routing-protocol</strong><br><br><img src="autonomous-system-graph.png" alt="autonomous-system-graph.png"><br><br>If a destination router of outside AS can be reached by more than one gateway router , the router inside AS can using <strong>Hot-Potato-Algorithm</strong> to choose which gateway router should be select. The hot-potato-algorithm is using information from Intra-AS-Routing-Protocol to choose the lease-cost path of gateway routers.<br><img src="hot-potato-algorithm.png" alt="hot-potato-algorithm.png"><br></p><h1 id="4-6-Routing-in-the-internet"><a href="#4-6-Routing-in-the-internet" class="headerlink" title="4.6 Routing in the internet"></a>4.6 Routing in the internet</h1><h2 id="4-6-1-Intra-AS-Routing-in-the-Internet-RIP"><a href="#4-6-1-Intra-AS-Routing-in-the-Internet-RIP" class="headerlink" title="4.6.1 Intra-AS Routing in the Internet : RIP"></a>4.6.1 Intra-AS Routing in the Internet : RIP</h2><p>RIP is a distance-vector algorithm that operates in a manner very close to idealized DV protocol . Each router maintains a RIP table is known as a routing table. RIP is implemented as an application-layer process can send and receive the (require/response) message over a standard socket (port 520) and using UDP protocol.<br><br><img src="RIP-UDP-Application.png" alt="RIP-UDP-Application.png"><br><br>In RIP , routing updates are exchanged between neighbors approximately every 30 seconds using a <strong>RIP response message</strong>(RIP response message also known as <strong>RIP advertisements</strong>) . If a router does not hear from its neighbor at least once every 180 seconds , that neighbor is considered to be no longer reachable ; that is , either neighbor is died or the connecting link has gone down , when this happen , RIP modifies the local routing table and then propagates this information by sending advertisement to still alive neighbors.<br></p><p><strong>Let us see a simple example:</strong><br><br>Dotted lines indicate that still has other AS connect on  ; thus this autonomous systems have many more routers and link than figure shown follow.<br><img src="ASs-connection-graph-RIP.png" alt="ASs-connection-graph-RIP.png"><br><br><strong>Routing table of Router-D before receiving advertisement from Router-A:</strong><br><br><img src="Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png" alt="Router-D-Routing-Table-Before-Receive-Infor-from-Router-A.png"><br></p><p><strong>Advertisement from router A:</strong><br><br><img src="Advertisement-From-RouterA.png" alt="Advertisement-From-RouterA.png"><br><br><strong>Routing table of Router-D after receiving advertisement from Router-A:</strong><br><br><img src="Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png" alt="Router-table-of-Router-D-After-receiving-adverstiment-from-router-A.png"><br></p><h2 id="4-6-2-Intra-AS-Routing-in-the-Internet-OSPF"><a href="#4-6-2-Intra-AS-Routing-in-the-Internet-OSPF" class="headerlink" title="4.6.2 Intra-AS Routing in the Internet : OSPF"></a>4.6.2 Intra-AS Routing in the Internet : OSPF</h2><p>OSPF is a link-state algorithm that uses flooding of link-state information and dijkstra least-cost path algorithm . With OSPF protocol , a router constructs a complete topological map of the entire autonomous system , The router then locally run dijkstra algorithm to determine the shortest-path tree to all subnet. Individual link cost can be configured by the network administrator .<br></p><p>Under OSPF protocol , A router broadcast link-state information whenever there is change in a link’s state , It also broadcast information periodically (at least once every 30 minutes) even if the link’s state has not changed. OSPF protocol advertisements are contains in OSPF message that carried directly by IP protocol , with a upper-layer protocol 89 for OSPF.<br></p><p>The OSPF protocol also checks that link are operational and allows an OPSF router to obtain a neighboring router’s database of network-wide link state.</p><p>OPSF is conceived as the successor to RIP and as has a number of advanced feature. The advanced feature is include the following:<br></p><ul><li><p><strong>Security:</strong> Exchanged between OPSF router can be authenticated , with authentication ,only trusted router can participate in OPSF protocol within an AS. Two type of authentication is can be configured — <strong>simple and MD5</strong>( discuss in chapter 8).</p></li><li><p><strong>Multiple same-cost path:</strong> OPSF allow multiple same-cost path to be used , don’t need to select a path to carry all traffic.</p></li><li><p><strong>Integrated support to unicast and multicast routing:</strong> Multicast OSPF (MOSPF).<br></p></li><li><strong>Support a hierarchy within a single routing domain:</strong> An OPSF autonomous system can be configured hierarchically into areas , Each area run its own OSPF link-state-algorithm , with each router in an area broadcasting its link-state to all other in that area. Within each area of a autonomous system has one or more <strong>area border router</strong> are responsible for routing packets to outside the area . And exactly one OPSF area in the AS is configured to be the <strong>backbone</strong> area. The primary role of the backbone area is to route traffic between the other area in the AS. <em>Inter-area routing</em> within the AS requires that the packet be first route to a area border router , and routed through the backbone to the area border router that is in the destination area , and then routed to the final destination.</li></ul><h2 id="4-6-3-Inter-AS-Routing-BGP-Border-Gateway-Protocol"><a href="#4-6-3-Inter-AS-Routing-BGP-Border-Gateway-Protocol" class="headerlink" title="4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)"></a>4.6.3 Inter-AS Routing : BGP (Border Gateway Protocol)</h2><p>Let’s us examine how path are determined for source-destination pair span multiple ASs.<br><br>Under BGP protocol , pair of router exchange information through semi-permanent TCP connection using port 179.<br><br>The BGP protocol TCP connection has two type of connection : <br></p><ul><li>BGP TCP connection between router within a same AS.</li><li>BGP TCP connection between routers in two different ASs.</li></ul><p>Two interconnecting router corresponding source and destination router that using TCP are called <strong>BGP peers</strong> . The TCP connection along with all BGP message sent over the connection is called <strong>BGP session</strong>.<br><br><strong>Two type of BGP session:</strong><br></p><ul><li>External BGP session (eBGP session) : The BGP message is sent span two routers.</li><li>Internal BGP session (iBGP session) : The BGP message is sent within an AS.<br><img src="BGP-sessions.png" alt="BGP-sessions.png"><br><br>In the BGP , destinations are not a host but instead are CIDRized prefixes with each prefixes is representing a subnet or a collection of subnet.<br></li></ul><p>In the BGP , some ASs has a globally unique <strong>autonomous system numbers(ASN)</strong> , the ASs hasn’t ASN is called stub AS. ASN similar to IP address are assigned by ICANN regional register.<br></p><p>When a router advertise prefix to outside ASs , it include with a number of <strong>BGP attributes :</strong> , in BGP jargon , a prefix along with its attributes is called a route. The BGP  attributes is following: <br></p><ul><li><strong>AS-PATH :</strong> The attributes contain the ASN that the prefix have been passed.</li><li><strong>NEXT-HOP:</strong> The NEXT-HOP is router interface that begins the AS-PATH. </li></ul><h3 id="BGP-Route-selection"><a href="#BGP-Route-selection" class="headerlink" title="BGP Route selection"></a>BGP Route selection</h3><p>Under BGP protocol , a router may be receive more than one route to the same prefix . Then BGP must be sequentially invokes the following elimination rules until one possible remain , The elimination rules is following:<br></p><ul><li>Routes are assigned a local preference values as one of their attributes , the routes with the highest local preference value are selected.</li><li>From the remaining routes ( all routes has same preference value ) with the shortest AS-PATH are selected.</li><li>From the remaining routes ( all routes has same preference value and same AS-PATH length) with closest NEXT-HOP are selected, here closest mean the least-cost path of a router itself interface and its corresponding eBGP session interface.</li><li>If more than one route still remains , the router use the BGP identifiers to select the route.</li></ul><h3 id="Putting-all-together-How-does-an-entry-get-into-a-router’s-forwarding-table"><a href="#Putting-all-together-How-does-an-entry-get-into-a-router’s-forwarding-table" class="headerlink" title="Putting all together : How does an entry get into a router’s forwarding table ?"></a>Putting all together : How does an entry get into a router’s forwarding table ?</h3><p><strong>How does the packet is forwarded within a router ?<br></strong><br>When a packet arrive to the router , the packet’s destination IP address compared with the prefixes in the forwarding table and find a longest prefix match . Then the packet is forwarded to router’s port that associated with that matched prefix.<br><br><strong>How does an entry get into a router’s forwarding table ?</strong><br><br><em>In order to get an entry into a router’s forwarding table , first , the router must be aware of the prefix. The router become aware of the prefix via a BGP route advertisement , such a route advertisement may be sent over a eBGP session or over a iBGP session. After the router become aware of prefix , it need to determine appropriate output port to which datagram destined to that prefix will be forwarded. Before it can enter that entry (prefix + port) into its forwarding table . If router receive more than one route advertisement for this prefix , it is uses the BGP selection process to select to best route for the prefix , suppose the route have been selected , the selected route include NEXT-HOP attribute , which is IP address of first router outside the router’s AS along this best route. Then the router uses its Intra-AS routing protocol (typically OSPF) , to determine the shortest path to the NEXT-HOP router. The router finally determines the port number to associate with the prefix by identifying the first link along the shortest path . The router finally can enter the prefix-port pair into the forwarding table.</em></p><h1 id="4-7-Broadcast-and-Multicast-Routing"><a href="#4-7-Broadcast-and-Multicast-Routing" class="headerlink" title="4.7 Broadcast and Multicast Routing"></a>4.7 Broadcast and Multicast Routing</h1><h2 id="4-7-1-Broadcast-Routing-Algorithm"><a href="#4-7-1-Broadcast-Routing-Algorithm" class="headerlink" title="4.7.1 Broadcast Routing Algorithm"></a>4.7.1 Broadcast Routing Algorithm</h2><p><strong>Two type of Broadcast routing algorithm: <br></strong></p><ul><li><strong>Source-Duplication:</strong> A packet is created and duplicated by a source router , and source router broadcast to all router in the network by unicast. This approach has several drawback is following:<ul><li>inefficiency : The source router is required to copy a large amount of same packet and send these via a single link.</li><li>Additional protocol mechanisms to obtain the address of the broadcast recipient ,would add more overhead and make the system more complex .</li></ul></li><li><strong>In-network duplication:</strong> The source router broadcast by sending only one packet to attached routers , and then the attached routers copy the packet and send it to next attached routers .<br><img src="Source-duplication-In-network-duplication.png" alt="Source-duplication-In-network-duplication.png"><br></li></ul><h3 id="Uncontrolled-Flooding"><a href="#Uncontrolled-Flooding" class="headerlink" title="Uncontrolled Flooding"></a>Uncontrolled Flooding</h3><p>The most obvious technique for broadcast is <strong>Flooding</strong> approach in which the source node send its copy of packet to its neighbor.<br><br>Although this approach is simple and elegant , it has a fatal flaw , that is , if the graph has a cycles , then one or more broadcast packet will cycle indefinitely .<br><br>This broadcast storm along with broadcast packet increasingly would cause the network crash (network useless).</p><h3 id="Controlled-Flooding"><a href="#Controlled-Flooding" class="headerlink" title="Controlled Flooding"></a>Controlled Flooding</h3><p>In practice , we have several way to solve the problem of uncontrolled flooding .<br></p><ul><li><p><strong>Sequence-number-controlled-flooding:</strong> A source node put its address or other unique identifies as well as broadcast sequence number into broadcast packet , then send it to all neighbors. Each node maintain a list of the source address and sequence number of broadcast packet , it first checks whether the packet is in this list , if so , the packet is dropped , if not , the packet is duplicated and forwarded to all node’s neighbors.<br></p></li><li><p><strong>Reverse path forwarding (RPF):</strong> Reverse path forwarding is also known as Reverse path broadcast (RPB) , When a node receives a broadcast packet with the source node address , <strong>the node transmits the packet on all of its outgoing link (expect one that outgoing link of its receive that packet)only if the packet arrived on the link that is on its own shortest unicast path back to the source. Otherwise , this packet is discarded simply.</strong><br>As likely the figure following , the router E transmits only the packet that arrived from router C to all neighbors(because it is the shortest path from router D to source router A), Otherwise , the packet is discarded simply.<br><img src="RPF.png" alt="RPF.png"><br></p></li></ul><h3 id="Spanning-Tree-Broadcast"><a href="#Spanning-Tree-Broadcast" class="headerlink" title="Spanning-Tree Broadcast"></a>Spanning-Tree Broadcast</h3><p>Although The sequence-number-controlled-flooding algorithm and RPF algorithm avoid the broadcast storm , these don’t completely avoid the transmission of redundant broadcast packet.<br><br>Actually , every node receive only one broadcast packet is enough. The Spanning-Tree Broadcast algorithm can solve this problem .<br></p><p>Thus , a node first have to construct a spanning-tree , when it wants to provide broadcast for all network node.<br></p><p>We consider only one simple algorithm here , that is <strong>Center-based approach</strong> to build a spanning-tree.<br></p><ul><li>First determine a center node (also known as <strong>core</strong> and <strong>rendezvous point</strong>)</li><li>The network node then unicast <strong>tree-join message</strong> addressed to center node. A tree-join message is forwarded using unicast routing toward the center until either arrives at a node that has already belong to the spanning tree or arrives at the center node.</li></ul><p><em>If each link associated cost , then a spanning-tree whose cost is the minimum of all of graph’s spanning-tree is called a <strong>minimum spanning-tree</strong> .</em> <br></p><iframe     width="800"     height="450"     src="https://www.youtube.com/embed/Uj47dxYPow8"    frameborder="0"     allowfullscreen></iframe><h2 id="4-7-2-Multicast"><a href="#4-7-2-Multicast" class="headerlink" title="4.7.2 Multicast"></a>4.7.2 Multicast</h2><p>In multicast communication , we are immediately faced with two problem .<br></p><ul><li>How to identify the receiver of multicast packet.</li><li>How to address a packet send to these receivers.<br>Network layer multicast in the internet consist of two complementary components : <strong>IGMP (Internet Group Management Protocol) and Multicast routing protocol</strong>. The IGMP is used to solve first problem. The Multicast routing protocol is used to solve second problem.<br></li></ul><h3 id="Internet-Group-Management-Protocol"><a href="#Internet-Group-Management-Protocol" class="headerlink" title="Internet Group Management Protocol"></a>Internet Group Management Protocol</h3><p>The IGMP protocol version 3 operates between a host and its directly attached router. The figure following , shows three fist-hop multicast protocol each connected to its attached hosts via one outgoing local interface.<br><br><img src="IGMP-component.png" alt="IGMP-component.png"><br><br>IGMP provide the mean for a host to inform its attached router that an application running on the host want to join a specific multicast group.<br></p><p><strong>IGMP has three message types.</strong><br></p><ul><li><strong>Membership_query message:</strong> That is sent by router to all host on an attached interface to determine which hosts on attached network are member of which multicast group.</li><li><strong>Membership_report message :</strong> This message is used to respond to Membership_query message for inform the attached router that it still in multicast group and also be used to first joins a multicast group.</li><li><strong>Leave_group message :</strong> This message is used to inform the router stops forwarding the multicast message to it. Interesting this message is optional , but it is optional , how to detect when a host leave the multicast group , The answer is the router infer this host have been leaved a multicast if this host no longer respond to Membership_query message. This example is called <strong>soft state</strong> in the internet protocol.<br></li></ul><h3 id="Multicast-Routing-Algorithm"><a href="#Multicast-Routing-Algorithm" class="headerlink" title="Multicast Routing Algorithm"></a>Multicast Routing Algorithm</h3><p>The goal of multicast routing , then is find a tree of links that connects all of routers that have attached hosts belonging to the multicast group . Multicast packet will be routed along with this tree from the multicast sender to all of the host belong to this multicast tree , of course , the tree also can contain some router that haven’t hosts belong to Multicast group.<br></p><p>Two approach have been adopted for determining the multicast router tree.<br></p><ul><li><strong>A group shared tree :</strong> As in the case of Spanning-tree broadcast , multicast routing over a group-shared tree is base on building a tree that include all edge router with attached host belonging to multicast group. In practice , a center-based approach is used to construct the multicast routing tree with edge router with attached hosts belonging to multicast group send (via unicast) join-message addressed to center router.<br></li><li><strong>A source base tree :</strong> The group shared tree constructs a single, shared routing tree to route packet from all senders . This approach is constructs a multicast routing tree for each source in the multicast group . In practice , an RPF algorithm is used to construct a multicast forwarding tree for multicast datagram originating at source x. The RPF broadcast algorithm require a bits of tweaking when it is used to multicast. To see why consider router D in Figure following. Under broadcast RPF , it forward packets to router G , even though router has no attached hosts that are joined to multicast group . While this is not so bad for this case , where router D has only one downstream router G , imagine what would happen if router D has thousand of downstream router ? Each of these downstream router would receive unwanted multicast packets. The solution of this problem is known as <strong>pruning</strong>.<br><img src="RPF-Multicast.png" alt="RPF-Multicast.png"><br></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chapter3-Homework-Problems-and-Questions</title>
    <link href="/2020/05/01/Chapter3-Homework-Problems-and-Questions/"/>
    <url>/2020/05/01/Chapter3-Homework-Problems-and-Questions/</url>
    
    <content type="html"><![CDATA[<h1 id="Chapter3-Homework-Problems-and-Questions"><a href="#Chapter3-Homework-Problems-and-Questions" class="headerlink" title="Chapter3-Homework-Problems-and-Questions"></a>Chapter3-Homework-Problems-and-Questions</h1><p><img src="1.png" alt="1.png"><br><br><img src="2.png" alt="2.png"><br><br><img src="3.png" alt="3.png"><br><br><img src="4.png" alt="4.png"><br><br><img src="5.png" alt="5.png"><br><br><img src="6.png" alt="6.png"><br></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
      <tag>计算机网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>面试题35. 复杂链表的复制</title>
    <link href="/2020/04/27/%E9%9D%A2%E8%AF%95%E9%A2%9835-%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6/"/>
    <url>/2020/04/27/%E9%9D%A2%E8%AF%95%E9%A2%9835-%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p>题目在此<a href="https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/">面试题35．复杂的链表的复制</a><br></p><p>有三种方法可以做这一道题<br></p><ul><li>迭代法</li><li>BFS</li><li>DFS<br>unordered_map<key,value>是无序的哈希函数<br><br><em>unordered_map&lt;Node\</em>,Node*&gt; copylist 其实是用来同步复制结点和原结点，例如，原结点到达了head.那么head的复制结点就是copylist[head],相当于把原结点和复制节点绑定了起来<em><br><br>  <em>*这样做的好处是:</em></em><br><br>举个例子若不使用unordered_map函数，我们创建3个复制结点就需要创建3个指针(例如：p1,p2,p3)去指向它，以备后续建立结点相互链接关系时再次访问，但是如果我原节点有10000个，那么我就需要手动创建10000个指针，而用了unordered_map就可以将创建的复制结点与原结点绑定起来，结点间建立链接关系时只需要通过原节点就可以访问相应的复制结点(原结点head的复制节点copylist[head])<br></li></ul><p><em>下面方法除了优化迭代法的时间复杂度为O(n)，空间复杂度为O(1)，其他的时间空间复杂度都为O(n)</em></p><h3 id="迭代法"><a href="#迭代法" class="headerlink" title="迭代法"></a>迭代法<br></h3><pre><code>class Solution &#123;public:    Node* copyRandomList(Node* head) &#123;       if(head==NULL) //防止传入head就是NULL       return head;       unordered_map&lt;Node*,Node*&gt;copylist;       Node* temp = head;       while(temp!=NULL) //先把所有结点复制一遍       &#123;           copylist[temp]=new Node(temp-&gt;val);           temp=temp-&gt;next;       &#125;       temp=head;       while(temp!=NULL) //复制每个结点的next关系       &#123;               copylist[temp]-&gt;next=copylist[temp-&gt;next];               temp=temp-&gt;next;       &#125;        temp=head;       while(temp!=NULL)&#123; //复制每个结点的random关系           copylist[temp]-&gt;random=copylist[temp-&gt;random];           temp=temp-&gt;next;       &#125;       return copylist[head];    &#125;&#125;;</code></pre><h3 id="优化版迭代"><a href="#优化版迭代" class="headerlink" title="优化版迭代"></a>优化版迭代</h3><p><img src="优化迭代法-图解.png" alt="优化版迭代"><br></p><p><strong>这个版本的迭代和普通的迭代有什么区别呢？</strong><br><br><em>其实这个版本的用原节点的next指针代替了unordered_map，用来绑定(定位)复制结点</em><br></p><pre><code>class Solution &#123;public:    Node* copyRandomList(Node* head) &#123;        if(head==NULL)        return head;        Node* cphead;        Node* start;        Node* end;        Node* temp=head;        while(temp!=NULL)        &#123;            Node* copyhead=new Node(temp-&gt;val);            copyhead-&gt;next=temp-&gt;next;            temp-&gt;next=copyhead;            temp=temp-&gt;next-&gt;next;        &#125;        //建立random链接        temp=head;        while(temp!=NULL)        &#123;            if(temp-&gt;random!=NULL)            temp-&gt;next-&gt;random=temp-&gt;random-&gt;next;            else            temp-&gt;next-&gt;random=NULL;            temp=temp-&gt;next-&gt;next;        &#125;        //建立next链接        cphead=head-&gt;next; //记录复制头节点的位置，以便return        start=head;        end=head-&gt;next;        while(end!=NULL)        &#123;            start-&gt;next=end-&gt;next;            start=end;            end=end-&gt;next;        &#125;        return cphead;    &#125;&#125;;</code></pre><h3 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS<br></h3><p>因为链表可以变相的可以看为一个图，所以我们可以用DFS解决，DFS递归就相当于保存了上一个节点的信息　(递归就像是一个另类的栈，隐藏的栈和linux0.11进程切换的隐藏栈差不多)．<br><br>DFS传递进去的参数是<strong>DFS(期望建立链接的结点，哈希表)</strong><br><br>DFS递归的创建复杂结点，在返回的时候用copylist[head]-&gt;next 和 copylist[head]-&gt;random 来建立前后结点的链接关系．<br></p><pre><code>class Solution &#123;public: //注意unordered_map&lt;Node*,Node*&gt; &amp;copylist这里使用了引用    Node* DFS(Node* head,unordered_map&lt;Node*,Node*&gt; &amp;copylist)    &#123;        if(head==NULL)        return head;        //copylist[head].count用来计算head在哈希表中出现几次，因为unordered_map是不允许重复的所以只会返回0或１.                if(copylist.count(head)) return copylist[head];  //如果已经创建过了所以就直接返回        copylist[head]=new Node(head-&gt;val);                copylist[head]-&gt;next=DFS(head-&gt;next,copylist); //这一句和下面一句就是结点之间建立链接关系的语句．        copylist[head]-&gt;random=DFS(head-&gt;random,copylist);        return copylist[head];    &#125;   Node* copyRandomList(Node* head) &#123;       unordered_map&lt;Node*,Node*&gt;copylist;       return DFS(head,copylist);    &#125;&#125;;</code></pre><h3 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS<br></h3><p><em>其实和DFS差不多，就是换了一种遍历的方法，有一点和DFS不同就是BFS是在便利途中结点之间就建立了链接，但是DFS是在遍历完结后回退的过程中建立链接</em><br></p><pre><code>class Solution &#123;public:    Node* BFS(Node*head)    &#123;        if(head==NULL)        return head;        unordered_map&lt;Node*,Node*&gt;copylist;        copylist[head]=new Node(head-&gt;val);                queue&lt;Node*&gt; q; //队列        q.push(head);        while(!q.empty())&#123;            Node* temp=q.front();            q.pop();                        //建立next链接            if(temp-&gt;next!=NULL &amp;&amp; copylist.count(temp-&gt;next))　//首先要判断下一个结点存不存在(存在则直接建立链接，不存在则是NULL或者还没建立)            &#123;                copylist[temp]-&gt;next=copylist[temp-&gt;next];            &#125;            else            &#123;                if(temp-&gt;next!=NULL)&#123;　//下一个结点非NULL而是还没遍历到                copylist[temp-&gt;next]=new Node(temp-&gt;next-&gt;val);                copylist[temp]-&gt;next=copylist[temp-&gt;next];                q.push(temp-&gt;next);                &#125;                                else　//下一个结点为NULL                copylist[temp]-&gt;next=NULL;            &#125;                        //建立random 链接            if(temp-&gt;random!=NULL &amp;&amp; copylist.count(temp-&gt;random))            &#123;                copylist[temp]-&gt;random=copylist[temp-&gt;random];            &#125;            else            &#123;                if(temp-&gt;random!=NULL)&#123;                copylist[temp-&gt;random]=new Node(temp-&gt;random-&gt;val);                copylist[temp]-&gt;random= copylist[temp-&gt;random];                q.push(temp-&gt;random);                &#125;                else                copylist[temp]-&gt;random=NULL;            &#125;        &#125;        return copylist[head];    &#125;    Node* copyRandomList(Node* head) &#123;        return BFS(head);    &#125;&#125;;</code></pre>]]></content>
    
    
    <categories>
      
      <category>力扣</category>
      
    </categories>
    
    
    <tags>
      
      <tag>力扣</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对于指针的一些理解</title>
    <link href="/2020/04/20/%E5%AF%B9%E4%BA%8E%E6%8C%87%E9%92%88%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/"/>
    <url>/2020/04/20/%E5%AF%B9%E4%BA%8E%E6%8C%87%E9%92%88%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>在复习数据结构链表那一章时对创建<strong>头指针</strong>然后指向<strong>首元节点</strong>或者<strong>头节点</strong>(两者是不同的东西)的具体实现过程有些许疑问，它们在内存中是怎么工作的呢？<br><br>于是我写了个小程序来验证了一下<br></p><pre><code class="lang-c">#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;struct test&#123;    struct test* next;    int data;&#125;;int main ()&#123;    struct test* temp=NULL ;    struct test* address;    printf(&quot;未申请内存时的&amp;address=%p\n&quot;,&amp;address);    address=(struct test*)malloc(sizeof(struct test));    address-&gt;data=10;    address-&gt;next=NULL;    temp=address;    printf(&quot;&amp;address=%p\n&quot;,&amp;address);    printf(&quot;address=%p\n&quot;,address);    printf(&quot;temp=%p\n&quot;,temp);    printf(&quot;用%%x来打印地址，在64位机器中会被截断\n&quot;);    printf(&quot;address=%#x\n&quot;,address);    printf(&quot;temp=%#x\n&quot;,temp);    return 0;&#125;</code></pre><p><strong>执行结果</strong><br><br><img src="指针.png" alt="指针"><br><br><code>struct test* address</code>计算机会给变量address分配一个内存，然后当<code>address=(struct test*)malloc(sizeof(struct test));</code> 执行后，计算机就会给指针address的内存中填入新申请的大小为(sizeof(struct test))的内存的地址．<code>temp=address</code>就是将address的内存装载的内容赋值给temp.<br></p><p><strong>本质是有两个指针同时指向一个结构内存(struct test). 而不是address指向结构内存，temp再指向address</strong></p><p><em>一个有趣的发现就是在64位机上面%x打印16进制只能打印出32位数而%p能够完美打印出48位地址(64位机用48位地址)，所以打印地址还是老老实实用%p</em></p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chapter 3: Transport Layer</title>
    <link href="/2020/04/17/Chapter3-Transport-Layer/"/>
    <url>/2020/04/17/Chapter3-Transport-Layer/</url>
    
    <content type="html"><![CDATA[<p><strong>Most of content come from Computer-network-A-Top-Down-Approach.</strong></p><h1 id="3-4-Principles-of-Reliable-Data-Transfer"><a href="#3-4-Principles-of-Reliable-Data-Transfer" class="headerlink" title="3.4 Principles of Reliable Data Transfer"></a>3.4 Principles of Reliable Data Transfer</h1><p>it may be corrupt bits , lose packets, packets out of order during the data transfer from client to servers . So . For avoid the data lose or other situation happened When we receive the data at the <strong>Application layer</strong>,we need to build a reliable data transfer protocol.<br><br>In fact , the layer that below the reliable data transfer protocol is unreliable . For example , TCP protocol is reliable data transfer protocol that is implemented top of unreliable (IP) end-to-end network layer.<br><br>we will discuss “build a reliable data transfer protocol above unreliable layer to reliable data transfer” following section below.<br></p><p><img src="Reliable-data-tranfer.png" alt="Reliable-data-tranfer"><br></p><h1 id="3-4-1-Building-a-Reliable-Data-Transfer-Protocol"><a href="#3-4-1-Building-a-Reliable-Data-Transfer-Protocol" class="headerlink" title="3.4.1 Building a Reliable Data Transfer Protocol"></a>3.4.1 Building a Reliable Data Transfer Protocol</h1><p>We now step through a series of protocols , each one becoming more complex until arriving at a flawless reliable data transfer protocol.<br></p><h2 id="Reliable-Data-Transfer-over-a-Perfectly-Reliable-Channel-rdt1-0"><a href="#Reliable-Data-Transfer-over-a-Perfectly-Reliable-Channel-rdt1-0" class="headerlink" title="Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0"></a>Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0</h2><p>We first consider a simple case, in which the underlying channel is completely reliable. We call that protocol <em>rdt1.0</em>. The finite-state-machine (FSM) definitions for the sender and receiver are shown in Figure below.<br><br><img src="rdt1.0-finite-state-machine.png" alt="rdt1.0-finite-state-machine"><br></p><p><strong>rdt1.0 data transferred actions:</strong> <br></p><ol><li>sending side<br></li></ol><ul><li>The sending side simply accepts data from upper layer (application layer) via rdt_send(data) event.</li><li>Creates packets containing the data via the make_pkt(data) event.</li><li>Send the packets to the underlying channel (network layer) via the udt_send(packet) event.</li></ul><ol><li>receiving side <br></li></ol><ul><li>rdt receives packets from underlying channel (network layer) via the rdt_rcv(packet) event.</li><li>Remove the data from the packet via extract(packet,data) event.</li><li>Passes the data up to the upper layer(application layer) via the deliver_data(data).</li></ul><p><strong>In summary of rdt1.0</strong><br></p><p><em>In this simple protocol , these is no difference between a unit of data or packet. Also all packet flow is send from sender to receiver over a reliable prefer channel, So receiver don’t need send feedback to sender (tell the sender ‘I have received the packet’) since nothing can go wrong! Note that we have assume the receiver can receive data as fast as the sender happens to send data, Thus , there is no need for the receiver to ask the sender to slow down.</em></p><h2 id="Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-0"><a href="#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-0" class="headerlink" title="Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.0</h2><p>A more realistic model of the underlying channel is one in which bit in the packet may be corrupted , such bit errors typically occur in physical components of network as a packet is transmitted packets , propagated , or buffered.<br><br><strong>we will continue assume for the moment that all transmitted packets are received in the order in which they we sent.</strong></p><p><strong>Question:</strong><br></p><ul><li>The bit of packet may be corrupted , when the packet is transmitted ,propagated,or buffered .<br><br>For example: yourself might dictate a long message over the phone and send to your friends. In typical scenario, the message receiver might say “OK”<br>after he has been heard , understood and recorded. But ! If the message receiver hears a garbled sentence . How to solve this problem?<br></li></ul><p><strong>Solution:</strong><br><br>The message receiver will ask the sender to repeat the garbled sentence.<br><br>The rdt2.0 uses both positive acknowledgments (OK) and negative acknowledgments (“Please repeat that”). These control messages allow the receiver let sender know what have been received correctly , and what have been received error and thus requires repeating.<br><br>In the computer network setting , reliable data transfer protocols base on such retransmission are known as ARQ (Automatic Repeat reQuest) protocols. </p><p>Fundamentally, three additional protocols capabilities are required in ARQ protocol to handle the presence of bit errors.<br></p><ul><li><strong>Error detection :</strong> A mechanism is needed to allow the receiver to detect when bit error have occurred . We can use internet checksum field to achieve this function as UDP did.</li><li><strong>Receiver feedback :</strong> The receiver needs to provide explicit feedback to the sender to let the sender know the receiver’s view of the world. <strong>Positive acknowledgment (ACK) and Negative acknowledgment (NAK)</strong></li><li><strong>Retransmission :</strong> The sender need to repeat send the corrupted packet to receiver.<br></li></ul><p><img src="rdt2.0-A-protocol.png" alt="rdt2.0-A-protocol"><br></p><p><strong>rdt2.0 data transferred actions</strong></p><ol><li>sending side<br></li></ol><ul><li>First of all the protocol state is “Wait from call from above” . The sender will pass data via <em>rdt_send(data)</em> event from upper layer to transfer layer, when the sender wanna to tranfer data.<br></li><li>The sender will create packet(sndpkt) containing the data to be sent along with the checksum filed via <em>sndpkt=make_pkt(data,checksum) event</em>.<br></li><li>Then send the packet(sndpkt）via udt_send(sndpkt) operation to receiver side.<br></li><li>In the end change the protocol state to “Wait for ACK or NAK” for waiting response message from receiver <strong>(In this state ,the sender cannot get more data from upper layer)</strong><br></li><li>The sender will receive the response message and check it when the response message arrived. If the response is ACK (rdt_rcv(rcvpkt)&amp;&amp;isACK(rcvpkt)) , the sender will change the state back, otherwise the sender will resend the sndpkt to receiver via udt_send(sndpkt) event .<br></li></ul><ol><li>receiving side <br><br>The receiving side still only has a state (wait call from below).<br></li></ol><ul><li>The receiver will receive the packet and check it from below layer via <strong>(rdt_rcv(rcvpkt)&amp;&amp;corrupt(rcvpkt)) and (rdt_rcv(rcvpkt)&amp;7notcorrupt(rcvpkt))</strong> event.</li><li>The receiver will make a packet along with NAK and send it back to sender side. If the packet suffer bit errors. </li><li>Otherwise the receiver gets the corrupt packet, it will extract the packet and deliver the data to upper layer via <strong>extract(rcvpkt,data) and deliver_data(data)</strong> event. In the end . The receiver will make a packet along with ACK and send it back to sender via <strong>make_pkt(ACK) and udt_send(sndpkt)</strong><br></li></ul><p><strong>fatal flaw of rdt2.0</strong><br><br>Unfortunately rdt2.0 has a fatal flaw. In particular , we haven’t account for the possibility that the ACK and NAK could be corrupted !<br><br>And more difficulty question is how to recover from errors in ACK and NAK packets..</p><p><strong>Solution for fatal flaw of rdt2.0</strong><br><br>Simply, we just need to retransmit the packet to the receiver when the sender got a corrupted ACK or NAK packets. <br></p><p><strong>This approach , however introduce the duplicates packets into the sender-receiver-channel. The difficulty is receiver can not know whether the arrived packet containing content is retransmitted packet or new packet ?</strong></p><p>A simple solution to this new problem is to add a new filed and have sender number its data packets by putting sequence number into this filed. The receiver then need only check this sequence number to know whether or not the receiver packet is retransmission .<br><br>In the sender side use 0 and 1 sequence numbers represent different  state of packets (new packet and old packet) . The packet containing sequence number 0 and sequence number 1 corresponding to the old packet and new packet, when the sender send packet containing sequence number 0 recent. In contrast ,the packet containing sequence number 0 and sequence number 1 corresponding to the new packet and old packet,when the sender send packet containing sequence number 1 recent. <br></p><h2 id="Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-1"><a href="#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-1" class="headerlink" title="Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.1</h2><p><em>rdt2.0 added a sequence number filed called rdt2.1.</em><br></p><p><strong>rdt2.1 data transfer action:</strong></p><p><img src="rdt2.1-sender.png" alt="rdt2.1-sender"><br></p><p><img src="rdt2.1-receiver.png" alt="rdt2.1-receiver"><br></p><h2 id="Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-2"><a href="#Reliable-Data-Transfer-Over-a-Channel-With-Bit-Errors-rdt2-2" class="headerlink" title="Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2"></a>Reliable Data Transfer Over a Channel With Bit Errors: rdt2.2</h2><p><em>We can accomplish the same effect as a NAK via only send ACK .<br><br>Out free NAK reliable data transfer protocol for a channel with bit errors known as rdt2.2.</em><br></p><p>Suppose the sender sends a packet containing sequence number 0, the receiver receives this packet and sends ACK 0 response (containing sequence number 0) to the sender. Sender got this ACK 0 response message and send a new packet containing sequence number 1 to the receiver, at this moment, the receiver that receiver a corrupted new packet, then the receiver will send an ACK of last received correctly packet (ACK 0)to sender side. The sender that receiver the same ACK 0 response twice (that is, receiver duplicate ACK) know that the receiver did not receive the new packet.<br></p><p><strong>rdt2.2 data transfer action:</strong><br></p><ol><li>sender side<br><br><img src="rdt2.2-sender.png" alt="rdt2.2-sender"><br></li><li>receiver side<br><br><img src="rdt2.2-receiver.png" alt="rdt2.2-receiver"><br></li></ol><h2 id="Reliable-Data-Transfer-Over-a-Lossy-Channel-With-Bit-Errors-rdt3-0"><a href="#Reliable-Data-Transfer-Over-a-Lossy-Channel-With-Bit-Errors-rdt3-0" class="headerlink" title="Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0"></a>Reliable Data Transfer Over a Lossy Channel With Bit Errors: rdt3.0</h2><p><em>suppose now that in additions to corrupting bit errors , the underlying channel can lose packet as well.</em> <br></p><p><strong>Questions:</strong><br> </p><ul><li>How to detect packet loss and what to do when packet loss occurs.<br></li></ul><p><strong>Solution:</strong><br></p><ul><li>The use of checksumming sequence numbers ACK packet and retransmissions - the techniques already developed in rdt2.2 allow us to solution the latter concern.<br></li><li>To handling the first concern we require introduce a new protocol  mechanism. The protocol require the sender judiciously choose a time value. If an ACK is not received within this time , the packet is retransmitted .<br></li></ul><p><strong>rdt3.0 data transfer action:</strong><br><br>Because the packet sequence number alternate between 0 and 1, protocol rdt3.0 sometimes known as <strong>alternating-bit-protocol</strong><br><br><em>In the rdt3.0 , the sender will start a timer for packet via start_timer() event</em></p><p><strong>rdt3.0 sender side.<br></strong></p><p><img src="rdt3.0-sender.png" alt="rdt3.0-sender"><br></p><p><img src="operation-of-rdt3.0-1.png" alt="rdt3.0-operation-of-data-transfer-1"><br></p><p><img src="operation-of-rdt3.0-2.png" alt="rdt3.0-operation-of-data-transfer-2"><br></p><p><strong>Question:</strong></p><ul><li>How long must the sender wait to be certain that something has been lost ?<br></li></ul><h1 id="3-4-2-Pipelined-Reliable-Data-Transfer-Protocols"><a href="#3-4-2-Pipelined-Reliable-Data-Transfer-Protocols" class="headerlink" title="3.4.2 Pipelined Reliable Data Transfer Protocols"></a>3.4.2 Pipelined Reliable Data Transfer Protocols</h1><p><strong>Question:</strong><br></p><ul><li>Although the rdt3.0 is a functionally correct protocol . But it’s unlikely that anyone would happy with its performance . In fact , rdt3.0 has a dismal sender utilization. (more detail of calculation we can read the textbook)<br></li></ul><p><strong>Solution:</strong><br><br>To solution this performance problem is simple: Rather than operate in a stop-and-wait-protocol, the sender is allowed to send multiple packet without waiting for acknowledgment as illustrated figure below.<br></p><p><img src="Stop-and-wait-versus-pipelined-protocol.png" alt="Stop-and-wait-versus-pipelined-protocol"></p><p><em>Since the many in-transit sender to receiver packets can be visualized as filling pipeline , the technique is known as pipelining</em></p><p><strong>pipelining has the following consequence for reliable data transfer protocols:</strong><br></p><ul><li>The range of sequence number must be increated . Since we require to send mutiple packet , each packet need a unquie sequence number.</li><li>The sender and receiver side of protocol must has to buffer more than one packet.</li><li>The range of sequence number and buffering requirements will depend on the manner in which data transfer protocol responds to lost, corrupt and overlay delayed packets. Two basic approaches toward pipelined errors recovery can be identified :<strong>GO-Back-N and Selective repeat</strong>.<br></li></ul><h2 id="3-4-3-Go-Back-N-GBN"><a href="#3-4-3-Go-Back-N-GBN" class="headerlink" title="3.4.3 Go-Back-N(GBN)"></a>3.4.3 Go-Back-N(GBN)</h2><p>In the GBN protocol, the sender allowed to send mutiple packet without waiting for acknowledgment, but is constrained to have no more than some maximum allowable number N , the N often be referred as the window size, the Go-Back-N(GBN) protocol often be referred as sliding-window-protocol.<br></p><p><em>We maybe have questions that why we limit the window size N instead of unlimited</em><br><br>About this question we will discuss in the flow control and congestion control sections.<br></p><p><strong>Define</strong><br><br><img src="Sender&#39;s-view-of-sequence-numbers-in-the-Go-Back-N.png" alt="Sender&#39;s-view-of-sequence-numbers-in-the-Go-Back-N"><br></p><ul><li><strong>Base:</strong> The sequence number of the oldest unacknowledgment .</li><li><strong>nextseqnum :</strong> The smallest unused sequence number.</li><li><strong>[0 ~ base-1]:</strong> corresponds to have already been transmitted and acknowledged.</li><li><strong>[base ~ nextseqnum-1]:</strong> corresponds to have already been sent but not yet acknowledge.</li><li><strong>[nextseqnum ~ base+N-1]:</strong> can be used to send packet when the data arrived from upper layer.<br><br><strong>[base+N ~ ]:</strong> can not be used until an unacknowledged packet has been acknowledged. </li></ul><p><em>Note that the GBN protocol packet containing fixed-length-sequence-number-filed ,in TCP protocol ,the length of sequence-number-filed is 32 bits, the range of sequence number is [0 ~ $2^{32} -1$ ] different to rdt3.0 that ranger of sequence number is [0 ~ 1],and the length of sequence-number-filed is 1 bits.</em><br></p><p><strong>GBN data transfer action:</strong><br></p><ol><li>receiver side <br></li></ol><p><img src="GBN&#39;s-FSM-receiver.png" alt="GBN&#39;s-FSM-description-receiver"><br></p><p><strong>The GBN’s sender must respond to three type of event.</strong><br></p><ul><li><strong>Invacation from above:</strong> When rdt_send() be invoked from the upper layer. The sender requires to check the window whether the window has full. If the window is not full , the data from above can make be packet and sent . The sender will update appropriately some variables. If the window is full, the sender will refuse data and indication the upper layer that the window has full. The upper layer will resend it again before a period of time.<br></li><li><strong>Receipt of an ACK:</strong> Noting function <code>base = getacknum(rcvpkt)+1</code> because the receiver use <strong>cumulative acknowledgment</strong>(we will discuss in receiver side ), for example , we can know packet of sequence number low than n has received correctly in the receiver side. When the sender side got the packet of sequence number n. Then we can update <code>base = n+1</code> and (stop_timer()orstart_timer) according to corrusp<br></li><li><strong>A timeout event:</strong> If timeout occurs , the sender will resends all packets that previously sent but have not yet been acknowledgment . Namely<code>udt_send(sndpkt[base])....udt_send(sndpkt[nextseqnum-1])</code><br></li></ul><p><strong>The GBN’s receiver must respond to event:</strong><br><br><em>In the GBN protocol , the receiver will discard out-of-order packets , for example the receiver expected sequence number is n , but the receiver receive a packet containing sequence number n+1 or more larger than n , the receiver will discard this packet and resend the packet containing expected sequence number to sender via udt_send(sndpkt) event. So the receiver be called use <strong>cumulative acknowledgment</strong>.</em> <br></p><p><img src="GBN-in-operation.png" alt="GBN-in-operation"><br></p><p><strong>Note that the GBN protocol sender must be maintain The upper and lower bound of its window and position of nextseqnum within this window. The receiver must be maintain the sequence number of next in-order-packet.(expectedseqnum)</strong><br></p><p>How does GBN protocol work we can see this video: <a href="https://www.youtube.com/watch?v=9BuaeEjIeQI">GBN</a><br></p><h2 id="3-4-4-Selective-Repeat-SR"><a href="#3-4-4-Selective-Repeat-SR" class="headerlink" title="3.4.4 Selective Repeat (SR)"></a>3.4.4 Selective Repeat (SR)</h2><p><strong>Question:</strong><br>Although GBN protocol avoiding the utilization problem of rdt3.0 , The GBN itself also has a performance problem . When the window size and bandwidth-delay both large, many packets can be in pipeline. If have a packet lost in the transmission will cause a large number of packets to retransmission.<br></p><p><strong>Solution:</strong><br>As the name suggests, <strong>selective repeat protocol</strong> avoid unnecessary retransmission by having the sender retransmit those packets that it suspects were received in error(that were lost or corrupted ) at the receiver.<br></p><p><img src="Selective-repeat-sender-and-receiver-views-of-sequence-number-space.png" alt="Selective-repeat(SR)-sender-and-receiver-views-of-sequence-number-space.png"><br></p><p><strong>Difference to GBN protocol, SR protocol has window in the receiver side like the figure above. <br></strong><br><em>The receiver will acknowledgment a correctly received packet whether or not it is in-order. Out-of-order packet will be buffering until any missing packet (that is lower than sequence number has buffered) are received. When the packet of sequence number (rcv_base) is received , the receiver will deliver a batch of packet that <strong>begin with sequence number (rcv_base) and end with smallest unreceived sequence number minus one</strong> to upper layer. Then number rcv_base increase <br></em></p><p><strong>SR protocol data transfer action:</strong><br></p><ol><li>sender side <br></li></ol><ul><li><strong>Data received from above:</strong> The sender will check the next sequence number (nextseqnum) whether or not larger than window size <code>If(nextseqnum&gt;base+N)</code>.If the nextseqnum is within the window, the sender will make data into packet and send it to receiver. Otherwise the sender will either buffered or returned to upper layer for later transmission as in GBN.<br></li><li><strong>Timeout:</strong>  Different to GBN protocol , in the SR protocol , each packet has its own logical timer since only a single packet will be transmitted on timeout.<br></li><li><strong>ACK received:</strong> If an ACK packet within the window is received , the SR sender will marks that packet as having been received. Until the packet containing sequence number (send_base) is received . Then the sender will move the send_base forward to the unackknowledgment packet with smallest sequence number.<br></li></ul><ol><li>receiver side <br></li></ol><ul><li>Packet with sequence number in [rcv_base,rcv_base+N-1] is correctly received whatever whether or not in-order. Then the packet is buffered at the receiver . If the packet containing sequence number (rcv_base) is received. The receiver will deliver the packet that begins with rcv_base and end with the smallest unreceived sequence number minus one to the upper layer. Then move rcv_base forward to the smallest unreceived sequence number.<br></li><li>Packet with sequence number in [rcv_base-N,rcv_base] is correctly received . Occur this situation cause is a ACK with sequence number in [rcv_base-N,rcv_base] maybe lost or corrupted or bandwidth-delay ,then timeout the sender retransmission the packet , In this case , an ACK must be generated and resend this ACK to sender, even though this is a packet that has previously acknowledgment.<br></li><li>Otherwise : Ignore this packet.</li></ul><p><img src="SR-operation.png" alt="SR-operation.png"><br></p><p><strong>Disadvantages of SR protocol</strong><br><br><em>The two case could happen when the window size too-large and the range of sequence number too-small</em><br><br>The window size is 3 and the range of sequence number is 4 in the example <br></p><p><img src="SR-receiver-dilemma-a.png" alt="SR-receiver-dilemma-a.png"><br></p><p><strong>In this case , the old packet 0 is recognized as new packet 0, packet confuse</strong></p><p><img src="SR-receiver-dilemma-b.png" alt="SR-receiver-dilemma-b.png"><br></p><p><strong>In this case , packet 3 is lost , the rcv_base = 3 , The packet 0 containing new data will be recognized as old packet 0 when the sender send the new packet 0. Because <code>0&lt; [3,3+3-1]</code>. Packet confuse.</strong><br></p><p><em>How small window size must be ?</em><br><br><strong>Answer is window size must be less than or equal to a half of sequence number space for SR protocol.<br></strong></p><p>How does SR protocol work we can see this video : <a href="https://www.youtube.com/watch?v=Cs8tR8A9jm8">SR</a></p><h1 id="3-5-Connection-Oriented-Transport-TCP"><a href="#3-5-Connection-Oriented-Transport-TCP" class="headerlink" title="3.5 Connection-Oriented Transport:TCP"></a>3.5 Connection-Oriented Transport:TCP</h1><h2 id="3-5-1-The-TCP-connection"><a href="#3-5-1-The-TCP-connection" class="headerlink" title="3.5.1　The TCP connection"></a>3.5.1　The TCP connection</h2><p>The TCP “connection” is not an end-to-end TDM or FDM circuit as in a circuit switch network. Nor it’s a virtual circuit , only as the connection state reside entirely in two end system.<br><br>The TCP connection provide <strong>full-duplex service</strong>, namely , Application layer data of two end system  can sent to other side.</p><p><strong>The TCP connection always point-of-point that is between a single sender and a single receiver.</strong><br><br>The TCP connection established by <strong>three-way-handshake</strong> , the first two handshake by send the segment that can not carry payload, the third handshake by send the segment that can carry payload.<br></p><p>The TCP connection also always point-to-point , that is a singer sender and a single receiver.<br><br><strong>The TCP connection has buffer in two end system. The data is passed through socket then the TCP directs this data to connection’s sender buffer then the TCP will grab chuck of data from send’s buffer and pass the data to network layer. As shown in figrue below.</strong><br><br><img src="TCP-sender-and-receiver-buffer.png" alt="TCP-sender-and-receiver-buffer"><br></p><p><strong>Two terminology</strong><br></p><ul><li>MSS(Maximum segment size): The maximum amount of application data can place in segment.<br></li><li>MTU(Maximum transmission unit): The largest frame size (application data plus TCP/IP header line)<br> </li></ul><p><strong>In Summary</strong><br><br><em>The TCP connection consist of sender’s buffer and sender’s variables and socket connection to process in sender’s host and socket connection to process in receiver’s host and receiver’s variables and receiver’s buffer.</em><br> <em>As mentioned early TCP connection only has two state reside in the sender host and receiver host , no buffer and variable allocated in network element between two end system host (router and switch and repeater)<br></em></p><h2 id="3-5-2-TCP-Segment-Structure"><a href="#3-5-2-TCP-Segment-Structure" class="headerlink" title="3.5.2 TCP Segment Structure"></a>3.5.2 TCP Segment Structure</h2><p><img src="TCP-Segment-structure.png" alt="TCP-segment-structure"><br></p><ul><li><strong>Source and destination port numbers</strong>:corresponding to sender socket and receiver socket.<br></li><li><strong>Checksum field</strong>: for detecting the corrupt whether occurred during the traveling as like UDP checksum field.<br></li><li><strong>The 32 bits sequence number field</strong>: The sequence number is the byte number of first byte of data in the TCP packet sent (also called TCP segment)</li><li><strong>The 32 bits acknowledgment numbers</strong>: The next packet that receiver expects to receive.</li><li><strong>The 16-bits receiver number</strong>: Used for flow control , indicate the window size N that we discuss in the GBN and SR protocol.<br></li><li><strong>The 4-bits header length field</strong>: indicates how long the header is, in 32 bit “words”. The minimum value is “5” which would be 160 bits, or 20 bytes. The maximum length is 15, which would be 480 bits, or 60 bytes</li><li><strong>The optional and variable-length optional field</strong>: Used  when  a  sender  andreceiver negotiate the maximum segment size (MSS) or as a window scaling fac-tor for use in high-speed networks. A time-stamping option is also defined. </li><li><strong>The flag field contain 6 bits</strong>:<ul><li>ACK bit : Used to indicate that value carried in the acknowledgment field is valid .</li><li>RST,SYN,FIN bit: Used for connection setup and teardown .</li><li>PSH bit: Used to indicate the receiver should pass the data to upper layer immediately.</li><li>URG bit: I don’t know what this means</li></ul></li></ul><h3 id="Sequence-number-and-acknowledgment-number"><a href="#Sequence-number-and-acknowledgment-number" class="headerlink" title="Sequence number and acknowledgment number"></a>Sequence number and acknowledgment number</h3><p>Cause These two fields are critical part of TCP connection , We discuss more detail about these.<br></p><p><em>All byte in TCP connection are numbered beginning at a <strong>randomly choose</strong> initial sequence number(ISN) , The SYN packets consume one sequence number , so actual data begin at ISN+1</em><br></p><p><strong>For example The TCP connection establish as shown in figure below</strong><br><br><img src="TCP-connection.png" alt="TCP-connection-establish"><br></p><ul><li>Step 1: The client want to establish connection with server , it will send a packet contain SYN bit and randomly choose initial sequence number (Client_isn) to sever.(no payload)<br></li><li>Step 2: The server has received this packet then response a packet contain initial sequence number (server_isn) and SYN bit and acknowledgment number (Client_isn+1) to Client.(no payload)<br></li><li>Step 3: The connection established success when the Client has received the response of packet, Client then change the SYN to 0 and send the packet contain sequence number client_isn+1 and acknowledgment number server_isn+1 and actual data (payload) to server.<br> </li></ul><h2 id="3-5-3-Round-Trip-Time-Estimation-and-Timeout"><a href="#3-5-3-Round-Trip-Time-Estimation-and-Timeout" class="headerlink" title="3.5.3 Round-Trip Time Estimation and Timeout"></a>3.5.3 Round-Trip Time Estimation and Timeout</h2><p>TCP like rdt3.0 use timeout/retransmission mechanism to recover from lost segment.<br><br>Although conceptually simple , many subtle issue arise when we implement timeout/retransmission mechanism in actual protocol such as TCP protocol.<br><br><strong>Questions:</strong></p><ul><li>How larger time is timeout .<br> </li><li>How estimating the round-trip-time between the sender and receiver<br></li><li>Should a timer be associated with each and every unacknowledgment packet?<br></li></ul><h3 id="Estimating-The-Round-Trip-Time"><a href="#Estimating-The-Round-Trip-Time" class="headerlink" title="Estimating The Round-Trip-Time"></a>Estimating The Round-Trip-Time</h3><ul><li><strong>SampleRTT</strong>: Represent the amount of time between when the packet sent from the sender (that is pass the packet to the network layer) and when the acknowledgment segment has received.<br><br><em>The TCP does not estimate stampleRTT for every single packet(segment), Instead of TCP implementation take only one sampleRTT measurement at a time</em></li><li><strong>EstimatedRTT</strong>: Because different sampleRTT value will be fluctuate due to congestion in the routers and to varying load on the end systems. The sampleRTT is atypical , In order to estimate a typical RTT ,it is therefore natural to take some sort of avenger of sampleRTT . The TCP maintains an avenger called <strong>EstimatedRTT</strong>.<br><br><code>EstimatedRTT = (1- a) * EstimatedRTT + a * SampleRTT</code><br><br>The value of <code>a</code> typically choose 0.125.<br><br><code>EstimatedRTT = 0.875 * EstimatedRTT + 0.125 * sampleRTT</code><br><br><img src="RTT-sample-and-RTT-estimates.png" alt="RTT-sample-and-RTT-estimates"><br></li><li><strong>DevRTT</strong>: DevRTT as an estimate of how much sampleRTT typical deviates from EstimatedRTT.<br><br><code>DevRTT = (1-b) * DevRTT + b * |sampleRTT - EstimatedRTT|</code><br><br>The value of <code>b</code> typical choose 0.25.<br><br><code>DevRTT = 0.75 * DevRTT + 0.25 * |sampleRTT - EstimatedRTT|</code><br></li><li><strong>Timeout Interval</strong>: Clearly The timeout interval should be greater than or equal to EstiamtedRTT or unnecessary retransmission will be sent. But the timeout should not be too larger than EstimatedRTT . Otherwise when the segment has lost , The TCP would not retransmission quickly , leading to large transfer delay.<br><br><code>TimeoutInterval = EstimatedRTT + 4 * DevRTT</code><br><br>An <strong>initial</strong> Timeoutinterval value of 1 second is recommended </li></ul><h2 id="3-5-4-Reliable-Data-Transfer"><a href="#3-5-4-Reliable-Data-Transfer" class="headerlink" title="3.5.4 Reliable Data Transfer"></a>3.5.4 Reliable Data Transfer</h2><p>TCP is best categorize as a hybrid of GBN and SR protocol.<br></p><p><strong>In the receiver(server) side:</strong><br><br>In TCP protocol ,server use <strong>cumulative ACK</strong> as like GBN protocol does, server also buffer out-of-order packet as like SR protocol. <br><br><strong>In the sender(client)  side:</strong><br><br>Since TCP use cumulative ACK, If the client has received ACK with acknowledgment number 120, just mean the server has received all byte lower than 120<br><br><em>For example: The server sends the ACK with acknowledgment number is 120, namely, server expect next sequence number is 120, the client got the ACK packet, then sent two packets with sequence number 120,130 to the server , unfortunately, the packet with sequence number 120 is lost, the server received the out-of-order packet with sequence number 130, then, the server buffers the out-of-order packet as like SR protocol does and sent ACK with acknowledgment number 120 back to the client , here is different to SR protocol, as like GBN protocol does.</em></p><h3 id="TCP-Retransmission-and-Doubling-the-timeout-interval"><a href="#TCP-Retransmission-and-Doubling-the-timeout-interval" class="headerlink" title="TCP Retransmission and Doubling the timeout interval"></a>TCP Retransmission and Doubling the timeout interval</h3><p>Different from GBN and SR protocol, TCP only retransmits the not-yet-acknowledgment segment with the smallest sequence number when the timeout occurs, then restart timer with doubling timeout interval.<br></p><p><em>For example : Suppose the timeoutinterval associated with oldest not-yet-acknowledgment segment is 0.75 sec when the timer expires, TCP will retransmit this segment and set new expiration time to 1.5 sec , If the timer expires again 1.5 sec later , TCP will retransmit this segment and set new expiration time to 3.0 sec, however whenever the timer is started after either of two other events (that is ACK received and data received from application above), the timeoutinterval is derived from the most recent value of EstimatedRTT and DevRTT</em><br></p><p><strong>Qusetion: Why we need to doubling timeout interval.</strong><br><br>Because, in times of congestion , the segment maybe dropped or suffer long queues delay, If we resent the packet persistently , the congestion may get worse . Instead TCP should acts more politely with earn sender retransmit after long and long interval.<br></p><p><strong>TCP Fast Retransmit</strong><br><br>One of problem with timeout-triggered retransmissions is that the timeout period relatively long , when a segment is lost, this long timeout period will force sender to delay this segment retransmit thereby increasing the end-to-end delay. So we need to fast retransmits mechanism.<br></p><p>Before discuss TCP Fast Retransmit , we should know how does ACK generate .<br><br><strong>TCP ACK Generation Recommendation</strong><br><img src="TCP-ACK-Generation-Recommendation.png" alt="TCP-ACK-Generation-Recommendation"><br><br>The duplicate ACK is indicated that this segment has been lost, when the sender has received this same segment three time . TCP will perform fast retransmit , send this segment to receiver again.<br><br><em>For example : The sender send a large number of segment back to back , if one segment is lost , there will likely be many back-to-back duplicate ACK, if the sender received same duplicate more than three time , The sender will be perform fast retransmit, As shown in figure below.</em><br></p><p><img src="Fast-retransmit.png" alt="Fast-retransmit"></p><p><strong>Code snippet of Fast retransmit</strong><br><br><img src="Code-snippet-of-fast-retransmit.png" alt="Code snippet of Fast retransmit"><br></p><h2 id="3-5-5-Flow-Control"><a href="#3-5-5-Flow-Control" class="headerlink" title="3.5.5 Flow Control"></a>3.5.5 Flow Control</h2><p>Flow control is speed-matching-service that be used to matching the sender sending speed and the receiver’s application reading speed.<br><br>If the application reading receiver’s buffer at slow speed , the sender can very easily overflow the connection’s receive buffer by sending too much data and too quickly.<br> </p><p>TCP provide the flow control by having the sender maintain a variable called <strong>receive window</strong>, Because the TCP is full-duplex , the sender at each side of the connection maintain a distinct receive window.<br></p><p>Suppose the host A send segments to host B over TCP connection, host B allocate a buffer to this connection.<br><br>Let me define some variables for host B and host A.<br><br><strong>For Host B (server)</strong><br></p><ul><li>RcvBuffer : the size of receive window(buffer) size of host B.<br></li><li>LastByteRead : the number of the last byte in the data stream read from receive buffer by application in B.<br></li><li>LastByteRcv : the number of the last byte in the data stream has been received from network and has been placed in receive buffer.<br></li><li>rwnd : the amount of space room in the buffer  <code>rwnd = Rcvbuffer - [LastByteRead - LastByteRcv]</code> <br><br><img src="TCP-RcvBuffer.png" alt="RcvBuffer"><br><br><strong>For Host A (Client)</strong> <br></li><li>LastByteSent : the number of last byte in the data stream has sent at the sender side .<br></li><li>LastByteAcked : the number of last byte in the data stream has ACKed at the sender side . <br></li></ul><p>Host B and host A maintain those variables that we mention above.<br></p><p><strong>How to control the flow through these information.</strong><br><br>The Host B tells Host A that how much space room it has in the connection buffer by place the value of rwnd in receive window field of ACK segment.<br><br>The host A just need to keep the <code>LastByteSent - LastByteAcked</code> less than <code>rwnd</code> (,LastByteSent - LastByteAcked &lt;= rwnd`), the sender can assure that it is not overflowing the receive buffer at the Host B.<br></p><p>If the receive buffer has filled at the Host B, the Host A will stop sending data to Host B, instead, Host A will send one bit to Host B for keeping the connection until the Host B has space room again. <br></p><h2 id="3-5-6-TCP-Connection-Manage"><a href="#3-5-6-TCP-Connection-Manage" class="headerlink" title="3.5.6 TCP-Connection-Manage"></a>3.5.6 TCP-Connection-Manage</h2><p><strong>Establish TCP connection</strong><br><br><img src="TCP-connection-manage-1.png" alt="TCP-Connection-Manage-1"><br><br><strong>Finish TCP connection</strong><br><br><img src="TCP-connection-manage-2.png" alt="TCP-Connection-Manage-2"><br><br><strong>TCP states at the sender side</strong><br><br><img src="TCP-connection-manage-3.png" alt="TCP-Connection-Manage-3"><br><br><strong>TCP states at the receiver side</strong><br><br><img src="TCP-connection-manage-4.png" alt="TCP-Connection-Manage-4"><br></p><p><strong>The SYN flood attack</strong><br><br><em>we can see detail in the textbook</em><br></p><h2 id="3-6-Principles-of-Congestion-control"><a href="#3-6-Principles-of-Congestion-control" class="headerlink" title="3.6 Principles of Congestion control"></a>3.6 Principles of Congestion control</h2><h3 id="3-6-1-The-Causes-and-the-costs-of-Congestion"><a href="#3-6-1-The-Causes-and-the-costs-of-Congestion" class="headerlink" title="3.6.1 The Causes and the costs of Congestion"></a>3.6.1 The Causes and the costs of Congestion</h3><ul><li><p><strong>Scenario 1: Two sender , a Router with infinite buffer</strong><br><br>Assume the host A and host B have same sending original data rate $\lambda <em>{in}$ ( application sending original data into socket  by $\lambda </em>{in}$  ignore the cost of that be encapsulated by TCP/IP header line) and the router throughput capability is $R$<br><img src="Congestion-scenario-1-two-connection.png" alt="Chapter3-Transport-Layer/Congestion-scenario-1-two-connection.png"><br></p><p>  <em>The throughput equal to R/2 is consequence of two sender Host A and Host B sharing outgoing link of the router.<br></em><br><img src="Congestion-scenario-1-throughput-and-delay.png" alt="Chapter3-Transport-Layer/Congestion-scenario-1-throughput-and-delay.png"><br></p><p>  <em>We can see the sender sending rate more approaches $R/2$ , delay become more larger and larger. The delay become to infinite when the $\lambda_{in}$ larger than $R/2$<br></em></p><p>  <strong>Here , we found one cost of congestion — large queue delay are experienced as the packet-arrived rate near the link throughput capability.<br></strong></p></li><li><p><strong>Scenario 2: Two Senders and a Router with Finite Buffers</strong><br></p><p>  The $\lambda<em>{in}$ is denoted application layer sending the original data into socket by $\lambda</em>{in}$ bytes/sec.<br><br>  The $\lambda’<em>{in}$ is denoted transfer layer sending segment into network by $\lambda’</em>{in}$ bytes/sec (containing original data and retransmited data).<br><br>  The Router throughput capacity is $R$ bytes/sec.<br><br><img src="Scenario-2-two-hosts.png" alt="Chapter3-Transport-Layer/Scenario-2-two-hosts.png"><br><br><strong>a.</strong> The Host A and Host B is able to somehow (magically) determine whether or not the buffer is free in the router . sender only sends data only has free buffer . In this case  $\lambda<em>{in}$ equal to $\lambda’</em>{in}$, didn’t occur packet loss. This case is shown as figure.a below <br><br><strong>b.</strong> The Host A and Host B may set a larger enough timeout can determine the pakect has been lost , then sender only retransmit packet that is determinded has been lost. This case is shown as figure.b below, we can see the $0.5R$ units of data transmitted . $0.333R$ bytes is original data and $0.166R$ bytes is retransmitted data<br><br><strong>we can here see another cost of congestion is the sender must perform retransmit packet in order to compensate for dropped packet due to buffer overflow.</strong><br><br><strong>c.</strong> The Host A and Host B may set a small timeout interval (or in face of large delay), the sender retransmit prematurely and retransmit packet that have been delay in queue but not yet lost. The original data and retransmited data both may reach the receiver , the receiver will discard the copy of original data . This case is shown as figure.c below <br><br><strong>we can here see the third cost of congestion — unneeded retransmissions by sender in face of large delay may cause router to use it link bandwish to forward unneeded copies of packet</strong><br><img src="Scenario-2-performance.png" alt="Chapter3-Transport-Layer/Scenario-2-performance.png"><br></p></li><li><strong>Scenario 3 Four sender and Router with Finite Buffer and Multihop Paths</strong></li></ul><p><img src="Scenario-3-Four-senders.png" alt="Chapter3-Transport-Layer/Scenario-3-Four-senders.png"><br><br>In this case the A-C connection share route R2 with B-D connection. Consider The host A send data to host C and host B send data to host D both at the same time . The data of host A arrive router R2 with R bytes/sec i , The data of Host B arrive router R2 with $\lambda$ , the Host A and Host B need to compare for the free buffer of router R2, if the $\lambda &lt;&lt; R$ , nothing going happen , data will safely arrive in destination host, but if the $\lambda &gt;&gt; R$ (the $\lambda$ extremely large) , the router will be filled immediately by data of host B , the data of host A will lost because of buffer overflow and that work done by router A will be wasted.<br></p><p><img src="Scenario-3-performance.png" alt="Chapter3-Transport-Layer/Scenario-3-performance.png"><br><br><strong>We can see the fourth cost of dropping the packet due to congestion — when a packet is drop along a path, the transmission capacity that was used at each of upstream link to forward that packet to this point at which it is dropped end up having been wasted.</strong><br></p><h3 id="3-6-2-Approach-to-Congestion-Control"><a href="#3-6-2-Approach-to-Congestion-Control" class="headerlink" title="3.6.2 Approach to Congestion Control"></a>3.6.2 Approach to Congestion Control</h3><p><strong>Two kind of Congestion control way</strong><br></p><ul><li><strong>End-to-End Congestion Control</strong></li><li><strong>Network-assisted Congestion Control:</strong> The Network (router) provide the feedback to sender indicate the congestion state .<strong>Two feedback way for congestion control.</strong><br><ul><li>Direct feedback: The router direct inform the sender via send choke packet.<br></li><li>The router mark/updata in a packet flowing from sender to receiver to indicate the congestion. Upon recipt of a marked packet , the receiver notifies the sender congestion indication .<br></li></ul></li></ul><p><img src="Two-feedback-way.png" alt="Chapter3-Transport-Layer/Two-feedback-way.png"></p><h3 id="3-6-3-Network-Assisted-ATM-ABR-Congestion-Control"><a href="#3-6-3-Network-Assisted-ATM-ABR-Congestion-Control" class="headerlink" title="3.6.3 Network Assisted ATM ABR Congestion Control"></a>3.6.3 Network Assisted ATM ABR Congestion Control</h3><p><strong>This section we can learn by textboot</strong><br></p><h2 id="3-7-TCP-Congestion-Control-End-To-End-Congestion-Control"><a href="#3-7-TCP-Congestion-Control-End-To-End-Congestion-Control" class="headerlink" title="3.7 TCP Congestion Control (End-To-End Congestion Control)"></a>3.7 TCP Congestion Control (End-To-End Congestion Control)</h2><p>This approach (The TCP Congestion Control Mechanism )taken by TCP is to have each sender limit the rate at which its sends traffic into its connection as a function of perceive network congestion. How to perceive the congestion ? we will discuss below. <br><br>This approach requires senders keep track of an additional variable , <strong>the congestion window</strong> that is denoted <strong>cwnd</strong> [different to <strong>receive window(rwnd)</strong> at flow control]<br><br>The congestion window imposes an constraint on the rate at which a TCP sender can send into the network.<br><br><code>The unacknowledged data = LastByteSent - LastBystAck &lt;= min&#123; cwnd , rwnd&#125;</code></p><ul><li><strong>In order to focus to Congestion Control , we assume the receive window is large enough that we can ignore it.</strong><br></li><li><strong>We also assume the sender always has data to send.</strong><br></li><li><strong>We define the “loss event” at a TCP sender as the ocurrence of either a timeout or recipt of three duplicate ACK from the receiver.<br></strong></li></ul><p><strong>How congestion is detected ?.</strong><br><br><em>In the TCP congestion mechanism, The ACK is used to perceive the network congestion situation, The congestion window is used to constrain sent data rate. If ACK is received quickly, the TCP will increase the sender congestion window size quickly. If ACK is received slowly, the TCP will increase the sender congestion window size slowly. If “loss event” occurred (indicate Netwok congestion ),　the TCP will take some measures to reduce the congestion window size<br></em></p><p><strong>Give a overview of TCP congestion control, Now ,let me see more detail about TCP congestion-control algorithm</strong><br></p><p>The TCP congestion-control algorithm has three major components:</p><ul><li><strong>Slow start</strong></li><li><strong>Congestion avoidance</strong></li><li><strong>Fast recovery</strong></li></ul><h3 id="Slow-Start"><a href="#Slow-Start" class="headerlink" title="Slow Start"></a>Slow Start</h3><p>When a TCP connection begin . the value of cwnd typically initialized to a small value of 1 MSS (maximum segment size) resulting in an initial sending rate of roundly MSS/RTT. For example , The MSS equal to 500 bytes , the RTT equal to 200 msec , the resulting inital sending rate is only roundly 20 kbps.<br><br><strong>If each ACK that is sent within RTT can be received within the same RTT. The TCP is doubling the value of cwnd. Namely increase the value of cwnd by a single MSS every ACK within the same RTT</strong><br><br>For example, the initial value of cwnd is 1 MSS, the sender is sending 1 segment into the network within an RTT . when ACK of this segment is received at the sender within the same RTT  , the TCP is doubling the value of cwnd that is to say cwnd become to 2 MSS, the sender can send two-segment within RTT right now. If these two ACK of segments is received at the sender within the same RTT  , the cwnd is doubling to 4 MSS.<br><br><strong>Thus the TCP send rate start slow , but grow exponentially during the slow phase.</strong><br><br><img src="Slow-Start.png" alt="Slow-Start"> <br><br><strong>When should this exponentail growth end?</strong></p><ul><li><strong>The first way:</strong> When timeout event ocurred , The TCP will set the value of cwnd back to 1 MSS begin slow start process anew, and <em>set a new state variable <strong>ssthresh</strong> (that is “Slow Start Threashold”) to $cwnd/2$</em></li><li><strong>The second way:</strong> When the $cwnd \geq ssthresh$ ocurred , the slow start end and turn into congestion aviodance mode.</li><li><strong>The third way:</strong> When the thripe duplicate ACK is detected , the slow start end and turn into fast recovery mode, perform fast retransmit.</li></ul><h3 id="Congestion-Avoidance"><a href="#Congestion-Avoidance" class="headerlink" title="Congestion Avoidance"></a>Congestion Avoidance</h3><p>On entry to the Congestion-Avoidance state , the value of cwnd is approximately half its value when congestion was last encountered , that is to say , the congestion could be just around the corner.<br><br><strong>Thus , rather than doubling the value of cwnd every RTT. TCP adopt more conservative approach and increase the value of cwnd by just a single MSS every RTT</strong></p><p><strong>The several events should do in the Congestion Avoidance state.</strong><br></p><ul><li>The TCP sender increases the value of cwnd by $MSS\cdot(\frac{MSS}{cwnd})$ bytes (here cwnd is constant) when ever a new Acknowledgment arrives. For example the cwnd equal to 500 bytes and the MSS equal to 50 bytes, the sender is sending 10 segment within an RTT . Thus the TCP sender is increasing the value of cwnd by $5$ bytes when ever a new Acknowledgment arrives.</li><li>When the timeout occurred , The TCP sender is set the value of cwnd back to $1$ MSS and the value of ssthresh is updated to half the value of cwnd , end up turn into slow start mode .<br></li><li>When the thripe duplicate Acknowledgment is received . The sender is seting $ssthresh =\frac{cwnd}{2}$ and $cwnd = ssthresh + 3 \ast MSS$,then turn into fast recovery mode.</li></ul><h3 id="Fast-Recovery"><a href="#Fast-Recovery" class="headerlink" title="Fast Recovery"></a>Fast Recovery</h3><p><strong>The several events should do in the Fast Recovery state</strong><br></p><ul><li>The value of cwnd increased by $1$ MSS for every duplicate ACK received for the missing segment that caused TCP enter the fast-recovery state.</li><li><p>When the ACK arrived for the missing segment , the sender set $cwnd = ssthresh$ and turn into congestion avoidance state .</p></li><li><p>If the timeout occurred , the sender  set the value of ssthresh to half the value of cwnd and set the value of cwnd to $1$ MSS, then turn into slow start state.<br><br><strong>The relationship between the three kinds of state</strong><br><br><img src="The-three-state-of-congestion-algorithm.png" alt="The-three-state-of-congestion-algorithm.png"><br><br><strong>Congestion window size changes along with time Ignoring theinitial slow-start period when a connection begins and assuming that losses are indi-cated by triple duplicate ACKs rather than timeouts.<br></strong><br><img src="Congestion-window-size-changes-along-with-time.png" alt="Congestion-window-size-changes-along-with-time.png"><br></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Shell入门学习</title>
    <link href="/2020/04/09/Shell%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2020/04/09/Shell%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<pre><code>#!/bin/bashecho -e &quot;hello, world\n&quot;# 1.变量的定义使用my_name=lexssamaecho &quot;1.$my_name&quot;# 2. 另一种定义方式course=&quot;linux start&quot;echo 2. $&#123;course&#125;# 3. 只读变量readonly coursecourse=&quot;linux kernel&quot; #readonly 不能写入(改变)echo &quot;3. $&#123;course&#125;&quot; # 输出的还是linux start# 4.删除变量unset my_name echo &quot;4.$&#123;my_name&#125;&quot;# 5.export 导出一个环境变量export MY_NAME=&quot;lexssama&quot;# 6. 查找自定义的环境变量env | grep MY_NAME# 7. 特殊变量echo &quot;文件名称: $0&quot; # 特殊变量$0表示脚本文件的名称echo &quot;参数１: $1&quot; #特殊变量$1表示传入第一个参数echo &quot;参数２: $2&quot; #特殊变量$2表示传入第二个参数echo &quot;参数３: $3&quot; #特殊变量$3表示传入第三个参数echo &quot;全部参数: $@&quot; #特殊参数$@表示传入的所有参数echo &quot;参数个数: $#&quot; #特殊参数$#表示传入参数的个数# 8. 基本运算# 8.1 算术运算 (加减乘除取余，+-*/%)a=16b=17# 加法expr 用加法举例子var0=`expr $a+$b`echo &quot;$a+$b=$var0&quot;# 另一种运算方式var1=$[$a+$b] echo &quot;$a+$b=$var1&quot;#8.2 关系运算# -eq(相等) -ne(不相等) -gt(大于) -ge(大于等于) -lt(小于) -le(小于等于)if [ $a -eq $b ] #注意格式是[空格$a.....$b空格]then    echo &quot;$a -eq $b : a 等于 b&quot;else    echo &quot;$a -eq $b : a 不等于 b&quot;fi# 8.3 布尔与逻辑运算# ! 非运算# -o 或运算# -a 与运算# &amp;&amp; 逻辑与 (逻辑与和与运算是不一样的，一个逻辑判断true,false 一个是二进制运算# || 逻辑或# == 相等(仅仅限于数字比较)# != 不相等(仅仅限于数字比较)if [[ $a -gt 0 &amp;&amp; $b -gt 0 ]] #注意格式是[[空格$a.....$b空格]],并且逻辑判断是[[then     echo &quot;a,b都大于0&quot;fi# 8.4文件测试运算# -d 是否为目录# -f 是否为普通文件# -r -w -x 是否可读，可写，可执行# -s 文件是否为空# -e 文件是否存在file=$0if [ -f $file ]then     echo &quot;为普通文件&quot;fiif [ -e $file ]then     echo &quot;文件存在&quot;else    echo &quot;文件不存在&quot;fiif [ -r $file ]then     echo &quot;文件可读&quot;else    echo &quot;文件不可读&quot;fi if [ -w $file ]then     echo &quot;文件可写&quot;else    echo &quot;文件不可写&quot;fiif [ -x $file ]then     echo &quot;文件可执行&quot;else    echo &quot;文件不可执行&quot;fi# 9.字符串# 单引号：原样输出，变量无效# 双引号：可以包含变量course1=&quot;Linux-shell入门学习&quot;# 单引号questions=&#39;Linux-shell入门学习：$course!&#39;echo &quot;$questions&quot;# 双引号answer=&quot;请学习&lt;&lt;$course1&gt;&gt;课程!&quot;echo &quot;$answer&quot;# 字符串拼接echo -e &quot;拼接后一起输出:\n&quot;$questions &quot;\n&quot; $answer#字符串长度(命令: $&#123;#str&#125;)str=&quot;hello,world&quot;echo &quot;字符串&quot;$str&quot;的长度为:&quot;$&#123;#str&#125;#获取子串，从第一个字符开始截取三个(命令: $&#123;str:1:3&#125;)echo &quot;字符串&quot;$str&quot;子串:&quot;$&#123;str:1:3&#125;#查找子串(命令: `expr index &quot;$str&quot; wo`)matched=`expr index &quot;$str&quot; wo`echo &quot;字符串&quot;$str&quot;查找wo的位置在&quot;$matched# 9.1 字符串运算符号# = 字符串是否相等　[ $a = $b ]# != 字符串是否不相等　[ $a != $b ]# -z 字符串长度是否为0 [ -z $a ]# -n 字符串长度是否不为0 [ -n &quot;$a&quot; ]# $　字符串是否为空　[ $a ]# 10. 数组# 10.1 数组的定义arr=(&quot;aa&quot; &quot;bb&quot; &quot;cc&quot; &quot;hello world&quot;)# 10.2 设置　元素arr[2]=&quot;222&quot;# 10.3 读取　元素echo &quot;下标为2的元素:&quot;$&#123;arr[2]&#125;# 10.4 读取　所有元素echo &quot;所有元素: &quot;$&#123;arr[@]&#125;# 10.5 获取数组的长度len=$&#123;#arr[@]&#125;echo &quot;数组长度: $len&quot;echo &quot;数组长度: &quot;$&#123;#arr[@]&#125;# 11.分支 (if else , case)# 11.1 if else age=20if [ $age -le 10 ] # &lt;=10then    echo &quot;少年&quot;elif [ $age -le 20 ]  # &lt;=20 注意是elifthen    echo &quot;青年&quot;elif [ $age -le 50 ]  # &lt;=50then    echo &quot;中年&quot;else # &gt;50    echo &quot;老年&quot;fi# 11.2 case status=1case $status in    0) echo &quot;todo&quot; ;;    1) echo &quot;doing&quot; ;;    2) echo &quot;done&quot; ;;esac# 12.循环# for...in..do...done# while...do...done# util...do...done# breakfor item in $&#123;arr[@]&#125;do    echo &quot;$item&quot;done# 13. 函数# function关键字可加可不加 # 函数后面的()可加可不加function myfun()&#123;    echo &quot;这是shell函数!&quot;&#125;myfun# 函数传参和返回值function add()&#123;    local ret=$(($1+$2))    return $ret&#125;add 5 8echo $?</code></pre>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
      <category>Shell</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Shell</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Manjaro-System-configuran</title>
    <link href="/2020/04/03/Manjaro-System-configuran/"/>
    <url>/2020/04/03/Manjaro-System-configuran/</url>
    
    <content type="html"><![CDATA[<h1 id="Manjaro-System-finish-picture"><a href="#Manjaro-System-finish-picture" class="headerlink" title="Manjaro System finish picture"></a>Manjaro System finish picture</h1><p><img src="manjaro_System_finish.png" alt="Manjaro"></p><p>一下配置文件都在 <a href="https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System">https://github.com/LEXSSAMA/Configure-file-of-Manjaro-System</a></p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="1-首先下载镜像安装"><a href="#1-首先下载镜像安装" class="headerlink" title="1.首先下载镜像安装"></a>1.首先下载镜像安装</h2><h2 id="２．换源"><a href="#２．换源" class="headerlink" title="２．换源"></a>２．换源</h2><pre><code>sudo pacman-mirrors -i -c China -m rank</code></pre><p>选择一个好用的就可以，我选择的是<br><a href="https://mirrors.sjtug.sjtu.edu.cn/manjaro/">https://mirrors.sjtug.sjtu.edu.cn/manjaro/</a></p><h2 id="３．更新系统"><a href="#３．更新系统" class="headerlink" title="３．更新系统"></a>３．更新系统</h2><pre><code>sudo pacman -Syy     #更新缓存sudo Pacman -Syyu    #更新系统</code></pre><h2 id="４．配置VIM"><a href="#４．配置VIM" class="headerlink" title="４．配置VIM"></a>４．配置VIM</h2><pre><code>sudo pacman -S vim</code></pre><p>然后编辑$HOME下的.vim/vimrc文件即可<br><br>我的也是刚刚开始使用vim所以配置的内容并不丰富</p><pre><code>syntax onset numberset relativenumberset hlsearchset smartcaseset cursorlineset cursorcolumn hi CursorColumn term=reverse ctermbg=white guibg=grey40hi CursorColumn ctermbg=238 guibg=grey40hi CursorLine term=underline cterm=underline guibg=grey40set ignorecaseset cursorlineset wrapset incsearchset showcmdset wildmenumap s &lt;nop&gt;map S :w&lt;CR&gt;map Q :q&lt;CR&gt;map R :source $MYVIMRC&lt;CR&gt;noremap U 5knoremap D 5jcall plug#begin(&#39;~/.vim/plugged&#39;)Plug &#39;vim-airline/vim-airline&#39;Plug &#39;rakr/vim-one&#39;Plug &#39;preservim/nerdtree&#39;Plug &#39;ybian/smartim&#39;Plug &#39;arcticicestudio/nord-vim&#39; Plug &#39;connorholyday/vim-snazzy&#39;Plug &#39;Valloric/YouCompleteMe&#39;Plug &#39;iamcco/markdown-preview.nvim&#39;, &#123; &#39;do&#39;: &#39;cd app &amp; yarn install&#39;  &#125;Plug &#39;dhruvasagar/vim-table-mode&#39;, &#123; &#39;on&#39;: &#39;TableModeToggle&#39; &#125;Plug &#39;vimwiki/vimwiki&#39;call plug#end()    let g:lightline = &#123;\ &#39;colorscheme&#39;: &#39;snazzy&#39;,\ &#125;</code></pre><h2 id="5-安装i3wm"><a href="#5-安装i3wm" class="headerlink" title="5.安装i3wm"></a>5.安装i3wm</h2><pre><code>sudo pacman -S i3</code></pre><p>配置i3只需要配置~/.config/i3/config文件即可<br><br>安装完i3可能会有分辨率的问题可以修改$HOME下的.Xresources文件<br>添加一下语句：<br></p><pre><code>Xft.dpi = 200     #数字可以随便改</code></pre><h2 id="6-安装fcitx中文输入法"><a href="#6-安装fcitx中文输入法" class="headerlink" title="6.安装fcitx中文输入法"></a>6.安装fcitx中文输入法</h2><pre><code>$ sudo pacman -S fcitx-sogoupinyin$ sudo pacman -S fcitx-im     # 全部安装$ sudo pacman -S fcitx-configtool     # 图形化配置工具</code></pre><p>将fcitx添加到环境变量中去</p><pre><code>sudo vim ~/.xprofile</code></pre><p>然后在里面添加：</p><pre><code>export GTK_IM_MODULE=fcitxexport QT_IM_MODULE=fcitxexport XMODIFIERS=”@im=fcitx”</code></pre><p>最后在~/.config/i3/config文件中添加</p><pre><code>exec_always fcitx</code></pre><p>这样开机就会直接启动fcitx了</p><h2 id="7-安装alacritty"><a href="#7-安装alacritty" class="headerlink" title="7.安装alacritty"></a>7.安装alacritty</h2><pre><code>sudo pacman -S alacritty</code></pre><p>在i3中修改alacritty的快捷键为mod+回车键</p><pre><code>bindsym $mod+return exec alacritty</code></pre><p>配置alacritty只需要修改~/.config/alacritty/alacritty.yml文件即可<br></p><p><strong>如果~/.config/文件中没有alacritty/alacritty.yml文件就自己创建一个，或者上github上面复制一个就可以了</strong><br><br>如果要alacritty的透明的话要安装picom，这个软件就是以前的compton</p><pre><code>sudo pacman -S picom</code></pre><p>执行picom,然后修改~/.config/alacritty/alacritty.yml<br></p><pre><code>background_opacity: 0.75</code></pre><p>也可以修改成其他的值，我比较喜欢0.75的透明度<br><br>最后把picom加入i3的开机启动中</p><h2 id="8-安装SSR"><a href="#8-安装SSR" class="headerlink" title="8.安装SSR"></a>8.安装SSR</h2><p><strong>无图像界面的SSR client</strong></p><pre><code>wget http://www.texfox.com/ssrsudo mv ssr /usr/local/binsudo chmod +x /usr/local/bin/ssrssr install</code></pre><p>安装完成后配置SSR</p><pre><code>ssr config</code></pre><p>把机场的SSR信息填入</p><pre><code>ssr start</code></pre><p>就连接上了，有不明白的命令可以执行</p><pre><code>ssr help</code></pre><p><strong>有图像界面的SSR client可以用electron-ssr</strong><br><br>链接：<br><a href="https://github.com/qingshuisiyuan/electron-ssr-backup">https://github.com/qingshuisiyuan/electron-ssr-backup</a></p><h2 id="9-安装google-chrome-谷歌浏览器"><a href="#9-安装google-chrome-谷歌浏览器" class="headerlink" title="9.安装google-chrome_(谷歌浏览器)"></a>9.安装google-chrome_(谷歌浏览器)</h2><pre><code>sudo pacman -S google-chrome</code></pre><p>因为很经常用到google所以我把它设置成i3的快捷键，即在~/.config/i3/config中添加下面语句</p><pre><code>bindsym $mod+c exec google-chrome-stable</code></pre><h2 id="10-安装Albert"><a href="#10-安装Albert" class="headerlink" title="10.安装Albert"></a>10.安装Albert</h2><p>因为i3默认的$mod+d的菜单快捷键太丑了，所以安装Albert<br><img src="albert.png" alt="albert"><br></p><pre><code>sudo pacman -S albert</code></pre><p>在i3中设置albert开机启动<br></p><pre><code>exec_always albert</code></pre><p>然后修改albert的热键在终端第一次执行albert时会提醒修改热键，下图是我的配置．<br></p><p><img src="albert1.png" alt="albert1"><br><br><img src="albert2.png" alt="albert2"><br><br>因为我设置的热键ALT+d与i3的热键冲突（我的$mod键是ALT键）,所以我干脆取消了i3中的热键</p><h2 id="11-安装ranger"><a href="#11-安装ranger" class="headerlink" title="11. 安装ranger"></a>11. 安装ranger</h2><pre><code>sudo pacman -S ranger</code></pre><p>配置ranger依旧是修改~/.config/ranger/rc.conf文件<br><br><strong>如果没有这些文件可以自己创建，详细看官方</strong></p><h2 id="12-安装网易云音乐"><a href="#12-安装网易云音乐" class="headerlink" title="12. 安装网易云音乐"></a>12. 安装网易云音乐</h2><pre><code>sudo pacman -S netease-cloud-music</code></pre><h2 id="13-安装QQ-TIM"><a href="#13-安装QQ-TIM" class="headerlink" title="13.安装QQ/TIM"></a>13.安装QQ/TIM</h2><pre><code>sudo pacman -S deepin.qq.com.officesudo pacman -S deepin.qq.com.im</code></pre><p>由于在i3的环境下，一打开QQ就会闪退，解决方法是<br></p><pre><code>yaourt -S gnome-setting-daemon</code></pre><p>然后运行/usr/lib/gsd-xsettings(最好在i3配置中设置开机启动)，然后就可以运行ＱＱ了</p><h2 id="14-安装light"><a href="#14-安装light" class="headerlink" title="14. 安装light"></a>14. 安装light</h2><p>因为i3装上之后亮度调节是个问题所以装一个light</p><pre><code>sudo pacman -S light</code></pre><p>要设置亮度的时候只要在命令行输入</p><pre><code>sudo light -S 20     #数值可改，我一般用２０</code></pre>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>chapter2 :Homework problems and Questions</title>
    <link href="/2020/03/31/chapter2-Homework-problems-and-Questions/"/>
    <url>/2020/03/31/chapter2-Homework-problems-and-Questions/</url>
    
    <content type="html"><![CDATA[<p>下面提到的的文档都收藏在 <a href="https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中">https://github.com/LEXSSAMA/Valuable-document-collention-during-learning-process中</a><br></p><p>课本是：computer network a top-down approach<br></p><p><strong>1.列出5个(非专有)的互联网应用，并说明他们使用的应用层协议</strong><br><br><em>查过一些资料，好像有一个技术叫做Deep packet inspection (DPI)可以查到软件使用的协议，github上也有一个开源软件nDPI，还有一个软件叫做wireshark,但是因为有点复杂，我现在暂且不深入研究，下面答案都来着互联网</em></p><ul><li>1 . Chrome (谷歌浏览器貌似不是开源的．．．,不管了用的最多,下面答案来自stackoverflow)<br><br>  in term of what protocol you can use in the chrome browser bar you can use: HTTP,HTTPS,FILE and FTP.SSH is not implemented by chrome,but rather it implements SSL, it also does nit implement SMTP,but rather when you visiting a website(via HTTP or hopefully HTTPS).That website is not at all connecting to an SMTP server to display you you emails, but is merely serving up web pages and conneting to API’s to display/edit/compose your email (by then which the email client’s backend is connected to their SMTP server).<br><br>Also chrome does implement FTP,like you can visit an IP address that has FTP enable such as : ftp://123.34.45.890 and you can use the directory listings as a webpage. An example of this would the CentOS mirrors <a href="https://www.centos.org/download/mirrors/">here</a>.on the right column they have FTP sites. You can access the FIP director via web browser that supports FTP or you can fire up a terminal and do ftp ftp://ftp.is.co.za/mirror/centos/.<br></li><li>2 .  网易云音乐<br><br>在应用层使用的是HTTP协议</li><li>3 . 微信<br><br>微信是应用层是使用HTTP协议（来源是: 利用Wireshark软件对微信协议的分析——QPIC）</li><li>4 . 大部分软件都需要使用DNS协议,例如上面文章有提到微信就需要使用DNS来进行域名解析</li><li>5 . QQ <br><br>应用层使用的是QICQ协议</li></ul><p><strong>2.网络体系结构和应用程序的体系结构有什么不同?</strong></p><ul><li>应用程序体系结构（application architecture）<br></li></ul><ol><li>客户－服务器体系结构（client-servers architecture）<br>答：<br></li><li>P2P（peer to peer）</li><li>混合体系结构 (hybind architecture)</li></ol><ul><li>网络体系结构(network architecture)</li></ul><ol><li>应用层(application layer)</li><li>传输层(transport layer)</li><li>网络层(network layer)</li><li>链路层(link layer)</li><li>物理层(physical layer)</li></ol><p>所以有什么不同呢？<br></p><div class="table-container"><table><thead><tr><th style="text-align:center">Network architecture</th><th style="text-align:center">Application architecture</th></tr></thead><tbody><tr><td style="text-align:center">Network architecture refers to the organization of the communication process into layers.</td><td style="text-align:center">Application architecture, on the other hand, is designed by an application developer and dictates the broad structure of the application.</td></tr><tr><td style="text-align:center">How any network of any local area or wide area is built is  called the Network Architecture.</td><td style="text-align:center">How any application is built is called the application architecture</td></tr><tr><td style="text-align:center">Example -  The five-layer Internet architecture, Servers.</td><td style="text-align:center">Example - Client-server or P2P.</td></tr></tbody></table></div><p>(来源是：<a href="http://computer-science-solutions.blogspot.com/2017/05/what-is-difference-between-network.html">What is the difference between network architecture and application architecture?</a>)<br><br>我感觉这个比较没有意义啊，要比较也是P2P和client-servers architecture之间有什么不同吧．．<br></p><p><strong>3. 在两个进程的通信会话中哪个进程是客户端，那个进程是服务端</strong><br><br>答：In the context of communication session between a pair of process,the process that initiates the communication session is labeled as client and the process that wait to be contacted is labeled as server.(来自课本) <br></p><p><strong>4.对于P2P的协议你是否同意在通信会话时没有客户端－服务端的概念，请说明理由</strong><br><br>答：不同意，P2P协议也存在客户端－服务端的概念，但是与client-servers架构稍有不同的是，P2P中的peer即当客户端也当服务端，当peer接受数据的时候为客户端，上传数据的时候就是服务端，上传下载也可以同时进行,此时peer即是客户端，也是服务端.<br></p><p><strong>5.一个运行在源主机的进程如何识别确认运行的目标主机和运行在目标主机上的进程</strong><br><br>答：通过目标主机的IP地址可以确认目标主机，通过目标主机程序占用的套接字端口号可以确认目标主机程序<br></p><p><strong>6.假如你想做一个交易(do a transation)从远端的客户端到服务端，要求尽可能的快，你会选择用TCP还是UDP,说明理由</strong><br><br>答：我会选择UDP,因为UDP只需要一次RTT（round-trip-time），而TCP至少两次RTT,所以用UDP更快<br></p><ul><li><strong>TCP:</strong><br><img src="TCP-handshake.png" alt="TCP-handshake"></li></ul><p><strong>7.课本2.4提及到的应用程序都是no data loss and timing(没有数据丢失，以及不规定时间的)能不能构想一个应用程序要求没有数据丢失并且对时间有很高的敏感性</strong><br><br>答：网络游戏．<br></p><p><strong>8.列出传输层协议能提供的４类服务，对于每项服务指出是由TCP还是UDP(或者两者都可以)提供</strong><br><br>答：We have organized transfer protocol services along four dismensions : <strong>reliable date transfer</strong>,<strong>throughput</strong>,<strong>timing</strong>,<strong>security</strong>(来自课本)<br></p><ul><li>reliable data transfer : TCP do,UDP not.</li><li>throughput: TCP have congestion-control mechanism,UDP not.</li><li>timing :Neither TCP nor UDP.</li><li>security: Neither TCP nor UDP.<br><br><strong>9.TCP可以增强为SSL(Secure Socket Layer)去提供进程之间的安全服务，例如加密，SSL的操作是在传输层还是在应用层，如果软件开发者想要将TCP增强为SSL，他应该怎么做．</strong><br></li></ul><p>答：We emphasize that SSL is not a third internet transport protocol, on the same level as TCP and UDP but instead is an enhancement of TCP, with the emhancement being implemented in the application layer,In particular, if an application wants to use the services of SSL, it needs to include SSL code(exiting highly optimized libraries and classes) in both the client and server side of the application.  SSL has its own socket API that is similar to the trandition of TCP socket API, When an application uses SSL, the sending process passes cleartext data to the SSL socket; SSL in the sending host then encrypts the data and passes the encrypted data to the TCP socket; The encrypted data travels over the internet to the TCP socket in the receiving process. The receiving socket passes the encrypted data to SSL,which decrypts the data. Finally.SSL passes the cleartext data through its SSL socket to receiving process.(来自课本)<br></p><p><strong>10. 什么是握手协议？</strong><br><br>答:握手协议就是两端在首次建立TCP链接时互相发送的三次消息,如第六题的图．<br></p><p><strong>11.为什么HTTP,FTP,SMTP,POP3,都是基于TCP,而不是UDP</strong><br><br>答：因为上面这些协议都需要得到的数据都是按照顺序，TCP可以提供这个功能而UDP不行<br></p><p><strong>12.想象电子商务网站想要保持每一个用户的购买记录，描述用用cookie怎么做到</strong><br><br>答：当你首次访问网站时，网站会给你创建一个独一无二的ID(cookie码),这个码会存放在你的浏览器中，也会存放在网站的后台数据库中，网站会把你选择的商品存入你cookie码的相应存储中，当你下次访问相同网站的时候，你发出的请求会夹带相应的cookie码，这时网站数据库就能匹配到你，从而展现你的购买记录．<br></p><p><strong>13.描述Web缓存怎么降低接收请求对象的延迟，Web缓存是能降低所以请求对象的延迟还是仅仅降低部分请求对象的延迟，为什么？</strong><br><br>答：Web缓存是在大学，企业，ISP 之类的在局域网中建立一个基础设施，用来存储最近局域网内用户访问过的网站，当在短时间内，用户再次访问该网站，Web缓存就可以在直接返回数据给用户，而不用请求网站的服务器，从而降低延迟,<strong>Web缓存是可以降低所有请求对象的延迟的，因为有缓存的存在，降低了局域网向外部互联网的请求流量，所以降低了所有请求对象的延迟．</strong><br></p><p><strong>14. Telnet一个Web服务器然后发生一些请求指令标题行要包括<code>If-modified-since:</code>去让强制服务器响应<code>304 Not Modified</code>status code.消息</strong><br><br>答：下面是google的答案，但是我对www.baidu.com照做得到的200,没办法得到304，所以…</p><pre><code>“telnet” command: It is a command used in windows (also in linux) to connect to the web server.The server responds to the HTTP GET requests.It reply to the client with the requested information.Command to open the connection with web server:        telnet &lt;domain name of web server&gt; &lt;port number&gt; example: telnet www.sr2jr.com 23After establishing the connection with the web serverit is possible to request a specified page from the web server.Command to request the page web server:        GET &lt;page name&gt; HTTP/1.0If the page is available then the server sends the page details.It include the “If-modified-since” message with the 304 Not Modifiedstatus code in the response.</code></pre><p><strong>15.为什么说FTP发送带外控制信息.</strong><br><br>答：因为FTP（文件传输协议）会建立两个TCP连接（端口为20,21），一个是用来传输文件数据(20)，一个是用来传输控制信息(21)，因为FTP协议传输控制信息是用额外的一个连接传送，而不是文件传输的连接所以叫做带外(out-of-band)<br></p><p><strong>16.假设Alice用基于Web的e-mail的站帐户例如（Hotmail 和 gmail)发送文件给Bob.Bob访问其邮箱服务器用POP3协议，描述消息是怎么从Alice发送到Bob这边，明确的表示出发送途中使用的应用层协议．</strong><br></p><pre><code>graph LRid1(Alice)==HTTP==&gt;id2(Web e-mail server)==SMTP==&gt;id3(Bob&#39;s mail server)==POP3==&gt;id4(Bob)</code></pre><p><strong>17.打印出你最近收到的邮件的标题(header of e-mail),一共有多少行，分析每一行的的作用.</strong><br><br>答：</p><ul><li><strong>Message header:</strong><br><img src="Messagesheader.png" alt="messageheader"><br><br>分析：Messageld,Created at,From,To,Subject字段就不说了．<br><br>SPF: sender policy framework (发送方策略架构)是一直email的认证协议，主要用来检测伪造的email地址．<br><br>DKIM: Domain Key Identify Mail(域密钥识别邮件),允许接受者通过数字签名去检查是否发件人的域名是否真正发生和认证过该邮件．<br><br>DMARC: Domain Message Authentication,Reporting and Comformance,是一种email的认证协议，用来保护邮件域名所有者的邮件域名免受未授权使用．<br></li></ul><p><strong>18.从用户的角度，阐述一下POP3的download-and-delete-mode和download-and-keep-mode的不同之处.</strong><br><br>答:不同之处就在于download-and-delete-mode下载完了就删除，当换一个设备(终端)再次访问的时候，就无法看到删除的消息了，这样消息的移动性就很差．<br>而download-and-keep-mode下载然后保留，当换一个设备再次登录邮箱服务器下载时，还可以看到，消息的移动性很好.<br></p><p><strong>19.是否可能组织的Web server 和mail server有相同的主机别名,如果可能，mail server的RR类型是什么？</strong><br><br>答:可以做到，mail server的类型是MX(Mail Exchange Record).<br></p><p><strong>20.是否可能根据邮件的头部信息地址(例如什么.edu)中确定信息发送的IP地址．对Gmail做同样的操作．</strong><br><br>答：You should be able to see the sender’s IP address for a user with an .edu email address. But you will not be able to see the sender’s IP address if the user uses a gmail account．</p><p><strong>21.在BitTorrent中假设Alicer在30秒中始终提供块给Bob,Bob是否有必要在这30秒内同样给Alice提供块呢?请说明理由</strong><br><br>答:没有必要，因为在BitTorrent中，没30秒选出一个而外的peer给其发送块是为了帮助新进入的peer以后可以有块去交易，当然如果Alice是Bob的top four neighboring 的话Bob也会给Alice发送块．</p><p><strong>22.思考一下，如果一个新进入的peer Alice，没有任何块，所以她不能成为邻居peer的Top four neighboring peer，也没有块可以上传，所以他是怎么样得到她的首块的呢?</strong><br><br>答:这道题其实21题时已经回答了，在BitTorrent中其他有块的peer每30秒就会选出一个幸运peer(optimistically unchocked)然后给其发送块，所以Alice有可能被选中然后就可以得到第一个块</p><p><strong>23.什么是覆盖网络(overlay network),它是否包括路由，它的网络边缘是什么.</strong><br><br>答:覆盖网络就是在P2P文件分享中两个peer的一种逻辑链接，即不是真实的在物理上的连接，它不包括路由，网络的边缘就每个peer.</p><p><strong>24.描述一下every peer keep tracks all peer 的DHT结构的优缺点，和circular DHT (no shortcut)的优点和缺点．</strong><br><br>答:</p><ul><li>Every peer keep tracks all peer 这种结构的优点就是你可以马上就知道你需要的东西的位置，但是缺点就是当peer量巨大的时候，每个peer都存储其他peer的踪迹实在是太耗存储资源了，而且很难维护．</li><li>circular DHT(no shortcut)的优点就是它只需要记住两个peer就可以了，缺点就是peer数量N巨大的时候，peer的询问请求的平均时间是N/2.</li></ul><p><strong>25.列出至少4个不同的适合使用p2p架构的应用程序.</strong><br>答:文件分发，即时信息，视频流，分布式计算</p><p><strong>26.在章节2.7的描述中UDP服务器仅仅需要一个套接字，而TCP服务器需要两个套接字，为什么，如果TCP服务器支持n个用户同时连接，每个用户来自不同的客户端主机，TCP服务器需要的多少个套接字.</strong><br><br>答:在TCP服务器一端有一个wecoming socket,用来进行握手协议的,握手协议结束后TCP会新开一个端口叫做connecting socket进行数据的传输,所以TCP服务器支持n个客户端同时连接就会有n+1个socket,而UDP没有wecoming socket仅仅需要一个套接字．</p><p><strong>27.在章节2.7中的客户－服务端应用程序中，TCP连接为什么服务端一定要在客户端之前先启动，而UDP相反，必须服务端先在客户端之前启动．</strong><br><br>答:因为TCP在传输数据之前必须进行三次握手，而UDP可以直接传输数据</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chapter 2: Application Layer</title>
    <link href="/2020/03/28/Chapter-2-Application-Layer/"/>
    <url>/2020/03/28/Chapter-2-Application-Layer/</url>
    
    <content type="html"><![CDATA[<p><strong>The questions is provided below,we can find the answer in the Computer Network A Top-down Approach</strong></p><h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><ul><li>HTTP is said to be a stateless protocol<h2 id="no-persistent-connections-and-persistent-connections"><a href="#no-persistent-connections-and-persistent-connections" class="headerlink" title="no-persistent-connections and persistent-connections"></a>no-persistent-connections and persistent-connections</h2>no-persistent-connections:Client obtains the 10 JPEGs over 10 serial TCP connections or whether JEPGs are obtained over parallel TCP connections?<br></li></ul><p>Advantage of persistent-connections(or disadvantage of no-persistent-connections):NO-persistent-connection has some shortcoming.First, a brand-new connection must be established and maintained for each requires objects. For earn TCP connections, TCP buffer must be allocated and TCP variable keeps between client and servers, This is a significant burden on the web servers. But persistent-connections don’t need to establish so many connections, just establish once connections can work.<br></p><h2 id="HTTP-Require-and-Response"><a href="#HTTP-Require-and-Response" class="headerlink" title="HTTP Require and Response"></a>HTTP Require and Response</h2><p><strong>HTTP-Require</strong><br><img src="HTTP_requires.png" alt="HTTP-Require"></p><p><strong>HTTP-Response</strong><br><img src="HTTP_respont.png" alt="HTTP-Response"></p><h2 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h2><p>Cookie allow web site to keep track of users.<br><br>Cookie technology has four components: <br></p><ul><li>a cookie header line in the HTTP response message.</li><li>a cookie header line in the HTTP require message.</li><li>a cookie file kept on user’s end system and managed by user’s browser</li><li>a cookie back-end database at the web site.</li></ul><p><img src="Cookie-process.png" alt="HTTP-Cookie"></p><h2 id="Web-cache"><a href="#Web-cache" class="headerlink" title="Web cache"></a>Web cache</h2><p>Web cache also called proxy servers,Web cache can increasing response speed and reduce the cost of throughput.</p><p><img src="Web-cache.png" alt="HTTP-Web cache"></p><h2 id="The-condition-GET"><a href="#The-condition-GET" class="headerlink" title="The condition GET"></a>The condition GET</h2><p>At explore above ,We already have cache ,We now face a problem is that if the informations  of requirements have been modified but the cache still stored the old information ,How to solve this problem?<br><br>The answer is <strong>The condition GET</strong> ,. We can see details at the Computer network a Top-Down Approach<br></p><h1 id="File-Transfer-Protocol-FTP"><a href="#File-Transfer-Protocol-FTP" class="headerlink" title="File Transfer Protocol (FTP)"></a>File Transfer Protocol (FTP)</h1><h2 id="control-connection-and-data-connection"><a href="#control-connection-and-data-connection" class="headerlink" title="control connection and data connection"></a>control connection and data connection<br></h2><p><strong>Control connection</strong> is used for sending control informations between two host, such as identification, password, commands<br><br><strong>Data connection</strong> is used for actually send a file .<br></p><p>FTP use port 21 as Control connection and use port 20 as Data connection<br><br><img src="FTP-TCP-connections.png" alt="FTP-TCP"><br>As you see,FTP is established two TCP connections<br></p><p>In the typically FTP sessions, Users initial access remote hosts, namely establish TCP control connection used port 21, then provide identifications and passwords through port 21. After providing this authorization information. Users can transfer files from localhost to remote host vice versa.</p><p><img src="FTP-transfer-file.png" alt="FTP-transfer-file"><br>If user wanna to transfer another files during the same sessions,FTP will opens the another <strong>data connections</strong>(The data connections is no-persistent)<br><br>Throughout a sessions,the FTP servers must maintain state about the user. In particularly, The servers must be associate the <strong>control connections</strong> with a specific user and must keep track of user’s current directory as user’s wanders about the remote directory tree.<br></p><h2 id="FTP-Commands-and-Replies"><a href="#FTP-Commands-and-Replies" class="headerlink" title="FTP Commands and Replies"></a>FTP Commands and Replies</h2><p>The FTP Commands and Replies sent across the control connection in 7-bits ASCLL format.<br><br>We can see details at computer-network-a-top-down-approach.</p><h1 id="SMTP-Simple-Mail-Transfer-Protocol"><a href="#SMTP-Simple-Mail-Transfer-Protocol" class="headerlink" title="SMTP(Simple Mail Transfer Protocol)"></a>SMTP(Simple Mail Transfer Protocol)</h1><p>SMTP is a principal application layer protocol for electronic mail. As most application layer protocol, SMTP base on TCP provides reliable data transfer service and SMTP also has two side , client side which executes on the sender’s mail server, servers side which executes on recipient’s mail servers. When the mail server send mail to other mail servers , it act as a SMTP client, when the mail server receive mail from other mail server, it act as SMTP server.<br><img src="SMTP-transfer.png" alt="SMTP-transfer"></p><ol><li>Alice provides Bob’s email-address and composes a message then instruct Alice’s agent  send the message to Bob.<br></li><li>Alice’s send the message to Alice’s mail servers,where it is placeing in message queue.<br></li><li>Alice’s mail server established TCP connections to port 25 at Bob’s mail server. <br></li><li>After initail SMTP handshaking, the SMTP client (Alice’s mail server) send the message to Bob’s server through TCP connection.<br></li><li>The recipient side receives the message and places the message in Bob mailbox.<br></li><li>Bob invoke his user agent to read the message at his convenience.<br></li></ol><p><em>In particular , if Bob’s mail server is down . The message can’t send to Bob’s mail server, the message will remain in Alice’s mail server and wait for a new attempt — the message do not get place in any other intermediate mail server, Reattempt done for every 30 minutes , if<br>resend  not success after several day , Alice’s mail server remove the message and notice Alice with e-mail message</em><br> <strong>More details of SMTP handshake or SMTP commands please see the Computer Network A Top-Down Approach</strong> <br></p><h2 id="Comparison-with-HTTP"><a href="#Comparison-with-HTTP" class="headerlink" title="Comparison with HTTP"></a>Comparison with HTTP</h2><ol><li>HTTP and SMTP both use persistent connections</li><li>HTTP is mainly a pull protocol — Some one load information with browser on web servers or use HTTP to pull some information from the server at their convenience. SMTP is mainly a push protocol — The sending mail server push file to other receiving mail server . <br> </li><li>SMTP requires each message include body of each message that must be encode be 7-bit-ASCLL , so that The SMTP is a bit of pain to send the large attachment ,video, image, audio. But HTTP data does not impose this restriction. <br></li><li>HTTP encapsulate each object in it own HTTP response message , SMTP place all message’s object into one message. <h2 id="Mail-Access-Protocol"><a href="#Mail-Access-Protocol" class="headerlink" title="Mail Access Protocol"></a>Mail Access Protocol</h2>Bob can’t obtain the message through SMTP from the Bob’s mail server. Because SMTP is push protocol,obtain message is pull operation. To solve this problem by introducing a special mail access protocol that transfer messages from Bob’s mail server to Bob’s host .There are currently a number of mail access protocol including <strong>Post Office Protocol - version 3 (POP3),Internet Mail Access Protocol (IMAP) and HTTP</strong><br><img src="SMTP-access-mail.png" alt="SMTP-access-mail"></li></ol><h3 id="POP3-Post-Office-Protocol-Version-3"><a href="#POP3-Post-Office-Protocol-Version-3" class="headerlink" title="POP3 (Post Office Protocol -Version 3)"></a>POP3 (Post Office Protocol -Version 3)</h3><p>POP3 Bob’s agent use port 110 establish TCP connection with Bob’s mail servers , With the TCP connections established , POP3 through three phase: <strong>authorization</strong>, <strong>transaction</strong>, <strong>Update</strong>.<br></p><ol><li><strong>authorization</strong>: Bob’s agent send the username and password to authenticate the user 2. <strong>transaction</strong>: During this phase , user agent can mark retrieves the message also can mark message for deletion (or remove the mask) ,and obtain mail statistic .  3. <strong>Update</strong>: Update occurs after user agent issued the <em>quit</em> command ending this POP3 session ,at this time, mail server will delete messages that were marked for deletion.<br></li></ol><p><em>more details about POP3 commands or process can see in the textbook</em><br></p><p><strong>During the POP3 sessions, the user agent and mail server maintain some state information. For example, maintain mark information for deletion during this POP3 session. However, POP3 doesn’t carry state information across POP3 sessions. (As I think, that’s mean POP3 maintain state information only occurs at POP3 sessions phase ,the state information will be deleted,if user agent ending the session)</strong></p><h3 id="IMAP-Internet-Mail-Access-Protocol"><a href="#IMAP-Internet-Mail-Access-Protocol" class="headerlink" title="IMAP (Internet Mail Access Protocol)"></a>IMAP (Internet Mail Access Protocol)</h3><p>The IMAP is significantly complex than POP3,and more feature than POP3<br><br><strong>The most significantly difference is IMAP can carry the state informations across IMAP sessions, but POP3 can’t</strong><br></p><h3 id="Web-base-Email-use-HTTP"><a href="#Web-base-Email-use-HTTP" class="headerlink" title="Web-base Email (use HTTP)"></a>Web-base Email (use HTTP)</h3><p>Web-base Email also famous today, for example gmail . Web browser and user communicates with its mailbox via HTTP.</p><h1 id="DNS-domain-name-system"><a href="#DNS-domain-name-system" class="headerlink" title="DNS (domain name system)"></a>DNS (domain name system)</h1><p><strong>The DNS protocols run over UDP and uses port 53.</strong> <br></p><p>The DNS is commonly employed by other application-layer protocol —including HTTP,SMTP, and FTP —to translate the user-supplied hostnames to IP address.<br></p><p>We see example above the DNS adds an additional delay, but ,fortunately the DNS cache will help reduce this delay. <br></p><p>DNS provide features: <strong>Host aliasing</strong> , <strong>Mail server aliasing</strong> , <strong>Load distribution</strong></p><ul><li>host aliasing and mail server aliasing make hostnames more mnemonic.<br></li><li>load distribution : For replicated web server , a numbers set of IP address associated with one canonical hostname . It can make server easier to handle the large access .<br><h2 id="overview-of-how-DNS-work"><a href="#overview-of-how-DNS-work" class="headerlink" title="overview of how DNS work"></a>overview of how DNS work</h2><strong>Let’s take closer to look at these three classes of DNS servers</strong> <br></li><li>Root DNS servers.</li><li>Top-level domain(TLD) server.</li><li>Authoritative DNS server.</li></ul><p>Take a look a simple example : <strong>www.amazon.com.</strong> (Don’t forget we have a . at the end) <br></p><ul><li>The <strong>.</strong> is Root DNS servers.</li><li>The <strong>com.</strong> is Top-lever domain (TLD) server</li><li>The <strong>amazon.com.</strong> is Authoritative DNS server.</li><li>The <strong>www</strong> is hostname<br><img src="DNS-hierarchy.png" alt="DNS-hierarchy"><br>We also have a another critically important DNS servers is <strong>Local DNS server</strong> that does not strictly belong to the hierarchy of DNS server.<br><br>When the host make a DNS query, the query is send to Local DNS server which act as proxy forwarding the query into the DNS hierarchy server.<br><h2 id="Two-way-for-send-DNS-queries"><a href="#Two-way-for-send-DNS-queries" class="headerlink" title="Two way for send DNS queries"></a>Two way for send DNS queries</h2></li><li><strong>iterative queries</strong><br><img src="DNS-server-iterative-queries.png" alt="DNS-iterative-queries"></li><li><strong>recursive queries</strong><br><img src="DNS-server-recursive-queries.png" alt="DNS-recursive-queries"><h2 id="DNS-caching"><a href="#DNS-caching" class="headerlink" title="DNS caching"></a>DNS caching</h2>We reduce the delay of DNS server by DNS cache technology.<br></li></ul><p><strong>The DNS server receives a DNS reply (for example the mapping of IP address and hostname) it can cache the mapping into the local memory(also can cache the mapping of TLD servers). For example , the local DNS server can cache the mapping of each host queries,When the user’s host send a query to local DNS server frequently at the short period of time . The local DNS server can send the reply to user’s host instantly</strong>.<br></p><p><em>The DNS servers discard the cache information after a period time (Often set to one or two day)</em><br></p><h2 id="DNS-Records-and-Messages"><a href="#DNS-Records-and-Messages" class="headerlink" title="DNS Records and Messages"></a>DNS Records and Messages</h2><h3 id="DNS-Records"><a href="#DNS-Records" class="headerlink" title="DNS Records"></a>DNS Records</h3><p>The DNS distributed database store <strong>resource records (RRs)</strong><br><br>The RRs provide Hostname-to-IP address mappings.Each DNS reply carries one or more RRs .<br></p><h4 id="DNS-Records-Format"><a href="#DNS-Records-Format" class="headerlink" title="DNS Records Format"></a>DNS Records Format</h4><p>The DNS Record have four fields that provide following below.<br></p><div class="table-container"><table><thead><tr><th style="text-align:left">Name</th><th style="text-align:left">Value</th><th style="text-align:left">Type</th><th style="text-align:left">TTL</th></tr></thead><tbody><tr><td style="text-align:left"></td></tr></tbody></table></div><p>The TTL is live time of Records in the RRs . The meaning of Name and Value is depend on Type. <br></p><p>In following example we will ignore the TTL filed.<br></p><div class="table-container"><table><thead><tr><th style="text-align:center">Type</th><th style="text-align:center">Name</th><th style="text-align:center">Value</th><th style="text-align:center">Description</th></tr></thead><tbody><tr><td style="text-align:center">A</td><td style="text-align:center">Hostname</td><td style="text-align:center">IP address</td><td style="text-align:center">Address record</td></tr><tr><td style="text-align:center">NS</td><td style="text-align:center">Domain</td><td style="text-align:center">Hostname of authoritative</td><td style="text-align:center">Name server record</td></tr><tr><td style="text-align:center">CNAME</td><td style="text-align:center">Alisa hostname</td><td style="text-align:center">Canonical name</td><td style="text-align:center">Canonical name record</td></tr><tr><td style="text-align:center">MX</td><td style="text-align:center">Alisa hostname of mail server</td><td style="text-align:center">Canonical name of mail server</td><td style="text-align:center">Mail exchange record</td></tr></tbody></table></div><p><strong>If a DNS server is authoritative for particular hostname ,then the DNS server will contain type A record for the hostname.</strong><br></p><p><strong>If a DNS server is not authoritative for a hostname ,then it will contain a type NS record for domain that include hostname, it also contain a type A record that provide IP address of DNS server in the value field of the NS record.</strong><br></p><ul><li>For example in the TLD server<br></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">Type</th><th style="text-align:center">Name</th><th style="text-align:center">Value</th></tr></thead><tbody><tr><td style="text-align:center">NS</td><td style="text-align:center">umass.edu</td><td style="text-align:center">dns.umass.edu</td></tr><tr><td style="text-align:center">A</td><td style="text-align:center">dns.umass.edu</td><td style="text-align:center">128.119.40.111</td></tr></tbody></table></div><h2 id="DNS-Messages"><a href="#DNS-Messages" class="headerlink" title="DNS Messages"></a>DNS Messages</h2><p>The DNS query and DNS reply have same Messages format as shown in Figure below .<br></p><ul><li><p><strong>DNS-Messages-Format</strong><br><img src="DNS-Messages.png" alt="DNS-Messages"></p></li><li><p><strong>We can use dig command to see DNS reply messages</strong></p></li></ul><p><img src="DNS-Messagas-dig.png" alt="DNS-Messages-dig"><br>ID:30379 is 16-bit number that identifies the query corresponding <strong>identification</strong> of figure above .This identifies is copied into the reply messages allowing the client match receive messages with sent queries. <br><br><strong>Let’s see more detail about header flags format</strong><br></p><div class="table-container"><table><thead><tr><th style="text-align:center">Flag field</th><th style="text-align:center">Description</th><th style="text-align:center">Length(bits)</th></tr></thead><tbody><tr><td style="text-align:center">OR</td><td style="text-align:center">indicate message is reply(1) or query(0)</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">OPCODE</td><td style="text-align:center">The type can be QUERY(standard query ,0),IQUERY(inverse query,1) or STATUS(server status request,2)</td><td style="text-align:center">4</td></tr><tr><td style="text-align:center">AA</td><td style="text-align:center">Authoritative Answer, in the response,indicates if the DNS server is authoritative for queried hostname</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">TC</td><td style="text-align:center">Truncation, indicates that this messages was truncated due excessive length</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">RD</td><td style="text-align:center">Recursion desired indicate if client means a recursion query.</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">RA</td><td style="text-align:center">Recursion Available indicate if reply messages supports recursion</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">Z</td><td style="text-align:center">zero ,reserved for future use</td><td style="text-align:center">3</td></tr><tr><td style="text-align:center">RCODE</td><td style="text-align:center">Response code, can be NOERROR(0),FORMERR(format error,1),SERVFAIL(2),NXDOMAIN(nonexistent domain 3),etc</td><td style="text-align:center">4</td></tr></tbody></table></div><h1 id="Peer-to-Peer-Applications"><a href="#Peer-to-Peer-Applications" class="headerlink" title="Peer-to-Peer Applications"></a>Peer-to-Peer Applications</h1><h2 id="BitTorrent"><a href="#BitTorrent" class="headerlink" title="BitTorrent"></a>BitTorrent</h2><p>BitTorrent is popular P2P protocol for file distribution.<br></p><p>In BItTorrent lingo, the collection of all peer in the distribution is called torrent.<br></p><p>Each torrent has a infrastructure called tracker.When a peer join in a torrent, it must register itself with tracker and periodically informs the tracker that it is still in the torrent. In this manner the tracker can keep the track of the peers that participating in the torrent. <br> </p><p><strong>Let we see a example to know more detail about how does p2p work.</strong><br><br>When a new peer Alice  want to join in torrent,what does it need to do.</p><ol><li>Alice must register herself with tracker.</li><li>The tracker will randomly select a subset of peers from a set of participating peers and send the all IP address of subset peers to Alice</li><li>Alice attempts concurrent establish TCP connection with subset peers. The succeed establish TCP connection peer is called <strong>“neighboring peers”</strong>. The neighboring peer probably leave at any time .</li><li>Periodically Alice will ask (over the TCP connection)neighboring peer for list of chucks they have. If Alice have L neighboring peers ,Alice will obtain L list of chuck that neighboring peers have, with this knowledge, Alice can issue(over the TCP connection) require for chucks she current doesn’t have .</li><li>Along with time pass .Alice have a set of chuck and know which chuck her neighboring peers have . At this instant of time .<strong>Alice will issue require for chucks her doesn’t have and rarest among her neighboring peers</strong> and <strong>Use clever trading algorithm determine which require her need to response namely which neighboring peer she need send the chuck(about the clever trading algorithm we discuss below)</strong> <br><h3 id="Incentive-mechanism-Clever-trading-algorithm"><a href="#Incentive-mechanism-Clever-trading-algorithm" class="headerlink" title="Incentive mechanism: Clever trading algorithm"></a>Incentive mechanism: Clever trading algorithm</h3>To determine which require  need to response , BitTorrent use clever trading algorithm.<br></li></ol><p>Specifically. For each of her neighboring peers , Alice will continuity measures the rate at which she receive bits and determine the four peer that feed her bit at the highest rate. Alice will reciprocates by send the chucks to these same four peers.<br></p><p>In the BitTorrent lingo , the four peers is said to be <strong>unchoked</strong>.<br>Every 10 seconds , Alice will recalculates the rate and possibly modifies the set of four peers.<br> </p><p>In specially, every 30 seconds , Alice will select a addition neighboring peer at random and send it chuck, The peer is said to be <strong>optimistically unchocked</strong> , The optimistically unchocked may become one of Alice’s top four peer , if it rate which send chuck to Alice is high enough.<br><br>The optimistically unchocked allow new peer to get chuck so that they can have something to trade. All the other neighboring peers beside the five peers (one optimistically unchoked and four unchoked) can’t received any chucks from Alice.</p><h1 id="distributed-Hash-Table-DHTs"><a href="#distributed-Hash-Table-DHTs" class="headerlink" title="distributed Hash Table (DHTs)"></a>distributed Hash Table (DHTs)</h1><p>Distributed Hash Table is referred to a distributed P2P version database.<br></p><h2 id="Circular-DHT"><a href="#Circular-DHT" class="headerlink" title="Circular DHT"></a>Circular DHT</h2><p>Each peer only award two peers ,immediate successor and predecessor<br></p><p>We use a hash function map each key to a integer in the ranger [0-2^n-1]. For example suppose n = 4 ,we get the ranger is [0-15]. Further suppose that these are eight peer in the system 1,3,4,5,8,10,12,15. Suppose we want to stored a pair (format:key value) (11,johnny wu) to one of peers in the system. Using out closest conventions ,since peer 12 is closest successor for key 11. We therefore store the pair into peer 12.<br><br><strong>Let’s see more detail about the example that we mentioned above.</strong><br></p><p>If the peer 3 (in figure below) want to know “who is responsible for key 11”, it only send the messages to clockwise around the circle , namely pass the message to peer 4 , if peer 4 don’t responsible key 11, it just passes the message to peer 5 , This process continues until the message arrives at the peer 12 , peer 12 receive the message will send response back to peer 3.</p><p><img src="Circle-DHT.png" alt="circle"><br></p><p>This circular arrangement of the peers is a special case of an overlay network. In an overlay network, the peers form an abstract logical network which resides above the “underlay” computer network consisting of physical links, routers,and hosts. The links in an overlay network are not physical links, but are simply vir-tual liaisons between pairs of peers. In the overlay in Figure(a) above, there are eightpeers and eight overlay links; in the overlay in Figure (b) there are eight peersand 16 overlay links. A single overlay link typically uses many physical links and physical routers in the underlay network.<br></p><p>The circular DHT provide a elegant way to build the database , but all N peer in the system , we have to forward the message around the circle , N/2 message are send average.<br></p><p>Fortunately we can refine the circular DHT, we can add a number of <strong>shortcut</strong> to each peer in the system . So that the each peer not only keep track of successor and predecessor but also keep track of a small number of shortcut like figure(b) above.<br></p><p>Thus,when the peer 4 receives message passes from peer 3 asking about key 11, it can determine the closer peer to key is its shortcut peer 10,then forward message directly to peer 10. Clearly the shortcut can significantly reduce the number of messages used to query<br></p><p>The next native question is “How many shortcut should the peer have and which peer should be these neighboring shortcut. “<br><br>The answer doesn’t referred in the textbook (computer-network-a-top-down-approach),we can only search with network use google.<br></p><h2 id="peer-churn"><a href="#peer-churn" class="headerlink" title="peer churn"></a>peer churn</h2><p>About peer churn we can learn in textbook page 155.</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>VIM指令学习</title>
    <link href="/2020/03/22/VIM%E6%8C%87%E4%BB%A4%E5%AD%A6%E4%B9%A0/"/>
    <url>/2020/03/22/VIM%E6%8C%87%E4%BB%A4%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="vim-选中的行列递增"><a href="#vim-选中的行列递增" class="headerlink" title="vim 选中的行列递增"></a>vim 选中的行列递增</h1><p><strong>例如想要替换下行中10行BL1,依次递增为BL1.BL2….BL10,可以用这种方法</strong></p><pre><code>BL1BL1  BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1BL1</code></pre><p>先用可视块选中这10行，然后ESC退到命令模式再按：输入命令<br></p><pre><code>:&#39;&lt;,&#39;&gt;s/BL\zs\d*\ze/\=line(&quot;.&quot;)-line(&quot;&#39;&lt;&quot;)+1/g</code></pre><p>这些指令的意思如下：</p><pre><code>&#39;&lt;,&#39;&gt;        我们所选中的区域 (:help &#39;&lt;，:help &#39;&gt; )s            在选中的区域中进行替换 (:help :s )\zs          指明匹配由此开始 (:help /\zs )\d*          查找任意位数的数字 (:help /\d )\ze          指明匹配到此为止 (:help /\ze )\=           指明后面是一个表达式 (:help :s\= )line(&quot;.&quot;)    当前光标所在行的行号 (:help line() )line(&quot;&#39;&lt;&quot;)   我们所选区域中第一行的行号 (:help line() )/g         代表一行内所有的BL都使用，如果没有\g就只会对第一个BL使用命令</code></pre><p>最后得到的结果是：（有\g）</p><pre><code>BL1BL1BL2BL2BL3BL3BL4BL4BL5BL5BL6BL6BL7BL7BL8BL8BL9BL9BL10BL10</code></pre><p>没有/g的情况是：<br></p><pre><code>BL1BL1BL2BL1BL3BL1BL4BL1BL5BL1BL6BL1BL7BL1BL8BL1BL9BL1BL10BL1</code></pre>]]></content>
    
    
    <categories>
      
      <category>vim</category>
      
    </categories>
    
    
    <tags>
      
      <tag>vim</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>KMP算法</title>
    <link href="/2020/03/22/KMP%E7%AE%97%E6%B3%95/"/>
    <url>/2020/03/22/KMP%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><strong>感谢:<br></strong><br><a href="https://blog.csdn.net/qq_30974369/article/details/74276186">KMP算法 Next数组详解(【洛谷3375】KMP字符串匹配 )</a><br><br><a href="https://wiki.jikexueyuan.com/project/kmp-algorithm/define.html">从头到尾彻底理解 KMP</a><br><br><a href="http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html">字符串匹配的KMP算法</a><br></p><p>KMP算法即是用来解决在一个字符串S(例如ABCDEFG)中快速查找字符串P(ABCD)的一个算法.<br><br>在介绍KMP算法之前我们先介绍暴力查找字符的算法<br></p><h1 id="字符串的暴力查找法"><a href="#字符串的暴力查找法" class="headerlink" title="字符串的暴力查找法"></a>字符串的暴力查找法</h1><p>如下图用暴力查找法在字符串S(BB….DE)中寻找匹配项字符P(ABCDABD）．<br></p><p><em>暴力查找法核心就是发现S[i]和P[j]不相等，S和P就开始回退，S回退到i=i-(j-1)处 ,j回退为０．具体看下图：<br></em></p><p><strong>比较S[0]!=P[0]不相等则回退,i=i-(j-1)=0-0+1=1,j=0,相当于S向前进一步，而P回到j=0再开始比较</strong><br><img src="BL1.png" alt="BL1"><br><strong>还是不相等，与上面情况相同</strong><br><img src="BL2.png" alt="BL2"><br><strong>S[i]=p[i],i++,j++继续向下比较</strong><br><img src="BL3.png" alt="BL3"><br><img src="BL4.png" alt="BL4"><br><strong>发现S[i]!=P[j]不相等开始回退</strong><br><img src="BL5.png" alt="BL5"><br><strong>置i=i-(j-1)=9-(6-1)=4,j=0,继续比较,即开始比较S[4]=B和P[0]=A,</strong><br><img src="BL6.png" alt="BL6"></p><p>可以发现暴力查找的缺点就在发现不相等，S和P都要回退，再重新比较，倘若S和P都特别长，假设S有10000个字符，P有1000个字符，S与P从第０个字符开始相等，而在第998个字符不等，这时，S就要从１号开始再和P从０开始重新比较，太费时．<br></p><p>有没有一种方法让i不改变而只改变j的方法来解决这个字符串的查找问题？没错就是KMP算法.<br></p><h1 id="KMP算法"><a href="#KMP算法" class="headerlink" title="KMP算法"></a>KMP算法</h1><p>在介绍KMP算法之前，需要先介绍<strong>部分匹配值表</strong><br></p><p>首先，要了解两个概念：”前缀”和”后缀”。 “前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。</p><p><strong>部分匹配值</strong>就是许多字符串＂前缀＂和＂后缀＂最长的共有元素长度，部分匹配值表就是各个子字符串的所以部分匹配值组成的表．<br></p><p>以字符串ABCDABD为例：<br></p><pre><code>-&quot;A&quot;,的＂前缀＂和＂后缀＂都是空集　共有元素长度是0． -&quot;AB&quot;,的＂前缀＂是｛A｝和＂后缀＂是｛B｝　共有元素长度是0 -&quot;ABC&quot;,的＂前缀＂是｛A,AB｝和＂后缀＂是&#123;C,BC&#125;　共有元素长度是0. -&quot;ABCD&quot;,的＂前缀＂是&#123;A,AB,ABC&#125;和＂后缀＂&#123;D,CD,BCD&#125;　共有元素长度是0 -&quot;ABCDA&quot;,的＂前缀＂是｛A,AB,ABC,ABCD｝和＂后缀＂是&#123;A,DA,CDA,BCDA&#125;　共有元素是A长度是1 -&quot;ABCDAB&quot;,的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA｝和＂后缀＂是｛B,AB,DAB,CDAB,BCDAB｝　共有元素是AB长度是2. -&quot;ABCDABD&quot;,的＂前缀＂是｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝和＂后缀＂是｛D,BD,ABD,DABD,CDABD,BCDABD,｝　共有元素长度0</code></pre><div class="table-container"><table><thead><tr><th style="text-align:center">字符串中各个子串</th><th style="text-align:center">前缀</th><th style="text-align:center">后缀</th><th style="text-align:center">最大共有元素长度</th></tr></thead><tbody><tr><td style="text-align:center">A</td><td style="text-align:center">空集</td><td style="text-align:center">空集</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">AB</td><td style="text-align:center">｛A｝</td><td style="text-align:center">｛B｝</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">ABC</td><td style="text-align:center">｛A,AB｝</td><td style="text-align:center">{C,BC}</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">ABCD</td><td style="text-align:center">{A,AB,ABC}</td><td style="text-align:center">{D,CD,BCD}　</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">ABCDA</td><td style="text-align:center">｛A,AB,ABC,ABCD｝</td><td style="text-align:center">{A,DA,CDA,BCDA}</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">ABCDAB</td><td style="text-align:center">｛A,AB,ABC,ABCD,ABCDA｝</td><td style="text-align:center">｛B,AB,DAB,CDAB,BCDAB｝</td><td style="text-align:center">2</td></tr><tr><td style="text-align:center">ABCDABD</td><td style="text-align:center">｛A,AB,ABC,ABCD,ABCDA,ABCDAB｝</td><td style="text-align:center">｛D,BD,ABD,DABD,CDABD,BCDABD,｝</td><td style="text-align:center">0</td></tr></tbody></table></div><p><br></p><p>如下图KMP算法在遇到S[i]!=P[j]时，i不改变而只改变j，j会向右前进，移动的位数符合以下公式：<br></p><pre><code>移动位数（Z）　＝　已匹配位数(X)　－　匹配子字符串的部分匹配值(Y)</code></pre><p><img src="KMP举例1.png" alt="KMP1"><br></p><p>P要向前移动的位数是6-2=4位，再进行比较．<br><img src="KMP举例2.png" alt="KMP2"></p><p><strong>为什么移动的位数要等于4呢，如果小于4会怎样？<br></strong><br>答：因为移动的位数等于4，再次比较时P字符前Y个字符不会发生不匹配的现象，而如果移动位数小于4，则再次<br>字符P,S再次比较时一定会发生不匹配的现象．<br><br><strong>为什么如果右移动小于Z就会发生不匹配的现象呢？</strong><br><br>答：如果向又移动３位则且要求再次比较不会发生不匹配的现象，就要求字符串P的前三位P0P1P2,与P3P4P5相等才不会发生不匹配的现象，但现在现实时P0P1和P4P5相等（部分匹配值为２），P0P1P2和P3P4P5不等，所以向右移动３一定会不匹配，同理向右移动２或者１都一样．<br></p><h2 id="KMP的代码实现"><a href="#KMP的代码实现" class="headerlink" title="KMP的代码实现"></a>KMP的代码实现</h2><p>next[i]里面存放就是计算出来的部分匹配值表的变形<br><br>部分匹配值表：<br><br>|部分匹配值表|||||||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|0|1|2|3|4|5|6|<br>|A|AB|ABC|ABCD|ABCDA|ABCDAB|ABCDABD|<br>|0|0|0|0|1|2|0|</p><div class="table-container"><table><thead><tr><th style="text-align:center">next[i]表</th><th style="text-align:center">相当于</th><th style="text-align:center">部分匹配值</th><th style="text-align:center">右移１位</th><th style="text-align:center">再把next[0]</th><th style="text-align:center">赋值为-1</th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">3</td><td style="text-align:center">4</td><td style="text-align:center">5</td><td style="text-align:center">6</td></tr><tr><td style="text-align:center">A</td><td style="text-align:center">AB</td><td style="text-align:center">ABC</td><td style="text-align:center">ABCD</td><td style="text-align:center">ABCDA</td><td style="text-align:center">ABCDAB</td><td style="text-align:center">ABCDABD</td></tr><tr><td style="text-align:center">-1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">2</td></tr></tbody></table></div><p><strong>为什么要这么做呢？而且为什么要把next[0]赋值为-1呢？</strong><br><br>因为这样方便写代码．把next[0]赋成-1,我认为是用来做一个标记，如果next[0]=0当两字符串从第0个就不匹配时，向又移动的位数就是0-0=0,相当于不移动，所以把next[0]设置成-1,当j=-1时代表第０个不匹配，就不用公式计算移动位数，直接i++,j++<br><br>假设现在文本串 S 匹配到 i 位置，模块串 P 匹配到 j 位置<br></p><ul><li>1.if (j == -1 || s[i] == p[j]) 则j++,i++<br></li><li>2.否则若s[i] != p[j]&amp;&amp; j!=-1,j=next[j]　(这里就相当于P向右边移动了j-next[j]位)<br>1</li></ul><pre><code class="lang-c">int KmpSearch(char* s, char* p)  &#123;      int i = 0;      int j = 0;      int sLen = strlen(s);      int pLen = strlen(p);      while (i &lt; sLen &amp;&amp; j &lt; pLen)      &#123;          //如果j = -1(第0个就不想等直接下一位)，或者当前字符匹配成功（即S[i] == P[j]），都令i++，j++              if (j == -1 || s[i] == p[j])          &#123;              i++;              j++;          &#125;          else          &#123;              //如果j != -1，且当前字符匹配失败（即S[i] != P[j]），则令 i 不变，j = next[j] (这条指令的效果相当于向右移动Z=j-next[j]位)                 //next[j]即为j所对应的next值                    j = next[j];          &#125;      &#125;      if (j == pLen)          return i - j;      else          return -1;  &#125;</code></pre><p>执行上述代码需要的条件是已经计算出需要匹配字符P的next[i]数组．</p><h2 id="next数组的计算"><a href="#next数组的计算" class="headerlink" title="next数组的计算"></a>next数组的计算</h2><p><strong>给出一个字符串P到底怎么计算出next[i]数组呢？</strong><br>答：<br></p><p><strong>这就是给出的字符串，黑黑一坨</strong><br><br><img src="next1.png" alt="next1"><br><br><strong>假设:字符串P的红色部分已经匹配，现在准备比较蓝色的位置</strong><br><br><img src="next2.png" alt="next2"><br><br><strong>蓝色位置和绿色位置比较,(后缀的下一位和前缀的下一位比较)</strong><br><img src="next3.png" alt="next3"><br><br><strong>蓝色与绿色匹配不上,此时寻找红色前缀的最大公共前后缀，即两个灰色部分相等</strong><br><br><img src="next4.png" alt="next4"><br><br><strong>由于两个红色部分是相同的所以红色后缀，也有两个灰色相同，（这四个灰色都是相同的）</strong><br><br><img src="next5.png" alt="next5"><br><br><strong>最后用第１个灰色的下一位，也就是紫色，与第４个灰色的下一位，也就是蓝色相比较</strong><br><br><img src="next6.png" alt="next6"><br></p><p>有点递归的感觉,具体代码如下：<br></p><pre><code class="lang-c">void GetNext(char* p,int next[])&#123;    int pLen = strlen(p);    next[0] = -1;    int k = -1;    int j = 0;    while (j &lt; pLen - 1)    &#123;        //p[k]表示前缀，p[j]表示后缀//next[0]=-1,next[1]=0是固定的        if (k == -1 || p[j] == p[k])         &#123;            ++k;            ++j;            next[j] = k;        &#125;        else         &#123;            k = next[k];        &#125;    &#125;&#125;</code></pre><p>尽管next数组已经可以很到的提高匹配的效率，但是如果遇到极端情况例如：<br><br>|0|1|2|3|4|5|6|7|8|9|10|11|12||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|A|A|A|A|A|A|A|A|B|B|B|B|B|…..|<br>|A|A|A|A|A|A|A|A|A|<br>|-1|0|1|2|3|4|5|6|7|这里是|next数组||<br>这样子匹配时，在８这里发生不匹配发生移动，移动的位数是８－７＝１位，也就是下次比较时是P[7]和S[8]比较，但是这两者也不匹配，则又会移动，同样是同样是移动１位，根据上图可以看出，如果遇到这种情况，KMP算法就相当于遍历又变成了暴力搜索了．<br></p><p><strong>那是否有办法解决这个问题？</strong><br><br>答案是：改进next数组，得到的新数组就是nextval数组．<br></p><h2 id="nextval数组"><a href="#nextval数组" class="headerlink" title="nextval数组"></a>nextval数组</h2><p>nextval数组值的求解方法：<br><br><strong>如果下标a的字符P[a]＝P[next[a]],则nextval[a]=nextval[next[a]]<br>如果不等则nextval[a]=next[a]</strong><br><br>所以得到的nextval数组：<br><br>|0|1|2|3|4|5|6|7|8|9|10|11|12||<br>|:——-:|:——-:|:——-:|:——-:|:——-:|——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|:——-:|<br>|A|A|A|A|A|A|A|A|B|B|B|B|B|…..|<br>|A|A|A|A|A|A|A|A|A|<br>|-1|0|1|2|3|4|5|6|7|next数组|||<br>|-1|-1|-1|-1|-1|-1|-1|-1|-1|nextval数组||<br>可以看到如果用nextval数组代替next数组，当在８号位不匹配时，直接遇到标志值，直接向右边移动了８位，再次比较时就是P[0]和S[8]比较了<br></p><p><strong>nextval数组是怎么解决这个问题的呢?</strong><br><br>答:下标为a的位置不匹配，next[a]表示的是(0~a-1),a个字符的部分匹配值<strong>X</strong>(<strong>注意：部分匹配值是从１开始算的</strong>)，所以0~X-1的字符是其匹配的前缀，P[next[a]]是匹配前缀的下一个数，所以如果P[a]=P[next[a]]再次跳到P[next[a]]这里比较还会不匹配，所以nextval[a]=nextval[next[a]]（相当于一个递归向前寻找），如果不相等，再次跳到这里比较就有意义，所以nextval[a]=next[a]</p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>二元组和图形描述逻辑结构</title>
    <link href="/2020/03/20/%E4%BA%8C%E5%85%83%E7%BB%84%E5%92%8C%E5%9B%BE%E5%BD%A2%E6%8F%8F%E8%BF%B0%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84/"/>
    <url>/2020/03/20/%E4%BA%8C%E5%85%83%E7%BB%84%E5%92%8C%E5%9B%BE%E5%BD%A2%E6%8F%8F%E8%BF%B0%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p><strong>数据结构分为：数据的逻辑结构和数据的存储结构</strong><br><br>逻辑结构:集合，线性结构，树状结构，图形结构.即线性表，栈，队列，树，图等逻辑结构.其中线性表，栈，队列为线性结构，树，图为非线性结构．<br></p><p>1.集合结构：数据结构中的元素之间除了“同属一个集合” 的相互关系外，别无其他关系<br><br>2.线性结构：数据结构中的元素存在一对一的相互关系 <br><br>3.树形结构：数据结构中的元素存在一对多的相互关系<br><br>4.图形结构：数据结构中的元素存在多对多的相互关系<br></p><p><strong>存储结构：分为顺序存储和链式存储</strong><br><br><em>逻辑结构和存储结构之间没有关系，只是抽象出来的数学模型方便理解</em></p><h2 id="描述逻辑结构的两种方法："><a href="#描述逻辑结构的两种方法：" class="headerlink" title="描述逻辑结构的两种方法："></a>描述逻辑结构的两种方法：<br></h2><p><strong>1. 二元组 DS=(D,S)</strong> <br><br>其中D是数据元素的集合，S是数据元素之间的关系集合，并且数据元素之间的关系是使用序偶来表示．<br><br>序偶：是由两个元素x和y按一定的顺序排列而成的二元组，记作<x,y> ,x是它的第一元素，y是它的第二元素．　<br></p><p><strong>2.用图形来表示</strong><br></p><p>就是画图．．．</p><h2 id="分别用两种表示方法来逻辑结构"><a href="#分别用两种表示方法来逻辑结构" class="headerlink" title="分别用两种表示方法来逻辑结构"></a>分别用两种表示方法来逻辑结构</h2><p><1>.<br></p><p>如果D =!null, S =null,表明DS是<strong>集合结构</strong>，元素相互之间没有关系．<br><br>如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5)},表明DS是<strong>线性结构</strong>，元素相互之间存在一对一的关系<br></p><p>如果D = {0,1,2,3,4,5}, S = {(0,1),(0,3),(1,2),(1,6)},表明DS是<strong>树状结构</strong>，元素相互之间存在一对多的关系<br></p><p>如果D = {0,1,2,3,4,5}, S = {(0,1),(2,3),(4,5),(3,2),(3,1),(5,4),(2,4),(4,2)},表明DS是<strong>图结构</strong>，元素相互之间存在多对多的关系<br></p><p><strong>其实只要懂得根据元素的对应关系S画图，就可以知道，相应的逻辑结构是什么了</strong></p><p><2>. <br></p><p><img src="870358-20160102224630526-1483051229.jpg" alt="逻辑结构图像表示"></p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chapter1 Review Questions</title>
    <link href="/2020/03/09/Chapter1-Review-Questions/"/>
    <url>/2020/03/09/Chapter1-Review-Questions/</url>
    
    <content type="html"><![CDATA[<h2 id="关于计算机网络自顶向下的第一章的问题回答"><a href="#关于计算机网络自顶向下的第一章的问题回答" class="headerlink" title=" 关于计算机网络自顶向下的第一章的问题回答"></a> 关于计算机网络自顶向下的第一章的问题回答</h2><p><strong>R1:主机和终端系统有什么不同？<br></strong><br>终端系统（end system）和主机(host)系统其实没有很大的区别都就具有连接网络和交换信息的能力，本质上没有很大的区别．但是在现实生活中主机常常指提供服务的一方，而终端指手机，手提电脑，台式电脑之类的．<br><br><strong>R2:protocol在维基百科上的定义<br></strong><br>protocol（协议）在维基百科上的定义是：给数据/信息在电子通信和网络上的传输制定的规则<br><br><strong>R3:为什么协议（protocol）如此重要？<br></strong><br>protocol由Internet engineering task force(IETF)制定，为了提供更好的更加有质量，更加安全的协议来给消费者使用，标准协议为了每个用户之间能够更有效的互相交流．例如：书上说的人打招呼的例子，如果没有协议就会乱套．<br><br><strong>R4:列出６个访问技术，以及将其分类家庭访问，企业访问和广域无线访问<br></strong><br><em>家庭访问：<br></em><br>1.DSL(digtal subscriber line):数字订阅通路<br><br>2.cable internet access: 有线上网，也可以叫做HFC(hybird fiber coax)：混合光纤同轴电缆<br><br>3.fiber to the home: 光纤到家（光纤）<br><br>4.Dial_up :数字拨号（用电话线<br><br>5.satellite:卫星<br><br><em>企业访问（家庭其实也可以）:<br></em><br>6.WIFI<br><br>7.Enternet<br><br>广域无线访问：<br>8.third/(fouth)-generation(3G)<br><br>9.LTE(long-term-Evolution)<br><br><strong>R5:HFC的传输速度是用户独享还是分享？是否可能在HFC的下游发生数据碰撞？<br></strong><br>HFC(hybird fiber coax)混合光纤同轴电缆也就是cable internet access有线连接，用的是电视公司提供的有线电视的电视线连接，因为这个互联网访问方式中用到了两种电缆线分别是光纤和同轴电缆，所以就叫HFC．<img src="2020-03-09_21:03_select.png" alt="cable internet access"><br>如图所示HFC是用户分享类型的，如图HFC的下载源只有一个所以downstream不冲突，但是上传（upstream）就有可能冲突，需要用协议来解决．<br><br><strong>R6:列出你所在城市的住宅访问技术（access technologies）,以及它们各种的下载，上传速度和价钱.</strong><br>目前中国电信能够提供基于ADSL、LAN以及FTTH光纤接入三种技术的宽带实现方式。速率从1Mbps到20Mbps不等，价格也从119到559不等。(抄的．．)<br><br><strong>R7:以太局域网（Enthernet LANs）的传输速度是多少？</strong><br><br>对于用户：通常有100Mbps,对于服务器：通常有１Gbps~10Gbps .<br></p><p><strong>R8:Enthernet（以太网）运行的物理介质是什么，有那些？</strong><br><br>有同轴电缆（coaxial cable）光纤（fiber optic）,双绞铜线（twisted-pair-copper Wire).<br><br><strong>R9:提供Dial-up modems,DSL,HFC,FTTH的速度范围和判断其是用户独占还是用户共享</strong><br></p><ul><li>DSL:上传速度：2.5Mbps，下载速度：24Mbps.[2003]</li><li>HFC:上传速度：30.7Mbps,下载速度：42.8Mbps.[DOCSIS.2.0]</li><li>FTTH:理论上可以达到１Gbps实际平均下载速度可以达到20Mbps[2011]</li><li>Dial-up modems: 56kbps [巨慢]<br></li></ul><p><strong>R10:描述现在最流行的无线连接技术，并且比较它们的差异</strong><br><br>最流行的无线连接技术:现在是WIFI和4G<br><br>差异：<br><br>WIFI是用户无线或有线连接到自己附近的路由器，通过路由器这个接入点连接网络如图：<br><img src="2020-03-10_15:03_select.png" alt="WIFI"><br><br>一般WIFI的范围是10米之内．WIFI提供的理论接入速度可以达到600Mbps(来自知乎，书上是54Mbps).<br><br>4G:4G用的是蜂窝技术（cellular telephony),4G提供的理论接入速度是100 Mbps,而且蜂窝技术的范围可以达到10千米内（范围更大）.<br><br><strong>R11:假设有只有一个分组交换机(parket switch)在发送端和接收端之间，传输速度发送端到分组交换机为R1,分组交换机到接收端之间为R2,假设使用的是存储转发交换机制(store-and-forward packet switch),计算端到端的总延迟[忽略处理延迟(processing delay),队列延迟(queuing delay),传播延迟（propagation delay）]</strong><br><br>那总延迟就等于这段路上的传输延迟（transmission delay）=R1+R2.<br></p><p><strong>R12:电路交换网络(circuit-switched network)相比分组交换网络(packet-switch network)有什么优势，在电路交换网络中，TDM对比FDM有什么优势</strong><br><br>我觉得电路交换网络系统的缺点也可以算是它的优点，因为其在传输信息时需要建立连接状态（circuit）这个时候用户可以用这条链路上的所有的速度，但是此时其他的用户无法使用，此时如果建立链路没有在传输信息而是待工，这个时候链路资源就没办法有效利用，这就是circut-switch network的缺点，但是如果其的应用场景使用链路的密度很大，这个时候就很OK,因为其传输速度是满的．<br><br>TDM(Time-Division Multiplexing)时分复用对比FDM(Frequency-Division Multiplexing)频分复用的优势：<br></p><pre><code> TDM is relatively a newer technique used for digital signals. TDM advantage over FDM is that it offers bandwidth saving with ATDM (allocate time slots on demand dynamically) and  there is low interference between the signals that are being multiplexed(from google)</code></pre><p><strong>R13:假设用户分享2Mbps的带宽，同时假设每个用户在传输数据是持续以1Mbps的带宽，链接网络时传输的占的时间与总时间的比值为20%</strong>　<br><br><strong>a.如果使用电路交换网络(circuit-switched network),可以支持多少用户使用.</strong> <br><br><strong>b.假设使用分组分配，两个或者更少用户同时传输数据的时候为什么实际上没有队列（排队）延迟，三个用户同时使用为什么会有队列延迟</strong><br><br><strong>c.计算用户正在传输的概率</strong><br><br><strong>d.假定现在有三个用户计算这个三个用户同时使用链路的概率，找到队列增长的概率</strong>(c.d应该是承接b)<br></p><p>1.两个用户可以同时使用<br><br>2.因为两个或者更少用户用的时候没有超过链路的最大带宽，而三个以上用户就会超过，所以用分组分配就会有队列延迟．<br><br>3.用户真正传输的概率是20%<br><br>4.三个用户同时使用的概率是$1\over5$ $\times$ $1\over5$ $\times$ $1\over5$ $=$ $1\over125$,队列增长的概率也是 $1\over125$<br><br><strong>R14:为什么处于同一个层级的ISPs互相对等，IXP是怎么赚钱的？</strong><br><br>一个城市与临近的另一个城市需要的用户需要数据传输如果这两个城市的ISPs没有进行对等(peer),则还需要通过更上一层的ISPs来达到互相连接，而更高一层的ISPs就会向低级的ISPs收费（收费的多少体现在流量上），对等（peer）了之后就不用通过更上一层ISPs,以达到节省开支的目的，而IXP(Internet Exchange Point)，IXP通常由电信公司以外的第三方公司来建立，主要作为ISPs的对接点，提供ISPs的对等服务．IXP赚钱通过想ISPs们收取少量的端口费盈利．<br><br><img src="2020-03-11_09:03_select.png" alt="网络提供者的层级结构"><br><strong>R15:一些内容的提供者也建立了它们自己的网络，描述一下Google,是什么促进它们建立自己的网络？</strong><br><br>google通过自己提供的TCP/IP网络把它分布在全球的大的小的数据中心连接起来（大的数据中心可能连接上百万个用户，小的可能几百个用户），<br>这些数据中心大多都是连接比较底层的用户或者ISPs提供，可以让谷歌绕过更高层级的ISPs．<br><br>促进他们建立自己网络的理由是：内容提供商（例如谷歌）建立自己的网络服务可以减少向上层ISPs支付费用，（因为谷歌可以直接和用户相连，或者连接更下层的ISPs和IXP,所以减少了中间ISPs的数量），同时也可以达到对用户更好的控制．<br><br><strong>R16:考虑在固定线路上从源主机发送一个包（packet）到目标主机，列出端到端的延迟，以及表示出那个延迟是常数，那个延迟是变量．</strong><br><br>分别有传输延迟（transmission delay），传播延迟(propagation delay)，队列延迟(queueing delay)，处理延迟(processing delay).<br><br>队列延迟是可变的，其他延迟是常数．<br><br><strong>R17:去这个小程序网站：Transmission Versus Propagation Delay，通过调整rates,propagation delay和packet sizes的大小，找到两个组合，使packet在源主机传输完成之前，第一个被发送的bit到达目标主机，和pakect在源主机完成传输之后，第一个被发送的bit才到达目标主机．</strong><br>第一个组合是：1000KM,1Mbps,100bytes.<br>第二个组合是：100KM,1Mbps,100bytes.<br><br><strong>R18:发送长度为1000bytes的packet,距离为2500Km,传播速度是$2.5$x$10^8$m/s,传输速度是2Mbps需要多长时间,更加抽象一点，发送长度为L的packet,距离为d,传播速度是s,传输速度是Rbps需要多长时间,在传递信息中的延迟是由打包的数据长度决定？还是传输的速度决定？</strong><br>假设忽略了处理延迟和队列延迟，那么需要的时间为<br><br>$1000\div(2000000\div8)+2500\times 1000 \div(2.5\times10^8)=0.01+0.004=0.014s=14msec$<br><br>抽象一点：<br>$time=L\times8/R+d/s$ <br><br>打包的数据长度和传输速度都不能呢个决定延迟大小．<br><br><strong>R19:假设源主机Ａ想传递一个很大的文件给目标主机Ｂ，在两者直接有三条链路，速度分别为R1=500kbps,R2=2Mbps,R3=1Mbps.</strong><br></p><ul><li>假设没有其他的流量在网络中，这个文件传输的吞吐量是多少？</li><li>假设文件大小为4Mbytes,大致需要多长时间传输这个文件．</li><li>重算1,2题现在R2降低到100kbps.<br><br>1.这个文件的吞吐量由最小的通路决定，文件吞吐量为500Kbps.<br><br>2.$T=4000000\div(500\times1000\div 8)=64s$<br><br>3.如果R2降为100kbps,文件传输的吞吐量为100kbps,则4Mbytes的文件传输大致时间为$4000000\div(100\times1000\div8)=320s$<br></li></ul><p><strong>R20:假设一个很大的文件从主机A传输到主机B,从一个比较高的角度描述一下主机A如何把一个文件变成一个个的packet，当一个packet到达交换机（switch）,哪些信息被用来指引（确定）packet前进路线，以及为什么互联网中分组交换需要模拟汽车从一个城市到另外一个城市并沿着路线不断问路的过程．</strong><br><br><img src="2020-03-11_14:03:1583906551_select.png" alt="packet的运行路线"><br><br>主机Ａ的文件本来是一个整体在层级结构中被称作消息(message),传递给下面的传输层（Transport layer),传输层中的TCP协议可以把message分割成一块一块加上一些信息放在每一块上组成段(segment),同时TCP协议拥有流控制（flow control）功能[匹配发生者和接受者的速度]，和拥堵控制机制（congestion-control mechanism),然后传递给网络层（Network layer),然后把段传到网络层(Network layer),网络层执行的是IP协议，以及一些路由协议（routing protocol）,同样是在每个段的头部加上一些信息组成数据报(Datagram),然后在传递给链路层（Link layer）,链路层用的协议不同链路上用的协议就不同，有：WIFI,Ethernet and cable network的DORSIS protocol,操作也是在数据报头部加入一些信息形成的桢（Frame）最后就是送到物理层（physical layer),物理层就把每一个桢中的数据一个bit一个bit的传播出去，物理层同样有协议，根据使用的物理介质的不同而不同．<br><br>一个packet到达交换机后根据每个packet中的IP地址找到前进路线．<br><br>第三问着实不懂．<br></p><p><strong>R21:去执行Queuing and Loss这个小程序,然后找到最大发送速率和最小的传输速率是多少？对于这些速率，流量强度是多少？用这些速率运行该小程序并确定出现丢包要花费多长时间？然后第多次重复该实验，再次确定出现丢包花费多长时间。这些值有什么不同？为什么会有这种现象？</strong><br><br>最大的发射速度是500packet/s,最小的传输速度是350packet/s,对于这些流量强度是$500\div350=1.428$用这些速度去运行，出现丢包的时间大约在31~34秒左右，并不能确定具体哪个时间会发生丢包，为什么？因为用户发生数据包有随机性，我们并不能控制每一个用户．</p><p><strong>R22:列出一层都可以执行5个任务,并且是否有可能这些任务中有可以执行在两个或者多个层？</strong><br><br>任务: 封装本层的报文段, 设置各种参数, 对接受到的报文段进行差错检查, 还可能进行流量设置, 分组重组等等.多个层是可能执行相同的一个(或两个)任务的, 比如差错检验<br><br><strong>R23:互联网协议栈的五层是什么，每一层的的主要职责是什么？</strong><br>互联网协议栈的五层从上到下分别是，应用层，传输层，网络层，链路层，物理层．关于他们的主要职责：在R20有讲到.</p><p><strong>R24:什么是应用层报文（message）,传输层报文（segment),网络层数据报（Datagram）,链路层帧(Frame).</strong></p><pre><code class="lang-mermaid">graph TDA[message]--&gt;B[message+Headt=segment]--&gt;C[segment+Headn=Datagram]--&gt;D[Datagram+Headl=Frame];</code></pre><p><br></p><p><strong>R25:在互联网协议栈中路由器处理哪几层，链路交换机处理哪几层，主机处理哪几层？</strong><br><br>路由器处理１到３层(现代路由器里还有防火墙和缓存组件，也可以处理传输层)，链路交换机处理１－２两层，主机处理全５层．<br></p><p><strong>R26:病毒（virus）和虫（worms）有什么不同?</strong><br><br>病毒需要用户与其互动，有交互，需要人进行操作，例如ＱＱ发个网站点进网站被盗号等，虫就是不需要与用户进行互动，例如用户运行一个很脆弱的软件，恶意软件进来不需要用户统一直接运行，并且会自我复制自动寻找下一个脆弱的软件进行攻击．<Br></p><p><strong>R27:描述一下僵尸网络(botnet)是怎么形成的,以及怎么利用僵尸网络来进行DDoS攻击？</strong><br>僵尸网络就是这个bad guy通过找到别人的应用或者是系统的漏洞，利用虫（worms)来侵入别人的主机，而这个虫又可以通过漏洞来复制和接着进行传播，僵尸网络的属性就是attacker可以远程通过命令来操控僵尸网络中的主机运作．而DDos（distributed denail-of-service attack）攻击就是通过成败上千台僵尸主机同时想目标主机发送信息，导致目标主机的带宽被占满从而使正确的信息无法传到目标主机．<br><br><img src="2020-03-11_20:03:1583929611_select.png" alt="botnet"><br><br><strong>R28:假设Alice和Bob真正互相发送信息，同时假设Trudy定位自己在网络中，Trudy可以捕获所有Alice发生的消息，也可以发送任何消息给Bob,同理相对与Bob也一样，列举出Trudy处在这个位置上可以做的恶意的事情</strong><br><br>借钱打这个账户1008668001.</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>Computer Network A Top-Down Approach</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Computer Network A Top-Down Approach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>计算机网络自顶向下有意思的单词</title>
    <link href="/2020/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E5%8D%95%E8%AF%8D/"/>
    <url>/2020/03/03/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E5%8D%95%E8%AF%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="Computer-Networking-A-Top-Down-Approach"><a href="#Computer-Networking-A-Top-Down-Approach" class="headerlink" title="Computer Networking A Top-Down Approach"></a>Computer Networking A Top-Down Approach</h1><ul><li>desirable to : 希望</li><li>To gain further insight into … :获得进一步深入的….</li><li>scenario:情景</li><li>In this ideal scenario : (idea n:点子，ideal adj: 理想的）</li><li>Clearly : 明显的</li><li>among ：在…中 （among  + 时间）</li><li>no longer ： 不再</li><li>nonetheless : 尽管如此，然而</li><li>In particular ： 尤其是，特别是</li><li>It is a apparent that ….: 这是清晰可见的 …..</li><li>deplane: 下飞机</li><li>turn out attention to: …</li><li>responsible for : 负责….</li><li>referred to as : 被称为是….</li><li>impact …. : 影响…</li><li>additional: 额外的</li><li>so-called ： 所谓的，被叫做…的</li><li>via ： 通过…</li><li>wreak havoc : 肆虐，造成严重破坏；</li><li>upcoming： 即将来临，即将发生的</li><li>In essence: 在本质上</li><li>the strengths and weaknesses : 长处和短处</li><li>throughout : 遍及，从始至终， 贯彻</li><li>namely ： 即 ，也就是说</li><li>hence: 因此</li><li>diving into: 跳进，潜进</li><li>draw on : 利用，借鉴</li><li>drawback : 缺点，弱点</li><li>is analogous to : 类似于…</li><li>It is also referrd to as : 这个也被称为．．．</li><li>we can think of as : 我们可以认为是….</li><li>This imformation is needed : 这个消息是必需的….</li><li>in general : 一般来说，通常…</li><li>acceptable : 可以接受的</li><li>lead to : 导致了．．．．</li><li>result in : 造成，导致．．．</li><li>albeit : 尽管</li><li>straightforward : 直接了当的</li><li>essentially : 实际上，本质上．．</li><li>on the scene : 在当时．</li><li>caught(catch的过去式)general public’s eye :抓住了公众的眼睛，引起公众的注意．</li><li>perhap :也许</li><li>general idea :总体思路，总体大意．．．</li><li>somewhat : 有些，稍微有点</li><li>in which case : 在这种情况下　．．</li><li>elapses: V:（随着时间的）流逝．</li><li>shortcoming : 缺点．．</li><li>moreover : 而且，加之，此外，再者．</li><li>back-to-back :背靠背，连续，一个接着一个．．</li><li>taking a close look :仔细看看．．</li><li>first of all : 首先</li><li>otherwise : 除此之外，否则．</li><li>leave out : 省略，忽略．．</li><li>indicate : 表明，表示，显示</li><li>associated : 有关联的，相关的．．</li><li>highly recommended : 强烈建议．．</li><li>thereby : 从而．．</li><li>substantially : 实质上．．</li><li>the rest of : 其余的．．</li><li>neglect : 忽略｀</li><li>clearly something must be done : 显然．．一定要去做一些事情．．</li><li>up to date : 现代的，最新的</li><li>significantly : 显著的．</li><li>coordinate with sb/sth : 与．．．配合，配合．．．</li><li>launch : 启动．．发射．．</li><li>authenticate : 认证</li><li>principal : 最重要的</li><li>restriction :限制</li><li>retrieves :　取回，拉回</li><li>mean :有手段的意思</li><li>invoke :引用</li><li>key aspects :关键的方面</li><li>vast : 巨大的</li><li>take place :发生　</li><li>alternatively: 或者，两者中选一个 </li><li>alternative : 另类的，替代的</li><li>primary,secondary :主要的，次要的</li><li>backup :后备</li><li>desire :欲望，渴望</li><li>desirable : 想要拥有的，期望的</li><li>overview :　概述，概观</li><li>brief: 简要的</li><li>authoritative : 命令式的，权威的</li><li>alias :别名</li><li>a number of … : 一些．．．</li><li>display :　显示</li><li>in the frist place ：首先</li><li>content :内容,满足的，知足的</li><li>contention : 论点，竞争，争夺</li><li>context :背景，语境，上下文</li><li>startup :新启动，新成立的</li><li>monopoly：垄断</li><li>accredit :　认证</li><li>make sure : 确定，保证</li><li>legitemate :合法的</li><li>scale,large-scale: 规模，大规模 </li><li>bypass :　绕过</li><li>bogus : 虚假，假冒的</li><li>trick :欺骗，欺诈</li><li>intercept : 拦截</li><li>exploit : 利用，漏洞利用</li><li>appropriate：适当的，恰当的</li><li>just as : 就像．．．</li><li>justify :证明…</li><li>aid　：　帮助</li><li>assist ：助攻</li><li>somewhat :有些，有些许，有少许</li><li>as time evolves: 随着时间的流逝</li><li>with this … :　有了．．．，根据．．．（不要用Have this ..了．）</li><li>equalize : 均衡｀</li><li>reciprocate :互换，报答，酬答</li><li>lingo :　行话</li><li>satisfied : 满意</li><li>earn other : 彼此</li><li>chunks : 块</li><li>tit-for-tat :以牙还牙，针锋相对</li><li>locate :定位</li><li>more specifically :更进一步..</li><li>naive :天真的</li><li>requires … to :　要求..要…</li><li>elegant : 高雅的,优雅的</li><li>likelihood : 可能性</li><li>Henceforth :因此</li><li>scheme: 方案</li><li>conventions :约定</li><li>convert : 转换</li><li>convenience :方便</li><li>circle :圈,圆｀</li><li>clockwise :顺时针</li><li>successor :继承者，接班人</li><li>aware :意识到的,明白的</li><li>be aware of  :意识到</li><li>refine :提炼，精炼</li><li>acceptable :　可接受的</li><li>shortcuts : 捷径</li><li>expedite :加快</li><li>accomplished :完成</li><li>verify : 检验，证明</li><li>periodically :定期的</li><li>abruptly : 突然</li><li>depart ：离开</li><li>replace :取代　（replace..with..）</li><li>explicitly : 明确的</li><li>churn : 流失</li><li>phase : 阶段，时期</li><li>frightened : 害怕的，受惊的(feel fear or worry)</li><li>reference : 参考资料</li><li>identifier : 识别码</li><li>As you might expect :如你所料</li><li>uppercase : 大写</li><li>emphasize :注重</li><li>intentionally :故意</li><li>invisible : 无形的</li><li>dedicate : 专用</li><li>demonstrate : 展示</li><li>vice versa : 反之毅然</li><li>accumulate : 累计，积累</li><li>as far as i know :据我所知</li><li>in term of :　就..而言</li><li>merely :仅仅</li><li>column : 栏，柱</li><li>concidence: 巧合</li><li>confront : 面对(V)</li><li>embody: 体现在(V)</li><li>numerous : 许多的</li><li>effort: 努力</li><li>best-effor : 最大努力</li><li>foremost: 最重要的</li><li>mitigate: 使缓和，减轻</li><li>inform: 告知</li><li>suited: 适合</li><li>regard: 注重，把．．看作，考虑</li><li>regardless: 不注重，不考虑</li><li>preliminary: 初步的,起始的</li><li>precisely :精准地，准确地</li><li>conferenc: 会议</li><li>controversial: 有争议的,引起争议的</li><li>induce: 诱发，诱导 </li><li>dramatically: 显著地</li><li>lack: 缺乏</li><li>trivial: 微不足道的</li><li>nontrivial: 不平凡的</li><li>impose: 强加</li><li>subject: 主题，科目(n) , 受支配的(adj),委托，使唤(v)</li><li>constraint: 约束，限制(n)</li><li>occupy: 占用</li><li>redundant: 多余的</li><li>fundamentally: 根本上的,重大性的</li><li>framework: 框架</li><li>corrupt: 腐化的，损坏的,毁坏的</li><li>abstraction: 抽象，抽象化</li><li>beneath: 在．．．下方</li><li>incrementally: 递增的</li><li>tedious: 冗长的，罗嗦的</li><li>flaw: 缺陷</li><li>flawless: 完美无暇</li><li>finite: 有限的</li><li>infinite: 无限的</li><li>separate: 单独的，间隔的</li><li>transition: 过渡，转变</li><li>feedback: 反馈</li><li>dictate: 听写</li><li>correct:　正确的，准确无误的(adj), 纠正,修正,改正(v)</li><li>leftmost: 最左边</li><li>notation: 符号系统，数学符号</li><li>fatal: 致命的，灾难性的</li><li>oversight: 失察，疏忽</li><li>clearly, we’re heading down a difficult path.: 明显的，我们真正走在一条艰难的路上</li><li>garbled:　混乱不清的，含糊不清的</li><li>argument: 参数</li><li>estimate:　估计</li><li>though, even though: 尽管</li><li>pipelined: 流水线</li><li>pipeline: 管道</li><li>emerging:　新兴的，出现</li><li>utilization: 利用率</li><li>dismal: 惨淡,悲伤绝望的</li><li>fortune: 大量财产，一大笔钱</li><li>triple: 三倍</li><li>presumably: 据推测,可能</li><li>synchronization: 同步化</li><li>silly: 愚蠢</li><li>it is worth noting :值得注意</li><li>encounter: 遭遇</li><li>incorporate: 合并</li><li>reiterated: 重申，重复的,反复的</li><li>itemize: 逐个记载，逐个列出</li><li>consecutively: 连续的</li><li>coincide: 重合</li><li>figurative: 比喻的，形象的</li><li>curtain: 窗帘</li><li>Companion: 同伴，伴侣</li><li>conclude: 以．．．结束(讲话，会议，文章),推断，最后决定</li><li>manifestation: 显示，表示，表明</li><li>manifest: 显示，表示（V）</li><li>preliminary: 初步的，起始的</li><li>many of: 许多</li><li>oblivious: (对周围的事情)毫不在意的，毫无知觉的</li><li>suffice: 足够，满足要求</li><li>payload: 有效载重量,净载重量</li><li>entrenched: 根深蒂固的</li><li>teardown: 带拆房屋，拆卸</li><li>urgent: 紧急</li><li>vulnerable:　易受影响的，易受伤的，脆弱的，</li><li>evaesdrop: 偷听，窃听</li><li>character: 写入，刻入</li><li>estimated: 估计的</li><li>statistic: 统计数据，统计资料</li><li>decay: 衰变</li><li>deviate: 脱离，偏离</li><li>margin: 边缘，差额，余地，界限</li><li>filp: 翻转</li><li>considerable: 相当大的，相当重要的</li><li>present: 礼物，目前(名词),显示，介绍(动词)</li><li>expiry: 到期，期满</li><li>subtlety: 微妙;巧妙</li><li>depict: 描绘</li><li>likely: 很可能的，可能要发生的</li><li>most likely: 最有可能发生的</li><li>convince: 说服</li><li>interchangeably: 可互换</li><li>savvy: 了解，实际知识(n), 懂得，领悟(v),有见识的，通情达理的(adj)</li><li>see the forest for the tree :透过一棵树看森林</li><li>dynamic: 动态的，思维活跃的，活泼的</li><li>assured: 确定的，自信的，有把握的</li><li>minor: 较不重要的，次要的</li><li>advertising: 广告</li><li>advertise : 广告</li><li>perceive: 察觉，领悟，看出</li><li>ascent: 上升，攀登</li><li>deallocated: 释放</li><li>reclaim: 回收，取回，拿回</li><li>deluge: 暴雨，洪水</li><li>exhausted: 筋疲力尽的，疲惫不堪的</li><li>exhaust : 用尽</li><li>deny: 否认，拒绝</li><li>denied: 被否认，被拒绝</li><li>craft:手工艺品,精心制作的东西</li><li>manifest: 体现，显露，表现</li><li>in the first place : 首先，最初，第一</li><li>upper limit: 上限</li><li>consequence: 后果</li><li>steady: 稳定的，持续的</li><li>available: 可用的</li><li>aggregate: 合计</li><li>ideal: 理想的</li><li>far from ideal : 离理想很远，远远不够</li><li>virtually: 实际上，实质上</li><li>evident: 显而易见的;明白的</li><li>embody: 体现，包含，使形象化</li><li>assistance: 帮助，协助</li><li>explicit: 显性的</li><li>sophisticated: 见多识广的，复杂的</li><li>in a general context: 在通常情况</li><li>latter: 后者</li><li>symptom : 症状</li><li>operate: 操作，运行</li><li>infer: 推断,推论</li><li>proposal : 提案</li><li>choke: 窒息，阻塞</li><li>stress : 强调,压力</li><li>intersperse: 点缀，散布</li><li>convey: 表达，运送，传送</li><li>tunable: 可调的，可调试的，可调试组件</li><li>perceive : 感知,认识到，知觉</li><li>trigger: 触发</li><li>that is : 放在两个句子中间的时候可以翻译为＂也就是说＂</li><li>coordinated: 协调一致的</li><li>mandatory : 强制的;法定的;义务的</li><li>roughly: 大概，大致，差不多</li><li>mitigate : 减轻</li><li>conservative: 保守的，守旧的</li><li>identical: 相同的，完全一样的</li><li>inextricably :　密不可分</li><li>retrospetive: 回顾性</li><li>factor : 因子，因素</li><li>probing :　探测，探寻，探讨</li><li>variation :变化,变动</li><li>imminent: 即将发生的，临近的</li><li>flavor: 风味,气味</li><li>tremendous: 巨大的，惊人的，可怕的</li><li>macroscopic : 宏观的，肉眼可见的</li><li>saw-toothed :　锯齿状</li><li>fairness: 公平，公正</li><li>cooperate: 合作, 配合</li><li>blissfully : 惬意的，幸福的</li><li>gridlocked: 僵局,水泄不通</li><li>anew: 重新</li><li>just around the corner : 就在拐角处，意思是很接近了，指日可待</li><li>adopt: 采用</li><li>conservative: 保守的</li><li>Hint : 暗示</li><li>have nothing to do with … : 与…无关</li><li>utilize : 利用</li><li>fragmentation :碎片，分裂，分片</li><li>prevalent : 流行的，盛行的，普遍的</li><li>deceptive : 欺骗性的，骗人的，造成假象的</li><li>centralize: 使集中，集中的，中央集权的</li><li>delve : 探索，深入查找，搜寻</li><li>successive: 连续的，连接的</li><li>confidentiality :秘密的，机密的</li><li>integrity : 完整性，诚信，正直</li><li>eventual :最终的，最后的</li><li>satisfy : 满足</li><li>scope: 范围</li><li>aim : 目标</li><li>substantial : 实质的，牢固的，大量的</li><li>oblivious : 遗忘的，忘却的，健忘的</li><li>look up : 查阅，查找</li><li>brute : 畜生，禽兽，残忍的</li><li>evolution : 演化，进化，发展，渐进</li><li>notion : 概念</li><li>chips: 芯片,晶片</li><li>roundabout: 圆环的，拐弯抹角的，不直接的</li><li>blazingly: 极度的</li><li>attendant: 服务员，侍者</li><li>concreteness : 具体化，具体性</li><li>ensure : 随后的</li><li>adopter :(新技术的）的接受者，收养人</li><li>headquarters :总部，司令部</li><li>revenue: (政府的)税收，(公司的)收入</li><li>venture : 冒险者</li><li>embed : 嵌入式，嵌入的</li><li>arguably : 大概，可能</li><li>criteria : 准则，条件，标准</li><li>intervention : 干预，调停，介入</li><li>Nonetheless: 尽管如此</li><li>overcome : 克服，压倒，征服</li><li>vertical : 垂直，垂直方向</li><li>intersect : 交叉，横断</li><li>extent : 程度，范围</li><li>extensive : 广泛的，大面积的</li><li>negligible : 微不足道的，可以忽略的</li><li>destined : 命中注定的，注定的</li><li>in the time : 在这个时候</li><li>in which case : 在这种情况下</li><li>fluctuation : 波动，起起伏伏</li><li>absorb : 吸收</li><li>theoretical : 理论上的，纯理论的</li><li>standpoint : 立场,观点</li><li>threshold : 阀值，临界值</li><li>as long as : 只要</li><li>phenomenon : 奇迹，珍品，事件</li><li>foray : 偷袭，进军，涉足</li><li>syntax : 句法，语法</li><li>semantics : 语义，语意</li><li>interpret : 解释，翻译</li><li>remainder : 剩余部分，其余部分</li><li>glue : 胶水</li><li>overhead : 开销，间接费用</li><li>whereas : 然而，而</li><li>squeeze : 挤压，压榨，紧缩</li><li>fragment : 断片，片段，碎块</li><li>reassembly : 重新组装</li><li>proper : 适当的，恰当的，正确的</li><li>does away with sth : 摆脱，摒弃，废除</li><li>contiguous : 相近的，邻近的</li><li>nonprofit :非盈利的，非盈利组织</li><li>attractive : 诱人的，有魅力的</li><li>dormitory : (寄宿学校的)宿舍</li><li>enviable : 令人羡慕的，引人妒忌的</li><li>lease : 租凭，租契，租期</li><li>expertise : 专业知识（专长），专业技能</li><li>patch : 补丁，打补丁</li><li>external : 外部的，外表的</li><li>nemesis : 克星(主要敌人)，报应</li><li>savior : 救主，救星</li><li>seldom : 很少，极少，几乎不</li><li>inspect : 检查，进行检查</li><li>malicious : 恶意的</li><li>intrusion : 侵入，入侵</li><li>approved :  核对的，已认可的</li><li>alert : 警报，警告，机灵的</li><li>shield : 盾牌，屏障，护盾</li><li>breathtaking : 极其刺激的，美的惊人的</li><li>augment : 提高，增强，增大</li><li>excellent : 优秀的</li><li>grain : 古粒，粒</li><li>sand : 沙，沙粒</li><li>streamline : 简化的，精简的，流线型的</li><li>counterpart : 副本，配对物</li><li>tunnel : 隧道,坑道</li><li>portable : 手提式的，可携带的</li><li>mutually : 相互的，互相的</li><li>mutually-trusted : 相互信任的</li><li>possess : 拥有，具有</li><li>consult : 商量，商议</li><li>boil down to sth : (形式与问题)主要原因在于，归结为</li><li>short-haul : 短层，短途路线</li><li>precise : 精确的，精准的</li><li>mandate : 命令，委任，要求</li><li>even if : 即使，纵然，就算</li><li>relieve : 缓解,减轻</li><li>skepticism : 怀疑，怀疑主义</li><li>miraculously : 奇迹般的，奇迹般地</li><li>quiescent : 静止的，静态的</li><li>poison: 中毒;下毒，中毒的</li><li>prohibitive : 高昂到难以承受的</li><li>enormous: 巨大的</li><li>sketch : 草图，示意图，素描图</li><li>cause and effect : 因果关系</li><li>nevertheless :不过，仍然，虽然如此</li><li>rudimentary : 基础的，基本的，初级的</li><li>semipermanent : 暂时的,半永久的</li><li>elimination : 淘汰,去除</li><li>calamitous : 多灾难的，多灾多难的</li><li>redundant : 多余的，过剩的，过多的</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>-英语学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The Network Core</title>
    <link href="/2020/02/28/The-Network-Core/"/>
    <url>/2020/02/28/The-Network-Core/</url>
    
    <content type="html"><![CDATA[<h1 id="The-Network-Core"><a href="#The-Network-Core" class="headerlink" title="The Network Core"></a>The Network Core</h1><p>The figure highlights the Network Core with thick, shaded lines.</p><p><img src="The-Network-Core/2020-02-28 19-54-24 的屏幕截图.png" alt=""></p><h2 id="Packet-Switching"><a href="#Packet-Switching" class="headerlink" title="Packet Switching"></a>Packet Switching</h2><p>To send a message from a source end system to a destination end system, the source breaks long message into smaller chunks of data known as <strong>Packets</strong>. Between source and destination, each packet travel through <strong>communication links and packet switches</strong>(for which there are two predominant types, routers and link-layer switches) .</p><h3 id="Store-and-Forward-Transmission"><a href="#Store-and-Forward-Transmission" class="headerlink" title="Store-and-Forward Transmission"></a>Store-and-Forward Transmission</h3><p>Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link. </p><p>To explore store-and-forward transmission in more detail. Consider a simple network consisting of two end systems connected by a single router as shown as figure below.</p><p>A router will typically have many incident link, since its job is to switch an incoming packet onto an outgoing link;  In this example the router has the rather simple task of transferring a packet from one(input) link to the only other attached link. In this example the source has three packets, each consisting of L bits to send to the destination. Because the router employ store-and-forwarding, at this instant of time, the router cannot transmit the bits it has received; only after the router has received all of the packet’s bits can it begin to transmit the packet onto the outbound link.</p><p><img src="2020-02-28 19-47-00 的屏幕截图.png" alt="s"></p><p>To gain some insight into store-and-forward transmission, let’s now calculate the amount of time that elapses from when the source begins to send the packet until the destination has received the entire packet.(Here we will ignore propagation delay - the time it take for the bits to travel across the wire at near the speed of light). The source begins to transmit at time 0; at time L/R seconds, the sources has transmitted the entire packet and the entire packet has been received and store at the router(since there is no propagation delay). At time L/R seconds, since the router  has just received the entire packet, it can begin to transmit the packet onto the outbound link towards the destination; at time 2L/R, the router have transmitted the entire packet, and the entire packet has been received by the desination. Thus the total delay is 2L/R. If the switch instead forwarded bits as soon as they arrive.(without first receving store and process the entire packet before forwarding) then the total delay would be L/R since bits are not help up at the router. But as we will discuss in Section1.4 routers need to receive, store,and process the entrie packet before forwarding.</p><p>let’s now consider the general case of sending one packet from source to destination over a path consisting of N link each of rate R(thus, there are N-1 routers between source and destination). Applying the same logic as above, we see that the end-to-end delay is :</p><script type="math/tex; mode=display">d_ {end-to-end}= N*L/R</script><h3 id="Queuing-Delays-and-Packet-Loss"><a href="#Queuing-Delays-and-Packet-Loss" class="headerlink" title="Queuing Delays and Packet Loss"></a>Queuing Delays and Packet Loss</h3><p>Each packet switch has multiple link attached to it . For each attached link, the packet switch has an <strong>output buffer</strong>(also called an <strong>output queue</strong>),which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link,but finds the link busy with the transmission of another packet, the arriving packets must wait in the output buffer. <strong>Thus, in addition to the store-and-forward delays,packets suffer output buffer queuing delay.</strong> These delay are variable and depend on the level of congestion in the network. since the amount of buffer space is finite. an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, <strong>Packet Loss will occur</strong> - either the arriving packet or one of the already-queued packets will be dropped.</p><h3 id="Forwarding-Tables-and-Routing-Protocols"><a href="#Forwarding-Tables-and-Routing-Protocols" class="headerlink" title="Forwarding Tables and Routing Protocols"></a>Forwarding Tables and Routing Protocols</h3><p>Earlier, we said that a router takes a packet arriving on one of its attached communication links and forwards that packet onto another one of attached communication links. But how does the router determine which link it should forward the packet onto? Packet forwarding is actually done in different ways in different types of computer networks. Here, we briefly describe how it is done in the Internet.</p><p>​    In the Internet,every end system has an address called an <strong>IP address.</strong> when a source end system wants to send a packet to a destination end system, the source include the destination’s IP address in the packet’s header. As with postal addresses. each router has a <strong>forwarding table</strong> that maps destination addresses(or portions of the destination addresses) to that router’s outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.</p><p>​    We just learned that a router uses a packet’s destination address to index a forwarding table and determine the appropriate outbound link. But this statement begs yet another question: “How do forwarding tables get set ?”, Are they configured by hand in each and every router, or does the Internet use a more automated procedure? The issue will be studied in depth in after. but we’ll note now that the Internet has a number of special routing protocols that are used to automatically set the forwarding tables.</p><h2 id="Circuit-Switching"><a href="#Circuit-Switching" class="headerlink" title="Circuit Switching"></a>Circuit Switching</h2><p>In circuit-switching networds, the resource needed along a path(buffer link transmission rate) to provide for communication between the end systems are  reserved for the duration of the communication session between the end systems. In the packet-switched networks, these resources are not reserved; a session’s messages use the resources on demand and as a consequence ,may have to wait for access to a  communication link.</p><p>​    Traditional telephone networks are examples of circuit-switched network. Consider what happens when one person want to send information(voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver, for which the switches on the path between the sender and receiver maintain connection state for that connection.  In the jargon of telephony, this connection is called a <strong>circuit</strong>. when the network establishes the circuit , it also </p>]]></content>
    
    
    
    <tags>
      
      <tag>-Computer Network A Top-Down Approach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>The Network Edge</title>
    <link href="/2020/02/27/The%20Network%20Edge/"/>
    <url>/2020/02/27/The%20Network%20Edge/</url>
    
    <content type="html"><![CDATA[<h1 id="Access-Networks"><a href="#Access-Networks" class="headerlink" title="Access Networks"></a>Access Networks</h1><h2 id="Home-Access-DSL-Cable-FTTH-Dial-Up-and-Satellite"><a href="#Home-Access-DSL-Cable-FTTH-Dial-Up-and-Satellite" class="headerlink" title="Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite"></a>Home Access: DSL,Cable,FTTH,Dial-Up,and Satellite</h2><h3 id="DSL"><a href="#DSL" class="headerlink" title="DSL"></a>DSL</h3><p>Today, the two most prevalent types of broadband residential access are <strong>digital subscriber line (DSL)</strong> and cable. A residence typically obtains DSL Internet access from the same local telephone company(telco) that provides its wried local phone access.Thus, when DSL is used, a customer’s telco is also its ISP.</p><p>The residential telephone line carries both data and traditional telephone signals simultaneously, which are encode at difference frequencies:</p><ul><li>A high-speed downstream channel , in the 50 kHz to 1MHz band.</li><li>A medium-speed upstream channel, in the 4 kHz to 50 kHz band.</li><li>An ordinary two-way telephone channel, in the 0 to 4 kHz band.</li></ul><p>This approach makes the single DSL link appear as  if there were three separate links, so that a telephone call and an Internet connection can share the DSL link at the same time</p><p><img src="The Network Edge/2020-02-27 14-34-38 的屏幕截图.png" alt=""></p><p>On the customer’s side a splitter separates the data and telephone signals arriving to the home and forwards the data signal to the DSL modem. On the telco side ,in the <strong>CO(Central office)</strong>,the DSLAM separates the data and phone signals and sends the data into the Internet. Hundreds or even thousands of households connect to a single DSLAM.</p><h3 id="Cable-Internet-access"><a href="#Cable-Internet-access" class="headerlink" title="Cable Internet access"></a>Cable Internet access</h3><p>Cable Internet access makes use of the cable television company’s existing cable company that provides its cable television.</p><p>As illustrated in Figure,fiber optics connect the cable head end to neighborhood-level junctions, from which traditional coaxial cable is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5000 homes. Because both fiber and coaxial cable are employed in this system, <strong>it is often referred to as hybrid fiber coax(HFC)</strong> </p><p><img src="Access-Networks/2020-02-27 20-56-20 的屏幕截图.png" alt=""></p><p><strong>Cable Internet access requires special modems, called cable modems.</strong> As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port.</p><p>At the cable head end, <strong>the cable modem termination system(CMTS )serves</strong> a similar function as the DSL network’s DSLAM - turning the analog signal sent from the cable modems in many downstream homes back into digital format.</p><h3 id="FTTH-fiber-to-the-home"><a href="#FTTH-fiber-to-the-home" class="headerlink" title="FTTH(fiber to the home)"></a>FTTH(fiber to the home)</h3><p>Although DSL and cable network currently represent more than 90 percent of residential broadband access in the united States , an up-and-coming technology that promises even hight speeds is <strong>the deployment of fiber to the home(FTTH).</strong></p><p>As the name suggests , the FTTH concept is simple-provide an optical fiber path from the CO directly to the home.</p><p>There are several competing technologies for optical distribution from the CO to home. The simplest optical distribution network is called direct fiber,with one fiber leaving the CO for each home. More commonly each fiber leaving the CO(central office) is actually shared by many homes. These are two competing optical-distribution network architectures that perform this splitting : <strong>active optical networks (AONs) and passive optical networks(PONs).</strong></p><p>Here, we briefly discuss PON, which is used in Verizon’s FIOS service.</p><p><img src="The Network Edge/2020-02-27 21-43-25 的屏幕截图.png" alt=""></p><p>Each home has an optical network terminator(ONT),which is connected by dedicated optical fiber(Optical fibers) to a neighborhood splitter. The splitter combines a number of homes(typically less than 100) onto a single, shared optical fiber,which connects to an <strong>optical line terminator(OLT)</strong> in the telco’s CO. The OLT providing conversion between optical line and electrical signals, connects to the Internet via a telco router. In the home, users connect a home router(typically a wireless router) to the ONT and access the Internet via this home router.</p><h3 id="Satellite"><a href="#Satellite" class="headerlink" title="Satellite"></a>Satellite</h3><p>In location where DSL, cable and FTTH are not available, a satellite link can be used to connect a residence to the Internet at speed of more than 1 Mbps; StarBand and HughesNet are two such satellite access providers.</p><h3 id="Dial-up-access"><a href="#Dial-up-access" class="headerlink" title="Dial-up access"></a>Dial-up access</h3><p>Dial-up access over traditional phone lines is based on the same model as DSL - a home modem connect over phone line to a modem in the ISP. Compared with DSL and other broadband access networks , dial-up access is excruciatingly slow at 56 kbps.</p><h2 id="Access-in-the-Enterprise-and-the-home-Ethernet-and-WiFi"><a href="#Access-in-the-Enterprise-and-the-home-Ethernet-and-WiFi" class="headerlink" title="Access in the Enterprise(and the home): Ethernet and WiFi"></a>Access in the Enterprise(and the home): Ethernet and WiFi</h2><p>On corporate and university campuses and increasingly in the home setting , <strong>a local area network(LAN)</strong> is used to connect an end system to the edge router. Although there are many types of LAN technologies, Ethernet is by far the most prevalent access technology in corporate, university and home networks. As shown in the Figure. Ethernet users use twisted-pair copper wire to connect to an Ethernet switch.</p><p><img src="The Network Edge/2020-02-27 23-49-06 的屏幕截图.png" alt=""></p><p>The Ethernet switch or a network of such interconnected switch is then into the larger Internet. With Ethernet access, users typically have 100 Mbps access to the Ethernet switch, whereas servers may have 1 Gbps or even 10 Gbps access.</p><p>Increasingly, however people are accessing the Internet wirelessly from laptops, smartphones, tablets and other devices. In the a wireless LAN setting, wireless users transmit/receive packets to/from an access point that is connected into the enterprise’s networks,which in turn is connected to the wired Internet. A wireless LAN user must typically be within a few ten of meters of the access point. Wireless LAN access based on IEEE 802.11 technology, more colloquially known as WiFi.(A wireless LAN user must typically be within a few ten of meters of the access point.)</p><p>Many home combine broadband residential access(that is cable modem or DSL) with these inexpensive wireless LAN technology to create powerful home networks. Figure shows a typically home networks. This home network consist of roaming laptop as well as wired PC; a base station(the wireless access point),which communicates with the wireless PC; a cable modem providing broadband access to the Internet; and a router,which interconnects the base station and the stationary PC with the cable modem.</p><p><img src="Access-Networks/2020-02-28 00-21-20 的屏幕截图.png" alt=""></p><h2 id="Wide-Area-Wireless-Access-3G-and-LTE"><a href="#Wide-Area-Wireless-Access-3G-and-LTE" class="headerlink" title="Wide-Area Wireless Access: 3G and LTE"></a>Wide-Area Wireless Access: 3G and LTE</h2><p>Increasingly, devices such as iphone, Blackberrys and Android devices are being used to send email, surf the Web, Tweet,and download music while on the run. These devices employ the same wireless infrastructure used for cellular telephony to send/receive packets through a base station that is operated by cellular network provider. Unlike WiFi , a user need only be within a few tens of kilometers(as opposed to a few tens of meters) of the base station.</p><p>Telecommunications companies have made enormous investments in so-called third-generation(3G) wireless,which provides packet-switched wide-area wireless Internet access at speeds in excess of 1 Mbps, But even higher-speed wide-area accesss technologies - fourth-generation(4G) of wide-area wireless networks are alread being deployed. LTF(Long-Term Evolution) has its root in 3G technology and can potentially achieve rates in excess of 10 Mbps. LTF downstream rates of many tens of Mbps have been reported in commercial deployments.</p><h1 id="Physical-Media"><a href="#Physical-Media" class="headerlink" title="Physical Media"></a>Physical Media</h1><p>Physical media fall into two categories: <strong>guided media</strong> and <strong>unguided media</strong> with guided media, the waves are guided along a solid medium, such as a fiber-optic cable, a twisted-pair copper wire or a coaxial cable. with unguided media, the waves propagate in the atmosphere and in outer space, such as in a wireless LAN or a digital satellite channel.</p><h2 id="Twisted-Pair-Copper-Wire"><a href="#Twisted-Pair-Copper-Wire" class="headerlink" title="Twisted-Pair Copper Wire"></a>Twisted-Pair Copper Wire</h2><p>The least expensive and most commonly used guided transmission medium is twisted-pair copper wire. In fact, more than 99 percent of the wired connection from telephone handset to the local telephone switch use twisted-pair copper wire. Twisted pair consist of two insulated copper wires, each about 1 mm thick, arranged in a regular spiral patten. The wires are twisted together to reduce the electrical interference from similar pairs close by. Typically a number of pairs are bundled together in a cable by wrapping the pairs in protective shield. <strong>Unshielded twisted pair(UTP)</strong> is commonly used for computer networks within a building  ,that is for LAN. Data rates for LANs using twisted pair today range from 10 Mbps to 10 Gpbs. The data rates that can be achieve depend on the thickness of the wire and the distance between transmitter and receiver.</p><h2 id="Coaxial-cable"><a href="#Coaxial-cable" class="headerlink" title="Coaxial cable"></a>Coaxial cable</h2><p>Coaxial cable is quite common in cable television system. As we saw earlier, cable television system have recently been couple with cable modems to provide residential users with Internet access at rate of tens of Mbps. In cable television and cable Internet access, the transmitter shifs the digital signal to a specific frequency band, and resulting analog signal is send from the transmitter to one or more receivers. Coaxial cable can be used as a guided shared medium. Specifically , a number of end systems can be connected directly to the cable, with each of the end systems receiving whatever is send by the other end system.</p><h2 id="Fiber-Optics"><a href="#Fiber-Optics" class="headerlink" title="Fiber Optics"></a>Fiber Optics</h2><p>An optical fiber is a thin, flexible medium that conducts pulses of light, with each pulse representing a bit. A single optical fiber can support tremendous bit rates, up to ten or even hundreds of gigabits per second. They are immune to electromagnetic interference , have  very low signal attenuation up to 100 kilometers and are very hard to tap. There characteristics have made fiber optics the preferred long-haul guided transmission media, particularly for overseas links. Many of the long-distance telephone networks in the united states and elsewhere now use fiber optics exclusively. However the high cost of optical devices- such as transmitters receivers and switches - has hindered their deployment for short-haul transport, such as in a LAN or into the home in a residential access network.</p><h2 id="Terrestrial-Radio-Channels"><a href="#Terrestrial-Radio-Channels" class="headerlink" title="Terrestrial Radio Channels"></a>Terrestrial Radio Channels</h2><p>Radio channels carry signal in the electromagnetic spectrum. They require no physical wire to be installed can penetrate walls, provide connectivity to mobile user, and can potentially carry a signal for long distances. The characteristics of a radio channel depend on significantly on the propagation environment and the distance over which a signal is to be carried.</p><p>Terrestrial radio channels can be broadly classified into three groups: those that operate over very short distance(e.g : with one or two meters); those that operate in local areas, typically spanning from ten to a few hundred meters; and those that operate in the wide area spanning tens of kilometers. Personal devices such as wireless headsets, keyboards and medical devices over short distances; the wireless LAN technologies use local-area radio channels; the cellular access technologies use wide-area radio channels.</p><h2 id="Satellite-Radio-Channels"><a href="#Satellite-Radio-Channels" class="headerlink" title="Satellite Radio Channels"></a>Satellite Radio Channels</h2><p>A communications satellite links two or more Earth-based microwave transmitter/receivers, known as ground stations. The satellite receives transmissions on one frequency band, regenerates the signal using a repeater and transmits the signal on another frequency. two type of satellite are used in communications: <strong>geostationary satellites and low-earth orbiting(LEO) satellite.</strong></p><p>Geostationary satellites permanently remain above the same spot on Earth. This stationary presence achieve by placing the satellite in orbit at 36000 kilometers above Earth’s surface. This huge distance from ground station through satellite back to ground station introduces a substantial signal propagation delay of 280 milliseconds. Nevertheless, satellite links, which can operate at speed of hundreds of Mbps , are often used in areas without access to DSL or cable-based Internet.</p><p>LEO satellites are placed much closer to Earth and do not remain permanently above one spot on Earth. They rotate around Earth(just as the moon does) and may communicate with each other as well as ground stations. To provide continuous coverage to an area , many satellite need to be place in orbit. there are currently may low- altitude communications system in development. LEO satellite technology may be used for Internet access sometime in the future.</p>]]></content>
    
    
    
    <tags>
      
      <tag>-Computer Network A Top-Down Approach</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>process-switch-base-on-stack-switch</title>
    <link href="/2020/02/16/process-switch-base-on-stack-switch/"/>
    <url>/2020/02/16/process-switch-base-on-stack-switch/</url>
    
    <content type="html"><![CDATA[<h1 id="基于内核栈切换的进程切换"><a href="#基于内核栈切换的进程切换" class="headerlink" title="基于内核栈切换的进程切换"></a>基于内核栈切换的进程切换</h1><h2 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a>实验目的</h2><ul><li>深入理解进程和进程切换的概念；</li><li>综合应用进程、CPU 管理、PCB、LDT、内核栈、内核态等知识解决实际问题；</li><li>开始建立系统认识。</li></ul><h2 id="实验内容"><a href="#实验内容" class="headerlink" title="实验内容"></a>实验内容</h2><p>现在的 Linux 0.11 采用 TSS（后面会有详细论述）和一条指令就能完成任务切换，虽然简单，但这指令的执行时间却很长，在实现任务切换时大概需要 200 多个时钟周期。</p><p>而通过堆栈实现任务切换可能要更快，而且采用堆栈的切换还可以使用指令流水的并行优化技术，同时又使得 CPU 的设计变得简单。所以无论是 Linux 还是 Windows，进程/线程的切换都没有使用 Intel 提供的这种 TSS 切换手段，而都是通过堆栈实现的。</p><p>本次实践项目就是将 Linux 0.11 中采用的 TSS 切换部分去掉，取而代之的是基于堆栈的切换程序。具体的说，就是将 Linux 0.11 中的 <code>switch_to</code> 实现去掉，写成一段基于堆栈切换的代码。</p><p>本次实验包括如下内容：</p><ul><li>编写汇编程序 <code>switch_to</code>：</li><li>完成主体框架；</li><li>在主体框架下依次完成 PCB 切换、内核栈切换、LDT 切换等；</li><li>修改 <code>fork()</code>，由于是基于内核栈的切换，所以进程需要创建出能完成内核栈切换的样子。</li><li>修改 PCB，即 <code>task_struct</code> 结构，增加相应的内容域，同时处理由于修改了 task_struct 所造成的影响。</li><li>用修改后的 Linux 0.11 仍然可以启动、可以正常使用。</li><li>（选做）分析实验 3 的日志体会修改前后系统运行的差别。</li></ul><h2 id="实验报告"><a href="#实验报告" class="headerlink" title="实验报告"></a>实验报告</h2><p>回答下面三个题：</p><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题 1"></a>问题 1</h4><p>针对下面的代码片段：</p><pre><code>movl tss,%ecxaddl $4096,%ebxmovl %ebx,ESP0(%ecx)</code></pre><p>回答问题：</p><ul><li><p>（1）为什么要加 4096；</p><p>答：因为一页内存低地址存进程PCB，高地址是堆栈，linux-0.11 一页内存大小为4Kb,所以+4096。</p></li><li><p>（2）为什么没有设置 tss 中的 ss0。</p><p>答</p></li></ul><h4 id="问题-2"><a href="#问题-2" class="headerlink" title="问题 2"></a>问题 2</h4><p>针对代码片段：</p><pre><code class="lang-c">*(--krnstack) = ebp;*(--krnstack) = ecx;*(--krnstack) = ebx;*(--krnstack) = 0;</code></pre><p>回答问题：</p><ul><li><p>（1）子进程第一次执行时，eax=？为什么要等于这个数？哪里的工作让 eax 等于这样一个数？</p><p>答：子进程第一次执行是eax =0;，为了让代码<code>if (!fork()) &#123;....&#125;</code>区分子进程和父进程。</p></li><li><p>（2）这段代码中的 ebx 和 ecx 来自哪里，是什么含义，为什么要通过这些代码将其写到子进程的内核栈中？</p><p>答：这段代码中的ebx和ecx是栈切换执行switch_to时压入的值，我觉得是为了切换进程时保护现场而压入的，在fork创建新进程（子进程）时添加这些代码进新进程内核栈是为了模拟父进程的内核栈。</p></li><li><p>（3）这段代码中的 ebp 来自哪里，是什么含义，为什么要做这样的设置？可以不设置吗？为什么？</p><p>答：ebp也是来自基于栈切换的switch_to（）时压入的，是当前进程在进行切换时保存当前进程现场的操作，为什么要这样设置呢？因为创建新的子进程当进程切换时需要pop所以这里是为了模拟父进程的内核栈.</p></li></ul><h4 id="问题-3"><a href="#问题-3" class="headerlink" title="问题 3"></a>问题 3</h4><p>为什么要在切换完 LDT 之后要重新设置 fs=0x17？而且为什么重设操作要出现在切换完 LDT 之后，出现在 LDT 之前又会怎么样？</p><p>答：因为需要重新设置fs对应的隐藏寄存器的段基址和段限长，所以需要重设操作，出现在LDT之前则没有任何意义不会有任何改变。</p><h2 id="TSS的切换"><a href="#TSS的切换" class="headerlink" title="TSS的切换"></a>TSS的切换</h2><h3 id="TSS-task-state-segment"><a href="#TSS-task-state-segment" class="headerlink" title="TSS (task state segment)"></a>TSS (task state segment)</h3><p>The <strong>task state segment (TTS)</strong> is a structure on x86-based computers which holds information about a task, it is used by the operating system kernel for task managenment. specifically, the following information is stored in the TSS:</p><ul><li>processor register state</li><li>I/O port permissions</li><li>Inner-lever stack pointers (内部堆栈指针)</li><li>Previous TSS link</li></ul><p>All this information should be stored at specific locations within the TSS as specified in the IA-32 manuals.</p><h3 id="TR-task-register"><a href="#TR-task-register" class="headerlink" title="TR (task register)."></a>TR (task register).</h3><p>The TR register is a 16-bit register which holds a segment selector for the TSS. It may be loaded through the LTR instruction. LTR is a privileged instruction and acts in a manner similar to other segment register loads. The task register has two parts: a portion visible and accessible by the programmer and an invisible one that is automatically loaded from the TSS descriptor.<br></p><p>In the current Linux 0.11,the real completion of the  process switch is accomplished by the task state segment(Task State Segment,TSS for short).</p><p>Specifically, when designing the “Intel architecture”(that is the x86 system structure),</p><p>each task(process or thread) corresponds to an independent TSS. TSS is a  corresponds</p><p>to an independent TSS. TSS is a structure in memory that contains almost all CPU registers Image. There is a Task Register(TR for short) pointing to the TSS structure corresponding to the current process. </p><p>The so-called TSS switch is copies almost all the registers in the CPU(current) to the TSS </p><p>structure pointed  by TR.</p><p>At the same time a target TSS is found ,that is the TSS corresponding to the next process to be switched to, and the register image of TSS structure of next process  stored in CPU.</p><p>In here  the execution site switching  is completed.</p><p>as shown in the figure  blow:</p><p><img src="process-switch-base-on-stack-switch/wm.png" alt=""></p><p>Inter architecture provides the command ljmp to achieve the process switch .</p><p>The specific working process is:</p><ul><li>First, use the segment selector in TR to find the current TSS structure memory location in GDT table.</li><li>second,  the register image of current CPU  store to the TSS structure memory  of finding before.(store the current site !)</li><li>Now, we need to find the target process site and copy the register image of the target   process to the CPU. This just means we need to find TSS of the next process in  GDT table and copy the context of TSS structure memory to CPU.</li><li>when the register image of TSS structure of the target process store in CPU completely, that means achieve switch to target process site, now, the target process becomes the current process. </li><li>Finally , TR should be changed to point to the location of the target TSS segment in the GDT table.<br></li></ul><p>all explain above  through one sentence execute  (ljmp segment selector : intra-segment offset).</p><p>So switch_to (a instruction) base on TSS for process and thread switching is actually a ljmp instruction：</p><pre><code class="lang-assembly">#define switch_to(n) &#123;\struct &#123;long a,b;&#125; __tmp; \__asm__(&quot;cmpl %%ecx,current\n\t&quot; \         &quot;je 1f\n\t&quot; \    &quot;movw %%dx,%1\n\t&quot; \    &quot;xchgl %%ecx,current\n\t&quot; \    &quot;ljmp *%0\n\t&quot; \    &quot;cmpl %%ecx,last_task_used_math\n\t&quot; \    &quot;jne 1f\n\t&quot; \    &quot;clts\n&quot; \    &quot;1:&quot; \    ::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \    &quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \&#125;#define FIRST_TSS_ENTRY 4#define TSS(n) (((unsigned long) n) &lt;&lt; 4) + (FIRST_TSS_ENTRY &lt;&lt; 3))</code></pre><p>Each process is divided into two part which correspond to TSS and LDT, respectively. </p><p>TSS and LDT are both 64-bit(8 bytes).</p><p>so  _TSS(n) = n <em> 16 + 4 </em> 8 (bytes).</p><p><strong>ljmp instruction can be used in two ways, which are “ljmp $ segment selector, $ offset” and “ljmp <em> mem48” respectively. In here “ljmp </em>% 0” used the second way, “ljmp <em> mem48” mean jump to Logical address (48 bits) of the mem48 contain (mem48 also is an address), the hight 16 bits of 48 bits correspond to segment_selector, the low 32 bits of 48 bits correspond to offset. So ,the core of switch_to is ljmp 0 , n\</em>16+4*8  </strong></p><p><strong>!! it is worth out attention:</strong></p><p>The ‘*‘ of the “ljmp <em>mem48” is different from ‘\</em>‘ of C language . The ‘*‘ of the “ljmp *mem48”  is mean indirect jump.</p><h2 id="本次实验的内容"><a href="#本次实验的内容" class="headerlink" title="本次实验的内容"></a>本次实验的内容</h2><p>Although ，the task switching can be completed with one instruction, the execution time of the instruction is very long . It take almost 200 time cycles to complete the task switch using the ljmp instruction. if we want to increase the switching speed ,we can use the heap_stack switch instead of ljmp instruction.</p><p>Moreover. The use of heap_stack switching can also use the parallel optimization technology of instruction pipeline, while making design of the CPU simple.</p><p>Therefore, both Windows and Linux use the heap_stack switching technology to handle process switching.</p><p>Therefore rewriter the code of “switch_to” to  use the heap_stack switch instead of TSS is my task.</p><p>To achieve a process switch base on kernel , we need do three things :</p><ol><li>Rewrite “switch_to”</li><li>Connect the rewritten “switch_to” and schedule() functions together.</li><li>Modify the current fork().</li></ol><h2 id="schedule-与-switch-to"><a href="#schedule-与-switch-to" class="headerlink" title="schedule 与 switch_to"></a>schedule 与 switch_to</h2><h3 id="modify-shcedule"><a href="#modify-shcedule" class="headerlink" title="modify shcedule()"></a>modify shcedule()</h3><p>The task of schedule( ) is finding the position “next” of the next process in the array.  The “next” is equal to “n” of the GDT table(TSS[n]=n*16+4*8).  if we get the “next” in the schedule function, we can use “switch_to (next)” function move to another process.</p><p>Now, we use heap_stack switching instead of TSS switching ,and so we need informations of  current process PCB 、target process PCB、current process kernel stack and target process kernel stack.</p><p> The kernel stack of the Linux 0.11 process and the PCB of process are stored on the same page of memory (a 4kB size page of memory).The PCB is located at the low address of this page of memory ,and the stack is located at the high address of this page of memory.</p><p>In addition, since the PCB of the current process is pointed with a global variable “current”, we  need to tell new switch_to () function a pointer to the target process PCB and we need to tell new switch_to function LDT(next) instead of TSS (next). Just mean ,we don’t need TSS in each process now（we can delete code about TSS），but  also need LDT of  process.</p><p>In summary ,the current schedule() function (in kernel/sched.c) needs to be slightly modified, that is the following code:</p><pre><code class="lang-C">if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)     c = (*p)-&gt;counter, next = i; //......switch_to(next);</code></pre><p>modify:</p><pre><code class="lang-C">if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)     c = (*p)-&gt;counter, next = i, pnext = *p;//.......switch_to(pnext, _LDT(next));</code></pre><h3 id="Rewrite-switch-to"><a href="#Rewrite-switch-to" class="headerlink" title="Rewrite switch_to()"></a>Rewrite switch_to()</h3><p>Rewrite switch_to() function is the most important step in this experiment.</p><p>This function, in turn, completes the following functions:</p><ul><li>first, we need to handle the stack by the assembly language. just handle the ebp register.</li><li>second, we need to compare the parameter of stack about the next process’s PCB with the current process.</li><li>third, we need in turn to complete PCB switch, rewrite kernel stack pointer of TSS, switch kernel stack, switch LDT and switch PC pointer (CS:EIP).</li></ul><pre><code class="lang-assembly">switch_to:    pushl %ebp    movl %esp,%ebp    pushl %ecx    pushl %ebx    pushl %eax    movl 8(%ebp),%ebx    cmpl %ebx,current    je 1f! 切换PCB    ! ...! TSS中的内核栈指针的重写    ! ...! 切换内核栈    ! ...! 切换LDT    ! ...    movl $0x17,%ecx    mov %cx,%fs! 和后面的 clts 配合来处理协处理器，由于和主题关系不大，此处不做论述    cmpl %eax,last_task_used_math     jne 1f    clts1:    popl %eax    popl %ebx    popl %ecx    popl %ebpret</code></pre><p><strong>Switch PCB pointer</strong></p><p>ebx register is next process’s PCB pointer.</p><p>The function of xchgl instruction  is to exchange contents between  two register.</p><pre><code class="lang-assembly">movl %ebx,%eaxxchgl %eax,current</code></pre><p><strong>Rewrite pointer of kernel stack stored in  TSS</strong></p><p>The current TSS is different from TSS before. Before TSS is a global array but current TSS is a global variable. We need to redefine TSS pointer through two sentences.</p><pre><code>#define ESP0 =4struct tss_struct *tss = (init_task.task.tss);</code></pre><p>current TSS pointer <code>tss</code> similar current process pointer <code>current</code>.</p><p>This has already discussed in detail before. In the system interrupt ,we need to find and determine the location of the kernel stack. and push the five register SS : ESP, CS: EIP and EFLAGS in user mode onto kernel stack. This is the key bridge between the user mode (user stack) and kernel mode (kernel stack). The key of find kernel stack position is use the TR register point to current TSS.</p><p>Although we don’t need to use TSS for switch process in now.  We still stay the intel interrupt system. So we still need it that is we define global variable <code>tss</code>. All processes share that variable.</p><pre><code class="lang-assembly">movl tss,%ecxaddl $4096,%ebxmovl %ebx,ESP0(%ecx)</code></pre><p>ESP0 = 4 ,the ecx + ESP0 equal to position of kernel stack pointer in TSS (esp0).</p><pre><code class="lang-C">struct tss_struct &#123;    long    back_link;    /* 16 high bits zero */    long    esp0;    long    ss0;        /* 16 high bits zero */    long    esp1;    long    ss1;        /* 16 high bits zero */    long    esp2;    long    ss2;        /* 16 high bits zero */    long    cr3;    long    eip;    long    eflags;    long    eax,ecx,edx,ebx;    long    esp;    long    ebp;    long    esi;    long    edi;    long    es;        /* 16 high bits zero */    long    cs;        /* 16 high bits zero */    long    ss;        /* 16 high bits zero */    long    ds;        /* 16 high bits zero */    long    fs;        /* 16 high bits zero */    long    gs;        /* 16 high bits zero */    long    ldt;        /* 16 high bits zero */    long    trace_bitmap;    /* bits: trace 0, bitmap 16-31 */    struct i387_struct i387;&#125;;</code></pre><p><strong>switch kernel stack :</strong></p><p>It’s also simple to complete the kernel stack switch. we just need to store value of esp register of the current process  onto the current PCB , and take corresponding esp value of next PCB out and put it into esp register.</p><p>since Linux -0.11  didn’t define the variable of kernel stack pointer in PCB(task_struct). so we need to add a variable <code>kernelstack</code> to Linux-0.11 PCB, we still need define another variable <code>KERNEL_STACK = 12</code>  for determine variable of  <code>kernelstack</code> position in PCB.</p><p><strong>Why KERNEL_STACK equal to 12 ?</strong></p><p>because the kernel code have many  assembly hardcodes about manipulating this structure, so,if we add the variable <code>kernelstack</code> in other position, we need to modify kernel code in many difference place. </p><pre><code class="lang-C">KERNEL_STACK = 12movl %esp,KERNEL_STACK(%eax)    ! 保存上一个进程的栈顶指针! 再取一下 ebx，因为前面修改过 ebx 的值,此时eax的值等于上一个进程的PCB指针movl 8(%ebp),%ebx    movl KERNEL_STACK(%ebx),%esp    ！取下个进程的栈顶指针放入esp</code></pre><p>task_struct:</p><pre><code class="lang-C">// 在 include/linux/sched.h 中struct task_struct &#123;    long state;    long counter;    long priority;    long kernelstack;//......</code></pre><p>because we modify the PCB structure,  we also need to modify initialization code of 0 process PCB structure .Modify <code>#define INIT_TASK &#123; 0,15,15, 0,&#123; &#123; &#125;,&#125;,0,...</code>  to <code>#define INIT_TASK &#123; 0,15,15,PAGE_SIZE+(long)&amp;init_task, 0,&#123; &#123; &#125;,&#125;,0,...</code></p><p><strong>switch LDT</strong></p><pre><code class="lang-assembly">movl 12(%ebp),%ecxlldt %cx!上面使改LDT代码movl $0x17,%ecxmov %cx,%fs</code></pre><p>Why we have to add two code <code>movl $0x17,%ecx</code> <code>mov %cx,%fs</code> behind that code of switch LDT.</p><p>because we need to change the segment base address and segment length limit in the hidden register about fs.</p><p>Examlpe with CS. The hidden register for increase CPU processing speed.</p><p><img src="process-switch-base-on-stack-switch/wm1.png" alt=""></p><p><strong>switch PC （switch to next process）</strong></p><pre><code class="lang-assembly">1:    popl %eax    popl %ebx    popl %ecx    popl %ebpret</code></pre><p><strong>kernel stack  now</strong></p><p><img src="https://img-blog.csdnimg.cn/20190819230403925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTc2MTQ3OA==,size_16,color_FFFFFF,t_70" alt=""></p><p>Execute those codes to turn to the next process,if it isn’t come here through code <code>je 1f</code>. Because we have been changed the kernel stack before. we <code>pop  (eax ,ebx,ecx,ebp)</code> is register of next process.   ret instruction equal to <code>pop IP</code>.So we execute <code>ret</code> turn to schedule() function tail of next process. Now ! we completed the stack switch perfectly.</p><h2 id="modify-fork"><a href="#modify-fork" class="headerlink" title="modify fork()"></a>modify fork()</h2><p><strong>Why we need to modify fork() function ?</strong></p><p><strong>Because, we need to simulate the parent process’s kernel stack for the newly created child process. </strong></p><p>Now, we need to modify the fork() function. it is to associate the process’s user stack, user program to its kernel stack with SS: ESP, CS: IP, which is pushed in the kernel stack.</p><p>In addition, since fork() function-core is let the child process to use code, data, and stack of the parent process . the fork core has not changed, although we use the stack switching.</p><p><img src="process-switch-base-on-stack-switch/wm2.png" alt=""></p><p>Don’t hard to imagine. modify fork which  mean  initialize child process’s kernel stack. In <code>copy_process ()</code>as the core code of <code>fork ()</code>, it used to apply a page of memory as process PCB. The kernel stack address position equal pointer p position add the one page of memory size.  so the code <code>krnstack = (*long)(PAGE_SIZE + (long)p)</code> can find the child process kernel stack position. next step is to initialize the content of krnstack pointer .</p><pre><code class="lang-C">/*modify in fork()*/long *krnstack;p = (struct task_struct *) get_free_page();krnstack = (long)(PAGE_SIZE +(long)p); *(--krnstack) = ss &amp; 0xffff; *(--krnstack) = esp; *(--krnstack) = eflags; *(--krnstack) = cs &amp; 0xffff; *(--krnstack) = eip; *(--krnstack) = ds &amp; 0xffff; *(--krnstack) = es &amp; 0xffff; *(--krnstack) = fs &amp; 0xffff; *(--krnstack) = gs &amp; 0xffff; *(--krnstack) = esi; *(--krnstack) = edi; *(--krnstack) = edx; *(--krnstack) = (long)first_return_from_kernel; *(--krnstack) = ebp; *(--krnstack) = ecx; *(--krnstack) = ebx; *(--krnstack) = 0; p-&gt;kernelstack = krnstack; ......</code></pre><p>Those code for simulate parent kernel stack for child process! </p><p>Make a attention !</p><pre><code class="lang-c">*(--krnstack) = (long)first_return_from_kernel;*(--krnstack) = 0;</code></pre><p>We need to code a first_return_from_kernel as a mark! If we return to address first_return_from_kernel. We need to execute those code following.</p><pre><code class="lang-assembly">/*modify in system_call.s*/.align 2first_return_from_kernel:popl %edxpopl %edipopl %esipop %gspop %fspop %espop %dsiret</code></pre><p>instruction <code>iret</code> equal to </p><pre><code class="lang-assembly">pop eippop cspop eflagspop esppop ss</code></pre><p> instruction <code>*(--krnstack) = 0;</code>  Means eax =0 for distinguish parent process and child process.</p><p><strong>In the end , don’t forget add the two code following to corresponding .c file </strong></p><pre><code class="lang-C">extern void first_return_kernel(void); // in the fork()extern long switch_to(struct task_struct *p , unsigned long _ldt); // in the sched.c</code></pre><h2 id="Modify-step"><a href="#Modify-step" class="headerlink" title="Modify step"></a>Modify step</h2><p><strong>Modify in system_call.s</strong></p><p>Write the switch_to、first_return_from_kernel、etc in the system_call.s**</p><pre><code class="lang-assembly"># Don&#39;t forget to change the hardcode.# Because I forget to change the hardcode , I stayed here so long time.state    = 0        # these are offsets into the task-struct.counter    = 4priority = 8KERNEL_STACK = 12signal    = 16sigaction = 20        # MUST be 16 (=len of sigaction)blocked = (33*16+4)# Define as a global variable，can be used in other file with the keyword extern declaration..globl first_return_from_kernel, switch_to .align 2switch_to:    pushl %ebp    movl %esp, %ebp    pushl %ecx    pushl %ebx    pushl %eax     movl 8(%ebp), %ebx     cmpl %ebx, current     je 1f    movl %ebx, %eax    xchgl %eax, current # eax=old_current, so current=pnext    movl tss, %ecx        # ecx = tss of pnext, it also the new current    addl $4096, %ebx    # ebx=the top of current kernel stack(pnext)    movl %ebx, 4(%ecx)    movl %esp, KERNEL_STACK(%eax)    movl 8(%ebp), %ebx     movl KERNEL_STACK(%ebx), %esp    movl 12(%ebp), %ecx    lldt %cx    movl $0x17, %ecx    mov %cx, %fs    cmpl %eax, last_task_used_math        jne 1f    clts1:  popl %eax    popl %ebx    popl %ecx    popl %ebp    ret.align 2first_return_from_kernel:    popl %edx    popl %edi    popl %esi    pop %gs    pop %fs    pop %es    pop %ds    iret</code></pre><p><strong>Modify sched.h </strong></p><pre><code class="lang-C">struct task_struct &#123;/* these are hardcoded - don&#39;t touch */    long state;    /* -1 unrunnable, 0 runnable, &gt;0 stopped */    long counter;    long priority;    long kernelstack;    long signal;    struct sigaction sigaction[32];    long blocked;    /* bitmap of masked signals */    ......&#125;#define INIT_TASK \/* state etc */    &#123; 0,15,15,PAGE_SIZE+(long)&amp;init_task, \/* signals */    0,&#123;&#123;&#125;,&#125;,0, \................................. /*注释掉#define switch_to(n) &#123;\struct &#123;long a,b;&#125; __tmp; \__asm__(&quot;cmpl %%ecx,current\n\t&quot; \    &quot;je 1f\n\t&quot; \    &quot;movw %%dx,%1\n\t&quot; \    &quot;xchgl %%ecx,current\n\t&quot; \    &quot;ljmp *%0\n\t&quot; \    &quot;cmpl %%ecx,last_task_used_math\n\t&quot; \    &quot;jne 1f\n\t&quot; \    &quot;clts\n&quot; \    &quot;1:&quot; \    ::&quot;m&quot; (*&amp;__tmp.a),&quot;m&quot; (*&amp;__tmp.b), \    &quot;d&quot; (_TSS(n)),&quot;c&quot; ((long) task[n])); \&#125;*/</code></pre><p><strong>Modify sched.c</strong></p><pre><code class="lang-C">extern long switch_to(struct task_struct *p , unsigned long _ldt);struct tss_struct * tss = &amp;(init_task.task.tss);void schedule(void)&#123;    int i,next,c;    struct task_struct ** p;    struct task_struct *pnext = &amp;(init_task.task);/* check alarm, wake up any interruptible tasks that have got a signal */    for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)        if (*p) &#123;            if ((*p)-&gt;alarm &amp;&amp; (*p)-&gt;alarm &lt; jiffies) &#123;                    (*p)-&gt;signal |= (1&lt;&lt;(SIGALRM-1));                    (*p)-&gt;alarm = 0;                &#125;            if (((*p)-&gt;signal &amp; ~(_BLOCKABLE &amp; (*p)-&gt;blocked)) &amp;&amp;            (*p)-&gt;state==TASK_INTERRUPTIBLE)                (*p)-&gt;state=TASK_RUNNING;        &#125;/* this is the scheduler proper: */    while (1) &#123;        c = -1;        next = 0;        i = NR_TASKS;        p = &amp;task[NR_TASKS];        while (--i) &#123;            if (!*--p)                continue;            if ((*p)-&gt;state == TASK_RUNNING &amp;&amp; (*p)-&gt;counter &gt; c)&#123;                c = (*p)-&gt;counter, next = i;                pnext = *p;            &#125;        &#125;        if (c) break;        for(p = &amp;LAST_TASK ; p &gt; &amp;FIRST_TASK ; --p)            if (*p)                (*p)-&gt;counter = ((*p)-&gt;counter &gt;&gt; 1) +                        (*p)-&gt;priority;    &#125;    switch_to(pnext,_LDT(next));&#125;</code></pre><p><strong>Modify fork()</strong></p><pre><code class="lang-C">extern void first_return_kernel(void);  int copy_process(int nr,long ebp,long edi,long esi,long gs,long none,        long ebx,long ecx,long edx,        long fs,long es,long ds,        long eip,long cs,long eflags,long esp,long ss)&#123;    struct task_struct *p;    int i;    struct file *f;    p = (struct task_struct *) get_free_page();    if (!p)        return -EAGAIN;    task[nr] = p;    *p = *current;    /* NOTE! this doesn&#39;t copy the supervisor stack */    p-&gt;state = TASK_UNINTERRUPTIBLE;    p-&gt;pid = last_pid;    p-&gt;father = current-&gt;pid;    p-&gt;counter = p-&gt;priority;    long * krnstack ;    krnstack = (long *) (PAGE_SIZE + (long) p);    *(--krnstack) = ss &amp; 0xffff;    *(--krnstack) = esp;    *(--krnstack) = eflags;    *(--krnstack) = cs &amp; 0xffff;    *(--krnstack) = eip; *(--krnstack) = ds &amp; 0xffff;    *(--krnstack) = es &amp; 0xffff;    *(--krnstack) = fs &amp; 0xffff;  *(--krnstack) = gs &amp; 0xffff;  *(--krnstack) = esi;  *(--krnstack) = edi;     *(--krnstack) = edx;    *(--krnstack) =(long) first_return_kernel;    *(--krnstack) = ebp;    *(--krnstack) = ecx;    *(--krnstack) = ebx;    *(--krnstack) = 0;    p-&gt;kernelstack = krnstack;    p-&gt;signal = 0;    p-&gt;alarm = 0;    p-&gt;leader = 0;        /* process leadership doesn&#39;t inherit */    p-&gt;utime = p-&gt;stime = 0;    p-&gt;cutime = p-&gt;cstime = 0;    p-&gt;start_time = jiffies;    p-&gt;tss.back_link = 0;    p-&gt;tss.esp0 = PAGE_SIZE + (long) p;    p-&gt;tss.ss0 = 0x10;    p-&gt;tss.eip = eip;    p-&gt;tss.eflags = eflags;    p-&gt;tss.eax = 0;    p-&gt;tss.ecx = ecx;    p-&gt;tss.edx = edx;    p-&gt;tss.ebx = ebx;    p-&gt;tss.esp = esp;    p-&gt;tss.ebp = ebp;    p-&gt;tss.esi = esi;    p-&gt;tss.edi = edi;    p-&gt;tss.es = es &amp; 0xffff;    p-&gt;tss.cs = cs &amp; 0xffff;    p-&gt;tss.ss = ss &amp; 0xffff;    p-&gt;tss.ds = ds &amp; 0xffff;    p-&gt;tss.fs = fs &amp; 0xffff;    p-&gt;tss.gs = gs &amp; 0xffff;    p-&gt;tss.ldt = _LDT(nr);    p-&gt;tss.trace_bitmap = 0x80000000;    if (last_task_used_math == current)        __asm__(&quot;clts ; fnsave %0&quot;::&quot;m&quot; (p-&gt;tss.i387));    if (copy_mem(nr,p)) &#123;        task[nr] = NULL;        free_page((long) p);        return -EAGAIN;    &#125;    for (i=0; i&lt;NR_OPEN;i++)        if ((f=p-&gt;filp[i]))            f-&gt;f_count++;    if (current-&gt;pwd)        current-&gt;pwd-&gt;i_count++;    if (current-&gt;root)        current-&gt;root-&gt;i_count++;    if (current-&gt;executable)        current-&gt;executable-&gt;i_count++;    set_tss_desc(gdt+(nr&lt;&lt;1)+FIRST_TSS_ENTRY,&amp;(p-&gt;tss));    set_ldt_desc(gdt+(nr&lt;&lt;1)+FIRST_LDT_ENTRY,&amp;(p-&gt;ldt));    p-&gt;state = TASK_RUNNING;    /* do this last, just in case */    return last_pid;&#125;</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>-操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
